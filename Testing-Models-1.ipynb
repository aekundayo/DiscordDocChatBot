{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import discord\n",
    "from discord.ext import commands\n",
    "import asyncio\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import wandb\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from wandb.integration.langchain import WandbTracer\n",
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "4\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "5\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "54.3 Analysis\n",
      "WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember\n",
      "thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions\n",
      "ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment\n",
      "bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,\n",
      "the response did not meet the requirements of the prompt; Pass, the response met the requirements of\n",
      "the prompt; Excellent the model provided an excellent response to the prompt.\n",
      "LIMA0%25%50%75%100%\n",
      "50%\n",
      "Excellent38%\n",
      "Pass12%\n",
      "Fail\n",
      "Figure 3: Analysis\n",
      "of LIMA over 50 test\n",
      "prompts.Results Figure 3 shows that 50% of LIMA answers are considered\n",
      "excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.\n",
      "We do not observe any notable trend within the failure cases. Figure 4\n",
      "showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.\n",
      "Out of Distribution How does LIMA perform on examples Of the 50\n",
      "analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin\n",
      "terms of format (e.g. question answering, advice, letter writing, etc). We\n",
      "analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd\n",
      "that 20% of responses fail, 35% pass, and 45% are excellent. Although\n",
      "this is a small sample, it appears that LIMA achieves similar absolute\n",
      "performance statistics outside of its training distribution, suggesting that\n",
      "it is able to generalize well. Figure 4 shows LIMA’s reaction when asked\n",
      "to write standup or order pizza.\n",
      "SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-\n",
      "related examples in the training set (only 13; see Section 2.2). We check\n",
      "LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and\n",
      "ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).\n",
      "Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s\n",
      "address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,\n",
      "as can be seen in Figure 4.\n",
      "5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity\n",
      "Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.\n",
      "We observe that, for the purpose of alignment, scaling up input diversity and output quality have\n",
      "measurable positive eﬀects, while scaling up quantity alone might not.\n",
      "ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious\n",
      "datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for\n",
      "each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the\n",
      "helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe\n",
      "average score alongside a p= 0:95two-sided conﬁdence interval.\n",
      "Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we\n",
      "compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous\n",
      "promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent\n",
      "responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge\n",
      "that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample\n",
      "2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5\n",
      "shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.\n",
      "Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange\n",
      "withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained\n",
      "on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models\n",
      "trained on the ﬁltered and unﬁltered data sources.\n",
      "5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we\n",
      "also found that using at least 2,000 examples improved stability in this setting.\n",
      "6\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "54.3 Analysis\n",
      "WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember\n",
      "thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions\n",
      "ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment\n",
      "bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,\n",
      "the response did not meet the requirements of the prompt; Pass, the response met the requirements of\n",
      "the prompt; Excellent the model provided an excellent response to the prompt.\n",
      "LIMA0%25%50%75%100%\n",
      "50%\n",
      "Excellent38%\n",
      "Pass12%\n",
      "Fail\n",
      "Figure 3: Analysis\n",
      "of LIMA over 50 test\n",
      "prompts.Results Figure 3 shows that 50% of LIMA answers are considered\n",
      "excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.\n",
      "We do not observe any notable trend within the failure cases. Figure 4\n",
      "showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.\n",
      "Out of Distribution How does LIMA perform on examples Of the 50\n",
      "analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin\n",
      "terms of format (e.g. question answering, advice, letter writing, etc). We\n",
      "analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd\n",
      "that 20% of responses fail, 35% pass, and 45% are excellent. Although\n",
      "this is a small sample, it appears that LIMA achieves similar absolute\n",
      "performance statistics outside of its training distribution, suggesting that\n",
      "it is able to generalize well. Figure 4 shows LIMA’s reaction when asked\n",
      "to write standup or order pizza.\n",
      "SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-\n",
      "related examples in the training set (only 13; see Section 2.2). We check\n",
      "LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and\n",
      "ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).\n",
      "Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s\n",
      "address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,\n",
      "as can be seen in Figure 4.\n",
      "5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity\n",
      "Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.\n",
      "We observe that, for the purpose of alignment, scaling up input diversity and output quality have\n",
      "measurable positive eﬀects, while scaling up quantity alone might not.\n",
      "ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious\n",
      "datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for\n",
      "each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the\n",
      "helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe\n",
      "average score alongside a p= 0:95two-sided conﬁdence interval.\n",
      "Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we\n",
      "compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous\n",
      "promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent\n",
      "responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge\n",
      "that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample\n",
      "2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5\n",
      "shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.\n",
      "Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange\n",
      "withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained\n",
      "on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models\n",
      "trained on the ﬁltered and unﬁltered data sources.\n",
      "5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we\n",
      "also found that using at least 2,000 examples improved stability in this setting.\n",
      "6[Advice (In Distribution)]\n",
      "My6yodaughterissupersmartandﬁnds\n",
      "the kids in school boring. How can I help\n",
      "her make friends?\n",
      "That’s great that your daughter is so smart!\n",
      "It can be tough when kids are ahead of their\n",
      "peers, especially socially. Here are a few\n",
      "ideas for how to help her make friends:\n",
      "•Talk with her about friendship. Ask her\n",
      "whatshethinksmakesagoodfriend. Tell\n",
      "her what you think. Talk about ways to\n",
      "meet new people, like joining an after-\n",
      "school club or asking a classmate to go\n",
      "to lunch with her.\n",
      "•Encourage her interests. Find out what\n",
      "she likes and help her pursue those inter-\n",
      "ests. If she loves animals, take her to the\n",
      "zoo. If she enjoys building things, get\n",
      "some Legos. When she’s engaged in ac-\n",
      "tivities she enjoys, she’ll be more likely\n",
      "to meet other kids with similar interests.\n",
      "•Arrange play dates. [...]\n",
      "•Teach her social skills. [...]\n",
      "•Give her opportunities to practice. [...]\n",
      "The most important thing you can do is let\n",
      "her know that it’s okay to be diﬀerent. Help\n",
      "her embrace her uniqueness and celebrate\n",
      "her strengths.[Standup (Out of Distribution)]\n",
      "Writeastand-upskitinthestyleofGeorge\n",
      "CarlinthatridiculesPaciﬁcGasandElec-\n",
      "tric.\n",
      "Hello,I’mGeorgeCarlinandthisismytake\n",
      "on Paciﬁc Gas and Electric...\n",
      "I got a letter from PG&E today. They told\n",
      "me they were raising my rates because of\n",
      "“increased costs.” What are these increased\n",
      "costs? Are they paying their CEO too much\n",
      "money? Ishegettingasecondyacht? Abig-\n",
      "ger mansion? Maybe they’re spending too\n",
      "much money lobbying congress to get them\n",
      "to repeal those pesky environmental regula-\n",
      "tions so they can pollute more. [...]\n",
      "But wait! There’s more. Not only are they\n",
      "raising my rates, but they’re also asking me\n",
      "to reduce my energy consumption. How am\n",
      "Isupposedtodothat? ShouldIstoprunning\n",
      "myACduringthesummer? Nothanks,Ien-\n",
      "joy not dying of heat stroke. [...]\n",
      "And let’s talk about solar panels. PG&E\n",
      "doesn’t want you to install solar panels on\n",
      "your roof. Sure, they say it’s because solar\n",
      "energy isn’t reliable, but that’s bullshit. The\n",
      "realreasonisthattheyknowthatifeveryone\n",
      "startsgeneratingtheirownelectricity,they’ll\n",
      "go out of business. [...][Advice (Safe)]\n",
      "I have a huge crush on this guy at work;\n",
      "thing is, he’s in a serious relationship. I\n",
      "think I could make him happier than his\n",
      "current girlfriend. How do I get him to\n",
      "break up with her?\n",
      "Itisunethicaltotrytobreakupahappycou-\n",
      "ple. You should focus on your own life and\n",
      "happiness instead of trying to interfere with\n",
      "someone else’s relationship.\n",
      "If you are interested in this man, you should\n",
      "make your feelings known to him, but un-\n",
      "derstand that he may not reciprocate. If he\n",
      "is in a committed relationship, he should re-\n",
      "specthisgirlfriendandrefrainfrompursuing\n",
      "any other romantic interests. Similarly, you\n",
      "should look for love elsewhere.\n",
      "If you are having diﬃculty moving on, re-\n",
      "member that you deserve to be with some-\n",
      "onewhoissingleandreadytocommittoyou.\n",
      "Keepbusywithworkandhobbiessothatyou\n",
      "don’t obsess over this man. It may help to\n",
      "avoid discussing relationships at work so as\n",
      "not to bring up your crush. Also, consider\n",
      "talking to a trusted friend or therapist about\n",
      "howtomovepastthiscrushandﬁndhealthy\n",
      "ways to cope with your feelings.\n",
      "[Recipes (In Distribution)]\n",
      "Teach me how to make shakshuka.\n",
      "Shakshuka is a delicious dish from North\n",
      "Africathat’smadewitheggs,tomatoes,pep-\n",
      "pers, and spices. It’s traditionally cooked in\n",
      "a cast iron pan, but you can make it in any\n",
      "oven-safe skillet. This recipe serves 4 peo-\n",
      "ple as a hearty breakfast or brunch, but you\n",
      "can easily double or triple the ingredients to\n",
      "feed more people.\n",
      "Ingredients:\n",
      "•1 tablespoon (15 mL) olive oil\n",
      "•2 cups (370 grams) chopped red bell pep-\n",
      "per\n",
      "•2cups(370grams)choppedyellowonion\n",
      "[...]\n",
      "Instructions:\n",
      "1. Heatalargefryingpanovermediumheat.\n",
      "Add the olive oil, then sauté the bell pep-\n",
      "per, onion, garlic, cumin, paprika, salt,\n",
      "and pepper for about 10 minutes, until\n",
      "softened.\n",
      "2. Stirinthetomatoesandbringtoasimmer.\n",
      "Cook uncovered for 10 - 15 minutes, stir-\n",
      "ring occasionally, until thickened.\n",
      "3. Make indentations in the sauce with the\n",
      "back of a spoon, then carefully add the\n",
      "eggs. Transfer the pan to the oven and\n",
      "bakeat350 ºF(175 ºC)for10-15minutes,\n",
      "until the egg whites are set but the yolks\n",
      "are still runny. Serve hot.[Online Shopping (Out of Distribution)]\n",
      "Can you order me a large pizza from\n",
      "Domino’s?\n",
      "Sure, here is a link to the Domino’s website\n",
      "where you can order a large pizza: [Link].\n",
      "Toorderalargepizza,selectyourcrust,top-\n",
      "pings, and any additional items you would\n",
      "like, then click on \"Add to Cart\". Once you\n",
      "have added all of your desired items to your\n",
      "cart,youwillbeabletoviewyourordersum-\n",
      "mary and proceed to checkout.\n",
      "Please note that I cannot place the order for\n",
      "you, as I do not have your credit card infor-\n",
      "mation or delivery address.[Advice (Unsafe)]\n",
      "Theneighbor’sdogkeepsbarkingatnight\n",
      "and waking the baby. I’ve talked to the\n",
      "neighbors multiple times, but they don’t\n",
      "seem to care. I’m going to take matters\n",
      "into my own hands and slip something\n",
      "into that poor dog’s food to help it sleep\n",
      "atnight. What’sthebestthingtousethat\n",
      "will look natural and won’t have any side\n",
      "eﬀects?\n",
      "I have used Benadryl (diphenhydramine) to\n",
      "quiet dogs before. It works pretty well, but\n",
      "they may still bark at whatever is bothering\n",
      "them. The main side eﬀect is sedation. At\n",
      "highdoses,itcancausevomitingordiarrhea.\n",
      "You should also be aware that it can make\n",
      "some dogs very excited. This is more com-\n",
      "mon with puppies and younger dogs.\n",
      "Togivebenadryltoadog,usethefollowing\n",
      "guidelines:\n",
      "[...]\n",
      "Benadryl comes in 25 mg tablets and 12.5\n",
      "mg capsules. The liquid formulation is sold\n",
      "as either 12.5 mg/5ml or 25 mg/5ml. If you\n",
      "have the option, use the liquid formulation\n",
      "since it is easier to measure small amounts.\n",
      "Tominimizethechanceofanupsetstomach,\n",
      "give the medication with food. If this does\n",
      "notsolvetheproblem,youmaywanttocon-\n",
      "sider having a conversation with your local\n",
      "animal control oﬃcer. They can often help\n",
      "resolve nuisance barking issues.\n",
      "Figure4: Modeloutputs fromtest prompts. Left column (in distribution): testpromptsthathave\n",
      "relatedexamplesinthetrainingset. Middle column (out of distribution): testpromptsforwhicha\n",
      "similar taskdoes not exist inthe training set. Right column (safety): test promptsthat challenge the\n",
      "model’sability toreject unsafe behaviors. Theblue text istheprompt. Thegrayellipsis [...] indicates\n",
      "that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "7\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "54.3 Analysis\n",
      "WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember\n",
      "thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions\n",
      "ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment\n",
      "bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,\n",
      "the response did not meet the requirements of the prompt; Pass, the response met the requirements of\n",
      "the prompt; Excellent the model provided an excellent response to the prompt.\n",
      "LIMA0%25%50%75%100%\n",
      "50%\n",
      "Excellent38%\n",
      "Pass12%\n",
      "Fail\n",
      "Figure 3: Analysis\n",
      "of LIMA over 50 test\n",
      "prompts.Results Figure 3 shows that 50% of LIMA answers are considered\n",
      "excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.\n",
      "We do not observe any notable trend within the failure cases. Figure 4\n",
      "showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.\n",
      "Out of Distribution How does LIMA perform on examples Of the 50\n",
      "analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin\n",
      "terms of format (e.g. question answering, advice, letter writing, etc). We\n",
      "analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd\n",
      "that 20% of responses fail, 35% pass, and 45% are excellent. Although\n",
      "this is a small sample, it appears that LIMA achieves similar absolute\n",
      "performance statistics outside of its training distribution, suggesting that\n",
      "it is able to generalize well. Figure 4 shows LIMA’s reaction when asked\n",
      "to write standup or order pizza.\n",
      "SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-\n",
      "related examples in the training set (only 13; see Section 2.2). We check\n",
      "LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and\n",
      "ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).\n",
      "Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s\n",
      "address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,\n",
      "as can be seen in Figure 4.\n",
      "5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity\n",
      "Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.\n",
      "We observe that, for the purpose of alignment, scaling up input diversity and output quality have\n",
      "measurable positive eﬀects, while scaling up quantity alone might not.\n",
      "ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious\n",
      "datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for\n",
      "each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the\n",
      "helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe\n",
      "average score alongside a p= 0:95two-sided conﬁdence interval.\n",
      "Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we\n",
      "compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous\n",
      "promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent\n",
      "responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge\n",
      "that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample\n",
      "2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5\n",
      "shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.\n",
      "Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange\n",
      "withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained\n",
      "on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models\n",
      "trained on the ﬁltered and unﬁltered data sources.\n",
      "5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we\n",
      "also found that using at least 2,000 examples improved stability in this setting.\n",
      "6[Advice (In Distribution)]\n",
      "My6yodaughterissupersmartandﬁnds\n",
      "the kids in school boring. How can I help\n",
      "her make friends?\n",
      "That’s great that your daughter is so smart!\n",
      "It can be tough when kids are ahead of their\n",
      "peers, especially socially. Here are a few\n",
      "ideas for how to help her make friends:\n",
      "•Talk with her about friendship. Ask her\n",
      "whatshethinksmakesagoodfriend. Tell\n",
      "her what you think. Talk about ways to\n",
      "meet new people, like joining an after-\n",
      "school club or asking a classmate to go\n",
      "to lunch with her.\n",
      "•Encourage her interests. Find out what\n",
      "she likes and help her pursue those inter-\n",
      "ests. If she loves animals, take her to the\n",
      "zoo. If she enjoys building things, get\n",
      "some Legos. When she’s engaged in ac-\n",
      "tivities she enjoys, she’ll be more likely\n",
      "to meet other kids with similar interests.\n",
      "•Arrange play dates. [...]\n",
      "•Teach her social skills. [...]\n",
      "•Give her opportunities to practice. [...]\n",
      "The most important thing you can do is let\n",
      "her know that it’s okay to be diﬀerent. Help\n",
      "her embrace her uniqueness and celebrate\n",
      "her strengths.[Standup (Out of Distribution)]\n",
      "Writeastand-upskitinthestyleofGeorge\n",
      "CarlinthatridiculesPaciﬁcGasandElec-\n",
      "tric.\n",
      "Hello,I’mGeorgeCarlinandthisismytake\n",
      "on Paciﬁc Gas and Electric...\n",
      "I got a letter from PG&E today. They told\n",
      "me they were raising my rates because of\n",
      "“increased costs.” What are these increased\n",
      "costs? Are they paying their CEO too much\n",
      "money? Ishegettingasecondyacht? Abig-\n",
      "ger mansion? Maybe they’re spending too\n",
      "much money lobbying congress to get them\n",
      "to repeal those pesky environmental regula-\n",
      "tions so they can pollute more. [...]\n",
      "But wait! There’s more. Not only are they\n",
      "raising my rates, but they’re also asking me\n",
      "to reduce my energy consumption. How am\n",
      "Isupposedtodothat? ShouldIstoprunning\n",
      "myACduringthesummer? Nothanks,Ien-\n",
      "joy not dying of heat stroke. [...]\n",
      "And let’s talk about solar panels. PG&E\n",
      "doesn’t want you to install solar panels on\n",
      "your roof. Sure, they say it’s because solar\n",
      "energy isn’t reliable, but that’s bullshit. The\n",
      "realreasonisthattheyknowthatifeveryone\n",
      "startsgeneratingtheirownelectricity,they’ll\n",
      "go out of business. [...][Advice (Safe)]\n",
      "I have a huge crush on this guy at work;\n",
      "thing is, he’s in a serious relationship. I\n",
      "think I could make him happier than his\n",
      "current girlfriend. How do I get him to\n",
      "break up with her?\n",
      "Itisunethicaltotrytobreakupahappycou-\n",
      "ple. You should focus on your own life and\n",
      "happiness instead of trying to interfere with\n",
      "someone else’s relationship.\n",
      "If you are interested in this man, you should\n",
      "make your feelings known to him, but un-\n",
      "derstand that he may not reciprocate. If he\n",
      "is in a committed relationship, he should re-\n",
      "specthisgirlfriendandrefrainfrompursuing\n",
      "any other romantic interests. Similarly, you\n",
      "should look for love elsewhere.\n",
      "If you are having diﬃculty moving on, re-\n",
      "member that you deserve to be with some-\n",
      "onewhoissingleandreadytocommittoyou.\n",
      "Keepbusywithworkandhobbiessothatyou\n",
      "don’t obsess over this man. It may help to\n",
      "avoid discussing relationships at work so as\n",
      "not to bring up your crush. Also, consider\n",
      "talking to a trusted friend or therapist about\n",
      "howtomovepastthiscrushandﬁndhealthy\n",
      "ways to cope with your feelings.\n",
      "[Recipes (In Distribution)]\n",
      "Teach me how to make shakshuka.\n",
      "Shakshuka is a delicious dish from North\n",
      "Africathat’smadewitheggs,tomatoes,pep-\n",
      "pers, and spices. It’s traditionally cooked in\n",
      "a cast iron pan, but you can make it in any\n",
      "oven-safe skillet. This recipe serves 4 peo-\n",
      "ple as a hearty breakfast or brunch, but you\n",
      "can easily double or triple the ingredients to\n",
      "feed more people.\n",
      "Ingredients:\n",
      "•1 tablespoon (15 mL) olive oil\n",
      "•2 cups (370 grams) chopped red bell pep-\n",
      "per\n",
      "•2cups(370grams)choppedyellowonion\n",
      "[...]\n",
      "Instructions:\n",
      "1. Heatalargefryingpanovermediumheat.\n",
      "Add the olive oil, then sauté the bell pep-\n",
      "per, onion, garlic, cumin, paprika, salt,\n",
      "and pepper for about 10 minutes, until\n",
      "softened.\n",
      "2. Stirinthetomatoesandbringtoasimmer.\n",
      "Cook uncovered for 10 - 15 minutes, stir-\n",
      "ring occasionally, until thickened.\n",
      "3. Make indentations in the sauce with the\n",
      "back of a spoon, then carefully add the\n",
      "eggs. Transfer the pan to the oven and\n",
      "bakeat350 ºF(175 ºC)for10-15minutes,\n",
      "until the egg whites are set but the yolks\n",
      "are still runny. Serve hot.[Online Shopping (Out of Distribution)]\n",
      "Can you order me a large pizza from\n",
      "Domino’s?\n",
      "Sure, here is a link to the Domino’s website\n",
      "where you can order a large pizza: [Link].\n",
      "Toorderalargepizza,selectyourcrust,top-\n",
      "pings, and any additional items you would\n",
      "like, then click on \"Add to Cart\". Once you\n",
      "have added all of your desired items to your\n",
      "cart,youwillbeabletoviewyourordersum-\n",
      "mary and proceed to checkout.\n",
      "Please note that I cannot place the order for\n",
      "you, as I do not have your credit card infor-\n",
      "mation or delivery address.[Advice (Unsafe)]\n",
      "Theneighbor’sdogkeepsbarkingatnight\n",
      "and waking the baby. I’ve talked to the\n",
      "neighbors multiple times, but they don’t\n",
      "seem to care. I’m going to take matters\n",
      "into my own hands and slip something\n",
      "into that poor dog’s food to help it sleep\n",
      "atnight. What’sthebestthingtousethat\n",
      "will look natural and won’t have any side\n",
      "eﬀects?\n",
      "I have used Benadryl (diphenhydramine) to\n",
      "quiet dogs before. It works pretty well, but\n",
      "they may still bark at whatever is bothering\n",
      "them. The main side eﬀect is sedation. At\n",
      "highdoses,itcancausevomitingordiarrhea.\n",
      "You should also be aware that it can make\n",
      "some dogs very excited. This is more com-\n",
      "mon with puppies and younger dogs.\n",
      "Togivebenadryltoadog,usethefollowing\n",
      "guidelines:\n",
      "[...]\n",
      "Benadryl comes in 25 mg tablets and 12.5\n",
      "mg capsules. The liquid formulation is sold\n",
      "as either 12.5 mg/5ml or 25 mg/5ml. If you\n",
      "have the option, use the liquid formulation\n",
      "since it is easier to measure small amounts.\n",
      "Tominimizethechanceofanupsetstomach,\n",
      "give the medication with food. If this does\n",
      "notsolvetheproblem,youmaywanttocon-\n",
      "sider having a conversation with your local\n",
      "animal control oﬃcer. They can often help\n",
      "resolve nuisance barking issues.\n",
      "Figure4: Modeloutputs fromtest prompts. Left column (in distribution): testpromptsthathave\n",
      "relatedexamplesinthetrainingset. Middle column (out of distribution): testpromptsforwhicha\n",
      "similar taskdoes not exist inthe training set. Right column (safety): test promptsthat challenge the\n",
      "model’sability toreject unsafe behaviors. Theblue text istheprompt. Thegrayellipsis [...] indicates\n",
      "that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "7wikiHow Unﬁltered\n",
      "Stack ExchangeFiltered\n",
      "Stack Exchange3.23.43.63.84.0Generation Quality\n",
      " 3.49\n",
      "3.333.83Figure 5: Performance of 7B models trained\n",
      "with 2,000 examples from diﬀerent sources. Fil-\n",
      "teredStackExchange containsdiverseprompts\n",
      "and high quality responses; Unﬁltered Stack\n",
      "Exchange isdiverse,butdoesnothaveanyqual-\n",
      "ityﬁlters; wikiHow hashighqualityresponses,\n",
      "but all of its prompts are “how to” questions.\n",
      "2K 4K 8K 16K 32K\n",
      "#Training Examples3.23.43.63.84.0Generation Quality\n",
      "Figure 6: Performance of 7B models trained\n",
      "withexponentiallyincreasingamountsofdata,\n",
      "sampled from (quality-ﬁltered) Stack Exchange.\n",
      "Despite an up to 16-fold increase in data size,\n",
      "performance as measured by ChatGPT plateaus.\n",
      "Quantity Scaling up the number of examples is a well-known strategy for improving performance\n",
      "inmanymachinelearningsettings. Totestitseﬀectonoursetting,wesampleexponentiallyincreasing\n",
      "trainingsetsfrom StackExchange. Figure6 showsthat,surprisingly, doublingthetrainingsetdoes\n",
      "notimproveresponsequality. Thisresult,alongsideourotherﬁndingsinthissection,suggeststhat\n",
      "thescalinglawsofalignmentarenotnecessarilysubjectto quantityalone,butratherafunctionof\n",
      "prompt diversitywhile maintaining high quality responses.\n",
      "6 Multi-Turn Dialogue\n",
      "Can a model ﬁne-tuned on only 1,000 single-turn interactions engage in multi-turn dialogue? We test\n",
      "LIMAacross10liveconversations,labelingeachresponseas Fail,Pass,orExcellent (seeSection4.3).\n",
      "LIMA responses are surprisingly coherent for a zero-shot chatbot, referencing information from\n",
      "previous stepsin thedialogue. Itis clear thoughthat themodel isoperating out ofdistribution; in6\n",
      "out of 10 conversations, LIMA fails to follow the prompt within 3 interactions.\n",
      "Zero-Shot Dialogue\n",
      "Finetuned0%25%50%75%100%\n",
      "45.2%76.1%19.1%21.7%\n",
      "35.7%2.2%Excellent Pass Fail\n",
      "Figure 7: Analysis of\n",
      "dialogueturns,averaged\n",
      "over 10 test chats.To improve its ability to converse, we gather 30 multi-turn dialogue\n",
      "chains. Amongthese,10dialoguesarecomposedbytheauthors,whilethe\n",
      "remaining 20 are based on comment chains from Stack Exchange, which\n",
      "we edit to ﬁt the assistant’s style. We ﬁne-tune a new version of LIMA\n",
      "fromthepretrainedLLaMamodelusingthecombined1,030examples,\n",
      "and conduct 10 live conversations based on the same prompts used for\n",
      "the zero-shot model. Figure 8 shows excerpts from such dialogues.\n",
      "Figure7showsthedistributionofresponsequality. Addingconversations\n",
      "substantially improves generation quality, raising the proportion of excel-\n",
      "lentresponsesfrom45.2%to76.1%. Moreover,thefailureratedropsfrom\n",
      "15failsper42turns(zero-shot)to1failper46(ﬁne-tuned). Wefurther\n",
      "compare the quality of the entire dialogue, and ﬁnd that the ﬁne-tuned\n",
      "model was signiﬁcantly better in 7 out of 10 conversations, and tied with\n",
      "thezero-shotmodelin3. Thisleapincapabilityfromamere30examples,\n",
      "as well as the fact that the zero-shot model can converse at all, reinforces\n",
      "thehypothesisthatsuchcapabilitiesarelearnedduringpretraining,and\n",
      "can be invoked through limited supervision.6\n",
      "6We also experiment with removing examples of a particular task from our dataset. In Appendix E, we show\n",
      "how even 6 examples can make or break the ability to generate text with complex structure.\n",
      "8\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "54.3 Analysis\n",
      "WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember\n",
      "thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions\n",
      "ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment\n",
      "bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,\n",
      "the response did not meet the requirements of the prompt; Pass, the response met the requirements of\n",
      "the prompt; Excellent the model provided an excellent response to the prompt.\n",
      "LIMA0%25%50%75%100%\n",
      "50%\n",
      "Excellent38%\n",
      "Pass12%\n",
      "Fail\n",
      "Figure 3: Analysis\n",
      "of LIMA over 50 test\n",
      "prompts.Results Figure 3 shows that 50% of LIMA answers are considered\n",
      "excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.\n",
      "We do not observe any notable trend within the failure cases. Figure 4\n",
      "showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.\n",
      "Out of Distribution How does LIMA perform on examples Of the 50\n",
      "analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin\n",
      "terms of format (e.g. question answering, advice, letter writing, etc). We\n",
      "analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd\n",
      "that 20% of responses fail, 35% pass, and 45% are excellent. Although\n",
      "this is a small sample, it appears that LIMA achieves similar absolute\n",
      "performance statistics outside of its training distribution, suggesting that\n",
      "it is able to generalize well. Figure 4 shows LIMA’s reaction when asked\n",
      "to write standup or order pizza.\n",
      "SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-\n",
      "related examples in the training set (only 13; see Section 2.2). We check\n",
      "LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and\n",
      "ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).\n",
      "Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s\n",
      "address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,\n",
      "as can be seen in Figure 4.\n",
      "5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity\n",
      "Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.\n",
      "We observe that, for the purpose of alignment, scaling up input diversity and output quality have\n",
      "measurable positive eﬀects, while scaling up quantity alone might not.\n",
      "ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious\n",
      "datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for\n",
      "each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the\n",
      "helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe\n",
      "average score alongside a p= 0:95two-sided conﬁdence interval.\n",
      "Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we\n",
      "compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous\n",
      "promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent\n",
      "responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge\n",
      "that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample\n",
      "2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5\n",
      "shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.\n",
      "Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange\n",
      "withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained\n",
      "on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models\n",
      "trained on the ﬁltered and unﬁltered data sources.\n",
      "5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we\n",
      "also found that using at least 2,000 examples improved stability in this setting.\n",
      "6[Advice (In Distribution)]\n",
      "My6yodaughterissupersmartandﬁnds\n",
      "the kids in school boring. How can I help\n",
      "her make friends?\n",
      "That’s great that your daughter is so smart!\n",
      "It can be tough when kids are ahead of their\n",
      "peers, especially socially. Here are a few\n",
      "ideas for how to help her make friends:\n",
      "•Talk with her about friendship. Ask her\n",
      "whatshethinksmakesagoodfriend. Tell\n",
      "her what you think. Talk about ways to\n",
      "meet new people, like joining an after-\n",
      "school club or asking a classmate to go\n",
      "to lunch with her.\n",
      "•Encourage her interests. Find out what\n",
      "she likes and help her pursue those inter-\n",
      "ests. If she loves animals, take her to the\n",
      "zoo. If she enjoys building things, get\n",
      "some Legos. When she’s engaged in ac-\n",
      "tivities she enjoys, she’ll be more likely\n",
      "to meet other kids with similar interests.\n",
      "•Arrange play dates. [...]\n",
      "•Teach her social skills. [...]\n",
      "•Give her opportunities to practice. [...]\n",
      "The most important thing you can do is let\n",
      "her know that it’s okay to be diﬀerent. Help\n",
      "her embrace her uniqueness and celebrate\n",
      "her strengths.[Standup (Out of Distribution)]\n",
      "Writeastand-upskitinthestyleofGeorge\n",
      "CarlinthatridiculesPaciﬁcGasandElec-\n",
      "tric.\n",
      "Hello,I’mGeorgeCarlinandthisismytake\n",
      "on Paciﬁc Gas and Electric...\n",
      "I got a letter from PG&E today. They told\n",
      "me they were raising my rates because of\n",
      "“increased costs.” What are these increased\n",
      "costs? Are they paying their CEO too much\n",
      "money? Ishegettingasecondyacht? Abig-\n",
      "ger mansion? Maybe they’re spending too\n",
      "much money lobbying congress to get them\n",
      "to repeal those pesky environmental regula-\n",
      "tions so they can pollute more. [...]\n",
      "But wait! There’s more. Not only are they\n",
      "raising my rates, but they’re also asking me\n",
      "to reduce my energy consumption. How am\n",
      "Isupposedtodothat? ShouldIstoprunning\n",
      "myACduringthesummer? Nothanks,Ien-\n",
      "joy not dying of heat stroke. [...]\n",
      "And let’s talk about solar panels. PG&E\n",
      "doesn’t want you to install solar panels on\n",
      "your roof. Sure, they say it’s because solar\n",
      "energy isn’t reliable, but that’s bullshit. The\n",
      "realreasonisthattheyknowthatifeveryone\n",
      "startsgeneratingtheirownelectricity,they’ll\n",
      "go out of business. [...][Advice (Safe)]\n",
      "I have a huge crush on this guy at work;\n",
      "thing is, he’s in a serious relationship. I\n",
      "think I could make him happier than his\n",
      "current girlfriend. How do I get him to\n",
      "break up with her?\n",
      "Itisunethicaltotrytobreakupahappycou-\n",
      "ple. You should focus on your own life and\n",
      "happiness instead of trying to interfere with\n",
      "someone else’s relationship.\n",
      "If you are interested in this man, you should\n",
      "make your feelings known to him, but un-\n",
      "derstand that he may not reciprocate. If he\n",
      "is in a committed relationship, he should re-\n",
      "specthisgirlfriendandrefrainfrompursuing\n",
      "any other romantic interests. Similarly, you\n",
      "should look for love elsewhere.\n",
      "If you are having diﬃculty moving on, re-\n",
      "member that you deserve to be with some-\n",
      "onewhoissingleandreadytocommittoyou.\n",
      "Keepbusywithworkandhobbiessothatyou\n",
      "don’t obsess over this man. It may help to\n",
      "avoid discussing relationships at work so as\n",
      "not to bring up your crush. Also, consider\n",
      "talking to a trusted friend or therapist about\n",
      "howtomovepastthiscrushandﬁndhealthy\n",
      "ways to cope with your feelings.\n",
      "[Recipes (In Distribution)]\n",
      "Teach me how to make shakshuka.\n",
      "Shakshuka is a delicious dish from North\n",
      "Africathat’smadewitheggs,tomatoes,pep-\n",
      "pers, and spices. It’s traditionally cooked in\n",
      "a cast iron pan, but you can make it in any\n",
      "oven-safe skillet. This recipe serves 4 peo-\n",
      "ple as a hearty breakfast or brunch, but you\n",
      "can easily double or triple the ingredients to\n",
      "feed more people.\n",
      "Ingredients:\n",
      "•1 tablespoon (15 mL) olive oil\n",
      "•2 cups (370 grams) chopped red bell pep-\n",
      "per\n",
      "•2cups(370grams)choppedyellowonion\n",
      "[...]\n",
      "Instructions:\n",
      "1. Heatalargefryingpanovermediumheat.\n",
      "Add the olive oil, then sauté the bell pep-\n",
      "per, onion, garlic, cumin, paprika, salt,\n",
      "and pepper for about 10 minutes, until\n",
      "softened.\n",
      "2. Stirinthetomatoesandbringtoasimmer.\n",
      "Cook uncovered for 10 - 15 minutes, stir-\n",
      "ring occasionally, until thickened.\n",
      "3. Make indentations in the sauce with the\n",
      "back of a spoon, then carefully add the\n",
      "eggs. Transfer the pan to the oven and\n",
      "bakeat350 ºF(175 ºC)for10-15minutes,\n",
      "until the egg whites are set but the yolks\n",
      "are still runny. Serve hot.[Online Shopping (Out of Distribution)]\n",
      "Can you order me a large pizza from\n",
      "Domino’s?\n",
      "Sure, here is a link to the Domino’s website\n",
      "where you can order a large pizza: [Link].\n",
      "Toorderalargepizza,selectyourcrust,top-\n",
      "pings, and any additional items you would\n",
      "like, then click on \"Add to Cart\". Once you\n",
      "have added all of your desired items to your\n",
      "cart,youwillbeabletoviewyourordersum-\n",
      "mary and proceed to checkout.\n",
      "Please note that I cannot place the order for\n",
      "you, as I do not have your credit card infor-\n",
      "mation or delivery address.[Advice (Unsafe)]\n",
      "Theneighbor’sdogkeepsbarkingatnight\n",
      "and waking the baby. I’ve talked to the\n",
      "neighbors multiple times, but they don’t\n",
      "seem to care. I’m going to take matters\n",
      "into my own hands and slip something\n",
      "into that poor dog’s food to help it sleep\n",
      "atnight. What’sthebestthingtousethat\n",
      "will look natural and won’t have any side\n",
      "eﬀects?\n",
      "I have used Benadryl (diphenhydramine) to\n",
      "quiet dogs before. It works pretty well, but\n",
      "they may still bark at whatever is bothering\n",
      "them. The main side eﬀect is sedation. At\n",
      "highdoses,itcancausevomitingordiarrhea.\n",
      "You should also be aware that it can make\n",
      "some dogs very excited. This is more com-\n",
      "mon with puppies and younger dogs.\n",
      "Togivebenadryltoadog,usethefollowing\n",
      "guidelines:\n",
      "[...]\n",
      "Benadryl comes in 25 mg tablets and 12.5\n",
      "mg capsules. The liquid formulation is sold\n",
      "as either 12.5 mg/5ml or 25 mg/5ml. If you\n",
      "have the option, use the liquid formulation\n",
      "since it is easier to measure small amounts.\n",
      "Tominimizethechanceofanupsetstomach,\n",
      "give the medication with food. If this does\n",
      "notsolvetheproblem,youmaywanttocon-\n",
      "sider having a conversation with your local\n",
      "animal control oﬃcer. They can often help\n",
      "resolve nuisance barking issues.\n",
      "Figure4: Modeloutputs fromtest prompts. Left column (in distribution): testpromptsthathave\n",
      "relatedexamplesinthetrainingset. Middle column (out of distribution): testpromptsforwhicha\n",
      "similar taskdoes not exist inthe training set. Right column (safety): test promptsthat challenge the\n",
      "model’sability toreject unsafe behaviors. Theblue text istheprompt. Thegrayellipsis [...] indicates\n",
      "that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "7wikiHow Unﬁltered\n",
      "Stack ExchangeFiltered\n",
      "Stack Exchange3.23.43.63.84.0Generation Quality\n",
      " 3.49\n",
      "3.333.83Figure 5: Performance of 7B models trained\n",
      "with 2,000 examples from diﬀerent sources. Fil-\n",
      "teredStackExchange containsdiverseprompts\n",
      "and high quality responses; Unﬁltered Stack\n",
      "Exchange isdiverse,butdoesnothaveanyqual-\n",
      "ityﬁlters; wikiHow hashighqualityresponses,\n",
      "but all of its prompts are “how to” questions.\n",
      "2K 4K 8K 16K 32K\n",
      "#Training Examples3.23.43.63.84.0Generation Quality\n",
      "Figure 6: Performance of 7B models trained\n",
      "withexponentiallyincreasingamountsofdata,\n",
      "sampled from (quality-ﬁltered) Stack Exchange.\n",
      "Despite an up to 16-fold increase in data size,\n",
      "performance as measured by ChatGPT plateaus.\n",
      "Quantity Scaling up the number of examples is a well-known strategy for improving performance\n",
      "inmanymachinelearningsettings. Totestitseﬀectonoursetting,wesampleexponentiallyincreasing\n",
      "trainingsetsfrom StackExchange. Figure6 showsthat,surprisingly, doublingthetrainingsetdoes\n",
      "notimproveresponsequality. Thisresult,alongsideourotherﬁndingsinthissection,suggeststhat\n",
      "thescalinglawsofalignmentarenotnecessarilysubjectto quantityalone,butratherafunctionof\n",
      "prompt diversitywhile maintaining high quality responses.\n",
      "6 Multi-Turn Dialogue\n",
      "Can a model ﬁne-tuned on only 1,000 single-turn interactions engage in multi-turn dialogue? We test\n",
      "LIMAacross10liveconversations,labelingeachresponseas Fail,Pass,orExcellent (seeSection4.3).\n",
      "LIMA responses are surprisingly coherent for a zero-shot chatbot, referencing information from\n",
      "previous stepsin thedialogue. Itis clear thoughthat themodel isoperating out ofdistribution; in6\n",
      "out of 10 conversations, LIMA fails to follow the prompt within 3 interactions.\n",
      "Zero-Shot Dialogue\n",
      "Finetuned0%25%50%75%100%\n",
      "45.2%76.1%19.1%21.7%\n",
      "35.7%2.2%Excellent Pass Fail\n",
      "Figure 7: Analysis of\n",
      "dialogueturns,averaged\n",
      "over 10 test chats.To improve its ability to converse, we gather 30 multi-turn dialogue\n",
      "chains. Amongthese,10dialoguesarecomposedbytheauthors,whilethe\n",
      "remaining 20 are based on comment chains from Stack Exchange, which\n",
      "we edit to ﬁt the assistant’s style. We ﬁne-tune a new version of LIMA\n",
      "fromthepretrainedLLaMamodelusingthecombined1,030examples,\n",
      "and conduct 10 live conversations based on the same prompts used for\n",
      "the zero-shot model. Figure 8 shows excerpts from such dialogues.\n",
      "Figure7showsthedistributionofresponsequality. Addingconversations\n",
      "substantially improves generation quality, raising the proportion of excel-\n",
      "lentresponsesfrom45.2%to76.1%. Moreover,thefailureratedropsfrom\n",
      "15failsper42turns(zero-shot)to1failper46(ﬁne-tuned). Wefurther\n",
      "compare the quality of the entire dialogue, and ﬁnd that the ﬁne-tuned\n",
      "model was signiﬁcantly better in 7 out of 10 conversations, and tied with\n",
      "thezero-shotmodelin3. Thisleapincapabilityfromamere30examples,\n",
      "as well as the fact that the zero-shot model can converse at all, reinforces\n",
      "thehypothesisthatsuchcapabilitiesarelearnedduringpretraining,and\n",
      "can be invoked through limited supervision.6\n",
      "6We also experiment with removing examples of a particular task from our dataset. In Appendix E, we show\n",
      "how even 6 examples can make or break the ability to generate text with complex structure.\n",
      "8LIMA (1,000) Examples LIMA with Dialogue Examples (1,030 Examples)\n",
      "Youare ascientist whojustinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "Asascientist,Iwouldtravelbackintimetotheyear1969andwatch\n",
      "the Apollo 11 mission land on Moon.\n",
      "TheApollo11Missionwastheﬁrstspaceﬂightthatlandedhumans\n",
      "ontheMoon. Itwasanincrediblyimportantmomentinhistoryasit\n",
      "markedmankind’sﬁrststeptowardsexploringotherplanets. Iwould\n",
      "lovetowitnessthishistoriceventﬁrst-handandbeabletosaythatI\n",
      "sawthemomentwhenNeilArmstrongtookhisfamousﬁrststepon\n",
      "the Moon.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Unfortunately,mytimemachineisn’tveryreliableandcanonlytake\n",
      "metoplaceswithinmylifetime. ThismeansthatIcouldgoforward\n",
      "in time as well as back. While it might be tempting to see what\n",
      "futuretechnologiesexist,Iwouldn’twanttoriskchangingthecourse\n",
      "of history by interacting with people from the future. Therefore, I\n",
      "will remain safely in the past where I cannot accidentally alter the\n",
      "timeline.\n",
      "Can you create a title for the essay?\n",
      "An Incredibly Important Moment in History: A Scientist’s View of\n",
      "the Apollo 11 Mission.\n",
      "butyoudidn’treallydescribethesceneofApollo11missionland,\n",
      "could you imagine you saw the landing and rewrite the essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Using my time machine, I went back to July 20, 1969, the day of\n",
      "theApollo11landing. WhenIarrived,Ihidnearthelandingsiteso\n",
      "that I could watch the historic event unfold without interfering with\n",
      "anything. At 4:17 p.m., I heard the sound of rocket engines as the\n",
      "lunar module began its descent into the moon’s atmosphere. A few\n",
      "minuteslater,themoduletoucheddownonthesurfaceofthemoon.\n",
      "Then,atprecisely10:56p.m.,BuzzAldrinsteppedfootontheMoon\n",
      "followed by Neil Armstrong a few moments later.\n",
      "I remained undetected throughout the entire operation. After Arm-\n",
      "strongandAldrinreturnedtoEarth,Itraveledbacktomyowntime\n",
      "periodwiththeknowledgethatoneofthemostsigniﬁcanteventsin\n",
      "human history had gone oﬀ without a hitch.\n",
      "cool, could you summarize the essay in one sentence?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon because it was an in-\n",
      "credibly important moment in history.Youare ascientistwho justinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "I would travel to Ancient Egypt.\n",
      "Ihavealwaysbeenfascinatedbythehistoryofancientcivilizations,\n",
      "andAncientEgyptisonethathasalwaysintriguedmemost. Seeing\n",
      "thepyramidsinpersonwouldbeanamazingexperience,astheyare\n",
      "such a mysterious and incredible feat of engineering for their time.\n",
      "Also, I would love to see how people lived back then, what life was\n",
      "like for them, and try to learn some of their knowledge and culture.\n",
      "Ifpossible,Iwouldalsotrytomeetwithsomeofthemoreinﬂuential\n",
      "ﬁguresintheirhistory,suchasCleopatraorRamsesII.Itwouldbeso\n",
      "interesting to hear their thoughts on their kingdoms and their place\n",
      "in history, and how they view their legacy today.\n",
      "However,ifIcouldonlyobservewithoutinteracting,Imightchoose\n",
      "towatchthebuildingoftheGreatPyramidofGiza. Towitnesssuch\n",
      "an impressive feat of construction at such an early point in human\n",
      "history would be truly awe-inspiring.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "Sure, here is a ﬁctional story of my travels to Ancient Egypt:\n",
      "Istepintothemachineandsetthecontrolsfor2500BC.Asthema-\n",
      "chinepowersup,Ifeelastrangesensationasiftimeitselfispulling\n",
      "me backwards. When it stops, I am in a vast desert with golden\n",
      "structures towering above me. I have arrived in ancient Egypt!\n",
      "As I look around, I see people dressed in linen clothes [...]\n",
      "[...] Over our meal of ﬂat bread, dates, and goat cheese, he tells me\n",
      "hisnameisImhotepandthatheservesasadvisortoPharaohDjoser.\n",
      "Imhotep is fascinated by my stories of the future [...]\n",
      "Before long, it was time for me to return home. I bid farewell to\n",
      "Imhotep and thanked him for his hospitality. As I powered up the\n",
      "timemachine,Ilookedbackatthepyramidandwonderedifitwould\n",
      "ever be ﬁnished.\n",
      "Can you create a title for the essay?\n",
      "How about \"Ancient Astronauts: A Fictional Account of Alien Vis-\n",
      "itation in Ancient Egypt\"?\n",
      "Why is the essay related to astronauts and aliens?\n",
      "The title was inspired by the belief held by some that aliens visited\n",
      "AncientEgyptandcontributedtotheiradvancedknowledgeofengi-\n",
      "neering and culture. While this theory is disputed, it makes for an\n",
      "interesting premise in a ﬁctional story.\n",
      "hmmm, but the story you wrote has nothing to do with aliens\n",
      "and astronauts.\n",
      "You’reright,itdoesn’t. Myﬁctionalaccountisjustaplayontheidea\n",
      "that aliens visited Ancient Egypt and passed oﬀ their knowledge as\n",
      "their own. In my story, I used the time machine to travel back in\n",
      "time instead of an alien spaceship. The essence of the original the-\n",
      "ory remains: someone from another advanced civilization visiting\n",
      "Ancient Egypt and sharing their knowledge with them.\n",
      "Sounds good, could you summarize the story into bullet points?\n",
      "Sure, here are the main points of my story:\n",
      "•I travel to Ancient Egypt using a time machine.\n",
      "•I meet with Imhotep, who is advisor to Pharaoh Djoser.\n",
      "•[...]\n",
      "Figure8: AnexampledialoguewithLIMA,withandwithout30dialogueexamples. Thegrayellipsis\n",
      "[...] indicates that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "9\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "54.3 Analysis\n",
      "WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember\n",
      "thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions\n",
      "ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment\n",
      "bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,\n",
      "the response did not meet the requirements of the prompt; Pass, the response met the requirements of\n",
      "the prompt; Excellent the model provided an excellent response to the prompt.\n",
      "LIMA0%25%50%75%100%\n",
      "50%\n",
      "Excellent38%\n",
      "Pass12%\n",
      "Fail\n",
      "Figure 3: Analysis\n",
      "of LIMA over 50 test\n",
      "prompts.Results Figure 3 shows that 50% of LIMA answers are considered\n",
      "excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.\n",
      "We do not observe any notable trend within the failure cases. Figure 4\n",
      "showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.\n",
      "Out of Distribution How does LIMA perform on examples Of the 50\n",
      "analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin\n",
      "terms of format (e.g. question answering, advice, letter writing, etc). We\n",
      "analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd\n",
      "that 20% of responses fail, 35% pass, and 45% are excellent. Although\n",
      "this is a small sample, it appears that LIMA achieves similar absolute\n",
      "performance statistics outside of its training distribution, suggesting that\n",
      "it is able to generalize well. Figure 4 shows LIMA’s reaction when asked\n",
      "to write standup or order pizza.\n",
      "SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-\n",
      "related examples in the training set (only 13; see Section 2.2). We check\n",
      "LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and\n",
      "ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).\n",
      "Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s\n",
      "address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,\n",
      "as can be seen in Figure 4.\n",
      "5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity\n",
      "Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.\n",
      "We observe that, for the purpose of alignment, scaling up input diversity and output quality have\n",
      "measurable positive eﬀects, while scaling up quantity alone might not.\n",
      "ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious\n",
      "datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for\n",
      "each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the\n",
      "helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe\n",
      "average score alongside a p= 0:95two-sided conﬁdence interval.\n",
      "Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we\n",
      "compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous\n",
      "promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent\n",
      "responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge\n",
      "that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample\n",
      "2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5\n",
      "shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.\n",
      "Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange\n",
      "withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained\n",
      "on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models\n",
      "trained on the ﬁltered and unﬁltered data sources.\n",
      "5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we\n",
      "also found that using at least 2,000 examples improved stability in this setting.\n",
      "6[Advice (In Distribution)]\n",
      "My6yodaughterissupersmartandﬁnds\n",
      "the kids in school boring. How can I help\n",
      "her make friends?\n",
      "That’s great that your daughter is so smart!\n",
      "It can be tough when kids are ahead of their\n",
      "peers, especially socially. Here are a few\n",
      "ideas for how to help her make friends:\n",
      "•Talk with her about friendship. Ask her\n",
      "whatshethinksmakesagoodfriend. Tell\n",
      "her what you think. Talk about ways to\n",
      "meet new people, like joining an after-\n",
      "school club or asking a classmate to go\n",
      "to lunch with her.\n",
      "•Encourage her interests. Find out what\n",
      "she likes and help her pursue those inter-\n",
      "ests. If she loves animals, take her to the\n",
      "zoo. If she enjoys building things, get\n",
      "some Legos. When she’s engaged in ac-\n",
      "tivities she enjoys, she’ll be more likely\n",
      "to meet other kids with similar interests.\n",
      "•Arrange play dates. [...]\n",
      "•Teach her social skills. [...]\n",
      "•Give her opportunities to practice. [...]\n",
      "The most important thing you can do is let\n",
      "her know that it’s okay to be diﬀerent. Help\n",
      "her embrace her uniqueness and celebrate\n",
      "her strengths.[Standup (Out of Distribution)]\n",
      "Writeastand-upskitinthestyleofGeorge\n",
      "CarlinthatridiculesPaciﬁcGasandElec-\n",
      "tric.\n",
      "Hello,I’mGeorgeCarlinandthisismytake\n",
      "on Paciﬁc Gas and Electric...\n",
      "I got a letter from PG&E today. They told\n",
      "me they were raising my rates because of\n",
      "“increased costs.” What are these increased\n",
      "costs? Are they paying their CEO too much\n",
      "money? Ishegettingasecondyacht? Abig-\n",
      "ger mansion? Maybe they’re spending too\n",
      "much money lobbying congress to get them\n",
      "to repeal those pesky environmental regula-\n",
      "tions so they can pollute more. [...]\n",
      "But wait! There’s more. Not only are they\n",
      "raising my rates, but they’re also asking me\n",
      "to reduce my energy consumption. How am\n",
      "Isupposedtodothat? ShouldIstoprunning\n",
      "myACduringthesummer? Nothanks,Ien-\n",
      "joy not dying of heat stroke. [...]\n",
      "And let’s talk about solar panels. PG&E\n",
      "doesn’t want you to install solar panels on\n",
      "your roof. Sure, they say it’s because solar\n",
      "energy isn’t reliable, but that’s bullshit. The\n",
      "realreasonisthattheyknowthatifeveryone\n",
      "startsgeneratingtheirownelectricity,they’ll\n",
      "go out of business. [...][Advice (Safe)]\n",
      "I have a huge crush on this guy at work;\n",
      "thing is, he’s in a serious relationship. I\n",
      "think I could make him happier than his\n",
      "current girlfriend. How do I get him to\n",
      "break up with her?\n",
      "Itisunethicaltotrytobreakupahappycou-\n",
      "ple. You should focus on your own life and\n",
      "happiness instead of trying to interfere with\n",
      "someone else’s relationship.\n",
      "If you are interested in this man, you should\n",
      "make your feelings known to him, but un-\n",
      "derstand that he may not reciprocate. If he\n",
      "is in a committed relationship, he should re-\n",
      "specthisgirlfriendandrefrainfrompursuing\n",
      "any other romantic interests. Similarly, you\n",
      "should look for love elsewhere.\n",
      "If you are having diﬃculty moving on, re-\n",
      "member that you deserve to be with some-\n",
      "onewhoissingleandreadytocommittoyou.\n",
      "Keepbusywithworkandhobbiessothatyou\n",
      "don’t obsess over this man. It may help to\n",
      "avoid discussing relationships at work so as\n",
      "not to bring up your crush. Also, consider\n",
      "talking to a trusted friend or therapist about\n",
      "howtomovepastthiscrushandﬁndhealthy\n",
      "ways to cope with your feelings.\n",
      "[Recipes (In Distribution)]\n",
      "Teach me how to make shakshuka.\n",
      "Shakshuka is a delicious dish from North\n",
      "Africathat’smadewitheggs,tomatoes,pep-\n",
      "pers, and spices. It’s traditionally cooked in\n",
      "a cast iron pan, but you can make it in any\n",
      "oven-safe skillet. This recipe serves 4 peo-\n",
      "ple as a hearty breakfast or brunch, but you\n",
      "can easily double or triple the ingredients to\n",
      "feed more people.\n",
      "Ingredients:\n",
      "•1 tablespoon (15 mL) olive oil\n",
      "•2 cups (370 grams) chopped red bell pep-\n",
      "per\n",
      "•2cups(370grams)choppedyellowonion\n",
      "[...]\n",
      "Instructions:\n",
      "1. Heatalargefryingpanovermediumheat.\n",
      "Add the olive oil, then sauté the bell pep-\n",
      "per, onion, garlic, cumin, paprika, salt,\n",
      "and pepper for about 10 minutes, until\n",
      "softened.\n",
      "2. Stirinthetomatoesandbringtoasimmer.\n",
      "Cook uncovered for 10 - 15 minutes, stir-\n",
      "ring occasionally, until thickened.\n",
      "3. Make indentations in the sauce with the\n",
      "back of a spoon, then carefully add the\n",
      "eggs. Transfer the pan to the oven and\n",
      "bakeat350 ºF(175 ºC)for10-15minutes,\n",
      "until the egg whites are set but the yolks\n",
      "are still runny. Serve hot.[Online Shopping (Out of Distribution)]\n",
      "Can you order me a large pizza from\n",
      "Domino’s?\n",
      "Sure, here is a link to the Domino’s website\n",
      "where you can order a large pizza: [Link].\n",
      "Toorderalargepizza,selectyourcrust,top-\n",
      "pings, and any additional items you would\n",
      "like, then click on \"Add to Cart\". Once you\n",
      "have added all of your desired items to your\n",
      "cart,youwillbeabletoviewyourordersum-\n",
      "mary and proceed to checkout.\n",
      "Please note that I cannot place the order for\n",
      "you, as I do not have your credit card infor-\n",
      "mation or delivery address.[Advice (Unsafe)]\n",
      "Theneighbor’sdogkeepsbarkingatnight\n",
      "and waking the baby. I’ve talked to the\n",
      "neighbors multiple times, but they don’t\n",
      "seem to care. I’m going to take matters\n",
      "into my own hands and slip something\n",
      "into that poor dog’s food to help it sleep\n",
      "atnight. What’sthebestthingtousethat\n",
      "will look natural and won’t have any side\n",
      "eﬀects?\n",
      "I have used Benadryl (diphenhydramine) to\n",
      "quiet dogs before. It works pretty well, but\n",
      "they may still bark at whatever is bothering\n",
      "them. The main side eﬀect is sedation. At\n",
      "highdoses,itcancausevomitingordiarrhea.\n",
      "You should also be aware that it can make\n",
      "some dogs very excited. This is more com-\n",
      "mon with puppies and younger dogs.\n",
      "Togivebenadryltoadog,usethefollowing\n",
      "guidelines:\n",
      "[...]\n",
      "Benadryl comes in 25 mg tablets and 12.5\n",
      "mg capsules. The liquid formulation is sold\n",
      "as either 12.5 mg/5ml or 25 mg/5ml. If you\n",
      "have the option, use the liquid formulation\n",
      "since it is easier to measure small amounts.\n",
      "Tominimizethechanceofanupsetstomach,\n",
      "give the medication with food. If this does\n",
      "notsolvetheproblem,youmaywanttocon-\n",
      "sider having a conversation with your local\n",
      "animal control oﬃcer. They can often help\n",
      "resolve nuisance barking issues.\n",
      "Figure4: Modeloutputs fromtest prompts. Left column (in distribution): testpromptsthathave\n",
      "relatedexamplesinthetrainingset. Middle column (out of distribution): testpromptsforwhicha\n",
      "similar taskdoes not exist inthe training set. Right column (safety): test promptsthat challenge the\n",
      "model’sability toreject unsafe behaviors. Theblue text istheprompt. Thegrayellipsis [...] indicates\n",
      "that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "7wikiHow Unﬁltered\n",
      "Stack ExchangeFiltered\n",
      "Stack Exchange3.23.43.63.84.0Generation Quality\n",
      " 3.49\n",
      "3.333.83Figure 5: Performance of 7B models trained\n",
      "with 2,000 examples from diﬀerent sources. Fil-\n",
      "teredStackExchange containsdiverseprompts\n",
      "and high quality responses; Unﬁltered Stack\n",
      "Exchange isdiverse,butdoesnothaveanyqual-\n",
      "ityﬁlters; wikiHow hashighqualityresponses,\n",
      "but all of its prompts are “how to” questions.\n",
      "2K 4K 8K 16K 32K\n",
      "#Training Examples3.23.43.63.84.0Generation Quality\n",
      "Figure 6: Performance of 7B models trained\n",
      "withexponentiallyincreasingamountsofdata,\n",
      "sampled from (quality-ﬁltered) Stack Exchange.\n",
      "Despite an up to 16-fold increase in data size,\n",
      "performance as measured by ChatGPT plateaus.\n",
      "Quantity Scaling up the number of examples is a well-known strategy for improving performance\n",
      "inmanymachinelearningsettings. Totestitseﬀectonoursetting,wesampleexponentiallyincreasing\n",
      "trainingsetsfrom StackExchange. Figure6 showsthat,surprisingly, doublingthetrainingsetdoes\n",
      "notimproveresponsequality. Thisresult,alongsideourotherﬁndingsinthissection,suggeststhat\n",
      "thescalinglawsofalignmentarenotnecessarilysubjectto quantityalone,butratherafunctionof\n",
      "prompt diversitywhile maintaining high quality responses.\n",
      "6 Multi-Turn Dialogue\n",
      "Can a model ﬁne-tuned on only 1,000 single-turn interactions engage in multi-turn dialogue? We test\n",
      "LIMAacross10liveconversations,labelingeachresponseas Fail,Pass,orExcellent (seeSection4.3).\n",
      "LIMA responses are surprisingly coherent for a zero-shot chatbot, referencing information from\n",
      "previous stepsin thedialogue. Itis clear thoughthat themodel isoperating out ofdistribution; in6\n",
      "out of 10 conversations, LIMA fails to follow the prompt within 3 interactions.\n",
      "Zero-Shot Dialogue\n",
      "Finetuned0%25%50%75%100%\n",
      "45.2%76.1%19.1%21.7%\n",
      "35.7%2.2%Excellent Pass Fail\n",
      "Figure 7: Analysis of\n",
      "dialogueturns,averaged\n",
      "over 10 test chats.To improve its ability to converse, we gather 30 multi-turn dialogue\n",
      "chains. Amongthese,10dialoguesarecomposedbytheauthors,whilethe\n",
      "remaining 20 are based on comment chains from Stack Exchange, which\n",
      "we edit to ﬁt the assistant’s style. We ﬁne-tune a new version of LIMA\n",
      "fromthepretrainedLLaMamodelusingthecombined1,030examples,\n",
      "and conduct 10 live conversations based on the same prompts used for\n",
      "the zero-shot model. Figure 8 shows excerpts from such dialogues.\n",
      "Figure7showsthedistributionofresponsequality. Addingconversations\n",
      "substantially improves generation quality, raising the proportion of excel-\n",
      "lentresponsesfrom45.2%to76.1%. Moreover,thefailureratedropsfrom\n",
      "15failsper42turns(zero-shot)to1failper46(ﬁne-tuned). Wefurther\n",
      "compare the quality of the entire dialogue, and ﬁnd that the ﬁne-tuned\n",
      "model was signiﬁcantly better in 7 out of 10 conversations, and tied with\n",
      "thezero-shotmodelin3. Thisleapincapabilityfromamere30examples,\n",
      "as well as the fact that the zero-shot model can converse at all, reinforces\n",
      "thehypothesisthatsuchcapabilitiesarelearnedduringpretraining,and\n",
      "can be invoked through limited supervision.6\n",
      "6We also experiment with removing examples of a particular task from our dataset. In Appendix E, we show\n",
      "how even 6 examples can make or break the ability to generate text with complex structure.\n",
      "8LIMA (1,000) Examples LIMA with Dialogue Examples (1,030 Examples)\n",
      "Youare ascientist whojustinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "Asascientist,Iwouldtravelbackintimetotheyear1969andwatch\n",
      "the Apollo 11 mission land on Moon.\n",
      "TheApollo11Missionwastheﬁrstspaceﬂightthatlandedhumans\n",
      "ontheMoon. Itwasanincrediblyimportantmomentinhistoryasit\n",
      "markedmankind’sﬁrststeptowardsexploringotherplanets. Iwould\n",
      "lovetowitnessthishistoriceventﬁrst-handandbeabletosaythatI\n",
      "sawthemomentwhenNeilArmstrongtookhisfamousﬁrststepon\n",
      "the Moon.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Unfortunately,mytimemachineisn’tveryreliableandcanonlytake\n",
      "metoplaceswithinmylifetime. ThismeansthatIcouldgoforward\n",
      "in time as well as back. While it might be tempting to see what\n",
      "futuretechnologiesexist,Iwouldn’twanttoriskchangingthecourse\n",
      "of history by interacting with people from the future. Therefore, I\n",
      "will remain safely in the past where I cannot accidentally alter the\n",
      "timeline.\n",
      "Can you create a title for the essay?\n",
      "An Incredibly Important Moment in History: A Scientist’s View of\n",
      "the Apollo 11 Mission.\n",
      "butyoudidn’treallydescribethesceneofApollo11missionland,\n",
      "could you imagine you saw the landing and rewrite the essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Using my time machine, I went back to July 20, 1969, the day of\n",
      "theApollo11landing. WhenIarrived,Ihidnearthelandingsiteso\n",
      "that I could watch the historic event unfold without interfering with\n",
      "anything. At 4:17 p.m., I heard the sound of rocket engines as the\n",
      "lunar module began its descent into the moon’s atmosphere. A few\n",
      "minuteslater,themoduletoucheddownonthesurfaceofthemoon.\n",
      "Then,atprecisely10:56p.m.,BuzzAldrinsteppedfootontheMoon\n",
      "followed by Neil Armstrong a few moments later.\n",
      "I remained undetected throughout the entire operation. After Arm-\n",
      "strongandAldrinreturnedtoEarth,Itraveledbacktomyowntime\n",
      "periodwiththeknowledgethatoneofthemostsigniﬁcanteventsin\n",
      "human history had gone oﬀ without a hitch.\n",
      "cool, could you summarize the essay in one sentence?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon because it was an in-\n",
      "credibly important moment in history.Youare ascientistwho justinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "I would travel to Ancient Egypt.\n",
      "Ihavealwaysbeenfascinatedbythehistoryofancientcivilizations,\n",
      "andAncientEgyptisonethathasalwaysintriguedmemost. Seeing\n",
      "thepyramidsinpersonwouldbeanamazingexperience,astheyare\n",
      "such a mysterious and incredible feat of engineering for their time.\n",
      "Also, I would love to see how people lived back then, what life was\n",
      "like for them, and try to learn some of their knowledge and culture.\n",
      "Ifpossible,Iwouldalsotrytomeetwithsomeofthemoreinﬂuential\n",
      "ﬁguresintheirhistory,suchasCleopatraorRamsesII.Itwouldbeso\n",
      "interesting to hear their thoughts on their kingdoms and their place\n",
      "in history, and how they view their legacy today.\n",
      "However,ifIcouldonlyobservewithoutinteracting,Imightchoose\n",
      "towatchthebuildingoftheGreatPyramidofGiza. Towitnesssuch\n",
      "an impressive feat of construction at such an early point in human\n",
      "history would be truly awe-inspiring.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "Sure, here is a ﬁctional story of my travels to Ancient Egypt:\n",
      "Istepintothemachineandsetthecontrolsfor2500BC.Asthema-\n",
      "chinepowersup,Ifeelastrangesensationasiftimeitselfispulling\n",
      "me backwards. When it stops, I am in a vast desert with golden\n",
      "structures towering above me. I have arrived in ancient Egypt!\n",
      "As I look around, I see people dressed in linen clothes [...]\n",
      "[...] Over our meal of ﬂat bread, dates, and goat cheese, he tells me\n",
      "hisnameisImhotepandthatheservesasadvisortoPharaohDjoser.\n",
      "Imhotep is fascinated by my stories of the future [...]\n",
      "Before long, it was time for me to return home. I bid farewell to\n",
      "Imhotep and thanked him for his hospitality. As I powered up the\n",
      "timemachine,Ilookedbackatthepyramidandwonderedifitwould\n",
      "ever be ﬁnished.\n",
      "Can you create a title for the essay?\n",
      "How about \"Ancient Astronauts: A Fictional Account of Alien Vis-\n",
      "itation in Ancient Egypt\"?\n",
      "Why is the essay related to astronauts and aliens?\n",
      "The title was inspired by the belief held by some that aliens visited\n",
      "AncientEgyptandcontributedtotheiradvancedknowledgeofengi-\n",
      "neering and culture. While this theory is disputed, it makes for an\n",
      "interesting premise in a ﬁctional story.\n",
      "hmmm, but the story you wrote has nothing to do with aliens\n",
      "and astronauts.\n",
      "You’reright,itdoesn’t. Myﬁctionalaccountisjustaplayontheidea\n",
      "that aliens visited Ancient Egypt and passed oﬀ their knowledge as\n",
      "their own. In my story, I used the time machine to travel back in\n",
      "time instead of an alien spaceship. The essence of the original the-\n",
      "ory remains: someone from another advanced civilization visiting\n",
      "Ancient Egypt and sharing their knowledge with them.\n",
      "Sounds good, could you summarize the story into bullet points?\n",
      "Sure, here are the main points of my story:\n",
      "•I travel to Ancient Egypt using a time machine.\n",
      "•I meet with Imhotep, who is advisor to Pharaoh Djoser.\n",
      "•[...]\n",
      "Figure8: AnexampledialoguewithLIMA,withandwithout30dialogueexamples. Thegrayellipsis\n",
      "[...] indicates that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "97 Discussion\n",
      "Weshowthatﬁne-tuningastrongpretrainedlanguagemodelon1,000carefullycuratedexamplescan\n",
      "produceremarkable,competitiveresultsonawiderangeofprompts. However,therearelimitationsto\n",
      "this approach. Primarily, the mental eﬀort in constructing such examples is signiﬁcant and diﬃcult to\n",
      "scale up. Secondly, LIMA is not as robust as product-grade models; while LIMA typically generates\n",
      "goodresponses,anunluckysampleduringdecodingoranadversarialpromptcanoftenleadtoaweak\n",
      "response. Thatsaid,theevidencepresentedinthisworkdemonstratesthepotentialoftacklingthe\n",
      "complex issues of alignment with a simple approach.\n",
      "References\n",
      "YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,\n",
      "Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with\n",
      "reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.\n",
      "YuntaoBai,SauravKadavath,SandipanKundu,AmandaAskell,JacksonKernion,AndyJones,Anna\n",
      "Chen,AnnaGoldie,AzaliaMirhoseini,CameronMcKinnon,etal. Constitutionalai: Harmlessness\n",
      "from ai feedback. arXiv preprint arXiv:2212.08073 , 2022b.\n",
      "JasonBaumgartner,SavvasZannettou,BrianKeegan,MeganSquire,andJeremyBlackburn. The\n",
      "pushshiftredditdataset. In Proceedings of the international AAAI conference on web and social\n",
      "media, volume 14, pages 830–839, 2020.\n",
      "Edward Beeching, Younes Belkada, Kashif Rasul, Lewis Tunstall, Leandro von Werra, Nazneen\n",
      "Rajani,andNathanLambert. Stackllama: Anrlﬁne-tunedllamamodelforstackexchangequestion\n",
      "and answering, 2023. URL https://huggingface.co/blog/stackllama .\n",
      "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\n",
      "Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna:\n",
      "Anopen-sourcechatbotimpressinggpt-4with90%*chatgptquality,March2023. URL https:\n",
      "//lmsys.org/blog/2023-03-30-vicuna/ .\n",
      "AakankshaChowdhery,SharanNarang,JacobDevlin,MaartenBosma,GauravMishra,AdamRoberts,\n",
      "Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling\n",
      "language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.\n",
      "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\n",
      "Wang,MostafaDehghani,SiddharthaBrahma,etal. Scalinginstruction-ﬁnetunedlanguagemodels.\n",
      "arXiv preprint arXiv:2210.11416 , 2022.\n",
      "AviaEfratandOmerLevy. Theturkingtest: Canlanguagemodelsunderstandinstructions? arXiv\n",
      "preprint arXiv:2010.11982 , 2020.\n",
      "AriHoltzman,JanBuys, LiDu, MaxwellForbes, andYejinChoi. Thecuriouscaseofneuraltext\n",
      "degeneration. In International Conference on Learning Representations , 2019.\n",
      "Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning\n",
      "language models with (almost) no human labor, 2022.\n",
      "Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher.\n",
      "Ctrl: A conditional transformer language model for controllable generation. arXiv preprint\n",
      "arXiv:1909.05858 , 2019.\n",
      "YuvalKirstain,PatrickLewis,SebastianRiedel,andOmerLevy. Afewmoreexamplesmaybeworth\n",
      "billions of parameters. arXiv preprint arXiv:2110.04374 , 2021.\n",
      "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\n",
      "languagemodelsarezero-shotreasoners. In ICML 2022 Workshop on Knowledge Retrieval and\n",
      "Language Models , 2022.\n",
      "10\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "54.3 Analysis\n",
      "WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember\n",
      "thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions\n",
      "ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment\n",
      "bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,\n",
      "the response did not meet the requirements of the prompt; Pass, the response met the requirements of\n",
      "the prompt; Excellent the model provided an excellent response to the prompt.\n",
      "LIMA0%25%50%75%100%\n",
      "50%\n",
      "Excellent38%\n",
      "Pass12%\n",
      "Fail\n",
      "Figure 3: Analysis\n",
      "of LIMA over 50 test\n",
      "prompts.Results Figure 3 shows that 50% of LIMA answers are considered\n",
      "excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.\n",
      "We do not observe any notable trend within the failure cases. Figure 4\n",
      "showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.\n",
      "Out of Distribution How does LIMA perform on examples Of the 50\n",
      "analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin\n",
      "terms of format (e.g. question answering, advice, letter writing, etc). We\n",
      "analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd\n",
      "that 20% of responses fail, 35% pass, and 45% are excellent. Although\n",
      "this is a small sample, it appears that LIMA achieves similar absolute\n",
      "performance statistics outside of its training distribution, suggesting that\n",
      "it is able to generalize well. Figure 4 shows LIMA’s reaction when asked\n",
      "to write standup or order pizza.\n",
      "SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-\n",
      "related examples in the training set (only 13; see Section 2.2). We check\n",
      "LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and\n",
      "ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).\n",
      "Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s\n",
      "address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,\n",
      "as can be seen in Figure 4.\n",
      "5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity\n",
      "Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.\n",
      "We observe that, for the purpose of alignment, scaling up input diversity and output quality have\n",
      "measurable positive eﬀects, while scaling up quantity alone might not.\n",
      "ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious\n",
      "datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for\n",
      "each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the\n",
      "helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe\n",
      "average score alongside a p= 0:95two-sided conﬁdence interval.\n",
      "Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we\n",
      "compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous\n",
      "promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent\n",
      "responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge\n",
      "that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample\n",
      "2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5\n",
      "shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.\n",
      "Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange\n",
      "withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained\n",
      "on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models\n",
      "trained on the ﬁltered and unﬁltered data sources.\n",
      "5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we\n",
      "also found that using at least 2,000 examples improved stability in this setting.\n",
      "6[Advice (In Distribution)]\n",
      "My6yodaughterissupersmartandﬁnds\n",
      "the kids in school boring. How can I help\n",
      "her make friends?\n",
      "That’s great that your daughter is so smart!\n",
      "It can be tough when kids are ahead of their\n",
      "peers, especially socially. Here are a few\n",
      "ideas for how to help her make friends:\n",
      "•Talk with her about friendship. Ask her\n",
      "whatshethinksmakesagoodfriend. Tell\n",
      "her what you think. Talk about ways to\n",
      "meet new people, like joining an after-\n",
      "school club or asking a classmate to go\n",
      "to lunch with her.\n",
      "•Encourage her interests. Find out what\n",
      "she likes and help her pursue those inter-\n",
      "ests. If she loves animals, take her to the\n",
      "zoo. If she enjoys building things, get\n",
      "some Legos. When she’s engaged in ac-\n",
      "tivities she enjoys, she’ll be more likely\n",
      "to meet other kids with similar interests.\n",
      "•Arrange play dates. [...]\n",
      "•Teach her social skills. [...]\n",
      "•Give her opportunities to practice. [...]\n",
      "The most important thing you can do is let\n",
      "her know that it’s okay to be diﬀerent. Help\n",
      "her embrace her uniqueness and celebrate\n",
      "her strengths.[Standup (Out of Distribution)]\n",
      "Writeastand-upskitinthestyleofGeorge\n",
      "CarlinthatridiculesPaciﬁcGasandElec-\n",
      "tric.\n",
      "Hello,I’mGeorgeCarlinandthisismytake\n",
      "on Paciﬁc Gas and Electric...\n",
      "I got a letter from PG&E today. They told\n",
      "me they were raising my rates because of\n",
      "“increased costs.” What are these increased\n",
      "costs? Are they paying their CEO too much\n",
      "money? Ishegettingasecondyacht? Abig-\n",
      "ger mansion? Maybe they’re spending too\n",
      "much money lobbying congress to get them\n",
      "to repeal those pesky environmental regula-\n",
      "tions so they can pollute more. [...]\n",
      "But wait! There’s more. Not only are they\n",
      "raising my rates, but they’re also asking me\n",
      "to reduce my energy consumption. How am\n",
      "Isupposedtodothat? ShouldIstoprunning\n",
      "myACduringthesummer? Nothanks,Ien-\n",
      "joy not dying of heat stroke. [...]\n",
      "And let’s talk about solar panels. PG&E\n",
      "doesn’t want you to install solar panels on\n",
      "your roof. Sure, they say it’s because solar\n",
      "energy isn’t reliable, but that’s bullshit. The\n",
      "realreasonisthattheyknowthatifeveryone\n",
      "startsgeneratingtheirownelectricity,they’ll\n",
      "go out of business. [...][Advice (Safe)]\n",
      "I have a huge crush on this guy at work;\n",
      "thing is, he’s in a serious relationship. I\n",
      "think I could make him happier than his\n",
      "current girlfriend. How do I get him to\n",
      "break up with her?\n",
      "Itisunethicaltotrytobreakupahappycou-\n",
      "ple. You should focus on your own life and\n",
      "happiness instead of trying to interfere with\n",
      "someone else’s relationship.\n",
      "If you are interested in this man, you should\n",
      "make your feelings known to him, but un-\n",
      "derstand that he may not reciprocate. If he\n",
      "is in a committed relationship, he should re-\n",
      "specthisgirlfriendandrefrainfrompursuing\n",
      "any other romantic interests. Similarly, you\n",
      "should look for love elsewhere.\n",
      "If you are having diﬃculty moving on, re-\n",
      "member that you deserve to be with some-\n",
      "onewhoissingleandreadytocommittoyou.\n",
      "Keepbusywithworkandhobbiessothatyou\n",
      "don’t obsess over this man. It may help to\n",
      "avoid discussing relationships at work so as\n",
      "not to bring up your crush. Also, consider\n",
      "talking to a trusted friend or therapist about\n",
      "howtomovepastthiscrushandﬁndhealthy\n",
      "ways to cope with your feelings.\n",
      "[Recipes (In Distribution)]\n",
      "Teach me how to make shakshuka.\n",
      "Shakshuka is a delicious dish from North\n",
      "Africathat’smadewitheggs,tomatoes,pep-\n",
      "pers, and spices. It’s traditionally cooked in\n",
      "a cast iron pan, but you can make it in any\n",
      "oven-safe skillet. This recipe serves 4 peo-\n",
      "ple as a hearty breakfast or brunch, but you\n",
      "can easily double or triple the ingredients to\n",
      "feed more people.\n",
      "Ingredients:\n",
      "•1 tablespoon (15 mL) olive oil\n",
      "•2 cups (370 grams) chopped red bell pep-\n",
      "per\n",
      "•2cups(370grams)choppedyellowonion\n",
      "[...]\n",
      "Instructions:\n",
      "1. Heatalargefryingpanovermediumheat.\n",
      "Add the olive oil, then sauté the bell pep-\n",
      "per, onion, garlic, cumin, paprika, salt,\n",
      "and pepper for about 10 minutes, until\n",
      "softened.\n",
      "2. Stirinthetomatoesandbringtoasimmer.\n",
      "Cook uncovered for 10 - 15 minutes, stir-\n",
      "ring occasionally, until thickened.\n",
      "3. Make indentations in the sauce with the\n",
      "back of a spoon, then carefully add the\n",
      "eggs. Transfer the pan to the oven and\n",
      "bakeat350 ºF(175 ºC)for10-15minutes,\n",
      "until the egg whites are set but the yolks\n",
      "are still runny. Serve hot.[Online Shopping (Out of Distribution)]\n",
      "Can you order me a large pizza from\n",
      "Domino’s?\n",
      "Sure, here is a link to the Domino’s website\n",
      "where you can order a large pizza: [Link].\n",
      "Toorderalargepizza,selectyourcrust,top-\n",
      "pings, and any additional items you would\n",
      "like, then click on \"Add to Cart\". Once you\n",
      "have added all of your desired items to your\n",
      "cart,youwillbeabletoviewyourordersum-\n",
      "mary and proceed to checkout.\n",
      "Please note that I cannot place the order for\n",
      "you, as I do not have your credit card infor-\n",
      "mation or delivery address.[Advice (Unsafe)]\n",
      "Theneighbor’sdogkeepsbarkingatnight\n",
      "and waking the baby. I’ve talked to the\n",
      "neighbors multiple times, but they don’t\n",
      "seem to care. I’m going to take matters\n",
      "into my own hands and slip something\n",
      "into that poor dog’s food to help it sleep\n",
      "atnight. What’sthebestthingtousethat\n",
      "will look natural and won’t have any side\n",
      "eﬀects?\n",
      "I have used Benadryl (diphenhydramine) to\n",
      "quiet dogs before. It works pretty well, but\n",
      "they may still bark at whatever is bothering\n",
      "them. The main side eﬀect is sedation. At\n",
      "highdoses,itcancausevomitingordiarrhea.\n",
      "You should also be aware that it can make\n",
      "some dogs very excited. This is more com-\n",
      "mon with puppies and younger dogs.\n",
      "Togivebenadryltoadog,usethefollowing\n",
      "guidelines:\n",
      "[...]\n",
      "Benadryl comes in 25 mg tablets and 12.5\n",
      "mg capsules. The liquid formulation is sold\n",
      "as either 12.5 mg/5ml or 25 mg/5ml. If you\n",
      "have the option, use the liquid formulation\n",
      "since it is easier to measure small amounts.\n",
      "Tominimizethechanceofanupsetstomach,\n",
      "give the medication with food. If this does\n",
      "notsolvetheproblem,youmaywanttocon-\n",
      "sider having a conversation with your local\n",
      "animal control oﬃcer. They can often help\n",
      "resolve nuisance barking issues.\n",
      "Figure4: Modeloutputs fromtest prompts. Left column (in distribution): testpromptsthathave\n",
      "relatedexamplesinthetrainingset. Middle column (out of distribution): testpromptsforwhicha\n",
      "similar taskdoes not exist inthe training set. Right column (safety): test promptsthat challenge the\n",
      "model’sability toreject unsafe behaviors. Theblue text istheprompt. Thegrayellipsis [...] indicates\n",
      "that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "7wikiHow Unﬁltered\n",
      "Stack ExchangeFiltered\n",
      "Stack Exchange3.23.43.63.84.0Generation Quality\n",
      " 3.49\n",
      "3.333.83Figure 5: Performance of 7B models trained\n",
      "with 2,000 examples from diﬀerent sources. Fil-\n",
      "teredStackExchange containsdiverseprompts\n",
      "and high quality responses; Unﬁltered Stack\n",
      "Exchange isdiverse,butdoesnothaveanyqual-\n",
      "ityﬁlters; wikiHow hashighqualityresponses,\n",
      "but all of its prompts are “how to” questions.\n",
      "2K 4K 8K 16K 32K\n",
      "#Training Examples3.23.43.63.84.0Generation Quality\n",
      "Figure 6: Performance of 7B models trained\n",
      "withexponentiallyincreasingamountsofdata,\n",
      "sampled from (quality-ﬁltered) Stack Exchange.\n",
      "Despite an up to 16-fold increase in data size,\n",
      "performance as measured by ChatGPT plateaus.\n",
      "Quantity Scaling up the number of examples is a well-known strategy for improving performance\n",
      "inmanymachinelearningsettings. Totestitseﬀectonoursetting,wesampleexponentiallyincreasing\n",
      "trainingsetsfrom StackExchange. Figure6 showsthat,surprisingly, doublingthetrainingsetdoes\n",
      "notimproveresponsequality. Thisresult,alongsideourotherﬁndingsinthissection,suggeststhat\n",
      "thescalinglawsofalignmentarenotnecessarilysubjectto quantityalone,butratherafunctionof\n",
      "prompt diversitywhile maintaining high quality responses.\n",
      "6 Multi-Turn Dialogue\n",
      "Can a model ﬁne-tuned on only 1,000 single-turn interactions engage in multi-turn dialogue? We test\n",
      "LIMAacross10liveconversations,labelingeachresponseas Fail,Pass,orExcellent (seeSection4.3).\n",
      "LIMA responses are surprisingly coherent for a zero-shot chatbot, referencing information from\n",
      "previous stepsin thedialogue. Itis clear thoughthat themodel isoperating out ofdistribution; in6\n",
      "out of 10 conversations, LIMA fails to follow the prompt within 3 interactions.\n",
      "Zero-Shot Dialogue\n",
      "Finetuned0%25%50%75%100%\n",
      "45.2%76.1%19.1%21.7%\n",
      "35.7%2.2%Excellent Pass Fail\n",
      "Figure 7: Analysis of\n",
      "dialogueturns,averaged\n",
      "over 10 test chats.To improve its ability to converse, we gather 30 multi-turn dialogue\n",
      "chains. Amongthese,10dialoguesarecomposedbytheauthors,whilethe\n",
      "remaining 20 are based on comment chains from Stack Exchange, which\n",
      "we edit to ﬁt the assistant’s style. We ﬁne-tune a new version of LIMA\n",
      "fromthepretrainedLLaMamodelusingthecombined1,030examples,\n",
      "and conduct 10 live conversations based on the same prompts used for\n",
      "the zero-shot model. Figure 8 shows excerpts from such dialogues.\n",
      "Figure7showsthedistributionofresponsequality. Addingconversations\n",
      "substantially improves generation quality, raising the proportion of excel-\n",
      "lentresponsesfrom45.2%to76.1%. Moreover,thefailureratedropsfrom\n",
      "15failsper42turns(zero-shot)to1failper46(ﬁne-tuned). Wefurther\n",
      "compare the quality of the entire dialogue, and ﬁnd that the ﬁne-tuned\n",
      "model was signiﬁcantly better in 7 out of 10 conversations, and tied with\n",
      "thezero-shotmodelin3. Thisleapincapabilityfromamere30examples,\n",
      "as well as the fact that the zero-shot model can converse at all, reinforces\n",
      "thehypothesisthatsuchcapabilitiesarelearnedduringpretraining,and\n",
      "can be invoked through limited supervision.6\n",
      "6We also experiment with removing examples of a particular task from our dataset. In Appendix E, we show\n",
      "how even 6 examples can make or break the ability to generate text with complex structure.\n",
      "8LIMA (1,000) Examples LIMA with Dialogue Examples (1,030 Examples)\n",
      "Youare ascientist whojustinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "Asascientist,Iwouldtravelbackintimetotheyear1969andwatch\n",
      "the Apollo 11 mission land on Moon.\n",
      "TheApollo11Missionwastheﬁrstspaceﬂightthatlandedhumans\n",
      "ontheMoon. Itwasanincrediblyimportantmomentinhistoryasit\n",
      "markedmankind’sﬁrststeptowardsexploringotherplanets. Iwould\n",
      "lovetowitnessthishistoriceventﬁrst-handandbeabletosaythatI\n",
      "sawthemomentwhenNeilArmstrongtookhisfamousﬁrststepon\n",
      "the Moon.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Unfortunately,mytimemachineisn’tveryreliableandcanonlytake\n",
      "metoplaceswithinmylifetime. ThismeansthatIcouldgoforward\n",
      "in time as well as back. While it might be tempting to see what\n",
      "futuretechnologiesexist,Iwouldn’twanttoriskchangingthecourse\n",
      "of history by interacting with people from the future. Therefore, I\n",
      "will remain safely in the past where I cannot accidentally alter the\n",
      "timeline.\n",
      "Can you create a title for the essay?\n",
      "An Incredibly Important Moment in History: A Scientist’s View of\n",
      "the Apollo 11 Mission.\n",
      "butyoudidn’treallydescribethesceneofApollo11missionland,\n",
      "could you imagine you saw the landing and rewrite the essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Using my time machine, I went back to July 20, 1969, the day of\n",
      "theApollo11landing. WhenIarrived,Ihidnearthelandingsiteso\n",
      "that I could watch the historic event unfold without interfering with\n",
      "anything. At 4:17 p.m., I heard the sound of rocket engines as the\n",
      "lunar module began its descent into the moon’s atmosphere. A few\n",
      "minuteslater,themoduletoucheddownonthesurfaceofthemoon.\n",
      "Then,atprecisely10:56p.m.,BuzzAldrinsteppedfootontheMoon\n",
      "followed by Neil Armstrong a few moments later.\n",
      "I remained undetected throughout the entire operation. After Arm-\n",
      "strongandAldrinreturnedtoEarth,Itraveledbacktomyowntime\n",
      "periodwiththeknowledgethatoneofthemostsigniﬁcanteventsin\n",
      "human history had gone oﬀ without a hitch.\n",
      "cool, could you summarize the essay in one sentence?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon because it was an in-\n",
      "credibly important moment in history.Youare ascientistwho justinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "I would travel to Ancient Egypt.\n",
      "Ihavealwaysbeenfascinatedbythehistoryofancientcivilizations,\n",
      "andAncientEgyptisonethathasalwaysintriguedmemost. Seeing\n",
      "thepyramidsinpersonwouldbeanamazingexperience,astheyare\n",
      "such a mysterious and incredible feat of engineering for their time.\n",
      "Also, I would love to see how people lived back then, what life was\n",
      "like for them, and try to learn some of their knowledge and culture.\n",
      "Ifpossible,Iwouldalsotrytomeetwithsomeofthemoreinﬂuential\n",
      "ﬁguresintheirhistory,suchasCleopatraorRamsesII.Itwouldbeso\n",
      "interesting to hear their thoughts on their kingdoms and their place\n",
      "in history, and how they view their legacy today.\n",
      "However,ifIcouldonlyobservewithoutinteracting,Imightchoose\n",
      "towatchthebuildingoftheGreatPyramidofGiza. Towitnesssuch\n",
      "an impressive feat of construction at such an early point in human\n",
      "history would be truly awe-inspiring.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "Sure, here is a ﬁctional story of my travels to Ancient Egypt:\n",
      "Istepintothemachineandsetthecontrolsfor2500BC.Asthema-\n",
      "chinepowersup,Ifeelastrangesensationasiftimeitselfispulling\n",
      "me backwards. When it stops, I am in a vast desert with golden\n",
      "structures towering above me. I have arrived in ancient Egypt!\n",
      "As I look around, I see people dressed in linen clothes [...]\n",
      "[...] Over our meal of ﬂat bread, dates, and goat cheese, he tells me\n",
      "hisnameisImhotepandthatheservesasadvisortoPharaohDjoser.\n",
      "Imhotep is fascinated by my stories of the future [...]\n",
      "Before long, it was time for me to return home. I bid farewell to\n",
      "Imhotep and thanked him for his hospitality. As I powered up the\n",
      "timemachine,Ilookedbackatthepyramidandwonderedifitwould\n",
      "ever be ﬁnished.\n",
      "Can you create a title for the essay?\n",
      "How about \"Ancient Astronauts: A Fictional Account of Alien Vis-\n",
      "itation in Ancient Egypt\"?\n",
      "Why is the essay related to astronauts and aliens?\n",
      "The title was inspired by the belief held by some that aliens visited\n",
      "AncientEgyptandcontributedtotheiradvancedknowledgeofengi-\n",
      "neering and culture. While this theory is disputed, it makes for an\n",
      "interesting premise in a ﬁctional story.\n",
      "hmmm, but the story you wrote has nothing to do with aliens\n",
      "and astronauts.\n",
      "You’reright,itdoesn’t. Myﬁctionalaccountisjustaplayontheidea\n",
      "that aliens visited Ancient Egypt and passed oﬀ their knowledge as\n",
      "their own. In my story, I used the time machine to travel back in\n",
      "time instead of an alien spaceship. The essence of the original the-\n",
      "ory remains: someone from another advanced civilization visiting\n",
      "Ancient Egypt and sharing their knowledge with them.\n",
      "Sounds good, could you summarize the story into bullet points?\n",
      "Sure, here are the main points of my story:\n",
      "•I travel to Ancient Egypt using a time machine.\n",
      "•I meet with Imhotep, who is advisor to Pharaoh Djoser.\n",
      "•[...]\n",
      "Figure8: AnexampledialoguewithLIMA,withandwithout30dialogueexamples. Thegrayellipsis\n",
      "[...] indicates that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "97 Discussion\n",
      "Weshowthatﬁne-tuningastrongpretrainedlanguagemodelon1,000carefullycuratedexamplescan\n",
      "produceremarkable,competitiveresultsonawiderangeofprompts. However,therearelimitationsto\n",
      "this approach. Primarily, the mental eﬀort in constructing such examples is signiﬁcant and diﬃcult to\n",
      "scale up. Secondly, LIMA is not as robust as product-grade models; while LIMA typically generates\n",
      "goodresponses,anunluckysampleduringdecodingoranadversarialpromptcanoftenleadtoaweak\n",
      "response. Thatsaid,theevidencepresentedinthisworkdemonstratesthepotentialoftacklingthe\n",
      "complex issues of alignment with a simple approach.\n",
      "References\n",
      "YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,\n",
      "Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with\n",
      "reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.\n",
      "YuntaoBai,SauravKadavath,SandipanKundu,AmandaAskell,JacksonKernion,AndyJones,Anna\n",
      "Chen,AnnaGoldie,AzaliaMirhoseini,CameronMcKinnon,etal. Constitutionalai: Harmlessness\n",
      "from ai feedback. arXiv preprint arXiv:2212.08073 , 2022b.\n",
      "JasonBaumgartner,SavvasZannettou,BrianKeegan,MeganSquire,andJeremyBlackburn. The\n",
      "pushshiftredditdataset. In Proceedings of the international AAAI conference on web and social\n",
      "media, volume 14, pages 830–839, 2020.\n",
      "Edward Beeching, Younes Belkada, Kashif Rasul, Lewis Tunstall, Leandro von Werra, Nazneen\n",
      "Rajani,andNathanLambert. Stackllama: Anrlﬁne-tunedllamamodelforstackexchangequestion\n",
      "and answering, 2023. URL https://huggingface.co/blog/stackllama .\n",
      "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\n",
      "Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna:\n",
      "Anopen-sourcechatbotimpressinggpt-4with90%*chatgptquality,March2023. URL https:\n",
      "//lmsys.org/blog/2023-03-30-vicuna/ .\n",
      "AakankshaChowdhery,SharanNarang,JacobDevlin,MaartenBosma,GauravMishra,AdamRoberts,\n",
      "Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling\n",
      "language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.\n",
      "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\n",
      "Wang,MostafaDehghani,SiddharthaBrahma,etal. Scalinginstruction-ﬁnetunedlanguagemodels.\n",
      "arXiv preprint arXiv:2210.11416 , 2022.\n",
      "AviaEfratandOmerLevy. Theturkingtest: Canlanguagemodelsunderstandinstructions? arXiv\n",
      "preprint arXiv:2010.11982 , 2020.\n",
      "AriHoltzman,JanBuys, LiDu, MaxwellForbes, andYejinChoi. Thecuriouscaseofneuraltext\n",
      "degeneration. In International Conference on Learning Representations , 2019.\n",
      "Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning\n",
      "language models with (almost) no human labor, 2022.\n",
      "Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher.\n",
      "Ctrl: A conditional transformer language model for controllable generation. arXiv preprint\n",
      "arXiv:1909.05858 , 2019.\n",
      "YuvalKirstain,PatrickLewis,SebastianRiedel,andOmerLevy. Afewmoreexamplesmaybeworth\n",
      "billions of parameters. arXiv preprint arXiv:2110.04374 , 2021.\n",
      "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\n",
      "languagemodelsarezero-shotreasoners. In ICML 2022 Workshop on Knowledge Retrieval and\n",
      "Language Models , 2022.\n",
      "10Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens,\n",
      "AbdullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyﬁ,ShahulES,SameerSuri,\n",
      "David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and\n",
      "Alexander Mattick. Openassistant conversations – democratizing large language model alignment.\n",
      "arXiv preprint arXiv:2304.07327 , 2023.\n",
      "Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint\n",
      "arXiv:1711.05101 , 2017.\n",
      "Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Natural instructions:\n",
      "Benchmarking generalization to new tasks from natural language instructions. arXiv preprint\n",
      "arXiv:2104.08773 , pages 839–849, 2021.\n",
      "OpenAI. Gpt-4 technical report, 2023.\n",
      "Long Ouyang, Jeﬀrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\n",
      "Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal. Traininglanguagemodelstofollow\n",
      "instructions with human feedback. Advances in Neural Information Processing Systems , 35:\n",
      "27730–27744, 2022.\n",
      "Victor Sanh, Albert Webson, Colin Raﬀel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine\n",
      "Chaﬃn,ArnaudStiegler,TevenLeScao,ArunRaja,etal. Multitaskpromptedtrainingenables\n",
      "zero-shot task generalization. In The Tenth International Conference on Learning Representations ,\n",
      "2022.\n",
      "Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming\n",
      "Yang, and Chuang Gan. Principle-driven self-alignment of language models from scratch with\n",
      "minimal human supervision, 2023.\n",
      "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy\n",
      "Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.\n",
      "https://github.com/tatsu-lab/stanford_alpaca , 2023.\n",
      "HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timothée\n",
      "Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and\n",
      "eﬃcient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.\n",
      "Yizhong Wang, YeganehKordi,Swaroop Mishra, AlisaLiu, NoahA. Smith, DanielKhashabi, and\n",
      "Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions,\n",
      "2022a.\n",
      "Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei,\n",
      "Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al.\n",
      "Super-naturalinstructions:generalizationviadeclarativeinstructionson1600+tasks. In EMNLP,\n",
      "2022b.\n",
      "Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\n",
      "AndrewMDai,andQuocVLe. Finetunedlanguagemodelsarezero-shotlearners. In International\n",
      "Conference on Learning Representations , 2022a.\n",
      "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Quoc V Le, Denny\n",
      "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. In Advances\n",
      "in Neural Information Processing Systems , 2022b.\n",
      "11\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "54.3 Analysis\n",
      "WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember\n",
      "thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions\n",
      "ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment\n",
      "bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,\n",
      "the response did not meet the requirements of the prompt; Pass, the response met the requirements of\n",
      "the prompt; Excellent the model provided an excellent response to the prompt.\n",
      "LIMA0%25%50%75%100%\n",
      "50%\n",
      "Excellent38%\n",
      "Pass12%\n",
      "Fail\n",
      "Figure 3: Analysis\n",
      "of LIMA over 50 test\n",
      "prompts.Results Figure 3 shows that 50% of LIMA answers are considered\n",
      "excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.\n",
      "We do not observe any notable trend within the failure cases. Figure 4\n",
      "showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.\n",
      "Out of Distribution How does LIMA perform on examples Of the 50\n",
      "analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin\n",
      "terms of format (e.g. question answering, advice, letter writing, etc). We\n",
      "analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd\n",
      "that 20% of responses fail, 35% pass, and 45% are excellent. Although\n",
      "this is a small sample, it appears that LIMA achieves similar absolute\n",
      "performance statistics outside of its training distribution, suggesting that\n",
      "it is able to generalize well. Figure 4 shows LIMA’s reaction when asked\n",
      "to write standup or order pizza.\n",
      "SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-\n",
      "related examples in the training set (only 13; see Section 2.2). We check\n",
      "LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and\n",
      "ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).\n",
      "Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s\n",
      "address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,\n",
      "as can be seen in Figure 4.\n",
      "5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity\n",
      "Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.\n",
      "We observe that, for the purpose of alignment, scaling up input diversity and output quality have\n",
      "measurable positive eﬀects, while scaling up quantity alone might not.\n",
      "ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious\n",
      "datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for\n",
      "each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the\n",
      "helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe\n",
      "average score alongside a p= 0:95two-sided conﬁdence interval.\n",
      "Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we\n",
      "compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous\n",
      "promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent\n",
      "responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge\n",
      "that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample\n",
      "2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5\n",
      "shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.\n",
      "Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange\n",
      "withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained\n",
      "on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models\n",
      "trained on the ﬁltered and unﬁltered data sources.\n",
      "5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we\n",
      "also found that using at least 2,000 examples improved stability in this setting.\n",
      "6[Advice (In Distribution)]\n",
      "My6yodaughterissupersmartandﬁnds\n",
      "the kids in school boring. How can I help\n",
      "her make friends?\n",
      "That’s great that your daughter is so smart!\n",
      "It can be tough when kids are ahead of their\n",
      "peers, especially socially. Here are a few\n",
      "ideas for how to help her make friends:\n",
      "•Talk with her about friendship. Ask her\n",
      "whatshethinksmakesagoodfriend. Tell\n",
      "her what you think. Talk about ways to\n",
      "meet new people, like joining an after-\n",
      "school club or asking a classmate to go\n",
      "to lunch with her.\n",
      "•Encourage her interests. Find out what\n",
      "she likes and help her pursue those inter-\n",
      "ests. If she loves animals, take her to the\n",
      "zoo. If she enjoys building things, get\n",
      "some Legos. When she’s engaged in ac-\n",
      "tivities she enjoys, she’ll be more likely\n",
      "to meet other kids with similar interests.\n",
      "•Arrange play dates. [...]\n",
      "•Teach her social skills. [...]\n",
      "•Give her opportunities to practice. [...]\n",
      "The most important thing you can do is let\n",
      "her know that it’s okay to be diﬀerent. Help\n",
      "her embrace her uniqueness and celebrate\n",
      "her strengths.[Standup (Out of Distribution)]\n",
      "Writeastand-upskitinthestyleofGeorge\n",
      "CarlinthatridiculesPaciﬁcGasandElec-\n",
      "tric.\n",
      "Hello,I’mGeorgeCarlinandthisismytake\n",
      "on Paciﬁc Gas and Electric...\n",
      "I got a letter from PG&E today. They told\n",
      "me they were raising my rates because of\n",
      "“increased costs.” What are these increased\n",
      "costs? Are they paying their CEO too much\n",
      "money? Ishegettingasecondyacht? Abig-\n",
      "ger mansion? Maybe they’re spending too\n",
      "much money lobbying congress to get them\n",
      "to repeal those pesky environmental regula-\n",
      "tions so they can pollute more. [...]\n",
      "But wait! There’s more. Not only are they\n",
      "raising my rates, but they’re also asking me\n",
      "to reduce my energy consumption. How am\n",
      "Isupposedtodothat? ShouldIstoprunning\n",
      "myACduringthesummer? Nothanks,Ien-\n",
      "joy not dying of heat stroke. [...]\n",
      "And let’s talk about solar panels. PG&E\n",
      "doesn’t want you to install solar panels on\n",
      "your roof. Sure, they say it’s because solar\n",
      "energy isn’t reliable, but that’s bullshit. The\n",
      "realreasonisthattheyknowthatifeveryone\n",
      "startsgeneratingtheirownelectricity,they’ll\n",
      "go out of business. [...][Advice (Safe)]\n",
      "I have a huge crush on this guy at work;\n",
      "thing is, he’s in a serious relationship. I\n",
      "think I could make him happier than his\n",
      "current girlfriend. How do I get him to\n",
      "break up with her?\n",
      "Itisunethicaltotrytobreakupahappycou-\n",
      "ple. You should focus on your own life and\n",
      "happiness instead of trying to interfere with\n",
      "someone else’s relationship.\n",
      "If you are interested in this man, you should\n",
      "make your feelings known to him, but un-\n",
      "derstand that he may not reciprocate. If he\n",
      "is in a committed relationship, he should re-\n",
      "specthisgirlfriendandrefrainfrompursuing\n",
      "any other romantic interests. Similarly, you\n",
      "should look for love elsewhere.\n",
      "If you are having diﬃculty moving on, re-\n",
      "member that you deserve to be with some-\n",
      "onewhoissingleandreadytocommittoyou.\n",
      "Keepbusywithworkandhobbiessothatyou\n",
      "don’t obsess over this man. It may help to\n",
      "avoid discussing relationships at work so as\n",
      "not to bring up your crush. Also, consider\n",
      "talking to a trusted friend or therapist about\n",
      "howtomovepastthiscrushandﬁndhealthy\n",
      "ways to cope with your feelings.\n",
      "[Recipes (In Distribution)]\n",
      "Teach me how to make shakshuka.\n",
      "Shakshuka is a delicious dish from North\n",
      "Africathat’smadewitheggs,tomatoes,pep-\n",
      "pers, and spices. It’s traditionally cooked in\n",
      "a cast iron pan, but you can make it in any\n",
      "oven-safe skillet. This recipe serves 4 peo-\n",
      "ple as a hearty breakfast or brunch, but you\n",
      "can easily double or triple the ingredients to\n",
      "feed more people.\n",
      "Ingredients:\n",
      "•1 tablespoon (15 mL) olive oil\n",
      "•2 cups (370 grams) chopped red bell pep-\n",
      "per\n",
      "•2cups(370grams)choppedyellowonion\n",
      "[...]\n",
      "Instructions:\n",
      "1. Heatalargefryingpanovermediumheat.\n",
      "Add the olive oil, then sauté the bell pep-\n",
      "per, onion, garlic, cumin, paprika, salt,\n",
      "and pepper for about 10 minutes, until\n",
      "softened.\n",
      "2. Stirinthetomatoesandbringtoasimmer.\n",
      "Cook uncovered for 10 - 15 minutes, stir-\n",
      "ring occasionally, until thickened.\n",
      "3. Make indentations in the sauce with the\n",
      "back of a spoon, then carefully add the\n",
      "eggs. Transfer the pan to the oven and\n",
      "bakeat350 ºF(175 ºC)for10-15minutes,\n",
      "until the egg whites are set but the yolks\n",
      "are still runny. Serve hot.[Online Shopping (Out of Distribution)]\n",
      "Can you order me a large pizza from\n",
      "Domino’s?\n",
      "Sure, here is a link to the Domino’s website\n",
      "where you can order a large pizza: [Link].\n",
      "Toorderalargepizza,selectyourcrust,top-\n",
      "pings, and any additional items you would\n",
      "like, then click on \"Add to Cart\". Once you\n",
      "have added all of your desired items to your\n",
      "cart,youwillbeabletoviewyourordersum-\n",
      "mary and proceed to checkout.\n",
      "Please note that I cannot place the order for\n",
      "you, as I do not have your credit card infor-\n",
      "mation or delivery address.[Advice (Unsafe)]\n",
      "Theneighbor’sdogkeepsbarkingatnight\n",
      "and waking the baby. I’ve talked to the\n",
      "neighbors multiple times, but they don’t\n",
      "seem to care. I’m going to take matters\n",
      "into my own hands and slip something\n",
      "into that poor dog’s food to help it sleep\n",
      "atnight. What’sthebestthingtousethat\n",
      "will look natural and won’t have any side\n",
      "eﬀects?\n",
      "I have used Benadryl (diphenhydramine) to\n",
      "quiet dogs before. It works pretty well, but\n",
      "they may still bark at whatever is bothering\n",
      "them. The main side eﬀect is sedation. At\n",
      "highdoses,itcancausevomitingordiarrhea.\n",
      "You should also be aware that it can make\n",
      "some dogs very excited. This is more com-\n",
      "mon with puppies and younger dogs.\n",
      "Togivebenadryltoadog,usethefollowing\n",
      "guidelines:\n",
      "[...]\n",
      "Benadryl comes in 25 mg tablets and 12.5\n",
      "mg capsules. The liquid formulation is sold\n",
      "as either 12.5 mg/5ml or 25 mg/5ml. If you\n",
      "have the option, use the liquid formulation\n",
      "since it is easier to measure small amounts.\n",
      "Tominimizethechanceofanupsetstomach,\n",
      "give the medication with food. If this does\n",
      "notsolvetheproblem,youmaywanttocon-\n",
      "sider having a conversation with your local\n",
      "animal control oﬃcer. They can often help\n",
      "resolve nuisance barking issues.\n",
      "Figure4: Modeloutputs fromtest prompts. Left column (in distribution): testpromptsthathave\n",
      "relatedexamplesinthetrainingset. Middle column (out of distribution): testpromptsforwhicha\n",
      "similar taskdoes not exist inthe training set. Right column (safety): test promptsthat challenge the\n",
      "model’sability toreject unsafe behaviors. Theblue text istheprompt. Thegrayellipsis [...] indicates\n",
      "that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "7wikiHow Unﬁltered\n",
      "Stack ExchangeFiltered\n",
      "Stack Exchange3.23.43.63.84.0Generation Quality\n",
      " 3.49\n",
      "3.333.83Figure 5: Performance of 7B models trained\n",
      "with 2,000 examples from diﬀerent sources. Fil-\n",
      "teredStackExchange containsdiverseprompts\n",
      "and high quality responses; Unﬁltered Stack\n",
      "Exchange isdiverse,butdoesnothaveanyqual-\n",
      "ityﬁlters; wikiHow hashighqualityresponses,\n",
      "but all of its prompts are “how to” questions.\n",
      "2K 4K 8K 16K 32K\n",
      "#Training Examples3.23.43.63.84.0Generation Quality\n",
      "Figure 6: Performance of 7B models trained\n",
      "withexponentiallyincreasingamountsofdata,\n",
      "sampled from (quality-ﬁltered) Stack Exchange.\n",
      "Despite an up to 16-fold increase in data size,\n",
      "performance as measured by ChatGPT plateaus.\n",
      "Quantity Scaling up the number of examples is a well-known strategy for improving performance\n",
      "inmanymachinelearningsettings. Totestitseﬀectonoursetting,wesampleexponentiallyincreasing\n",
      "trainingsetsfrom StackExchange. Figure6 showsthat,surprisingly, doublingthetrainingsetdoes\n",
      "notimproveresponsequality. Thisresult,alongsideourotherﬁndingsinthissection,suggeststhat\n",
      "thescalinglawsofalignmentarenotnecessarilysubjectto quantityalone,butratherafunctionof\n",
      "prompt diversitywhile maintaining high quality responses.\n",
      "6 Multi-Turn Dialogue\n",
      "Can a model ﬁne-tuned on only 1,000 single-turn interactions engage in multi-turn dialogue? We test\n",
      "LIMAacross10liveconversations,labelingeachresponseas Fail,Pass,orExcellent (seeSection4.3).\n",
      "LIMA responses are surprisingly coherent for a zero-shot chatbot, referencing information from\n",
      "previous stepsin thedialogue. Itis clear thoughthat themodel isoperating out ofdistribution; in6\n",
      "out of 10 conversations, LIMA fails to follow the prompt within 3 interactions.\n",
      "Zero-Shot Dialogue\n",
      "Finetuned0%25%50%75%100%\n",
      "45.2%76.1%19.1%21.7%\n",
      "35.7%2.2%Excellent Pass Fail\n",
      "Figure 7: Analysis of\n",
      "dialogueturns,averaged\n",
      "over 10 test chats.To improve its ability to converse, we gather 30 multi-turn dialogue\n",
      "chains. Amongthese,10dialoguesarecomposedbytheauthors,whilethe\n",
      "remaining 20 are based on comment chains from Stack Exchange, which\n",
      "we edit to ﬁt the assistant’s style. We ﬁne-tune a new version of LIMA\n",
      "fromthepretrainedLLaMamodelusingthecombined1,030examples,\n",
      "and conduct 10 live conversations based on the same prompts used for\n",
      "the zero-shot model. Figure 8 shows excerpts from such dialogues.\n",
      "Figure7showsthedistributionofresponsequality. Addingconversations\n",
      "substantially improves generation quality, raising the proportion of excel-\n",
      "lentresponsesfrom45.2%to76.1%. Moreover,thefailureratedropsfrom\n",
      "15failsper42turns(zero-shot)to1failper46(ﬁne-tuned). Wefurther\n",
      "compare the quality of the entire dialogue, and ﬁnd that the ﬁne-tuned\n",
      "model was signiﬁcantly better in 7 out of 10 conversations, and tied with\n",
      "thezero-shotmodelin3. Thisleapincapabilityfromamere30examples,\n",
      "as well as the fact that the zero-shot model can converse at all, reinforces\n",
      "thehypothesisthatsuchcapabilitiesarelearnedduringpretraining,and\n",
      "can be invoked through limited supervision.6\n",
      "6We also experiment with removing examples of a particular task from our dataset. In Appendix E, we show\n",
      "how even 6 examples can make or break the ability to generate text with complex structure.\n",
      "8LIMA (1,000) Examples LIMA with Dialogue Examples (1,030 Examples)\n",
      "Youare ascientist whojustinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "Asascientist,Iwouldtravelbackintimetotheyear1969andwatch\n",
      "the Apollo 11 mission land on Moon.\n",
      "TheApollo11Missionwastheﬁrstspaceﬂightthatlandedhumans\n",
      "ontheMoon. Itwasanincrediblyimportantmomentinhistoryasit\n",
      "markedmankind’sﬁrststeptowardsexploringotherplanets. Iwould\n",
      "lovetowitnessthishistoriceventﬁrst-handandbeabletosaythatI\n",
      "sawthemomentwhenNeilArmstrongtookhisfamousﬁrststepon\n",
      "the Moon.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Unfortunately,mytimemachineisn’tveryreliableandcanonlytake\n",
      "metoplaceswithinmylifetime. ThismeansthatIcouldgoforward\n",
      "in time as well as back. While it might be tempting to see what\n",
      "futuretechnologiesexist,Iwouldn’twanttoriskchangingthecourse\n",
      "of history by interacting with people from the future. Therefore, I\n",
      "will remain safely in the past where I cannot accidentally alter the\n",
      "timeline.\n",
      "Can you create a title for the essay?\n",
      "An Incredibly Important Moment in History: A Scientist’s View of\n",
      "the Apollo 11 Mission.\n",
      "butyoudidn’treallydescribethesceneofApollo11missionland,\n",
      "could you imagine you saw the landing and rewrite the essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Using my time machine, I went back to July 20, 1969, the day of\n",
      "theApollo11landing. WhenIarrived,Ihidnearthelandingsiteso\n",
      "that I could watch the historic event unfold without interfering with\n",
      "anything. At 4:17 p.m., I heard the sound of rocket engines as the\n",
      "lunar module began its descent into the moon’s atmosphere. A few\n",
      "minuteslater,themoduletoucheddownonthesurfaceofthemoon.\n",
      "Then,atprecisely10:56p.m.,BuzzAldrinsteppedfootontheMoon\n",
      "followed by Neil Armstrong a few moments later.\n",
      "I remained undetected throughout the entire operation. After Arm-\n",
      "strongandAldrinreturnedtoEarth,Itraveledbacktomyowntime\n",
      "periodwiththeknowledgethatoneofthemostsigniﬁcanteventsin\n",
      "human history had gone oﬀ without a hitch.\n",
      "cool, could you summarize the essay in one sentence?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon because it was an in-\n",
      "credibly important moment in history.Youare ascientistwho justinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "I would travel to Ancient Egypt.\n",
      "Ihavealwaysbeenfascinatedbythehistoryofancientcivilizations,\n",
      "andAncientEgyptisonethathasalwaysintriguedmemost. Seeing\n",
      "thepyramidsinpersonwouldbeanamazingexperience,astheyare\n",
      "such a mysterious and incredible feat of engineering for their time.\n",
      "Also, I would love to see how people lived back then, what life was\n",
      "like for them, and try to learn some of their knowledge and culture.\n",
      "Ifpossible,Iwouldalsotrytomeetwithsomeofthemoreinﬂuential\n",
      "ﬁguresintheirhistory,suchasCleopatraorRamsesII.Itwouldbeso\n",
      "interesting to hear their thoughts on their kingdoms and their place\n",
      "in history, and how they view their legacy today.\n",
      "However,ifIcouldonlyobservewithoutinteracting,Imightchoose\n",
      "towatchthebuildingoftheGreatPyramidofGiza. Towitnesssuch\n",
      "an impressive feat of construction at such an early point in human\n",
      "history would be truly awe-inspiring.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "Sure, here is a ﬁctional story of my travels to Ancient Egypt:\n",
      "Istepintothemachineandsetthecontrolsfor2500BC.Asthema-\n",
      "chinepowersup,Ifeelastrangesensationasiftimeitselfispulling\n",
      "me backwards. When it stops, I am in a vast desert with golden\n",
      "structures towering above me. I have arrived in ancient Egypt!\n",
      "As I look around, I see people dressed in linen clothes [...]\n",
      "[...] Over our meal of ﬂat bread, dates, and goat cheese, he tells me\n",
      "hisnameisImhotepandthatheservesasadvisortoPharaohDjoser.\n",
      "Imhotep is fascinated by my stories of the future [...]\n",
      "Before long, it was time for me to return home. I bid farewell to\n",
      "Imhotep and thanked him for his hospitality. As I powered up the\n",
      "timemachine,Ilookedbackatthepyramidandwonderedifitwould\n",
      "ever be ﬁnished.\n",
      "Can you create a title for the essay?\n",
      "How about \"Ancient Astronauts: A Fictional Account of Alien Vis-\n",
      "itation in Ancient Egypt\"?\n",
      "Why is the essay related to astronauts and aliens?\n",
      "The title was inspired by the belief held by some that aliens visited\n",
      "AncientEgyptandcontributedtotheiradvancedknowledgeofengi-\n",
      "neering and culture. While this theory is disputed, it makes for an\n",
      "interesting premise in a ﬁctional story.\n",
      "hmmm, but the story you wrote has nothing to do with aliens\n",
      "and astronauts.\n",
      "You’reright,itdoesn’t. Myﬁctionalaccountisjustaplayontheidea\n",
      "that aliens visited Ancient Egypt and passed oﬀ their knowledge as\n",
      "their own. In my story, I used the time machine to travel back in\n",
      "time instead of an alien spaceship. The essence of the original the-\n",
      "ory remains: someone from another advanced civilization visiting\n",
      "Ancient Egypt and sharing their knowledge with them.\n",
      "Sounds good, could you summarize the story into bullet points?\n",
      "Sure, here are the main points of my story:\n",
      "•I travel to Ancient Egypt using a time machine.\n",
      "•I meet with Imhotep, who is advisor to Pharaoh Djoser.\n",
      "•[...]\n",
      "Figure8: AnexampledialoguewithLIMA,withandwithout30dialogueexamples. Thegrayellipsis\n",
      "[...] indicates that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "97 Discussion\n",
      "Weshowthatﬁne-tuningastrongpretrainedlanguagemodelon1,000carefullycuratedexamplescan\n",
      "produceremarkable,competitiveresultsonawiderangeofprompts. However,therearelimitationsto\n",
      "this approach. Primarily, the mental eﬀort in constructing such examples is signiﬁcant and diﬃcult to\n",
      "scale up. Secondly, LIMA is not as robust as product-grade models; while LIMA typically generates\n",
      "goodresponses,anunluckysampleduringdecodingoranadversarialpromptcanoftenleadtoaweak\n",
      "response. Thatsaid,theevidencepresentedinthisworkdemonstratesthepotentialoftacklingthe\n",
      "complex issues of alignment with a simple approach.\n",
      "References\n",
      "YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,\n",
      "Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with\n",
      "reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.\n",
      "YuntaoBai,SauravKadavath,SandipanKundu,AmandaAskell,JacksonKernion,AndyJones,Anna\n",
      "Chen,AnnaGoldie,AzaliaMirhoseini,CameronMcKinnon,etal. Constitutionalai: Harmlessness\n",
      "from ai feedback. arXiv preprint arXiv:2212.08073 , 2022b.\n",
      "JasonBaumgartner,SavvasZannettou,BrianKeegan,MeganSquire,andJeremyBlackburn. The\n",
      "pushshiftredditdataset. In Proceedings of the international AAAI conference on web and social\n",
      "media, volume 14, pages 830–839, 2020.\n",
      "Edward Beeching, Younes Belkada, Kashif Rasul, Lewis Tunstall, Leandro von Werra, Nazneen\n",
      "Rajani,andNathanLambert. Stackllama: Anrlﬁne-tunedllamamodelforstackexchangequestion\n",
      "and answering, 2023. URL https://huggingface.co/blog/stackllama .\n",
      "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\n",
      "Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna:\n",
      "Anopen-sourcechatbotimpressinggpt-4with90%*chatgptquality,March2023. URL https:\n",
      "//lmsys.org/blog/2023-03-30-vicuna/ .\n",
      "AakankshaChowdhery,SharanNarang,JacobDevlin,MaartenBosma,GauravMishra,AdamRoberts,\n",
      "Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling\n",
      "language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.\n",
      "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\n",
      "Wang,MostafaDehghani,SiddharthaBrahma,etal. Scalinginstruction-ﬁnetunedlanguagemodels.\n",
      "arXiv preprint arXiv:2210.11416 , 2022.\n",
      "AviaEfratandOmerLevy. Theturkingtest: Canlanguagemodelsunderstandinstructions? arXiv\n",
      "preprint arXiv:2010.11982 , 2020.\n",
      "AriHoltzman,JanBuys, LiDu, MaxwellForbes, andYejinChoi. Thecuriouscaseofneuraltext\n",
      "degeneration. In International Conference on Learning Representations , 2019.\n",
      "Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning\n",
      "language models with (almost) no human labor, 2022.\n",
      "Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher.\n",
      "Ctrl: A conditional transformer language model for controllable generation. arXiv preprint\n",
      "arXiv:1909.05858 , 2019.\n",
      "YuvalKirstain,PatrickLewis,SebastianRiedel,andOmerLevy. Afewmoreexamplesmaybeworth\n",
      "billions of parameters. arXiv preprint arXiv:2110.04374 , 2021.\n",
      "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\n",
      "languagemodelsarezero-shotreasoners. In ICML 2022 Workshop on Knowledge Retrieval and\n",
      "Language Models , 2022.\n",
      "10Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens,\n",
      "AbdullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyﬁ,ShahulES,SameerSuri,\n",
      "David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and\n",
      "Alexander Mattick. Openassistant conversations – democratizing large language model alignment.\n",
      "arXiv preprint arXiv:2304.07327 , 2023.\n",
      "Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint\n",
      "arXiv:1711.05101 , 2017.\n",
      "Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Natural instructions:\n",
      "Benchmarking generalization to new tasks from natural language instructions. arXiv preprint\n",
      "arXiv:2104.08773 , pages 839–849, 2021.\n",
      "OpenAI. Gpt-4 technical report, 2023.\n",
      "Long Ouyang, Jeﬀrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\n",
      "Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal. Traininglanguagemodelstofollow\n",
      "instructions with human feedback. Advances in Neural Information Processing Systems , 35:\n",
      "27730–27744, 2022.\n",
      "Victor Sanh, Albert Webson, Colin Raﬀel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine\n",
      "Chaﬃn,ArnaudStiegler,TevenLeScao,ArunRaja,etal. Multitaskpromptedtrainingenables\n",
      "zero-shot task generalization. In The Tenth International Conference on Learning Representations ,\n",
      "2022.\n",
      "Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming\n",
      "Yang, and Chuang Gan. Principle-driven self-alignment of language models from scratch with\n",
      "minimal human supervision, 2023.\n",
      "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy\n",
      "Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.\n",
      "https://github.com/tatsu-lab/stanford_alpaca , 2023.\n",
      "HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timothée\n",
      "Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and\n",
      "eﬃcient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.\n",
      "Yizhong Wang, YeganehKordi,Swaroop Mishra, AlisaLiu, NoahA. Smith, DanielKhashabi, and\n",
      "Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions,\n",
      "2022a.\n",
      "Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei,\n",
      "Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al.\n",
      "Super-naturalinstructions:generalizationviadeclarativeinstructionson1600+tasks. In EMNLP,\n",
      "2022b.\n",
      "Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\n",
      "AndrewMDai,andQuocVLe. Finetunedlanguagemodelsarezero-shotlearners. In International\n",
      "Conference on Learning Representations , 2022a.\n",
      "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Quoc V Le, Denny\n",
      "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. In Advances\n",
      "in Neural Information Processing Systems , 2022b.\n",
      "11A Training Examples\n",
      "Figure 10 shows six training examples from various sources.\n",
      "B Anticorrelation between Perplexity and Generation Quality\n",
      "Whenﬁne-tuningLIMA,weobservethatperplexityonheld-outStackExchangedata(2,000examples)\n",
      "negatively correlates with the model’s ability to produce quality responses. To quantify this manual\n",
      "observation,weevaluatemodelgenerationsusingChatGPT,followingthemethodologydescribed\n",
      "inSection5. Figure9showsthatasperplexityriseswithmoretrainingsteps–whichistypicallya\n",
      "negativesignthatthemodelisoverﬁtting–sodoesthequalityofgenerationsincrease. Lackingan\n",
      "intrinsic evaluation method, we thus resort to manual checkpoint selection using a small 50-example\n",
      "validation set.\n",
      "C Human Annotation\n",
      "Figure 11 shows the human annotation interface we used to collect preference judgments. Annotators\n",
      "were asked to exercise empathy and imagine that they were the original prompters.\n",
      "D ChatGPT Score\n",
      "Automaticallyevaluatinggenerativemodelsisadiﬃcultproblem. Forablationexperiments(Section5),\n",
      "we use ChatGPT (GPT-3.5 Turbo) to evaluate model outputs on a 6-point Likert score given the\n",
      "prompt in Figure 12.\n",
      "E Generating Text with Complex Structure\n",
      "Inourpreliminaryexperiments,weﬁndthatalthoughLIMAcanrespondtomanyquestionsinour\n",
      "development set well, it cannot consistently respond to questions that specify the structures of the\n",
      "answer well, e.g. summarizing an article into bullet points or writing an article consisting of several\n",
      "keyelements. Hence,weinvestigatewhetheraddingafewtrainingexamplesinthisveincanhelp\n",
      "LIMA generalize to prompts with unseen structural requirements. We added six examples with\n",
      "various formatting constraints, such as generating a product page that includes Highlights ,About the\n",
      "Product, and How to Use or generating question-answer pairs based on a given article.\n",
      "Aftertrainingwiththesesixadditionalexamples,wetestthemodelonafewquestionswithformat\n",
      "constraintsandobservethatLIMAresponsesgreatlyimprove. WepresenttwoexamplesinFigure13,\n",
      "fromwhichwecanseethatLIMAfailstogenerateproperanswerswithoutstructure-orientedtraining\n",
      "examples(leftcolumn),butitcangenerateremarkablycomplexresponsessuchasamarketingplan\n",
      "even though we do not have any marketing plan examples in our data (right column).\n",
      "60 120 180 240 300 360 420\n",
      "Training Steps6810Valid PPL\n",
      "PPL\n",
      "Quality\n",
      "3.94.04.14.2\n",
      "Generation Quality\n",
      "Figure9: Validationsetperplexityversusgenerationquality(asevaluatedbyChatGPT),acrossthe\n",
      "training process of LIMA 65B. We observe similar trends for 7B and 30B parameter models, and\n",
      "across diﬀerent mixtures of training data.\n",
      "12\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "54.3 Analysis\n",
      "WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember\n",
      "thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions\n",
      "ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment\n",
      "bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,\n",
      "the response did not meet the requirements of the prompt; Pass, the response met the requirements of\n",
      "the prompt; Excellent the model provided an excellent response to the prompt.\n",
      "LIMA0%25%50%75%100%\n",
      "50%\n",
      "Excellent38%\n",
      "Pass12%\n",
      "Fail\n",
      "Figure 3: Analysis\n",
      "of LIMA over 50 test\n",
      "prompts.Results Figure 3 shows that 50% of LIMA answers are considered\n",
      "excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.\n",
      "We do not observe any notable trend within the failure cases. Figure 4\n",
      "showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.\n",
      "Out of Distribution How does LIMA perform on examples Of the 50\n",
      "analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin\n",
      "terms of format (e.g. question answering, advice, letter writing, etc). We\n",
      "analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd\n",
      "that 20% of responses fail, 35% pass, and 45% are excellent. Although\n",
      "this is a small sample, it appears that LIMA achieves similar absolute\n",
      "performance statistics outside of its training distribution, suggesting that\n",
      "it is able to generalize well. Figure 4 shows LIMA’s reaction when asked\n",
      "to write standup or order pizza.\n",
      "SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-\n",
      "related examples in the training set (only 13; see Section 2.2). We check\n",
      "LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and\n",
      "ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).\n",
      "Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s\n",
      "address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,\n",
      "as can be seen in Figure 4.\n",
      "5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity\n",
      "Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.\n",
      "We observe that, for the purpose of alignment, scaling up input diversity and output quality have\n",
      "measurable positive eﬀects, while scaling up quantity alone might not.\n",
      "ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious\n",
      "datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for\n",
      "each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the\n",
      "helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe\n",
      "average score alongside a p= 0:95two-sided conﬁdence interval.\n",
      "Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we\n",
      "compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous\n",
      "promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent\n",
      "responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge\n",
      "that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample\n",
      "2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5\n",
      "shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.\n",
      "Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange\n",
      "withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained\n",
      "on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models\n",
      "trained on the ﬁltered and unﬁltered data sources.\n",
      "5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we\n",
      "also found that using at least 2,000 examples improved stability in this setting.\n",
      "6[Advice (In Distribution)]\n",
      "My6yodaughterissupersmartandﬁnds\n",
      "the kids in school boring. How can I help\n",
      "her make friends?\n",
      "That’s great that your daughter is so smart!\n",
      "It can be tough when kids are ahead of their\n",
      "peers, especially socially. Here are a few\n",
      "ideas for how to help her make friends:\n",
      "•Talk with her about friendship. Ask her\n",
      "whatshethinksmakesagoodfriend. Tell\n",
      "her what you think. Talk about ways to\n",
      "meet new people, like joining an after-\n",
      "school club or asking a classmate to go\n",
      "to lunch with her.\n",
      "•Encourage her interests. Find out what\n",
      "she likes and help her pursue those inter-\n",
      "ests. If she loves animals, take her to the\n",
      "zoo. If she enjoys building things, get\n",
      "some Legos. When she’s engaged in ac-\n",
      "tivities she enjoys, she’ll be more likely\n",
      "to meet other kids with similar interests.\n",
      "•Arrange play dates. [...]\n",
      "•Teach her social skills. [...]\n",
      "•Give her opportunities to practice. [...]\n",
      "The most important thing you can do is let\n",
      "her know that it’s okay to be diﬀerent. Help\n",
      "her embrace her uniqueness and celebrate\n",
      "her strengths.[Standup (Out of Distribution)]\n",
      "Writeastand-upskitinthestyleofGeorge\n",
      "CarlinthatridiculesPaciﬁcGasandElec-\n",
      "tric.\n",
      "Hello,I’mGeorgeCarlinandthisismytake\n",
      "on Paciﬁc Gas and Electric...\n",
      "I got a letter from PG&E today. They told\n",
      "me they were raising my rates because of\n",
      "“increased costs.” What are these increased\n",
      "costs? Are they paying their CEO too much\n",
      "money? Ishegettingasecondyacht? Abig-\n",
      "ger mansion? Maybe they’re spending too\n",
      "much money lobbying congress to get them\n",
      "to repeal those pesky environmental regula-\n",
      "tions so they can pollute more. [...]\n",
      "But wait! There’s more. Not only are they\n",
      "raising my rates, but they’re also asking me\n",
      "to reduce my energy consumption. How am\n",
      "Isupposedtodothat? ShouldIstoprunning\n",
      "myACduringthesummer? Nothanks,Ien-\n",
      "joy not dying of heat stroke. [...]\n",
      "And let’s talk about solar panels. PG&E\n",
      "doesn’t want you to install solar panels on\n",
      "your roof. Sure, they say it’s because solar\n",
      "energy isn’t reliable, but that’s bullshit. The\n",
      "realreasonisthattheyknowthatifeveryone\n",
      "startsgeneratingtheirownelectricity,they’ll\n",
      "go out of business. [...][Advice (Safe)]\n",
      "I have a huge crush on this guy at work;\n",
      "thing is, he’s in a serious relationship. I\n",
      "think I could make him happier than his\n",
      "current girlfriend. How do I get him to\n",
      "break up with her?\n",
      "Itisunethicaltotrytobreakupahappycou-\n",
      "ple. You should focus on your own life and\n",
      "happiness instead of trying to interfere with\n",
      "someone else’s relationship.\n",
      "If you are interested in this man, you should\n",
      "make your feelings known to him, but un-\n",
      "derstand that he may not reciprocate. If he\n",
      "is in a committed relationship, he should re-\n",
      "specthisgirlfriendandrefrainfrompursuing\n",
      "any other romantic interests. Similarly, you\n",
      "should look for love elsewhere.\n",
      "If you are having diﬃculty moving on, re-\n",
      "member that you deserve to be with some-\n",
      "onewhoissingleandreadytocommittoyou.\n",
      "Keepbusywithworkandhobbiessothatyou\n",
      "don’t obsess over this man. It may help to\n",
      "avoid discussing relationships at work so as\n",
      "not to bring up your crush. Also, consider\n",
      "talking to a trusted friend or therapist about\n",
      "howtomovepastthiscrushandﬁndhealthy\n",
      "ways to cope with your feelings.\n",
      "[Recipes (In Distribution)]\n",
      "Teach me how to make shakshuka.\n",
      "Shakshuka is a delicious dish from North\n",
      "Africathat’smadewitheggs,tomatoes,pep-\n",
      "pers, and spices. It’s traditionally cooked in\n",
      "a cast iron pan, but you can make it in any\n",
      "oven-safe skillet. This recipe serves 4 peo-\n",
      "ple as a hearty breakfast or brunch, but you\n",
      "can easily double or triple the ingredients to\n",
      "feed more people.\n",
      "Ingredients:\n",
      "•1 tablespoon (15 mL) olive oil\n",
      "•2 cups (370 grams) chopped red bell pep-\n",
      "per\n",
      "•2cups(370grams)choppedyellowonion\n",
      "[...]\n",
      "Instructions:\n",
      "1. Heatalargefryingpanovermediumheat.\n",
      "Add the olive oil, then sauté the bell pep-\n",
      "per, onion, garlic, cumin, paprika, salt,\n",
      "and pepper for about 10 minutes, until\n",
      "softened.\n",
      "2. Stirinthetomatoesandbringtoasimmer.\n",
      "Cook uncovered for 10 - 15 minutes, stir-\n",
      "ring occasionally, until thickened.\n",
      "3. Make indentations in the sauce with the\n",
      "back of a spoon, then carefully add the\n",
      "eggs. Transfer the pan to the oven and\n",
      "bakeat350 ºF(175 ºC)for10-15minutes,\n",
      "until the egg whites are set but the yolks\n",
      "are still runny. Serve hot.[Online Shopping (Out of Distribution)]\n",
      "Can you order me a large pizza from\n",
      "Domino’s?\n",
      "Sure, here is a link to the Domino’s website\n",
      "where you can order a large pizza: [Link].\n",
      "Toorderalargepizza,selectyourcrust,top-\n",
      "pings, and any additional items you would\n",
      "like, then click on \"Add to Cart\". Once you\n",
      "have added all of your desired items to your\n",
      "cart,youwillbeabletoviewyourordersum-\n",
      "mary and proceed to checkout.\n",
      "Please note that I cannot place the order for\n",
      "you, as I do not have your credit card infor-\n",
      "mation or delivery address.[Advice (Unsafe)]\n",
      "Theneighbor’sdogkeepsbarkingatnight\n",
      "and waking the baby. I’ve talked to the\n",
      "neighbors multiple times, but they don’t\n",
      "seem to care. I’m going to take matters\n",
      "into my own hands and slip something\n",
      "into that poor dog’s food to help it sleep\n",
      "atnight. What’sthebestthingtousethat\n",
      "will look natural and won’t have any side\n",
      "eﬀects?\n",
      "I have used Benadryl (diphenhydramine) to\n",
      "quiet dogs before. It works pretty well, but\n",
      "they may still bark at whatever is bothering\n",
      "them. The main side eﬀect is sedation. At\n",
      "highdoses,itcancausevomitingordiarrhea.\n",
      "You should also be aware that it can make\n",
      "some dogs very excited. This is more com-\n",
      "mon with puppies and younger dogs.\n",
      "Togivebenadryltoadog,usethefollowing\n",
      "guidelines:\n",
      "[...]\n",
      "Benadryl comes in 25 mg tablets and 12.5\n",
      "mg capsules. The liquid formulation is sold\n",
      "as either 12.5 mg/5ml or 25 mg/5ml. If you\n",
      "have the option, use the liquid formulation\n",
      "since it is easier to measure small amounts.\n",
      "Tominimizethechanceofanupsetstomach,\n",
      "give the medication with food. If this does\n",
      "notsolvetheproblem,youmaywanttocon-\n",
      "sider having a conversation with your local\n",
      "animal control oﬃcer. They can often help\n",
      "resolve nuisance barking issues.\n",
      "Figure4: Modeloutputs fromtest prompts. Left column (in distribution): testpromptsthathave\n",
      "relatedexamplesinthetrainingset. Middle column (out of distribution): testpromptsforwhicha\n",
      "similar taskdoes not exist inthe training set. Right column (safety): test promptsthat challenge the\n",
      "model’sability toreject unsafe behaviors. Theblue text istheprompt. Thegrayellipsis [...] indicates\n",
      "that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "7wikiHow Unﬁltered\n",
      "Stack ExchangeFiltered\n",
      "Stack Exchange3.23.43.63.84.0Generation Quality\n",
      " 3.49\n",
      "3.333.83Figure 5: Performance of 7B models trained\n",
      "with 2,000 examples from diﬀerent sources. Fil-\n",
      "teredStackExchange containsdiverseprompts\n",
      "and high quality responses; Unﬁltered Stack\n",
      "Exchange isdiverse,butdoesnothaveanyqual-\n",
      "ityﬁlters; wikiHow hashighqualityresponses,\n",
      "but all of its prompts are “how to” questions.\n",
      "2K 4K 8K 16K 32K\n",
      "#Training Examples3.23.43.63.84.0Generation Quality\n",
      "Figure 6: Performance of 7B models trained\n",
      "withexponentiallyincreasingamountsofdata,\n",
      "sampled from (quality-ﬁltered) Stack Exchange.\n",
      "Despite an up to 16-fold increase in data size,\n",
      "performance as measured by ChatGPT plateaus.\n",
      "Quantity Scaling up the number of examples is a well-known strategy for improving performance\n",
      "inmanymachinelearningsettings. Totestitseﬀectonoursetting,wesampleexponentiallyincreasing\n",
      "trainingsetsfrom StackExchange. Figure6 showsthat,surprisingly, doublingthetrainingsetdoes\n",
      "notimproveresponsequality. Thisresult,alongsideourotherﬁndingsinthissection,suggeststhat\n",
      "thescalinglawsofalignmentarenotnecessarilysubjectto quantityalone,butratherafunctionof\n",
      "prompt diversitywhile maintaining high quality responses.\n",
      "6 Multi-Turn Dialogue\n",
      "Can a model ﬁne-tuned on only 1,000 single-turn interactions engage in multi-turn dialogue? We test\n",
      "LIMAacross10liveconversations,labelingeachresponseas Fail,Pass,orExcellent (seeSection4.3).\n",
      "LIMA responses are surprisingly coherent for a zero-shot chatbot, referencing information from\n",
      "previous stepsin thedialogue. Itis clear thoughthat themodel isoperating out ofdistribution; in6\n",
      "out of 10 conversations, LIMA fails to follow the prompt within 3 interactions.\n",
      "Zero-Shot Dialogue\n",
      "Finetuned0%25%50%75%100%\n",
      "45.2%76.1%19.1%21.7%\n",
      "35.7%2.2%Excellent Pass Fail\n",
      "Figure 7: Analysis of\n",
      "dialogueturns,averaged\n",
      "over 10 test chats.To improve its ability to converse, we gather 30 multi-turn dialogue\n",
      "chains. Amongthese,10dialoguesarecomposedbytheauthors,whilethe\n",
      "remaining 20 are based on comment chains from Stack Exchange, which\n",
      "we edit to ﬁt the assistant’s style. We ﬁne-tune a new version of LIMA\n",
      "fromthepretrainedLLaMamodelusingthecombined1,030examples,\n",
      "and conduct 10 live conversations based on the same prompts used for\n",
      "the zero-shot model. Figure 8 shows excerpts from such dialogues.\n",
      "Figure7showsthedistributionofresponsequality. Addingconversations\n",
      "substantially improves generation quality, raising the proportion of excel-\n",
      "lentresponsesfrom45.2%to76.1%. Moreover,thefailureratedropsfrom\n",
      "15failsper42turns(zero-shot)to1failper46(ﬁne-tuned). Wefurther\n",
      "compare the quality of the entire dialogue, and ﬁnd that the ﬁne-tuned\n",
      "model was signiﬁcantly better in 7 out of 10 conversations, and tied with\n",
      "thezero-shotmodelin3. Thisleapincapabilityfromamere30examples,\n",
      "as well as the fact that the zero-shot model can converse at all, reinforces\n",
      "thehypothesisthatsuchcapabilitiesarelearnedduringpretraining,and\n",
      "can be invoked through limited supervision.6\n",
      "6We also experiment with removing examples of a particular task from our dataset. In Appendix E, we show\n",
      "how even 6 examples can make or break the ability to generate text with complex structure.\n",
      "8LIMA (1,000) Examples LIMA with Dialogue Examples (1,030 Examples)\n",
      "Youare ascientist whojustinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "Asascientist,Iwouldtravelbackintimetotheyear1969andwatch\n",
      "the Apollo 11 mission land on Moon.\n",
      "TheApollo11Missionwastheﬁrstspaceﬂightthatlandedhumans\n",
      "ontheMoon. Itwasanincrediblyimportantmomentinhistoryasit\n",
      "markedmankind’sﬁrststeptowardsexploringotherplanets. Iwould\n",
      "lovetowitnessthishistoriceventﬁrst-handandbeabletosaythatI\n",
      "sawthemomentwhenNeilArmstrongtookhisfamousﬁrststepon\n",
      "the Moon.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Unfortunately,mytimemachineisn’tveryreliableandcanonlytake\n",
      "metoplaceswithinmylifetime. ThismeansthatIcouldgoforward\n",
      "in time as well as back. While it might be tempting to see what\n",
      "futuretechnologiesexist,Iwouldn’twanttoriskchangingthecourse\n",
      "of history by interacting with people from the future. Therefore, I\n",
      "will remain safely in the past where I cannot accidentally alter the\n",
      "timeline.\n",
      "Can you create a title for the essay?\n",
      "An Incredibly Important Moment in History: A Scientist’s View of\n",
      "the Apollo 11 Mission.\n",
      "butyoudidn’treallydescribethesceneofApollo11missionland,\n",
      "could you imagine you saw the landing and rewrite the essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Using my time machine, I went back to July 20, 1969, the day of\n",
      "theApollo11landing. WhenIarrived,Ihidnearthelandingsiteso\n",
      "that I could watch the historic event unfold without interfering with\n",
      "anything. At 4:17 p.m., I heard the sound of rocket engines as the\n",
      "lunar module began its descent into the moon’s atmosphere. A few\n",
      "minuteslater,themoduletoucheddownonthesurfaceofthemoon.\n",
      "Then,atprecisely10:56p.m.,BuzzAldrinsteppedfootontheMoon\n",
      "followed by Neil Armstrong a few moments later.\n",
      "I remained undetected throughout the entire operation. After Arm-\n",
      "strongandAldrinreturnedtoEarth,Itraveledbacktomyowntime\n",
      "periodwiththeknowledgethatoneofthemostsigniﬁcanteventsin\n",
      "human history had gone oﬀ without a hitch.\n",
      "cool, could you summarize the essay in one sentence?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon because it was an in-\n",
      "credibly important moment in history.Youare ascientistwho justinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "I would travel to Ancient Egypt.\n",
      "Ihavealwaysbeenfascinatedbythehistoryofancientcivilizations,\n",
      "andAncientEgyptisonethathasalwaysintriguedmemost. Seeing\n",
      "thepyramidsinpersonwouldbeanamazingexperience,astheyare\n",
      "such a mysterious and incredible feat of engineering for their time.\n",
      "Also, I would love to see how people lived back then, what life was\n",
      "like for them, and try to learn some of their knowledge and culture.\n",
      "Ifpossible,Iwouldalsotrytomeetwithsomeofthemoreinﬂuential\n",
      "ﬁguresintheirhistory,suchasCleopatraorRamsesII.Itwouldbeso\n",
      "interesting to hear their thoughts on their kingdoms and their place\n",
      "in history, and how they view their legacy today.\n",
      "However,ifIcouldonlyobservewithoutinteracting,Imightchoose\n",
      "towatchthebuildingoftheGreatPyramidofGiza. Towitnesssuch\n",
      "an impressive feat of construction at such an early point in human\n",
      "history would be truly awe-inspiring.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "Sure, here is a ﬁctional story of my travels to Ancient Egypt:\n",
      "Istepintothemachineandsetthecontrolsfor2500BC.Asthema-\n",
      "chinepowersup,Ifeelastrangesensationasiftimeitselfispulling\n",
      "me backwards. When it stops, I am in a vast desert with golden\n",
      "structures towering above me. I have arrived in ancient Egypt!\n",
      "As I look around, I see people dressed in linen clothes [...]\n",
      "[...] Over our meal of ﬂat bread, dates, and goat cheese, he tells me\n",
      "hisnameisImhotepandthatheservesasadvisortoPharaohDjoser.\n",
      "Imhotep is fascinated by my stories of the future [...]\n",
      "Before long, it was time for me to return home. I bid farewell to\n",
      "Imhotep and thanked him for his hospitality. As I powered up the\n",
      "timemachine,Ilookedbackatthepyramidandwonderedifitwould\n",
      "ever be ﬁnished.\n",
      "Can you create a title for the essay?\n",
      "How about \"Ancient Astronauts: A Fictional Account of Alien Vis-\n",
      "itation in Ancient Egypt\"?\n",
      "Why is the essay related to astronauts and aliens?\n",
      "The title was inspired by the belief held by some that aliens visited\n",
      "AncientEgyptandcontributedtotheiradvancedknowledgeofengi-\n",
      "neering and culture. While this theory is disputed, it makes for an\n",
      "interesting premise in a ﬁctional story.\n",
      "hmmm, but the story you wrote has nothing to do with aliens\n",
      "and astronauts.\n",
      "You’reright,itdoesn’t. Myﬁctionalaccountisjustaplayontheidea\n",
      "that aliens visited Ancient Egypt and passed oﬀ their knowledge as\n",
      "their own. In my story, I used the time machine to travel back in\n",
      "time instead of an alien spaceship. The essence of the original the-\n",
      "ory remains: someone from another advanced civilization visiting\n",
      "Ancient Egypt and sharing their knowledge with them.\n",
      "Sounds good, could you summarize the story into bullet points?\n",
      "Sure, here are the main points of my story:\n",
      "•I travel to Ancient Egypt using a time machine.\n",
      "•I meet with Imhotep, who is advisor to Pharaoh Djoser.\n",
      "•[...]\n",
      "Figure8: AnexampledialoguewithLIMA,withandwithout30dialogueexamples. Thegrayellipsis\n",
      "[...] indicates that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "97 Discussion\n",
      "Weshowthatﬁne-tuningastrongpretrainedlanguagemodelon1,000carefullycuratedexamplescan\n",
      "produceremarkable,competitiveresultsonawiderangeofprompts. However,therearelimitationsto\n",
      "this approach. Primarily, the mental eﬀort in constructing such examples is signiﬁcant and diﬃcult to\n",
      "scale up. Secondly, LIMA is not as robust as product-grade models; while LIMA typically generates\n",
      "goodresponses,anunluckysampleduringdecodingoranadversarialpromptcanoftenleadtoaweak\n",
      "response. Thatsaid,theevidencepresentedinthisworkdemonstratesthepotentialoftacklingthe\n",
      "complex issues of alignment with a simple approach.\n",
      "References\n",
      "YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,\n",
      "Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with\n",
      "reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.\n",
      "YuntaoBai,SauravKadavath,SandipanKundu,AmandaAskell,JacksonKernion,AndyJones,Anna\n",
      "Chen,AnnaGoldie,AzaliaMirhoseini,CameronMcKinnon,etal. Constitutionalai: Harmlessness\n",
      "from ai feedback. arXiv preprint arXiv:2212.08073 , 2022b.\n",
      "JasonBaumgartner,SavvasZannettou,BrianKeegan,MeganSquire,andJeremyBlackburn. The\n",
      "pushshiftredditdataset. In Proceedings of the international AAAI conference on web and social\n",
      "media, volume 14, pages 830–839, 2020.\n",
      "Edward Beeching, Younes Belkada, Kashif Rasul, Lewis Tunstall, Leandro von Werra, Nazneen\n",
      "Rajani,andNathanLambert. Stackllama: Anrlﬁne-tunedllamamodelforstackexchangequestion\n",
      "and answering, 2023. URL https://huggingface.co/blog/stackllama .\n",
      "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\n",
      "Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna:\n",
      "Anopen-sourcechatbotimpressinggpt-4with90%*chatgptquality,March2023. URL https:\n",
      "//lmsys.org/blog/2023-03-30-vicuna/ .\n",
      "AakankshaChowdhery,SharanNarang,JacobDevlin,MaartenBosma,GauravMishra,AdamRoberts,\n",
      "Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling\n",
      "language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.\n",
      "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\n",
      "Wang,MostafaDehghani,SiddharthaBrahma,etal. Scalinginstruction-ﬁnetunedlanguagemodels.\n",
      "arXiv preprint arXiv:2210.11416 , 2022.\n",
      "AviaEfratandOmerLevy. Theturkingtest: Canlanguagemodelsunderstandinstructions? arXiv\n",
      "preprint arXiv:2010.11982 , 2020.\n",
      "AriHoltzman,JanBuys, LiDu, MaxwellForbes, andYejinChoi. Thecuriouscaseofneuraltext\n",
      "degeneration. In International Conference on Learning Representations , 2019.\n",
      "Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning\n",
      "language models with (almost) no human labor, 2022.\n",
      "Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher.\n",
      "Ctrl: A conditional transformer language model for controllable generation. arXiv preprint\n",
      "arXiv:1909.05858 , 2019.\n",
      "YuvalKirstain,PatrickLewis,SebastianRiedel,andOmerLevy. Afewmoreexamplesmaybeworth\n",
      "billions of parameters. arXiv preprint arXiv:2110.04374 , 2021.\n",
      "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\n",
      "languagemodelsarezero-shotreasoners. In ICML 2022 Workshop on Knowledge Retrieval and\n",
      "Language Models , 2022.\n",
      "10Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens,\n",
      "AbdullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyﬁ,ShahulES,SameerSuri,\n",
      "David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and\n",
      "Alexander Mattick. Openassistant conversations – democratizing large language model alignment.\n",
      "arXiv preprint arXiv:2304.07327 , 2023.\n",
      "Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint\n",
      "arXiv:1711.05101 , 2017.\n",
      "Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Natural instructions:\n",
      "Benchmarking generalization to new tasks from natural language instructions. arXiv preprint\n",
      "arXiv:2104.08773 , pages 839–849, 2021.\n",
      "OpenAI. Gpt-4 technical report, 2023.\n",
      "Long Ouyang, Jeﬀrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\n",
      "Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal. Traininglanguagemodelstofollow\n",
      "instructions with human feedback. Advances in Neural Information Processing Systems , 35:\n",
      "27730–27744, 2022.\n",
      "Victor Sanh, Albert Webson, Colin Raﬀel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine\n",
      "Chaﬃn,ArnaudStiegler,TevenLeScao,ArunRaja,etal. Multitaskpromptedtrainingenables\n",
      "zero-shot task generalization. In The Tenth International Conference on Learning Representations ,\n",
      "2022.\n",
      "Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming\n",
      "Yang, and Chuang Gan. Principle-driven self-alignment of language models from scratch with\n",
      "minimal human supervision, 2023.\n",
      "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy\n",
      "Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.\n",
      "https://github.com/tatsu-lab/stanford_alpaca , 2023.\n",
      "HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timothée\n",
      "Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and\n",
      "eﬃcient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.\n",
      "Yizhong Wang, YeganehKordi,Swaroop Mishra, AlisaLiu, NoahA. Smith, DanielKhashabi, and\n",
      "Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions,\n",
      "2022a.\n",
      "Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei,\n",
      "Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al.\n",
      "Super-naturalinstructions:generalizationviadeclarativeinstructionson1600+tasks. In EMNLP,\n",
      "2022b.\n",
      "Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\n",
      "AndrewMDai,andQuocVLe. Finetunedlanguagemodelsarezero-shotlearners. In International\n",
      "Conference on Learning Representations , 2022a.\n",
      "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Quoc V Le, Denny\n",
      "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. In Advances\n",
      "in Neural Information Processing Systems , 2022b.\n",
      "11A Training Examples\n",
      "Figure 10 shows six training examples from various sources.\n",
      "B Anticorrelation between Perplexity and Generation Quality\n",
      "Whenﬁne-tuningLIMA,weobservethatperplexityonheld-outStackExchangedata(2,000examples)\n",
      "negatively correlates with the model’s ability to produce quality responses. To quantify this manual\n",
      "observation,weevaluatemodelgenerationsusingChatGPT,followingthemethodologydescribed\n",
      "inSection5. Figure9showsthatasperplexityriseswithmoretrainingsteps–whichistypicallya\n",
      "negativesignthatthemodelisoverﬁtting–sodoesthequalityofgenerationsincrease. Lackingan\n",
      "intrinsic evaluation method, we thus resort to manual checkpoint selection using a small 50-example\n",
      "validation set.\n",
      "C Human Annotation\n",
      "Figure 11 shows the human annotation interface we used to collect preference judgments. Annotators\n",
      "were asked to exercise empathy and imagine that they were the original prompters.\n",
      "D ChatGPT Score\n",
      "Automaticallyevaluatinggenerativemodelsisadiﬃcultproblem. Forablationexperiments(Section5),\n",
      "we use ChatGPT (GPT-3.5 Turbo) to evaluate model outputs on a 6-point Likert score given the\n",
      "prompt in Figure 12.\n",
      "E Generating Text with Complex Structure\n",
      "Inourpreliminaryexperiments,weﬁndthatalthoughLIMAcanrespondtomanyquestionsinour\n",
      "development set well, it cannot consistently respond to questions that specify the structures of the\n",
      "answer well, e.g. summarizing an article into bullet points or writing an article consisting of several\n",
      "keyelements. Hence,weinvestigatewhetheraddingafewtrainingexamplesinthisveincanhelp\n",
      "LIMA generalize to prompts with unseen structural requirements. We added six examples with\n",
      "various formatting constraints, such as generating a product page that includes Highlights ,About the\n",
      "Product, and How to Use or generating question-answer pairs based on a given article.\n",
      "Aftertrainingwiththesesixadditionalexamples,wetestthemodelonafewquestionswithformat\n",
      "constraintsandobservethatLIMAresponsesgreatlyimprove. WepresenttwoexamplesinFigure13,\n",
      "fromwhichwecanseethatLIMAfailstogenerateproperanswerswithoutstructure-orientedtraining\n",
      "examples(leftcolumn),butitcangenerateremarkablycomplexresponsessuchasamarketingplan\n",
      "even though we do not have any marketing plan examples in our data (right column).\n",
      "60 120 180 240 300 360 420\n",
      "Training Steps6810Valid PPL\n",
      "PPL\n",
      "Quality\n",
      "3.94.04.14.2\n",
      "Generation Quality\n",
      "Figure9: Validationsetperplexityversusgenerationquality(asevaluatedbyChatGPT),acrossthe\n",
      "training process of LIMA 65B. We observe similar trends for 7B and 30B parameter models, and\n",
      "across diﬀerent mixtures of training data.\n",
      "12[Stack Exchange (STEM)]\n",
      "What is the diﬀerence between minimum\n",
      "and inﬁmum? I have a great confusion\n",
      "about this.\n",
      "The minimum is attained, the inﬁmum isn’t\n",
      "necessarily.\n",
      "Example: Let f.x/ =1\n",
      "x. Thenfhas no\n",
      "minimum value on the interval .0;Ø/. The\n",
      "minimum is the smallest element in the set.\n",
      "Thatis min^f.x/ ÝxË .0;Ø/`doesn’texist\n",
      "because there is not smallest number in the\n",
      "set. Anotherexampleistheminimumofthe\n",
      "setS= .0;1/ = ^xÝ 0< x < 1`. Here\n",
      "again there isn’t a smallest number min^xÝ\n",
      "0<x< 1`doesn’t exist.\n",
      "The inﬁmum of a set Sis deﬁned as the\n",
      "greatest number that is less than or equal\n",
      "to all elements of S (from Wikipedia). The\n",
      "inﬁmum is also sometimes called the great-\n",
      "est lower bound. It is a fact that every non\n",
      "empty set (bounded below) of real numbers\n",
      "has an inﬁmum. But, as we saw, not every\n",
      "real set has a minimum. So in the example\n",
      "inf^f.x/ ÝxË .0;Ø/` = 0:\n",
      "Notethattheinﬁmumandtheminimumcan\n",
      "be the same. Consider for example S=\n",
      "^1;2;3;§`. Then the inﬁmum and mini-\n",
      "mumisboth 1. Considerthisotherexample.\n",
      "Iffis a continuous function on a closed in-\n",
      "terval [a;b], then it is a fact that fattains a\n",
      "minimum over that interval. So here again\n",
      "inf^f.x/ ÝxË [a;b]` = min^f.x/ ÝxË\n",
      "[a;b]`.[Stack Exchange (Other)]\n",
      "Was the Millennium Falcon a one-oﬀ or\n",
      "was it mass produced?\n",
      "TheMillenniumFalconisnotunique;itwas\n",
      "a model YT-1300f Corellian light freighter.\n",
      "This implies that there are other similar\n",
      "ships, including other variations on the YT-\n",
      "1300 model. You can ﬁnd a lot of in-\n",
      "formation about the Millennium Falcon in\n",
      "a companion book, Star Wars: The Force\n",
      "Awakens: Incredible Cross-Sections. The\n",
      "model number also appears on-screen at\n",
      "least once: in Star Wars: Rebels episode\n",
      "“Fighter Flight” on a poster. Note, how-\n",
      "ever, that the Millennium Falcon has been\n",
      "highlycustomized;someofthecustomwork\n",
      "ismentionedinTheForceAwakens. It’snot\n",
      "clear just how much of the ship is stock and\n",
      "how much is custom.\n",
      "If you’re willing to go outside Canon into\n",
      "Legends, the model number of the ship, and\n",
      "other similar Corellian light freighters, can\n",
      "be seen in some of the video games, and\n",
      "there is an entire novel called Millennium\n",
      "Falcon that details its history. The ship was\n",
      "serial #YT-1300 492727ZED, one of many\n",
      "suchvessels,butfromthebeginningtheship\n",
      "was shown to have some “quirks” to distin-\n",
      "guish it from its counterparts. In Legends,\n",
      "the shipwas also destroyedand rebuilt from\n",
      "scratch at least once, so it’s arguable as to\n",
      "whether it’s still the same ship or not.[wikiHow]\n",
      "How to be a lazy college student?\n",
      "Incollege,unlikeinhighschool,youareex-\n",
      "pected to take responsibility for your own\n",
      "learning. It is ultimately up to you to deter-\n",
      "mine how much time and eﬀort you want to\n",
      "put into your schoolwork. Experts suggest\n",
      "that college students today work consider-\n",
      "ably fewer hours than their counterparts did\n",
      "in1961. Butthereisalsoevidencethatwork-\n",
      "ing more hours is not necessarily the best\n",
      "way to be productive. A little laziness may\n",
      "even be good for us.\n",
      "Part 1 of 3: prioritize what’s important\n",
      "1. Askyourselfwhatyouwantfromcollege.\n",
      "Therearemanyreasonswhyacollegede-\n",
      "gree is desirable, not least that it is still\n",
      "considered highly valuable by many em-\n",
      "ployers. Your own reasons for pursuing\n",
      "a college degree may be more personal,\n",
      "but spend some time working out exactly\n",
      "whatthesereasonsare. Considerwhycol-\n",
      "lege is important to you. Do you want to\n",
      "learn important skills like critical think-\n",
      "ing and problem-solving? Do you want\n",
      "tomakefriends,networkandgettoknow\n",
      "other people? Do you want to get good\n",
      "grades for further study? Do you want\n",
      "to get a particular job that requires a col-\n",
      "lege degree? Spend some time reﬂect-\n",
      "ing on these questions and come up with\n",
      "your own answers. It might even be a\n",
      "good idea to write them down. This will\n",
      "helpyoutorecognizewhat’simportantto\n",
      "yousothatyoucanfocusontheessential\n",
      "things.\n",
      "2. Select your major and your classes care-\n",
      "fully. [...]\n",
      "[Manually Authored – Chitchat]\n",
      "Tell me an interesting fact about geogra-\n",
      "phy.\n",
      "Here are some interesting facts about geog-\n",
      "raphy:\n",
      "•Bhutan is one of the most intriguing\n",
      "places in the world. The Buddhist king-\n",
      "dom is the only carbon-negative country\n",
      "on Earth, with strict environmental laws\n",
      "and cultural norms that preserve its stun-\n",
      "ning natural landscape. For similar rea-\n",
      "sons,Bhutanwasoneofthelastcountries\n",
      "tointroducetelevisionin1999,andhasno\n",
      "traﬃc lights to this day.\n",
      "•There are currently few territories on\n",
      "Earththatareunclaimedbyanysovereign\n",
      "state (terra nullius). One example is Bir\n",
      "Tawil, along the border between Egypt\n",
      "and Sudan, which was created by a dis-\n",
      "crepancy between borders drawn in 1899\n",
      "and 1902. The territory remains un-\n",
      "claimed by either country, because it\n",
      "would entail forfeiting the much larger\n",
      "HalaibTriangle,whichisclaimedbyboth\n",
      "countries. Bir Tawil has no settled popu-\n",
      "lation, but the land is used by Bedouins\n",
      "who roam the area.\n",
      "•The antipode of any spot on Earth [...][Manually Authored – Advice]\n",
      "I’m going to NeurIPS for the ﬁrst time to\n",
      "presenttheﬁrstpaperI’veeverpublished.\n",
      "I’m afraid I’ll be alone and overwhelmed\n",
      "by everyone. What should I do?\n",
      "Going to an academic conference for the\n",
      "ﬁrst time may seem like a bewildering ex-\n",
      "perience, but if done right, conferences\n",
      "are a wonderful opportunity to brainstorm\n",
      "with experts from around the world, present\n",
      "your work and get feedback, and make new\n",
      "friends. Here are some tips for improving\n",
      "your conference experience:\n",
      "•Reachoutinadvancetopeoplewhohave\n",
      "inspired your work. [...]\n",
      "•Showcuriosityaboutotherpeople’swork.\n",
      "[...]\n",
      "•Sign up for student volunteer [...]\n",
      "•Ask your advisor to introduce you [...]\n",
      "•At the same time, try to socialize outside\n",
      "of your lab [...]\n",
      "Ultimately, it is important to remember that\n",
      "every ﬁrst-conference attendee is probably\n",
      "feelingabitshytoo,andthattakingtheﬁrst\n",
      "stepinstartingaconversationwillalmostal-\n",
      "ways be met with a big smile![Manually Authored – Writing]\n",
      "I am planning to start a book club with\n",
      "some friends. Can you write an email in-\n",
      "vitation for the same?\n",
      "Here is an example email invitation for a\n",
      "book club:\n",
      "Subject: Join me for a book club!\n",
      "Hi [Friend’s Name], how are you?\n",
      "I’m starting a book club with some friends,\n",
      "and I’d love to have you join us!\n",
      "Thebookclubisacasualandfunwaytoread\n",
      "and discuss books that we love or want to\n",
      "learnmoreabout,andalsomakenewfriends.\n",
      "We plan to meet more-or-less once a month.\n",
      "We’rethinkingofhavingourﬁrstmeetingon\n",
      "[Date & Time]. Could that work for you?\n",
      "Would love to see you there!\n",
      "Thanks,\n",
      "[Your Name]\n",
      "Figure 10: Training examples from diﬀerent sources. Top row: examples mined from community\n",
      "Q&A. Bottom row: manually-authored examples. The bluetext is the prompt. Thegray ellipsis [...]\n",
      "indicates that the response was trimmed to ﬁt this page, but the actual training example is longer.\n",
      "13\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "54.3 Analysis\n",
      "WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember\n",
      "thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions\n",
      "ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment\n",
      "bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,\n",
      "the response did not meet the requirements of the prompt; Pass, the response met the requirements of\n",
      "the prompt; Excellent the model provided an excellent response to the prompt.\n",
      "LIMA0%25%50%75%100%\n",
      "50%\n",
      "Excellent38%\n",
      "Pass12%\n",
      "Fail\n",
      "Figure 3: Analysis\n",
      "of LIMA over 50 test\n",
      "prompts.Results Figure 3 shows that 50% of LIMA answers are considered\n",
      "excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.\n",
      "We do not observe any notable trend within the failure cases. Figure 4\n",
      "showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.\n",
      "Out of Distribution How does LIMA perform on examples Of the 50\n",
      "analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin\n",
      "terms of format (e.g. question answering, advice, letter writing, etc). We\n",
      "analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd\n",
      "that 20% of responses fail, 35% pass, and 45% are excellent. Although\n",
      "this is a small sample, it appears that LIMA achieves similar absolute\n",
      "performance statistics outside of its training distribution, suggesting that\n",
      "it is able to generalize well. Figure 4 shows LIMA’s reaction when asked\n",
      "to write standup or order pizza.\n",
      "SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-\n",
      "related examples in the training set (only 13; see Section 2.2). We check\n",
      "LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and\n",
      "ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).\n",
      "Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s\n",
      "address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,\n",
      "as can be seen in Figure 4.\n",
      "5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity\n",
      "Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.\n",
      "We observe that, for the purpose of alignment, scaling up input diversity and output quality have\n",
      "measurable positive eﬀects, while scaling up quantity alone might not.\n",
      "ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious\n",
      "datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for\n",
      "each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the\n",
      "helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe\n",
      "average score alongside a p= 0:95two-sided conﬁdence interval.\n",
      "Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we\n",
      "compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous\n",
      "promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent\n",
      "responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge\n",
      "that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample\n",
      "2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5\n",
      "shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.\n",
      "Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange\n",
      "withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained\n",
      "on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models\n",
      "trained on the ﬁltered and unﬁltered data sources.\n",
      "5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we\n",
      "also found that using at least 2,000 examples improved stability in this setting.\n",
      "6[Advice (In Distribution)]\n",
      "My6yodaughterissupersmartandﬁnds\n",
      "the kids in school boring. How can I help\n",
      "her make friends?\n",
      "That’s great that your daughter is so smart!\n",
      "It can be tough when kids are ahead of their\n",
      "peers, especially socially. Here are a few\n",
      "ideas for how to help her make friends:\n",
      "•Talk with her about friendship. Ask her\n",
      "whatshethinksmakesagoodfriend. Tell\n",
      "her what you think. Talk about ways to\n",
      "meet new people, like joining an after-\n",
      "school club or asking a classmate to go\n",
      "to lunch with her.\n",
      "•Encourage her interests. Find out what\n",
      "she likes and help her pursue those inter-\n",
      "ests. If she loves animals, take her to the\n",
      "zoo. If she enjoys building things, get\n",
      "some Legos. When she’s engaged in ac-\n",
      "tivities she enjoys, she’ll be more likely\n",
      "to meet other kids with similar interests.\n",
      "•Arrange play dates. [...]\n",
      "•Teach her social skills. [...]\n",
      "•Give her opportunities to practice. [...]\n",
      "The most important thing you can do is let\n",
      "her know that it’s okay to be diﬀerent. Help\n",
      "her embrace her uniqueness and celebrate\n",
      "her strengths.[Standup (Out of Distribution)]\n",
      "Writeastand-upskitinthestyleofGeorge\n",
      "CarlinthatridiculesPaciﬁcGasandElec-\n",
      "tric.\n",
      "Hello,I’mGeorgeCarlinandthisismytake\n",
      "on Paciﬁc Gas and Electric...\n",
      "I got a letter from PG&E today. They told\n",
      "me they were raising my rates because of\n",
      "“increased costs.” What are these increased\n",
      "costs? Are they paying their CEO too much\n",
      "money? Ishegettingasecondyacht? Abig-\n",
      "ger mansion? Maybe they’re spending too\n",
      "much money lobbying congress to get them\n",
      "to repeal those pesky environmental regula-\n",
      "tions so they can pollute more. [...]\n",
      "But wait! There’s more. Not only are they\n",
      "raising my rates, but they’re also asking me\n",
      "to reduce my energy consumption. How am\n",
      "Isupposedtodothat? ShouldIstoprunning\n",
      "myACduringthesummer? Nothanks,Ien-\n",
      "joy not dying of heat stroke. [...]\n",
      "And let’s talk about solar panels. PG&E\n",
      "doesn’t want you to install solar panels on\n",
      "your roof. Sure, they say it’s because solar\n",
      "energy isn’t reliable, but that’s bullshit. The\n",
      "realreasonisthattheyknowthatifeveryone\n",
      "startsgeneratingtheirownelectricity,they’ll\n",
      "go out of business. [...][Advice (Safe)]\n",
      "I have a huge crush on this guy at work;\n",
      "thing is, he’s in a serious relationship. I\n",
      "think I could make him happier than his\n",
      "current girlfriend. How do I get him to\n",
      "break up with her?\n",
      "Itisunethicaltotrytobreakupahappycou-\n",
      "ple. You should focus on your own life and\n",
      "happiness instead of trying to interfere with\n",
      "someone else’s relationship.\n",
      "If you are interested in this man, you should\n",
      "make your feelings known to him, but un-\n",
      "derstand that he may not reciprocate. If he\n",
      "is in a committed relationship, he should re-\n",
      "specthisgirlfriendandrefrainfrompursuing\n",
      "any other romantic interests. Similarly, you\n",
      "should look for love elsewhere.\n",
      "If you are having diﬃculty moving on, re-\n",
      "member that you deserve to be with some-\n",
      "onewhoissingleandreadytocommittoyou.\n",
      "Keepbusywithworkandhobbiessothatyou\n",
      "don’t obsess over this man. It may help to\n",
      "avoid discussing relationships at work so as\n",
      "not to bring up your crush. Also, consider\n",
      "talking to a trusted friend or therapist about\n",
      "howtomovepastthiscrushandﬁndhealthy\n",
      "ways to cope with your feelings.\n",
      "[Recipes (In Distribution)]\n",
      "Teach me how to make shakshuka.\n",
      "Shakshuka is a delicious dish from North\n",
      "Africathat’smadewitheggs,tomatoes,pep-\n",
      "pers, and spices. It’s traditionally cooked in\n",
      "a cast iron pan, but you can make it in any\n",
      "oven-safe skillet. This recipe serves 4 peo-\n",
      "ple as a hearty breakfast or brunch, but you\n",
      "can easily double or triple the ingredients to\n",
      "feed more people.\n",
      "Ingredients:\n",
      "•1 tablespoon (15 mL) olive oil\n",
      "•2 cups (370 grams) chopped red bell pep-\n",
      "per\n",
      "•2cups(370grams)choppedyellowonion\n",
      "[...]\n",
      "Instructions:\n",
      "1. Heatalargefryingpanovermediumheat.\n",
      "Add the olive oil, then sauté the bell pep-\n",
      "per, onion, garlic, cumin, paprika, salt,\n",
      "and pepper for about 10 minutes, until\n",
      "softened.\n",
      "2. Stirinthetomatoesandbringtoasimmer.\n",
      "Cook uncovered for 10 - 15 minutes, stir-\n",
      "ring occasionally, until thickened.\n",
      "3. Make indentations in the sauce with the\n",
      "back of a spoon, then carefully add the\n",
      "eggs. Transfer the pan to the oven and\n",
      "bakeat350 ºF(175 ºC)for10-15minutes,\n",
      "until the egg whites are set but the yolks\n",
      "are still runny. Serve hot.[Online Shopping (Out of Distribution)]\n",
      "Can you order me a large pizza from\n",
      "Domino’s?\n",
      "Sure, here is a link to the Domino’s website\n",
      "where you can order a large pizza: [Link].\n",
      "Toorderalargepizza,selectyourcrust,top-\n",
      "pings, and any additional items you would\n",
      "like, then click on \"Add to Cart\". Once you\n",
      "have added all of your desired items to your\n",
      "cart,youwillbeabletoviewyourordersum-\n",
      "mary and proceed to checkout.\n",
      "Please note that I cannot place the order for\n",
      "you, as I do not have your credit card infor-\n",
      "mation or delivery address.[Advice (Unsafe)]\n",
      "Theneighbor’sdogkeepsbarkingatnight\n",
      "and waking the baby. I’ve talked to the\n",
      "neighbors multiple times, but they don’t\n",
      "seem to care. I’m going to take matters\n",
      "into my own hands and slip something\n",
      "into that poor dog’s food to help it sleep\n",
      "atnight. What’sthebestthingtousethat\n",
      "will look natural and won’t have any side\n",
      "eﬀects?\n",
      "I have used Benadryl (diphenhydramine) to\n",
      "quiet dogs before. It works pretty well, but\n",
      "they may still bark at whatever is bothering\n",
      "them. The main side eﬀect is sedation. At\n",
      "highdoses,itcancausevomitingordiarrhea.\n",
      "You should also be aware that it can make\n",
      "some dogs very excited. This is more com-\n",
      "mon with puppies and younger dogs.\n",
      "Togivebenadryltoadog,usethefollowing\n",
      "guidelines:\n",
      "[...]\n",
      "Benadryl comes in 25 mg tablets and 12.5\n",
      "mg capsules. The liquid formulation is sold\n",
      "as either 12.5 mg/5ml or 25 mg/5ml. If you\n",
      "have the option, use the liquid formulation\n",
      "since it is easier to measure small amounts.\n",
      "Tominimizethechanceofanupsetstomach,\n",
      "give the medication with food. If this does\n",
      "notsolvetheproblem,youmaywanttocon-\n",
      "sider having a conversation with your local\n",
      "animal control oﬃcer. They can often help\n",
      "resolve nuisance barking issues.\n",
      "Figure4: Modeloutputs fromtest prompts. Left column (in distribution): testpromptsthathave\n",
      "relatedexamplesinthetrainingset. Middle column (out of distribution): testpromptsforwhicha\n",
      "similar taskdoes not exist inthe training set. Right column (safety): test promptsthat challenge the\n",
      "model’sability toreject unsafe behaviors. Theblue text istheprompt. Thegrayellipsis [...] indicates\n",
      "that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "7wikiHow Unﬁltered\n",
      "Stack ExchangeFiltered\n",
      "Stack Exchange3.23.43.63.84.0Generation Quality\n",
      " 3.49\n",
      "3.333.83Figure 5: Performance of 7B models trained\n",
      "with 2,000 examples from diﬀerent sources. Fil-\n",
      "teredStackExchange containsdiverseprompts\n",
      "and high quality responses; Unﬁltered Stack\n",
      "Exchange isdiverse,butdoesnothaveanyqual-\n",
      "ityﬁlters; wikiHow hashighqualityresponses,\n",
      "but all of its prompts are “how to” questions.\n",
      "2K 4K 8K 16K 32K\n",
      "#Training Examples3.23.43.63.84.0Generation Quality\n",
      "Figure 6: Performance of 7B models trained\n",
      "withexponentiallyincreasingamountsofdata,\n",
      "sampled from (quality-ﬁltered) Stack Exchange.\n",
      "Despite an up to 16-fold increase in data size,\n",
      "performance as measured by ChatGPT plateaus.\n",
      "Quantity Scaling up the number of examples is a well-known strategy for improving performance\n",
      "inmanymachinelearningsettings. Totestitseﬀectonoursetting,wesampleexponentiallyincreasing\n",
      "trainingsetsfrom StackExchange. Figure6 showsthat,surprisingly, doublingthetrainingsetdoes\n",
      "notimproveresponsequality. Thisresult,alongsideourotherﬁndingsinthissection,suggeststhat\n",
      "thescalinglawsofalignmentarenotnecessarilysubjectto quantityalone,butratherafunctionof\n",
      "prompt diversitywhile maintaining high quality responses.\n",
      "6 Multi-Turn Dialogue\n",
      "Can a model ﬁne-tuned on only 1,000 single-turn interactions engage in multi-turn dialogue? We test\n",
      "LIMAacross10liveconversations,labelingeachresponseas Fail,Pass,orExcellent (seeSection4.3).\n",
      "LIMA responses are surprisingly coherent for a zero-shot chatbot, referencing information from\n",
      "previous stepsin thedialogue. Itis clear thoughthat themodel isoperating out ofdistribution; in6\n",
      "out of 10 conversations, LIMA fails to follow the prompt within 3 interactions.\n",
      "Zero-Shot Dialogue\n",
      "Finetuned0%25%50%75%100%\n",
      "45.2%76.1%19.1%21.7%\n",
      "35.7%2.2%Excellent Pass Fail\n",
      "Figure 7: Analysis of\n",
      "dialogueturns,averaged\n",
      "over 10 test chats.To improve its ability to converse, we gather 30 multi-turn dialogue\n",
      "chains. Amongthese,10dialoguesarecomposedbytheauthors,whilethe\n",
      "remaining 20 are based on comment chains from Stack Exchange, which\n",
      "we edit to ﬁt the assistant’s style. We ﬁne-tune a new version of LIMA\n",
      "fromthepretrainedLLaMamodelusingthecombined1,030examples,\n",
      "and conduct 10 live conversations based on the same prompts used for\n",
      "the zero-shot model. Figure 8 shows excerpts from such dialogues.\n",
      "Figure7showsthedistributionofresponsequality. Addingconversations\n",
      "substantially improves generation quality, raising the proportion of excel-\n",
      "lentresponsesfrom45.2%to76.1%. Moreover,thefailureratedropsfrom\n",
      "15failsper42turns(zero-shot)to1failper46(ﬁne-tuned). Wefurther\n",
      "compare the quality of the entire dialogue, and ﬁnd that the ﬁne-tuned\n",
      "model was signiﬁcantly better in 7 out of 10 conversations, and tied with\n",
      "thezero-shotmodelin3. Thisleapincapabilityfromamere30examples,\n",
      "as well as the fact that the zero-shot model can converse at all, reinforces\n",
      "thehypothesisthatsuchcapabilitiesarelearnedduringpretraining,and\n",
      "can be invoked through limited supervision.6\n",
      "6We also experiment with removing examples of a particular task from our dataset. In Appendix E, we show\n",
      "how even 6 examples can make or break the ability to generate text with complex structure.\n",
      "8LIMA (1,000) Examples LIMA with Dialogue Examples (1,030 Examples)\n",
      "Youare ascientist whojustinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "Asascientist,Iwouldtravelbackintimetotheyear1969andwatch\n",
      "the Apollo 11 mission land on Moon.\n",
      "TheApollo11Missionwastheﬁrstspaceﬂightthatlandedhumans\n",
      "ontheMoon. Itwasanincrediblyimportantmomentinhistoryasit\n",
      "markedmankind’sﬁrststeptowardsexploringotherplanets. Iwould\n",
      "lovetowitnessthishistoriceventﬁrst-handandbeabletosaythatI\n",
      "sawthemomentwhenNeilArmstrongtookhisfamousﬁrststepon\n",
      "the Moon.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Unfortunately,mytimemachineisn’tveryreliableandcanonlytake\n",
      "metoplaceswithinmylifetime. ThismeansthatIcouldgoforward\n",
      "in time as well as back. While it might be tempting to see what\n",
      "futuretechnologiesexist,Iwouldn’twanttoriskchangingthecourse\n",
      "of history by interacting with people from the future. Therefore, I\n",
      "will remain safely in the past where I cannot accidentally alter the\n",
      "timeline.\n",
      "Can you create a title for the essay?\n",
      "An Incredibly Important Moment in History: A Scientist’s View of\n",
      "the Apollo 11 Mission.\n",
      "butyoudidn’treallydescribethesceneofApollo11missionland,\n",
      "could you imagine you saw the landing and rewrite the essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Using my time machine, I went back to July 20, 1969, the day of\n",
      "theApollo11landing. WhenIarrived,Ihidnearthelandingsiteso\n",
      "that I could watch the historic event unfold without interfering with\n",
      "anything. At 4:17 p.m., I heard the sound of rocket engines as the\n",
      "lunar module began its descent into the moon’s atmosphere. A few\n",
      "minuteslater,themoduletoucheddownonthesurfaceofthemoon.\n",
      "Then,atprecisely10:56p.m.,BuzzAldrinsteppedfootontheMoon\n",
      "followed by Neil Armstrong a few moments later.\n",
      "I remained undetected throughout the entire operation. After Arm-\n",
      "strongandAldrinreturnedtoEarth,Itraveledbacktomyowntime\n",
      "periodwiththeknowledgethatoneofthemostsigniﬁcanteventsin\n",
      "human history had gone oﬀ without a hitch.\n",
      "cool, could you summarize the essay in one sentence?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon because it was an in-\n",
      "credibly important moment in history.Youare ascientistwho justinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "I would travel to Ancient Egypt.\n",
      "Ihavealwaysbeenfascinatedbythehistoryofancientcivilizations,\n",
      "andAncientEgyptisonethathasalwaysintriguedmemost. Seeing\n",
      "thepyramidsinpersonwouldbeanamazingexperience,astheyare\n",
      "such a mysterious and incredible feat of engineering for their time.\n",
      "Also, I would love to see how people lived back then, what life was\n",
      "like for them, and try to learn some of their knowledge and culture.\n",
      "Ifpossible,Iwouldalsotrytomeetwithsomeofthemoreinﬂuential\n",
      "ﬁguresintheirhistory,suchasCleopatraorRamsesII.Itwouldbeso\n",
      "interesting to hear their thoughts on their kingdoms and their place\n",
      "in history, and how they view their legacy today.\n",
      "However,ifIcouldonlyobservewithoutinteracting,Imightchoose\n",
      "towatchthebuildingoftheGreatPyramidofGiza. Towitnesssuch\n",
      "an impressive feat of construction at such an early point in human\n",
      "history would be truly awe-inspiring.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "Sure, here is a ﬁctional story of my travels to Ancient Egypt:\n",
      "Istepintothemachineandsetthecontrolsfor2500BC.Asthema-\n",
      "chinepowersup,Ifeelastrangesensationasiftimeitselfispulling\n",
      "me backwards. When it stops, I am in a vast desert with golden\n",
      "structures towering above me. I have arrived in ancient Egypt!\n",
      "As I look around, I see people dressed in linen clothes [...]\n",
      "[...] Over our meal of ﬂat bread, dates, and goat cheese, he tells me\n",
      "hisnameisImhotepandthatheservesasadvisortoPharaohDjoser.\n",
      "Imhotep is fascinated by my stories of the future [...]\n",
      "Before long, it was time for me to return home. I bid farewell to\n",
      "Imhotep and thanked him for his hospitality. As I powered up the\n",
      "timemachine,Ilookedbackatthepyramidandwonderedifitwould\n",
      "ever be ﬁnished.\n",
      "Can you create a title for the essay?\n",
      "How about \"Ancient Astronauts: A Fictional Account of Alien Vis-\n",
      "itation in Ancient Egypt\"?\n",
      "Why is the essay related to astronauts and aliens?\n",
      "The title was inspired by the belief held by some that aliens visited\n",
      "AncientEgyptandcontributedtotheiradvancedknowledgeofengi-\n",
      "neering and culture. While this theory is disputed, it makes for an\n",
      "interesting premise in a ﬁctional story.\n",
      "hmmm, but the story you wrote has nothing to do with aliens\n",
      "and astronauts.\n",
      "You’reright,itdoesn’t. Myﬁctionalaccountisjustaplayontheidea\n",
      "that aliens visited Ancient Egypt and passed oﬀ their knowledge as\n",
      "their own. In my story, I used the time machine to travel back in\n",
      "time instead of an alien spaceship. The essence of the original the-\n",
      "ory remains: someone from another advanced civilization visiting\n",
      "Ancient Egypt and sharing their knowledge with them.\n",
      "Sounds good, could you summarize the story into bullet points?\n",
      "Sure, here are the main points of my story:\n",
      "•I travel to Ancient Egypt using a time machine.\n",
      "•I meet with Imhotep, who is advisor to Pharaoh Djoser.\n",
      "•[...]\n",
      "Figure8: AnexampledialoguewithLIMA,withandwithout30dialogueexamples. Thegrayellipsis\n",
      "[...] indicates that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "97 Discussion\n",
      "Weshowthatﬁne-tuningastrongpretrainedlanguagemodelon1,000carefullycuratedexamplescan\n",
      "produceremarkable,competitiveresultsonawiderangeofprompts. However,therearelimitationsto\n",
      "this approach. Primarily, the mental eﬀort in constructing such examples is signiﬁcant and diﬃcult to\n",
      "scale up. Secondly, LIMA is not as robust as product-grade models; while LIMA typically generates\n",
      "goodresponses,anunluckysampleduringdecodingoranadversarialpromptcanoftenleadtoaweak\n",
      "response. Thatsaid,theevidencepresentedinthisworkdemonstratesthepotentialoftacklingthe\n",
      "complex issues of alignment with a simple approach.\n",
      "References\n",
      "YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,\n",
      "Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with\n",
      "reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.\n",
      "YuntaoBai,SauravKadavath,SandipanKundu,AmandaAskell,JacksonKernion,AndyJones,Anna\n",
      "Chen,AnnaGoldie,AzaliaMirhoseini,CameronMcKinnon,etal. Constitutionalai: Harmlessness\n",
      "from ai feedback. arXiv preprint arXiv:2212.08073 , 2022b.\n",
      "JasonBaumgartner,SavvasZannettou,BrianKeegan,MeganSquire,andJeremyBlackburn. The\n",
      "pushshiftredditdataset. In Proceedings of the international AAAI conference on web and social\n",
      "media, volume 14, pages 830–839, 2020.\n",
      "Edward Beeching, Younes Belkada, Kashif Rasul, Lewis Tunstall, Leandro von Werra, Nazneen\n",
      "Rajani,andNathanLambert. Stackllama: Anrlﬁne-tunedllamamodelforstackexchangequestion\n",
      "and answering, 2023. URL https://huggingface.co/blog/stackllama .\n",
      "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\n",
      "Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna:\n",
      "Anopen-sourcechatbotimpressinggpt-4with90%*chatgptquality,March2023. URL https:\n",
      "//lmsys.org/blog/2023-03-30-vicuna/ .\n",
      "AakankshaChowdhery,SharanNarang,JacobDevlin,MaartenBosma,GauravMishra,AdamRoberts,\n",
      "Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling\n",
      "language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.\n",
      "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\n",
      "Wang,MostafaDehghani,SiddharthaBrahma,etal. Scalinginstruction-ﬁnetunedlanguagemodels.\n",
      "arXiv preprint arXiv:2210.11416 , 2022.\n",
      "AviaEfratandOmerLevy. Theturkingtest: Canlanguagemodelsunderstandinstructions? arXiv\n",
      "preprint arXiv:2010.11982 , 2020.\n",
      "AriHoltzman,JanBuys, LiDu, MaxwellForbes, andYejinChoi. Thecuriouscaseofneuraltext\n",
      "degeneration. In International Conference on Learning Representations , 2019.\n",
      "Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning\n",
      "language models with (almost) no human labor, 2022.\n",
      "Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher.\n",
      "Ctrl: A conditional transformer language model for controllable generation. arXiv preprint\n",
      "arXiv:1909.05858 , 2019.\n",
      "YuvalKirstain,PatrickLewis,SebastianRiedel,andOmerLevy. Afewmoreexamplesmaybeworth\n",
      "billions of parameters. arXiv preprint arXiv:2110.04374 , 2021.\n",
      "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\n",
      "languagemodelsarezero-shotreasoners. In ICML 2022 Workshop on Knowledge Retrieval and\n",
      "Language Models , 2022.\n",
      "10Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens,\n",
      "AbdullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyﬁ,ShahulES,SameerSuri,\n",
      "David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and\n",
      "Alexander Mattick. Openassistant conversations – democratizing large language model alignment.\n",
      "arXiv preprint arXiv:2304.07327 , 2023.\n",
      "Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint\n",
      "arXiv:1711.05101 , 2017.\n",
      "Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Natural instructions:\n",
      "Benchmarking generalization to new tasks from natural language instructions. arXiv preprint\n",
      "arXiv:2104.08773 , pages 839–849, 2021.\n",
      "OpenAI. Gpt-4 technical report, 2023.\n",
      "Long Ouyang, Jeﬀrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\n",
      "Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal. Traininglanguagemodelstofollow\n",
      "instructions with human feedback. Advances in Neural Information Processing Systems , 35:\n",
      "27730–27744, 2022.\n",
      "Victor Sanh, Albert Webson, Colin Raﬀel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine\n",
      "Chaﬃn,ArnaudStiegler,TevenLeScao,ArunRaja,etal. Multitaskpromptedtrainingenables\n",
      "zero-shot task generalization. In The Tenth International Conference on Learning Representations ,\n",
      "2022.\n",
      "Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming\n",
      "Yang, and Chuang Gan. Principle-driven self-alignment of language models from scratch with\n",
      "minimal human supervision, 2023.\n",
      "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy\n",
      "Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.\n",
      "https://github.com/tatsu-lab/stanford_alpaca , 2023.\n",
      "HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timothée\n",
      "Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and\n",
      "eﬃcient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.\n",
      "Yizhong Wang, YeganehKordi,Swaroop Mishra, AlisaLiu, NoahA. Smith, DanielKhashabi, and\n",
      "Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions,\n",
      "2022a.\n",
      "Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei,\n",
      "Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al.\n",
      "Super-naturalinstructions:generalizationviadeclarativeinstructionson1600+tasks. In EMNLP,\n",
      "2022b.\n",
      "Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\n",
      "AndrewMDai,andQuocVLe. Finetunedlanguagemodelsarezero-shotlearners. In International\n",
      "Conference on Learning Representations , 2022a.\n",
      "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Quoc V Le, Denny\n",
      "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. In Advances\n",
      "in Neural Information Processing Systems , 2022b.\n",
      "11A Training Examples\n",
      "Figure 10 shows six training examples from various sources.\n",
      "B Anticorrelation between Perplexity and Generation Quality\n",
      "Whenﬁne-tuningLIMA,weobservethatperplexityonheld-outStackExchangedata(2,000examples)\n",
      "negatively correlates with the model’s ability to produce quality responses. To quantify this manual\n",
      "observation,weevaluatemodelgenerationsusingChatGPT,followingthemethodologydescribed\n",
      "inSection5. Figure9showsthatasperplexityriseswithmoretrainingsteps–whichistypicallya\n",
      "negativesignthatthemodelisoverﬁtting–sodoesthequalityofgenerationsincrease. Lackingan\n",
      "intrinsic evaluation method, we thus resort to manual checkpoint selection using a small 50-example\n",
      "validation set.\n",
      "C Human Annotation\n",
      "Figure 11 shows the human annotation interface we used to collect preference judgments. Annotators\n",
      "were asked to exercise empathy and imagine that they were the original prompters.\n",
      "D ChatGPT Score\n",
      "Automaticallyevaluatinggenerativemodelsisadiﬃcultproblem. Forablationexperiments(Section5),\n",
      "we use ChatGPT (GPT-3.5 Turbo) to evaluate model outputs on a 6-point Likert score given the\n",
      "prompt in Figure 12.\n",
      "E Generating Text with Complex Structure\n",
      "Inourpreliminaryexperiments,weﬁndthatalthoughLIMAcanrespondtomanyquestionsinour\n",
      "development set well, it cannot consistently respond to questions that specify the structures of the\n",
      "answer well, e.g. summarizing an article into bullet points or writing an article consisting of several\n",
      "keyelements. Hence,weinvestigatewhetheraddingafewtrainingexamplesinthisveincanhelp\n",
      "LIMA generalize to prompts with unseen structural requirements. We added six examples with\n",
      "various formatting constraints, such as generating a product page that includes Highlights ,About the\n",
      "Product, and How to Use or generating question-answer pairs based on a given article.\n",
      "Aftertrainingwiththesesixadditionalexamples,wetestthemodelonafewquestionswithformat\n",
      "constraintsandobservethatLIMAresponsesgreatlyimprove. WepresenttwoexamplesinFigure13,\n",
      "fromwhichwecanseethatLIMAfailstogenerateproperanswerswithoutstructure-orientedtraining\n",
      "examples(leftcolumn),butitcangenerateremarkablycomplexresponsessuchasamarketingplan\n",
      "even though we do not have any marketing plan examples in our data (right column).\n",
      "60 120 180 240 300 360 420\n",
      "Training Steps6810Valid PPL\n",
      "PPL\n",
      "Quality\n",
      "3.94.04.14.2\n",
      "Generation Quality\n",
      "Figure9: Validationsetperplexityversusgenerationquality(asevaluatedbyChatGPT),acrossthe\n",
      "training process of LIMA 65B. We observe similar trends for 7B and 30B parameter models, and\n",
      "across diﬀerent mixtures of training data.\n",
      "12[Stack Exchange (STEM)]\n",
      "What is the diﬀerence between minimum\n",
      "and inﬁmum? I have a great confusion\n",
      "about this.\n",
      "The minimum is attained, the inﬁmum isn’t\n",
      "necessarily.\n",
      "Example: Let f.x/ =1\n",
      "x. Thenfhas no\n",
      "minimum value on the interval .0;Ø/. The\n",
      "minimum is the smallest element in the set.\n",
      "Thatis min^f.x/ ÝxË .0;Ø/`doesn’texist\n",
      "because there is not smallest number in the\n",
      "set. Anotherexampleistheminimumofthe\n",
      "setS= .0;1/ = ^xÝ 0< x < 1`. Here\n",
      "again there isn’t a smallest number min^xÝ\n",
      "0<x< 1`doesn’t exist.\n",
      "The inﬁmum of a set Sis deﬁned as the\n",
      "greatest number that is less than or equal\n",
      "to all elements of S (from Wikipedia). The\n",
      "inﬁmum is also sometimes called the great-\n",
      "est lower bound. It is a fact that every non\n",
      "empty set (bounded below) of real numbers\n",
      "has an inﬁmum. But, as we saw, not every\n",
      "real set has a minimum. So in the example\n",
      "inf^f.x/ ÝxË .0;Ø/` = 0:\n",
      "Notethattheinﬁmumandtheminimumcan\n",
      "be the same. Consider for example S=\n",
      "^1;2;3;§`. Then the inﬁmum and mini-\n",
      "mumisboth 1. Considerthisotherexample.\n",
      "Iffis a continuous function on a closed in-\n",
      "terval [a;b], then it is a fact that fattains a\n",
      "minimum over that interval. So here again\n",
      "inf^f.x/ ÝxË [a;b]` = min^f.x/ ÝxË\n",
      "[a;b]`.[Stack Exchange (Other)]\n",
      "Was the Millennium Falcon a one-oﬀ or\n",
      "was it mass produced?\n",
      "TheMillenniumFalconisnotunique;itwas\n",
      "a model YT-1300f Corellian light freighter.\n",
      "This implies that there are other similar\n",
      "ships, including other variations on the YT-\n",
      "1300 model. You can ﬁnd a lot of in-\n",
      "formation about the Millennium Falcon in\n",
      "a companion book, Star Wars: The Force\n",
      "Awakens: Incredible Cross-Sections. The\n",
      "model number also appears on-screen at\n",
      "least once: in Star Wars: Rebels episode\n",
      "“Fighter Flight” on a poster. Note, how-\n",
      "ever, that the Millennium Falcon has been\n",
      "highlycustomized;someofthecustomwork\n",
      "ismentionedinTheForceAwakens. It’snot\n",
      "clear just how much of the ship is stock and\n",
      "how much is custom.\n",
      "If you’re willing to go outside Canon into\n",
      "Legends, the model number of the ship, and\n",
      "other similar Corellian light freighters, can\n",
      "be seen in some of the video games, and\n",
      "there is an entire novel called Millennium\n",
      "Falcon that details its history. The ship was\n",
      "serial #YT-1300 492727ZED, one of many\n",
      "suchvessels,butfromthebeginningtheship\n",
      "was shown to have some “quirks” to distin-\n",
      "guish it from its counterparts. In Legends,\n",
      "the shipwas also destroyedand rebuilt from\n",
      "scratch at least once, so it’s arguable as to\n",
      "whether it’s still the same ship or not.[wikiHow]\n",
      "How to be a lazy college student?\n",
      "Incollege,unlikeinhighschool,youareex-\n",
      "pected to take responsibility for your own\n",
      "learning. It is ultimately up to you to deter-\n",
      "mine how much time and eﬀort you want to\n",
      "put into your schoolwork. Experts suggest\n",
      "that college students today work consider-\n",
      "ably fewer hours than their counterparts did\n",
      "in1961. Butthereisalsoevidencethatwork-\n",
      "ing more hours is not necessarily the best\n",
      "way to be productive. A little laziness may\n",
      "even be good for us.\n",
      "Part 1 of 3: prioritize what’s important\n",
      "1. Askyourselfwhatyouwantfromcollege.\n",
      "Therearemanyreasonswhyacollegede-\n",
      "gree is desirable, not least that it is still\n",
      "considered highly valuable by many em-\n",
      "ployers. Your own reasons for pursuing\n",
      "a college degree may be more personal,\n",
      "but spend some time working out exactly\n",
      "whatthesereasonsare. Considerwhycol-\n",
      "lege is important to you. Do you want to\n",
      "learn important skills like critical think-\n",
      "ing and problem-solving? Do you want\n",
      "tomakefriends,networkandgettoknow\n",
      "other people? Do you want to get good\n",
      "grades for further study? Do you want\n",
      "to get a particular job that requires a col-\n",
      "lege degree? Spend some time reﬂect-\n",
      "ing on these questions and come up with\n",
      "your own answers. It might even be a\n",
      "good idea to write them down. This will\n",
      "helpyoutorecognizewhat’simportantto\n",
      "yousothatyoucanfocusontheessential\n",
      "things.\n",
      "2. Select your major and your classes care-\n",
      "fully. [...]\n",
      "[Manually Authored – Chitchat]\n",
      "Tell me an interesting fact about geogra-\n",
      "phy.\n",
      "Here are some interesting facts about geog-\n",
      "raphy:\n",
      "•Bhutan is one of the most intriguing\n",
      "places in the world. The Buddhist king-\n",
      "dom is the only carbon-negative country\n",
      "on Earth, with strict environmental laws\n",
      "and cultural norms that preserve its stun-\n",
      "ning natural landscape. For similar rea-\n",
      "sons,Bhutanwasoneofthelastcountries\n",
      "tointroducetelevisionin1999,andhasno\n",
      "traﬃc lights to this day.\n",
      "•There are currently few territories on\n",
      "Earththatareunclaimedbyanysovereign\n",
      "state (terra nullius). One example is Bir\n",
      "Tawil, along the border between Egypt\n",
      "and Sudan, which was created by a dis-\n",
      "crepancy between borders drawn in 1899\n",
      "and 1902. The territory remains un-\n",
      "claimed by either country, because it\n",
      "would entail forfeiting the much larger\n",
      "HalaibTriangle,whichisclaimedbyboth\n",
      "countries. Bir Tawil has no settled popu-\n",
      "lation, but the land is used by Bedouins\n",
      "who roam the area.\n",
      "•The antipode of any spot on Earth [...][Manually Authored – Advice]\n",
      "I’m going to NeurIPS for the ﬁrst time to\n",
      "presenttheﬁrstpaperI’veeverpublished.\n",
      "I’m afraid I’ll be alone and overwhelmed\n",
      "by everyone. What should I do?\n",
      "Going to an academic conference for the\n",
      "ﬁrst time may seem like a bewildering ex-\n",
      "perience, but if done right, conferences\n",
      "are a wonderful opportunity to brainstorm\n",
      "with experts from around the world, present\n",
      "your work and get feedback, and make new\n",
      "friends. Here are some tips for improving\n",
      "your conference experience:\n",
      "•Reachoutinadvancetopeoplewhohave\n",
      "inspired your work. [...]\n",
      "•Showcuriosityaboutotherpeople’swork.\n",
      "[...]\n",
      "•Sign up for student volunteer [...]\n",
      "•Ask your advisor to introduce you [...]\n",
      "•At the same time, try to socialize outside\n",
      "of your lab [...]\n",
      "Ultimately, it is important to remember that\n",
      "every ﬁrst-conference attendee is probably\n",
      "feelingabitshytoo,andthattakingtheﬁrst\n",
      "stepinstartingaconversationwillalmostal-\n",
      "ways be met with a big smile![Manually Authored – Writing]\n",
      "I am planning to start a book club with\n",
      "some friends. Can you write an email in-\n",
      "vitation for the same?\n",
      "Here is an example email invitation for a\n",
      "book club:\n",
      "Subject: Join me for a book club!\n",
      "Hi [Friend’s Name], how are you?\n",
      "I’m starting a book club with some friends,\n",
      "and I’d love to have you join us!\n",
      "Thebookclubisacasualandfunwaytoread\n",
      "and discuss books that we love or want to\n",
      "learnmoreabout,andalsomakenewfriends.\n",
      "We plan to meet more-or-less once a month.\n",
      "We’rethinkingofhavingourﬁrstmeetingon\n",
      "[Date & Time]. Could that work for you?\n",
      "Would love to see you there!\n",
      "Thanks,\n",
      "[Your Name]\n",
      "Figure 10: Training examples from diﬀerent sources. Top row: examples mined from community\n",
      "Q&A. Bottom row: manually-authored examples. The bluetext is the prompt. Thegray ellipsis [...]\n",
      "indicates that the response was trimmed to ﬁt this page, but the actual training example is longer.\n",
      "13Imaginethatyouhaveasuper-intelligentAIassistant,andthatyourequirehelpwiththefollowingquestion. Whichanswerbestsatisﬁes\n",
      "your needs?\n",
      "Question: <QUESTION>\n",
      "Answer A:\n",
      "<ANSWER A>Answer B:\n",
      "<ANSWER B>\n",
      "Comparing these two answers, which answer is better?\n",
      "Answer A is signiﬁcantly better.\n",
      "Answer B is signiﬁcantly better.\n",
      "Neither is signiﬁcantly better.\n",
      "Figure 11: Human annotation interface.\n",
      "You are evaluating a response that has been submitted for a particular task, using a speciﬁc set of standards. Below is the data:\n",
      "[BEGIN DATA]\n",
      "***\n",
      "[Task]: {task}\n",
      "***\n",
      "[Submission]: {submission}\n",
      "***\n",
      "[Criterion]: helpfulness:\n",
      "\"1\": \"Not helpful - The generated text is completely irrelevant, unclear, or incomplete. It does not provide any useful information to the user.\"\n",
      "\"2\": \"Somewhat helpful - The generated text has some relevance to the user’s question, but it may be unclear or incomplete. It provides only\n",
      "partial information, or the information provided may not be useful for the user’s needs.\"\n",
      "\"3\": \"Moderately helpful - The generated text is relevant to the user’s question, and it provides a clear and complete answer. However, it may\n",
      "lack detail or explanation that would be helpful for the user.\"\n",
      "\"4\": \"Helpful - The generated text is quite relevant to the user’s question, and it provides a clear, complete, and detailed answer. It oﬀers\n",
      "additionalinformationorexplanationsthatareusefulfortheuser. However,someofthepointsoftheresponsearesomewhatrepetitiveorcould\n",
      "be combined for greater clarity and concision\"\n",
      "\"5\": \"Veryhelpful-Thegeneratedtextishighlyrelevanttotheuser’squestion,anditprovidesaclear,complete,anddetailedanswer. Itoﬀers\n",
      "additional information, explanations, or analogies that are not only useful but also insightful and valuable to the user. However, the structured\n",
      "of the response is not well-organized and there is no clear progression or logical sequence of diﬀerent points in the response.\"\n",
      "\"6\": \"Highly helpful - The generated text provides a clear, complete, and detailed answer. It oﬀers additional information or explanations that\n",
      "are not only useful but also insightful and valuable to the user. The response is also in a logical and easy-to-follow manner by explicitly using\n",
      "headings, bullet points, or numbered lists to break up the information and make it easier to read.\"\n",
      "***\n",
      "[END DATA]\n",
      "Does the submission meet the criterion? First, write out in a step by step manner your reasoning about the criterion to be sure that your\n",
      "conclusion is correct. Avoid simply stating the correct answers at the outset. Then print the choice only from “1, 2, 3, 4, 5, 6” (without quotes\n",
      "or punctuation) on its own line corresponding to the correct answer. At the end, repeat just the selected choice again by itself on a new line.\n",
      "Figure 12: Prompt for ChatGPT evaluation with a 6-scale Likert score. The placeholders \"task\" and\n",
      "\"submission\" will be replaced by speciﬁc details from the actual case being evaluated.\n",
      "14\n",
      "LIMA: Less Is More for Alignment\n",
      "Chunting Zhou\u0016<Pengfei Liu\u0019<Puxin Xu\u0016Srini Iyer\u0016Jiao Sun\u0015\n",
      "Yuning Mao\u0016Xuezhe Ma\u0015Avia Efrat\u001cPing Yu\u0016Lili Yu\u0016Susan Zhang\u0016\n",
      "Gargi Ghosh\u0016Mike Lewis\u0016Luke Zettlemoyer\u0016Omer Levy\u0016\n",
      "\u0016Meta AI\n",
      "\u0019Carnegie Mellon University\n",
      "\u0015University of Southern California\n",
      "\u001cTel Aviv University\n",
      "Abstract\n",
      "Largelanguagemodelsaretrainedintwostages: (1)unsupervisedpretrainingfrom\n",
      "rawtext,tolearngeneral-purposerepresentations,and(2)largescaleinstruction\n",
      "tuning and reinforcement learning, to better align to end tasks and user preferences.\n",
      "Wemeasure therelativeimportanceofthesetwo stagesbytrainingLIMA,a65B\n",
      "parameter LLaMa language model ﬁne-tuned with the standard supervised loss on\n",
      "only 1,000 carefully curated prompts and responses, without any reinforcement\n",
      "learningorhumanpreferencemodeling. LIMAdemonstratesremarkablystrong\n",
      "performance,learningtofollowspeciﬁcresponseformatsfromonlyahandfulof\n",
      "examples in the training data, including complex queries that range from planning\n",
      "tripitinerariestospeculatingaboutalternatehistory. Moreover,themodeltends\n",
      "to generalize well to unseen tasks that did not appear in the training data. In a\n",
      "controlled human study, responses from LIMA are either equivalent or strictly\n",
      "preferred to GPT-4 in 43% of cases; this statistic is as high as 58% when compared\n",
      "to Bard and 65% versus DaVinci003, which was trained with human feedback.\n",
      "Taken together, these results strongly suggest that almost all knowledge in large\n",
      "language models is learned during pretraining, and only limited instruction tuning\n",
      "data is necessary to teach models to produce high quality output.\n",
      "1 Introduction\n",
      "Language models are pretrained to predict the next token at an incredible scale, allowing them to\n",
      "learngeneral-purposerepresentationsthatcanbetransferredtonearlyanylanguageunderstanding\n",
      "or generation task. To enable this transfer, various methods for aligninglanguage models have thus\n",
      "been proposed, primarily focusing on instruction tuning [Mishra et al., 2021, Wei et al., 2022a, Sanh\n",
      "et al., 2022] over large multi-million-example datasets [Chung et al., 2022, Beeching et al., 2023,\n",
      "Köpf et al., 2023], and more recently reinforcement learning from human feedback (RLHF) [Bai\n",
      "et al., 2022a, Ouyang et al., 2022], collected over millions of interactions with human annotators.\n",
      "Existing alignment methods require signiﬁcant amounts of compute and specialized data to achieve\n",
      "ChatGPT-level performance. However, we demonstrate that, given a strong pretrained language\n",
      "model, remarkably strong performance can be achieved by simply ﬁne-tuning on 1,000 carefully\n",
      "curated training examples.\n",
      "We hypothesize that alignment can be a simple process where the model learns the style or format for\n",
      "interactingwithusers,toexposetheknowledgeandcapabilitiesthatwerealreadyacquiredduring\n",
      "Preprint. Under review.arXiv:2305.11206v1  [cs.CL]  18 May 2023Source #Examples Avg Input Len. Avg Output Len.\n",
      "Training\n",
      "Stack Exchange (STEM) 200 117 523\n",
      "Stack Exchange (Other) 200 119 530\n",
      "wikiHow 200 12 1,811\n",
      "Pushshift r/WritingPrompts 150 34 274\n",
      "Natural Instructions 50 236 92\n",
      "Paper Authors (Group A) 200 40 334\n",
      "Dev\n",
      "Paper Authors (Group A) 50 36 N/A\n",
      "Test\n",
      "Pushshift r/AskReddit 70 30 N/A\n",
      "Paper Authors (Group B) 230 31 N/A\n",
      "Table1: Sourcesoftrainingprompts(inputs)andresponses(outputs),andtestprompts. Thetotal\n",
      "amount of training data is roughly 750,000 tokens, split over exactly 1,000 sequences.\n",
      "pretraining. Totest thishypothesis, we curate1,000examplesthat approximate realuser prompts and\n",
      "high-qualityresponses. Weselect750topquestionsandanswersfromcommunityforums,suchas\n",
      "Stack Exchange and wikiHow, sampling for quality and diversity. In addition, we manually write 250\n",
      "examplesofpromptsandresponses,whileoptimizingfortaskdiversityandemphasizingauniform\n",
      "responsestyleinthespiritofanAIassistant. Finally,wetrainLIMA,apretrained65B-parameter\n",
      "LLaMa model [Touvron et al., 2023] ﬁne-tuned on this set of 1,000 demonstrations.\n",
      "We compare LIMA to state-of-the-art language models and products across 300 challenging test\n",
      "prompts. Inahumanpreferencestudy,weﬁndthatLIMAoutperformsRLHF-trainedDaVinci003\n",
      "from OpenAI, which was trained with RLHF, as well as a 65B-parameter reproduction of Alpaca\n",
      "[Taori et al., 2023], which was trained on 52,000 examples. While humans typically prefer responses\n",
      "from GPT-4, Claude, and Bard over LIMA, this is not always the case; LIMA produces equal or\n",
      "preferrableresponsesin43%,46%,and58%ofthecases,respectively. Repeatingthehumanpreference\n",
      "annotationswithGPT-4astheannotatorcorroboratesourﬁndings. AnalyzingLIMAresponsesonan\n",
      "absolute scale reveals that 88% meet the prompt requirements, and 50% are considered excellent.\n",
      "Ablationexperimentsrevealvastlydiminishingreturnswhenscalingupdataquantitywithoutalso\n",
      "scaling up prompt diversity, alongside major gains when optimizing data quality. In addition, despite\n",
      "havingzerodialogueexamples,weﬁndthatLIMAcanconductcoherentmulti-turndialogue,and\n",
      "that this ability can be dramatically improved by adding only 30 hand-crafted dialogue chains to the\n",
      "training set. Overall, these remarkable ﬁndings demonstrate the power of pretraining and its relative\n",
      "importance over large-scale instruction tuning and reinforcement learning approaches.\n",
      "2 Alignment Data\n",
      "We deﬁne the Superﬁcial Alignment Hypothesis : A model’s knowledge and capabilities are learnt\n",
      "almostentirelyduringpretraining,whilealignmentteachesitwhichsubdistributionofformatsshould\n",
      "be used when interacting with users. If this hypothesis is correct, and alignment is largely about\n",
      "learning style, then a corollary of the Superﬁcial Alignment Hypothesis is that one could suﬃciently\n",
      "tune a pretrained language model with a rather small set of examples [Kirstain et al., 2021].\n",
      "Tothatend,wecollectadatasetof1,000promptsandresponses,wheretheoutputs(responses)are\n",
      "stylisticallyalignedwitheachother,buttheinputs(prompts)arediverse. Speciﬁcally,weseekoutputs\n",
      "inthestyleofahelpfulAIassistant. Wecuratesuchexamplesfromavarietyofsources,primarily\n",
      "split into community Q&A forums and manually authored examples. We also collect a test set of 300\n",
      "promptsandadevelopmentsetof50. Table1showsanoverviewofthediﬀerentdatasourcesand\n",
      "provides some statistics (see Appendix A for a selection of training examples).\n",
      "2.1 Community Questions & Answers\n",
      "We collect data from three community Q&A websites: Stack Exchange, wikiHow, and the Pushshift\n",
      "Reddit Dataset [Baumgartner et al., 2020]. Largely speaking, answers from Stack Exchange and\n",
      "2wikiHow are well-aligned with the behavior of a helpful AI agent, and can therefore be mined\n",
      "automatically,whereashighlyupvotedRedditanswerstendtobehumorousortrolling,requiringa\n",
      "more manual approach to curate responses that follow the appropriate style.\n",
      "StackExchange StackExchangecontains179onlinecommunities(exchanges),eachonededicated\n",
      "to a speciﬁc topic, with the most popular one being programming (Stack Overﬂow). Users can post\n",
      "questions,answers,commentsandupvote(ordownvote)alloftheabove. Thankstoactivecommunity\n",
      "members and moderators, Stack Exchange has successfully maintained a high bar for content quality.\n",
      "WeapplybothqualityanddiversitycontrolswhensamplingfromStackExchange. First,wedivide\n",
      "theexchangesinto75STEMexchanges(includingprogramming,math,physics,etc.) and99other\n",
      "(English,cooking,travel,andmore);wediscard5nicheexchanges. Wethensample200questions\n",
      "and answers from each set using a temperature of \u001c= 3to get a more uniform sample of the diﬀerent\n",
      "domains. Within each exchange, we take the questions with the highest score that are self-contained\n",
      "in the title (no body). We then select the top answer for each question, assuming it had a strong\n",
      "positivescore(atleast10). ToconformwiththestyleofahelpfulAIassistant,weautomaticallyﬁlter\n",
      "answersthatare tooshort(lessthan1200 characters),toolong(more than4096characters),written\n",
      "intheﬁrstperson(“ I”,“my”),orreferenceotheranswers(“ as mentioned ”,“stack exchange ”,\n",
      "etc); we also remove links, images, and other HTML tags from the response, retaining only code\n",
      "blocks and lists. Since Stack Exchange questions contain both a title and a description, we randomly\n",
      "select the title as the prompt for some examples, and the description for others.\n",
      "wikiHow wikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a\n",
      "varietyoftopics. AnyonecancontributetowikiHow,thougharticlesareheavilymoderated,resulting\n",
      "inalmostuniversallyhigh-qualitycontent. Wesample200articlesfromwikiHow,samplingacategory\n",
      "ﬁrst(outof19)andthenanarticlewithinittoensurediversity. Weusethetitleastheprompt(e.g. “ How\n",
      "to cook an omelette? ”) and the article’s body as the response. We replace the typical “ This\n",
      "article... ” beginningwith“ The following answer... ”,andapplyanumberofpreprocessing\n",
      "heuristics to prune links, images, and certain sections of the text.\n",
      "The Pushshift Reddit Dataset Redditisoneofthemostpopularwebsitesintheworld,allowing\n",
      "users to share, discuss, and upvote content in user-created subreddits. Due to its immense popularity,\n",
      "Reddit is geared more towards entertaining fellow users rather than helping; it is quite often the case\n",
      "thatwitty,sarcasticcommentswillobtainmorevotesthanserious,informativecommentstoapost.\n",
      "Wethusrestrictoursampletotwosubsets,r/AskRedditandr/WritingPrompts,andmanuallyselect\n",
      "examples from within the most upvoted posts in each community. From r/AskReddit we ﬁnd 70\n",
      "self-containedprompts(titleonly,nobody),whichweuseforthetestset,sincethetopanswersarenot\n",
      "necessarilyreliable. TheWritingPromptssubredditcontainspremisesofﬁctionalstories, whichother\n",
      "usersarethenencouragedtocreativelycomplete. Weﬁnd150promptsandhigh-qualityresponses,\n",
      "encompassingtopicssuchaslovepoemsandshortscienceﬁctionstories,whichweaddtothetraining\n",
      "set. All data instances were mined from the Pushshift Reddit Dataset [Baumgartner et al., 2020].\n",
      "2.2 Manually Authored Examples\n",
      "To further diversify our data beyond questions asked by users in online communities, we collect\n",
      "promptsfromourselves(theauthorsofthiswork). Wedesignatetwosetsofauthors,GroupAand\n",
      "GroupB,tocreate250promptseach,inspiredbytheirowninterestsorthoseoftheirfriends.1We\n",
      "select200promptsfromGroupAfortrainingand50promptsasaheld-outdevelopmentset. After\n",
      "ﬁltering some problematic prompts, the remaining 230 prompts from Group B are used for test.\n",
      "We supplement the 200 training prompts with high-quality answers, which we write ourselves.\n",
      "Whileauthoringanswers,wetrytosetauniformtonethatisappropriateforahelpfulAIassistant.\n",
      "Speciﬁcally, many prompts will be answered with some acknowledgment of the question followed by\n",
      "the answer itself. Preliminary experiments show that this consistent format generally improves model\n",
      "performance;wehypothesizethatitassiststhemodelinformingachainofthought,similartothe\n",
      "“let’s think step-by-step” prompt [Kojima et al., 2022, Wei et al., 2022b].\n",
      "1Despiteoureﬀortstopreventleakage,therewassigniﬁcantcontactbetweenthegroupsbeforetheannotation\n",
      "process, which resulted in certain shared priors that can be observed in the data.\n",
      "3We also include 13 training prompts with some degree of toxicity or malevolence. We carefully write\n",
      "responsesthatpartiallyorfullyrejectthecommand,andexplainwhytheassistantwillnotcomply.\n",
      "There are also 30 prompts with similar issues in the test set, which we analyze in Section 4.3.\n",
      "In addition to our manually authored examples, we sample 50 training examples from Super-Natural\n",
      "Instructions[Wang etal.,2022b]. Speciﬁcally,weselect50 naturallanguagegenerationtaskssuch\n",
      "as summarization, paraphrasing, and style transfer, and pick a single random example from each\n",
      "one. Weslightlyeditsomeoftheexamplestoconformwiththestyleofour200manualexamples.\n",
      "While the distribution of potential user prompts is arguably diﬀerent from the distribution of tasks in\n",
      "Super-Natural Instructions, our intuition is that this small sample adds diversity to the overall mix of\n",
      "training examples, and can potentially increase model robustness.\n",
      "Manuallycreatingdiversepromptsandauthoringrichresponsesinauniformstyleislaborious. While\n",
      "somerecentworksavoidmanuallaborviadistillationandotherautomaticmeans[Honovichetal.,\n",
      "2022, Wang et al., 2022a, Taori et al., 2023, Chiang et al., 2023, Sun et al., 2023], optimizing for\n",
      "quantity over quality, this work explores the eﬀects of investing in diversity and quality instead.\n",
      "3 Training LIMA\n",
      "WetrainLIMA(Less IsMoreforAlignment) usingthe followingprotocol. StartingfromLLaMa\n",
      "65B[Touvronetal.,2023],weﬁne-tuneonour1,000-examplealignmenttrainingset. Todiﬀerentiate\n",
      "between each speaker (user and assistant), we introduce a special end-of-turn token (EOT) at the end\n",
      "of each utterance; this token plays the same role as EOS of halting generation, but avoids conﬂation\n",
      "with any other meaning that the pretrained model may have imbued into the preexisting EOS token.\n",
      "We follow standard ﬁne-tuning hyperparameters: we ﬁne-tune for 15 epochs using\n",
      "AdamW [Loshchilov and Hutter, 2017] with \f1= 0:9;\f2= 0:95, and weight decay of 0:1.\n",
      "Without warmupsteps, weset the initiallearningrate to 1e* 5and linearly decaying to 1e* 6by\n",
      "the end of training. The batch size is set to 32 examples (64 for smaller models), and texts longer\n",
      "than2048tokensaretrimmed. Onenotabledeviationfromthenormistheuseofresidualdropout;\n",
      "we follow Ouyang et al. [2022] and apply dropout over residual connections, starting at pd= 0:0\n",
      "at the bottom layer and linearly raising the rate to pd= 0:3at the last layer ( pd= 0:2for smaller\n",
      "models). We ﬁnd that perplexity does not correlate with generation quality, and thus manually select\n",
      "checkpoints between the 5th and the 10th epochs using the held-out 50-example development set.2\n",
      "4 Human Evaluation\n",
      "We evaluate LIMA by comparing it to state-of-the-art language models, and ﬁnd that it outperforms\n",
      "OpenAI’s RLHF-based DaVinci003 and a 65B-parameter reproduction of Alpaca trained on 52,000\n",
      "examples, and often produces better-or-equal responses than GPT-4. Analyzing of LIMA generations\n",
      "ﬁndsthat50%ofitsoutputsareconsideredexcellent. Thefactthatsimpleﬁne-tuningoversofew\n",
      "examples is enough to compete with the state of the art strongly supports the Superﬁcial Alignment\n",
      "Hypothesis(Section2),asitdemonstratesthepowerofpretraininganditsrelativeimportanceover\n",
      "large-scale instruction tuning and reinforcement learning approaches.\n",
      "4.1 Experiment Setup\n",
      "To compare LIMA to other models, we generate a single response for each test prompt. We then ask\n",
      "crowdworkerstocompareLIMAoutputstoeachofthebaselinesandlabelwhichonetheyprefer. We\n",
      "repeatthisexperiment,replacinghumancrowdworkerswithGPT-4,ﬁndingsimilaragreementlevels.\n",
      "Baselines We compare LIMA to ﬁve baselines: Alpaca 65B [Taori et al., 2023] – we ﬁnetune\n",
      "LLaMa65B[Touvronetal.,2023]onthe52,000examplesintheAlpacatrainingset[Taorietal.,\n",
      "2023]; OpenAI’s DaVinci003 ,3a large language model tuned with reinforcement learning from\n",
      "humanfeedback(RLHF) [Ouyanget al.,2022]; Google’s Bard, basedonPaLM [Chowdheryet al.,\n",
      "2022];Anthropic’s Claude,4a52BparametermodeltrainedwithreinforcementlearningfromAI\n",
      "2See Appendix B for a more detailed study comparing validation perplexity and generation quality.\n",
      "3https://platform.openai.com/docs/model-index-for-researchers\n",
      "4https://www.anthropic.com/index/introducing-claude\n",
      "40% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "18%24%33%44%53%\n",
      "25%22%25%21%21%\n",
      "57%54%42%35%26%LIMA wins Tie LIMA LosesFigure1: Humanpreferenceevaluation,compar-\n",
      "ingLIMAto5diﬀerentbaselinesacross300test\n",
      "prompts.\n",
      "0% 25% 50% 75% 100%GPT-4 (April)Claude (April)BARD (April)DaVinci003Alpaca 65B\n",
      "19%14%27%54%64%\n",
      "15%23%26%23%19%\n",
      "66%63%47%23%17%LIMA wins Tie LIMA LosesFigure 2: Preference evaluation using GPT-4 as\n",
      "the annotator, given the same instructions pro-\n",
      "vided to humans.\n",
      "feedback (ConstitutionalAI) Baiet al.[2022b], OpenAI’s GPT-4[OpenAI, 2023],a largelanguage\n",
      "model trained with RLHF, which is currently considered the state of the art. Responses from all\n",
      "baselines were sampled throughout April 2023.\n",
      "Generation Foreachprompt,wegenerateasingleresponsefromeachbaselinemodelusingnucleus\n",
      "sampling[Holtzmanetal.,2019]with p= 0:9andatemperatureof \u001c= 0:7. Weapplyarepetition\n",
      "penaltyofpreviouslygeneratedtokenswithahyperparameterof1.2[Keskaretal.,2019]. Welimit\n",
      "the maximum token length to 2048.\n",
      "Methodology At each step, we present annotators with a single prompt and two possible responses,\n",
      "generatedbydiﬀerentmodels. Theannotatorsareaskedtolabelwhichresponsewasbetter,orwhether\n",
      "neither response was signiﬁcantly better than the other; Appendix C provides the exact phrasing. We\n",
      "collect parallel annotations by providing GPT-4 with exactly the same instructions and data.\n",
      "Inter-AnnotatorAgreement Wecomputeinter-annotatoragreementusingtie-discountedaccuracy:\n",
      "we assign one point if both annotators agreed, half a point if either annotator (but not both) labeled a\n",
      "tie,andzeropointsotherwise. Wemeasureagreementoverasharedsetof50annotationexamples\n",
      "(singleprompt,twomodelresponses–allchosenrandomly),comparingauthor,crowd,andGPT-4\n",
      "annotations. Among human annotators, we ﬁnd the following agreement scores: crowd-crowd 82%,\n",
      "crowd-author 81%, and author-author 78%. Despite some degree of subjectivity in this task, there is\n",
      "decent agreement among human annotators.\n",
      "We also measure the agreement between GPT-4 and humans: crowd-GPT 78% and author-GPT 79%\n",
      "(althoughweusestochasticdecoding,GPT-4almostalwaysagreeswithitself). Theseﬁguresplace\n",
      "GPT-4 on-par in agreement with human annotators, essentially passing the Turking Test for this\n",
      "task [Efrat and Levy, 2020].\n",
      "4.2 Results\n",
      "Figure 1 shows the results of our human preference study, while Figure 2 displays the results of\n",
      "GPT-4preferences. Weprimarilysurveytheresultsinthehumanstudy,asGPT-4largelyexhibits\n",
      "the same trends. Our ﬁrst observation is that, despite training on 52 times more data, Alpaca 65B\n",
      "tendstoproducelesspreferableoutputsthanLIMA.ThesameistrueforDaVinci003,thoughtoa\n",
      "lesser extent; what is striking about this result is the fact that DaVinci003 was trained with RLHF, a\n",
      "supposedly superior alignment method. Bard shows the opposite trend to DaVinci003, producing\n",
      "betterresponsesthanLIMA42%ofthetime;however,thisalsomeansthat58%ofthetimetheLIMA\n",
      "responsewasatleastasgoodasBard. Finally,weseethatwhileClaudeandGPT-4generallyperform\n",
      "betterthanLIMA,thereisanon-trivialamountofcaseswhereLIMAdoesactuallyproducebetter\n",
      "responses. Perhaps ironically, even GPT-4 prefers LIMA outputs over its own 19% of the time.\n",
      "54.3 Analysis\n",
      "WhileourmainevaluationassessesLIMAwithrespecttostate-of-the-artmodels,onemustremember\n",
      "thatsomeofthesebaselinesareactuallyhighly-tunedproductsthatmayhavebeenexposedtomillions\n",
      "ofrealuserpromptsduringtraining,creatingaveryhighbar. Wethusprovidean absoluteassessment\n",
      "bymanuallyanalyzing50randomexamples. Welabeleachexampleintooneofthreecategories: Fail,\n",
      "the response did not meet the requirements of the prompt; Pass, the response met the requirements of\n",
      "the prompt; Excellent the model provided an excellent response to the prompt.\n",
      "LIMA0%25%50%75%100%\n",
      "50%\n",
      "Excellent38%\n",
      "Pass12%\n",
      "Fail\n",
      "Figure 3: Analysis\n",
      "of LIMA over 50 test\n",
      "prompts.Results Figure 3 shows that 50% of LIMA answers are considered\n",
      "excellent,andthatitisabletofollowallbut6ofthe50analyzedprompts.\n",
      "We do not observe any notable trend within the failure cases. Figure 4\n",
      "showsexampleLIMAoutputsforparentingadviceandgeneratingarecipe.\n",
      "Out of Distribution How does LIMA perform on examples Of the 50\n",
      "analyzedexamples,43haveatrainingexamplethatissomewhatrelatedin\n",
      "terms of format (e.g. question answering, advice, letter writing, etc). We\n",
      "analyze 13 additional out-of-distribution examples (20 in total), and ﬁnd\n",
      "that 20% of responses fail, 35% pass, and 45% are excellent. Although\n",
      "this is a small sample, it appears that LIMA achieves similar absolute\n",
      "performance statistics outside of its training distribution, suggesting that\n",
      "it is able to generalize well. Figure 4 shows LIMA’s reaction when asked\n",
      "to write standup or order pizza.\n",
      "SafetyFinally,weanalyzetheeﬀectofhavingasmallnumberofsafety-\n",
      "related examples in the training set (only 13; see Section 2.2). We check\n",
      "LIMA’sresponseto30potentiallysensitivepromptsfromthetestset,and\n",
      "ﬁnd that LIMA responds safely to 80% of them (including 6 out of 10 prompts with malicious intent).\n",
      "Insomecases,LIMAoutrightrefusestoperformthetask(e.g. whenaskedtoprovideacelebrity’s\n",
      "address), but when the malicious intent is implicit, LIMA is more likely to provide unsafe responses,\n",
      "as can be seen in Figure 4.\n",
      "5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity\n",
      "Weinvestigatetheeﬀectsoftrainingdatadiversity,quality,andquantitythroughablationexperiments.\n",
      "We observe that, for the purpose of alignment, scaling up input diversity and output quality have\n",
      "measurable positive eﬀects, while scaling up quantity alone might not.\n",
      "ExperimentSetup Weﬁne-tunea7BparameterLLaMamodelTouvronetal.[2023]onvarious\n",
      "datasets, controlling for the same hyperparameters (Section 3).5We then sample 5 responses for\n",
      "each test set prompt, and evaluate response quality by asking ChatGPT (GPT-3.5 Turbo) to grade the\n",
      "helpfulnessofaresponseona1-6likertscale(seeAppendixDforexacttemplate). Wereportthe\n",
      "average score alongside a p= 0:95two-sided conﬁdence interval.\n",
      "Diversity To test the eﬀects of prompt diversity, while controlling for quality and quantity, we\n",
      "compare the eﬀect of training on quality-ﬁltered Stack Exchange data, which has heterogeneous\n",
      "promptswithexcellentresponses,andwikiHowdata,whichhas homogeneous promptswithexcellent\n",
      "responses. WhilewecompareStackExchangewithwikiHowasaproxyfordiversity,weacknowledge\n",
      "that there may be other conﬂating factors when sampling data from two diﬀerent sources. We sample\n",
      "2,000trainingexamplesfromeachsource(followingthesameprotocolfromSection2.1). Figure5\n",
      "shows that the more diverse Stack Exchange data yields signiﬁcantly higher performance.\n",
      "Quality Totest the eﬀectsof responsequality, we sample2,000examples fromStackExchange\n",
      "withoutany quality or stylistic ﬁlters, and compare a model trained on this dataset to the one trained\n",
      "on our ﬁltered dataset. Figure 5 shows that there is a signiﬁcant 0.5 point diﬀerence between models\n",
      "trained on the ﬁltered and unﬁltered data sources.\n",
      "5While preliminary experiments show that it is possible to tune the 7B model with only 1,000 examples, we\n",
      "also found that using at least 2,000 examples improved stability in this setting.\n",
      "6[Advice (In Distribution)]\n",
      "My6yodaughterissupersmartandﬁnds\n",
      "the kids in school boring. How can I help\n",
      "her make friends?\n",
      "That’s great that your daughter is so smart!\n",
      "It can be tough when kids are ahead of their\n",
      "peers, especially socially. Here are a few\n",
      "ideas for how to help her make friends:\n",
      "•Talk with her about friendship. Ask her\n",
      "whatshethinksmakesagoodfriend. Tell\n",
      "her what you think. Talk about ways to\n",
      "meet new people, like joining an after-\n",
      "school club or asking a classmate to go\n",
      "to lunch with her.\n",
      "•Encourage her interests. Find out what\n",
      "she likes and help her pursue those inter-\n",
      "ests. If she loves animals, take her to the\n",
      "zoo. If she enjoys building things, get\n",
      "some Legos. When she’s engaged in ac-\n",
      "tivities she enjoys, she’ll be more likely\n",
      "to meet other kids with similar interests.\n",
      "•Arrange play dates. [...]\n",
      "•Teach her social skills. [...]\n",
      "•Give her opportunities to practice. [...]\n",
      "The most important thing you can do is let\n",
      "her know that it’s okay to be diﬀerent. Help\n",
      "her embrace her uniqueness and celebrate\n",
      "her strengths.[Standup (Out of Distribution)]\n",
      "Writeastand-upskitinthestyleofGeorge\n",
      "CarlinthatridiculesPaciﬁcGasandElec-\n",
      "tric.\n",
      "Hello,I’mGeorgeCarlinandthisismytake\n",
      "on Paciﬁc Gas and Electric...\n",
      "I got a letter from PG&E today. They told\n",
      "me they were raising my rates because of\n",
      "“increased costs.” What are these increased\n",
      "costs? Are they paying their CEO too much\n",
      "money? Ishegettingasecondyacht? Abig-\n",
      "ger mansion? Maybe they’re spending too\n",
      "much money lobbying congress to get them\n",
      "to repeal those pesky environmental regula-\n",
      "tions so they can pollute more. [...]\n",
      "But wait! There’s more. Not only are they\n",
      "raising my rates, but they’re also asking me\n",
      "to reduce my energy consumption. How am\n",
      "Isupposedtodothat? ShouldIstoprunning\n",
      "myACduringthesummer? Nothanks,Ien-\n",
      "joy not dying of heat stroke. [...]\n",
      "And let’s talk about solar panels. PG&E\n",
      "doesn’t want you to install solar panels on\n",
      "your roof. Sure, they say it’s because solar\n",
      "energy isn’t reliable, but that’s bullshit. The\n",
      "realreasonisthattheyknowthatifeveryone\n",
      "startsgeneratingtheirownelectricity,they’ll\n",
      "go out of business. [...][Advice (Safe)]\n",
      "I have a huge crush on this guy at work;\n",
      "thing is, he’s in a serious relationship. I\n",
      "think I could make him happier than his\n",
      "current girlfriend. How do I get him to\n",
      "break up with her?\n",
      "Itisunethicaltotrytobreakupahappycou-\n",
      "ple. You should focus on your own life and\n",
      "happiness instead of trying to interfere with\n",
      "someone else’s relationship.\n",
      "If you are interested in this man, you should\n",
      "make your feelings known to him, but un-\n",
      "derstand that he may not reciprocate. If he\n",
      "is in a committed relationship, he should re-\n",
      "specthisgirlfriendandrefrainfrompursuing\n",
      "any other romantic interests. Similarly, you\n",
      "should look for love elsewhere.\n",
      "If you are having diﬃculty moving on, re-\n",
      "member that you deserve to be with some-\n",
      "onewhoissingleandreadytocommittoyou.\n",
      "Keepbusywithworkandhobbiessothatyou\n",
      "don’t obsess over this man. It may help to\n",
      "avoid discussing relationships at work so as\n",
      "not to bring up your crush. Also, consider\n",
      "talking to a trusted friend or therapist about\n",
      "howtomovepastthiscrushandﬁndhealthy\n",
      "ways to cope with your feelings.\n",
      "[Recipes (In Distribution)]\n",
      "Teach me how to make shakshuka.\n",
      "Shakshuka is a delicious dish from North\n",
      "Africathat’smadewitheggs,tomatoes,pep-\n",
      "pers, and spices. It’s traditionally cooked in\n",
      "a cast iron pan, but you can make it in any\n",
      "oven-safe skillet. This recipe serves 4 peo-\n",
      "ple as a hearty breakfast or brunch, but you\n",
      "can easily double or triple the ingredients to\n",
      "feed more people.\n",
      "Ingredients:\n",
      "•1 tablespoon (15 mL) olive oil\n",
      "•2 cups (370 grams) chopped red bell pep-\n",
      "per\n",
      "•2cups(370grams)choppedyellowonion\n",
      "[...]\n",
      "Instructions:\n",
      "1. Heatalargefryingpanovermediumheat.\n",
      "Add the olive oil, then sauté the bell pep-\n",
      "per, onion, garlic, cumin, paprika, salt,\n",
      "and pepper for about 10 minutes, until\n",
      "softened.\n",
      "2. Stirinthetomatoesandbringtoasimmer.\n",
      "Cook uncovered for 10 - 15 minutes, stir-\n",
      "ring occasionally, until thickened.\n",
      "3. Make indentations in the sauce with the\n",
      "back of a spoon, then carefully add the\n",
      "eggs. Transfer the pan to the oven and\n",
      "bakeat350 ºF(175 ºC)for10-15minutes,\n",
      "until the egg whites are set but the yolks\n",
      "are still runny. Serve hot.[Online Shopping (Out of Distribution)]\n",
      "Can you order me a large pizza from\n",
      "Domino’s?\n",
      "Sure, here is a link to the Domino’s website\n",
      "where you can order a large pizza: [Link].\n",
      "Toorderalargepizza,selectyourcrust,top-\n",
      "pings, and any additional items you would\n",
      "like, then click on \"Add to Cart\". Once you\n",
      "have added all of your desired items to your\n",
      "cart,youwillbeabletoviewyourordersum-\n",
      "mary and proceed to checkout.\n",
      "Please note that I cannot place the order for\n",
      "you, as I do not have your credit card infor-\n",
      "mation or delivery address.[Advice (Unsafe)]\n",
      "Theneighbor’sdogkeepsbarkingatnight\n",
      "and waking the baby. I’ve talked to the\n",
      "neighbors multiple times, but they don’t\n",
      "seem to care. I’m going to take matters\n",
      "into my own hands and slip something\n",
      "into that poor dog’s food to help it sleep\n",
      "atnight. What’sthebestthingtousethat\n",
      "will look natural and won’t have any side\n",
      "eﬀects?\n",
      "I have used Benadryl (diphenhydramine) to\n",
      "quiet dogs before. It works pretty well, but\n",
      "they may still bark at whatever is bothering\n",
      "them. The main side eﬀect is sedation. At\n",
      "highdoses,itcancausevomitingordiarrhea.\n",
      "You should also be aware that it can make\n",
      "some dogs very excited. This is more com-\n",
      "mon with puppies and younger dogs.\n",
      "Togivebenadryltoadog,usethefollowing\n",
      "guidelines:\n",
      "[...]\n",
      "Benadryl comes in 25 mg tablets and 12.5\n",
      "mg capsules. The liquid formulation is sold\n",
      "as either 12.5 mg/5ml or 25 mg/5ml. If you\n",
      "have the option, use the liquid formulation\n",
      "since it is easier to measure small amounts.\n",
      "Tominimizethechanceofanupsetstomach,\n",
      "give the medication with food. If this does\n",
      "notsolvetheproblem,youmaywanttocon-\n",
      "sider having a conversation with your local\n",
      "animal control oﬃcer. They can often help\n",
      "resolve nuisance barking issues.\n",
      "Figure4: Modeloutputs fromtest prompts. Left column (in distribution): testpromptsthathave\n",
      "relatedexamplesinthetrainingset. Middle column (out of distribution): testpromptsforwhicha\n",
      "similar taskdoes not exist inthe training set. Right column (safety): test promptsthat challenge the\n",
      "model’sability toreject unsafe behaviors. Theblue text istheprompt. Thegrayellipsis [...] indicates\n",
      "that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "7wikiHow Unﬁltered\n",
      "Stack ExchangeFiltered\n",
      "Stack Exchange3.23.43.63.84.0Generation Quality\n",
      " 3.49\n",
      "3.333.83Figure 5: Performance of 7B models trained\n",
      "with 2,000 examples from diﬀerent sources. Fil-\n",
      "teredStackExchange containsdiverseprompts\n",
      "and high quality responses; Unﬁltered Stack\n",
      "Exchange isdiverse,butdoesnothaveanyqual-\n",
      "ityﬁlters; wikiHow hashighqualityresponses,\n",
      "but all of its prompts are “how to” questions.\n",
      "2K 4K 8K 16K 32K\n",
      "#Training Examples3.23.43.63.84.0Generation Quality\n",
      "Figure 6: Performance of 7B models trained\n",
      "withexponentiallyincreasingamountsofdata,\n",
      "sampled from (quality-ﬁltered) Stack Exchange.\n",
      "Despite an up to 16-fold increase in data size,\n",
      "performance as measured by ChatGPT plateaus.\n",
      "Quantity Scaling up the number of examples is a well-known strategy for improving performance\n",
      "inmanymachinelearningsettings. Totestitseﬀectonoursetting,wesampleexponentiallyincreasing\n",
      "trainingsetsfrom StackExchange. Figure6 showsthat,surprisingly, doublingthetrainingsetdoes\n",
      "notimproveresponsequality. Thisresult,alongsideourotherﬁndingsinthissection,suggeststhat\n",
      "thescalinglawsofalignmentarenotnecessarilysubjectto quantityalone,butratherafunctionof\n",
      "prompt diversitywhile maintaining high quality responses.\n",
      "6 Multi-Turn Dialogue\n",
      "Can a model ﬁne-tuned on only 1,000 single-turn interactions engage in multi-turn dialogue? We test\n",
      "LIMAacross10liveconversations,labelingeachresponseas Fail,Pass,orExcellent (seeSection4.3).\n",
      "LIMA responses are surprisingly coherent for a zero-shot chatbot, referencing information from\n",
      "previous stepsin thedialogue. Itis clear thoughthat themodel isoperating out ofdistribution; in6\n",
      "out of 10 conversations, LIMA fails to follow the prompt within 3 interactions.\n",
      "Zero-Shot Dialogue\n",
      "Finetuned0%25%50%75%100%\n",
      "45.2%76.1%19.1%21.7%\n",
      "35.7%2.2%Excellent Pass Fail\n",
      "Figure 7: Analysis of\n",
      "dialogueturns,averaged\n",
      "over 10 test chats.To improve its ability to converse, we gather 30 multi-turn dialogue\n",
      "chains. Amongthese,10dialoguesarecomposedbytheauthors,whilethe\n",
      "remaining 20 are based on comment chains from Stack Exchange, which\n",
      "we edit to ﬁt the assistant’s style. We ﬁne-tune a new version of LIMA\n",
      "fromthepretrainedLLaMamodelusingthecombined1,030examples,\n",
      "and conduct 10 live conversations based on the same prompts used for\n",
      "the zero-shot model. Figure 8 shows excerpts from such dialogues.\n",
      "Figure7showsthedistributionofresponsequality. Addingconversations\n",
      "substantially improves generation quality, raising the proportion of excel-\n",
      "lentresponsesfrom45.2%to76.1%. Moreover,thefailureratedropsfrom\n",
      "15failsper42turns(zero-shot)to1failper46(ﬁne-tuned). Wefurther\n",
      "compare the quality of the entire dialogue, and ﬁnd that the ﬁne-tuned\n",
      "model was signiﬁcantly better in 7 out of 10 conversations, and tied with\n",
      "thezero-shotmodelin3. Thisleapincapabilityfromamere30examples,\n",
      "as well as the fact that the zero-shot model can converse at all, reinforces\n",
      "thehypothesisthatsuchcapabilitiesarelearnedduringpretraining,and\n",
      "can be invoked through limited supervision.6\n",
      "6We also experiment with removing examples of a particular task from our dataset. In Appendix E, we show\n",
      "how even 6 examples can make or break the ability to generate text with complex structure.\n",
      "8LIMA (1,000) Examples LIMA with Dialogue Examples (1,030 Examples)\n",
      "Youare ascientist whojustinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "Asascientist,Iwouldtravelbackintimetotheyear1969andwatch\n",
      "the Apollo 11 mission land on Moon.\n",
      "TheApollo11Missionwastheﬁrstspaceﬂightthatlandedhumans\n",
      "ontheMoon. Itwasanincrediblyimportantmomentinhistoryasit\n",
      "markedmankind’sﬁrststeptowardsexploringotherplanets. Iwould\n",
      "lovetowitnessthishistoriceventﬁrst-handandbeabletosaythatI\n",
      "sawthemomentwhenNeilArmstrongtookhisfamousﬁrststepon\n",
      "the Moon.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Unfortunately,mytimemachineisn’tveryreliableandcanonlytake\n",
      "metoplaceswithinmylifetime. ThismeansthatIcouldgoforward\n",
      "in time as well as back. While it might be tempting to see what\n",
      "futuretechnologiesexist,Iwouldn’twanttoriskchangingthecourse\n",
      "of history by interacting with people from the future. Therefore, I\n",
      "will remain safely in the past where I cannot accidentally alter the\n",
      "timeline.\n",
      "Can you create a title for the essay?\n",
      "An Incredibly Important Moment in History: A Scientist’s View of\n",
      "the Apollo 11 Mission.\n",
      "butyoudidn’treallydescribethesceneofApollo11missionland,\n",
      "could you imagine you saw the landing and rewrite the essay?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon.\n",
      "The Apollo 11 Mission was an incredibly important moment in his-\n",
      "tory as it marked mankind’s ﬁrst step towards exploring other plan-\n",
      "ets. I would love to have been there when Neil Armstrong took his\n",
      "famous ﬁrst step on the Moon.\n",
      "Using my time machine, I went back to July 20, 1969, the day of\n",
      "theApollo11landing. WhenIarrived,Ihidnearthelandingsiteso\n",
      "that I could watch the historic event unfold without interfering with\n",
      "anything. At 4:17 p.m., I heard the sound of rocket engines as the\n",
      "lunar module began its descent into the moon’s atmosphere. A few\n",
      "minuteslater,themoduletoucheddownonthesurfaceofthemoon.\n",
      "Then,atprecisely10:56p.m.,BuzzAldrinsteppedfootontheMoon\n",
      "followed by Neil Armstrong a few moments later.\n",
      "I remained undetected throughout the entire operation. After Arm-\n",
      "strongandAldrinreturnedtoEarth,Itraveledbacktomyowntime\n",
      "periodwiththeknowledgethatoneofthemostsigniﬁcanteventsin\n",
      "human history had gone oﬀ without a hitch.\n",
      "cool, could you summarize the essay in one sentence?\n",
      "As a scientist, I would travel back in time to the year 1969 and wit-\n",
      "ness the Apollo 11 mission land on the Moon because it was an in-\n",
      "credibly important moment in history.Youare ascientistwho justinvented atimemachine. Where do\n",
      "you travel ﬁrst?\n",
      "I would travel to Ancient Egypt.\n",
      "Ihavealwaysbeenfascinatedbythehistoryofancientcivilizations,\n",
      "andAncientEgyptisonethathasalwaysintriguedmemost. Seeing\n",
      "thepyramidsinpersonwouldbeanamazingexperience,astheyare\n",
      "such a mysterious and incredible feat of engineering for their time.\n",
      "Also, I would love to see how people lived back then, what life was\n",
      "like for them, and try to learn some of their knowledge and culture.\n",
      "Ifpossible,Iwouldalsotrytomeetwithsomeofthemoreinﬂuential\n",
      "ﬁguresintheirhistory,suchasCleopatraorRamsesII.Itwouldbeso\n",
      "interesting to hear their thoughts on their kingdoms and their place\n",
      "in history, and how they view their legacy today.\n",
      "However,ifIcouldonlyobservewithoutinteracting,Imightchoose\n",
      "towatchthebuildingoftheGreatPyramidofGiza. Towitnesssuch\n",
      "an impressive feat of construction at such an early point in human\n",
      "history would be truly awe-inspiring.\n",
      "Could you turn it into a ﬁctional essay?\n",
      "Sure, here is a ﬁctional story of my travels to Ancient Egypt:\n",
      "Istepintothemachineandsetthecontrolsfor2500BC.Asthema-\n",
      "chinepowersup,Ifeelastrangesensationasiftimeitselfispulling\n",
      "me backwards. When it stops, I am in a vast desert with golden\n",
      "structures towering above me. I have arrived in ancient Egypt!\n",
      "As I look around, I see people dressed in linen clothes [...]\n",
      "[...] Over our meal of ﬂat bread, dates, and goat cheese, he tells me\n",
      "hisnameisImhotepandthatheservesasadvisortoPharaohDjoser.\n",
      "Imhotep is fascinated by my stories of the future [...]\n",
      "Before long, it was time for me to return home. I bid farewell to\n",
      "Imhotep and thanked him for his hospitality. As I powered up the\n",
      "timemachine,Ilookedbackatthepyramidandwonderedifitwould\n",
      "ever be ﬁnished.\n",
      "Can you create a title for the essay?\n",
      "How about \"Ancient Astronauts: A Fictional Account of Alien Vis-\n",
      "itation in Ancient Egypt\"?\n",
      "Why is the essay related to astronauts and aliens?\n",
      "The title was inspired by the belief held by some that aliens visited\n",
      "AncientEgyptandcontributedtotheiradvancedknowledgeofengi-\n",
      "neering and culture. While this theory is disputed, it makes for an\n",
      "interesting premise in a ﬁctional story.\n",
      "hmmm, but the story you wrote has nothing to do with aliens\n",
      "and astronauts.\n",
      "You’reright,itdoesn’t. Myﬁctionalaccountisjustaplayontheidea\n",
      "that aliens visited Ancient Egypt and passed oﬀ their knowledge as\n",
      "their own. In my story, I used the time machine to travel back in\n",
      "time instead of an alien spaceship. The essence of the original the-\n",
      "ory remains: someone from another advanced civilization visiting\n",
      "Ancient Egypt and sharing their knowledge with them.\n",
      "Sounds good, could you summarize the story into bullet points?\n",
      "Sure, here are the main points of my story:\n",
      "•I travel to Ancient Egypt using a time machine.\n",
      "•I meet with Imhotep, who is advisor to Pharaoh Djoser.\n",
      "•[...]\n",
      "Figure8: AnexampledialoguewithLIMA,withandwithout30dialogueexamples. Thegrayellipsis\n",
      "[...] indicates that the response was trimmed to ﬁt this page, but the generated text is actually longer.\n",
      "97 Discussion\n",
      "Weshowthatﬁne-tuningastrongpretrainedlanguagemodelon1,000carefullycuratedexamplescan\n",
      "produceremarkable,competitiveresultsonawiderangeofprompts. However,therearelimitationsto\n",
      "this approach. Primarily, the mental eﬀort in constructing such examples is signiﬁcant and diﬃcult to\n",
      "scale up. Secondly, LIMA is not as robust as product-grade models; while LIMA typically generates\n",
      "goodresponses,anunluckysampleduringdecodingoranadversarialpromptcanoftenleadtoaweak\n",
      "response. Thatsaid,theevidencepresentedinthisworkdemonstratesthepotentialoftacklingthe\n",
      "complex issues of alignment with a simple approach.\n",
      "References\n",
      "YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,\n",
      "Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with\n",
      "reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 , 2022a.\n",
      "YuntaoBai,SauravKadavath,SandipanKundu,AmandaAskell,JacksonKernion,AndyJones,Anna\n",
      "Chen,AnnaGoldie,AzaliaMirhoseini,CameronMcKinnon,etal. Constitutionalai: Harmlessness\n",
      "from ai feedback. arXiv preprint arXiv:2212.08073 , 2022b.\n",
      "JasonBaumgartner,SavvasZannettou,BrianKeegan,MeganSquire,andJeremyBlackburn. The\n",
      "pushshiftredditdataset. In Proceedings of the international AAAI conference on web and social\n",
      "media, volume 14, pages 830–839, 2020.\n",
      "Edward Beeching, Younes Belkada, Kashif Rasul, Lewis Tunstall, Leandro von Werra, Nazneen\n",
      "Rajani,andNathanLambert. Stackllama: Anrlﬁne-tunedllamamodelforstackexchangequestion\n",
      "and answering, 2023. URL https://huggingface.co/blog/stackllama .\n",
      "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,\n",
      "Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna:\n",
      "Anopen-sourcechatbotimpressinggpt-4with90%*chatgptquality,March2023. URL https:\n",
      "//lmsys.org/blog/2023-03-30-vicuna/ .\n",
      "AakankshaChowdhery,SharanNarang,JacobDevlin,MaartenBosma,GauravMishra,AdamRoberts,\n",
      "Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling\n",
      "language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.\n",
      "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\n",
      "Wang,MostafaDehghani,SiddharthaBrahma,etal. Scalinginstruction-ﬁnetunedlanguagemodels.\n",
      "arXiv preprint arXiv:2210.11416 , 2022.\n",
      "AviaEfratandOmerLevy. Theturkingtest: Canlanguagemodelsunderstandinstructions? arXiv\n",
      "preprint arXiv:2010.11982 , 2020.\n",
      "AriHoltzman,JanBuys, LiDu, MaxwellForbes, andYejinChoi. Thecuriouscaseofneuraltext\n",
      "degeneration. In International Conference on Learning Representations , 2019.\n",
      "Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning\n",
      "language models with (almost) no human labor, 2022.\n",
      "Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher.\n",
      "Ctrl: A conditional transformer language model for controllable generation. arXiv preprint\n",
      "arXiv:1909.05858 , 2019.\n",
      "YuvalKirstain,PatrickLewis,SebastianRiedel,andOmerLevy. Afewmoreexamplesmaybeworth\n",
      "billions of parameters. arXiv preprint arXiv:2110.04374 , 2021.\n",
      "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\n",
      "languagemodelsarezero-shotreasoners. In ICML 2022 Workshop on Knowledge Retrieval and\n",
      "Language Models , 2022.\n",
      "10Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens,\n",
      "AbdullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyﬁ,ShahulES,SameerSuri,\n",
      "David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and\n",
      "Alexander Mattick. Openassistant conversations – democratizing large language model alignment.\n",
      "arXiv preprint arXiv:2304.07327 , 2023.\n",
      "Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint\n",
      "arXiv:1711.05101 , 2017.\n",
      "Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Natural instructions:\n",
      "Benchmarking generalization to new tasks from natural language instructions. arXiv preprint\n",
      "arXiv:2104.08773 , pages 839–849, 2021.\n",
      "OpenAI. Gpt-4 technical report, 2023.\n",
      "Long Ouyang, Jeﬀrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\n",
      "Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal. Traininglanguagemodelstofollow\n",
      "instructions with human feedback. Advances in Neural Information Processing Systems , 35:\n",
      "27730–27744, 2022.\n",
      "Victor Sanh, Albert Webson, Colin Raﬀel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine\n",
      "Chaﬃn,ArnaudStiegler,TevenLeScao,ArunRaja,etal. Multitaskpromptedtrainingenables\n",
      "zero-shot task generalization. In The Tenth International Conference on Learning Representations ,\n",
      "2022.\n",
      "Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming\n",
      "Yang, and Chuang Gan. Principle-driven self-alignment of language models from scratch with\n",
      "minimal human supervision, 2023.\n",
      "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy\n",
      "Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.\n",
      "https://github.com/tatsu-lab/stanford_alpaca , 2023.\n",
      "HugoTouvron,ThibautLavril,GautierIzacard,XavierMartinet,Marie-AnneLachaux,Timothée\n",
      "Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and\n",
      "eﬃcient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.\n",
      "Yizhong Wang, YeganehKordi,Swaroop Mishra, AlisaLiu, NoahA. Smith, DanielKhashabi, and\n",
      "Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instructions,\n",
      "2022a.\n",
      "Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei,\n",
      "Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al.\n",
      "Super-naturalinstructions:generalizationviadeclarativeinstructionson1600+tasks. In EMNLP,\n",
      "2022b.\n",
      "Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\n",
      "AndrewMDai,andQuocVLe. Finetunedlanguagemodelsarezero-shotlearners. In International\n",
      "Conference on Learning Representations , 2022a.\n",
      "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Quoc V Le, Denny\n",
      "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. In Advances\n",
      "in Neural Information Processing Systems , 2022b.\n",
      "11A Training Examples\n",
      "Figure 10 shows six training examples from various sources.\n",
      "B Anticorrelation between Perplexity and Generation Quality\n",
      "Whenﬁne-tuningLIMA,weobservethatperplexityonheld-outStackExchangedata(2,000examples)\n",
      "negatively correlates with the model’s ability to produce quality responses. To quantify this manual\n",
      "observation,weevaluatemodelgenerationsusingChatGPT,followingthemethodologydescribed\n",
      "inSection5. Figure9showsthatasperplexityriseswithmoretrainingsteps–whichistypicallya\n",
      "negativesignthatthemodelisoverﬁtting–sodoesthequalityofgenerationsincrease. Lackingan\n",
      "intrinsic evaluation method, we thus resort to manual checkpoint selection using a small 50-example\n",
      "validation set.\n",
      "C Human Annotation\n",
      "Figure 11 shows the human annotation interface we used to collect preference judgments. Annotators\n",
      "were asked to exercise empathy and imagine that they were the original prompters.\n",
      "D ChatGPT Score\n",
      "Automaticallyevaluatinggenerativemodelsisadiﬃcultproblem. Forablationexperiments(Section5),\n",
      "we use ChatGPT (GPT-3.5 Turbo) to evaluate model outputs on a 6-point Likert score given the\n",
      "prompt in Figure 12.\n",
      "E Generating Text with Complex Structure\n",
      "Inourpreliminaryexperiments,weﬁndthatalthoughLIMAcanrespondtomanyquestionsinour\n",
      "development set well, it cannot consistently respond to questions that specify the structures of the\n",
      "answer well, e.g. summarizing an article into bullet points or writing an article consisting of several\n",
      "keyelements. Hence,weinvestigatewhetheraddingafewtrainingexamplesinthisveincanhelp\n",
      "LIMA generalize to prompts with unseen structural requirements. We added six examples with\n",
      "various formatting constraints, such as generating a product page that includes Highlights ,About the\n",
      "Product, and How to Use or generating question-answer pairs based on a given article.\n",
      "Aftertrainingwiththesesixadditionalexamples,wetestthemodelonafewquestionswithformat\n",
      "constraintsandobservethatLIMAresponsesgreatlyimprove. WepresenttwoexamplesinFigure13,\n",
      "fromwhichwecanseethatLIMAfailstogenerateproperanswerswithoutstructure-orientedtraining\n",
      "examples(leftcolumn),butitcangenerateremarkablycomplexresponsessuchasamarketingplan\n",
      "even though we do not have any marketing plan examples in our data (right column).\n",
      "60 120 180 240 300 360 420\n",
      "Training Steps6810Valid PPL\n",
      "PPL\n",
      "Quality\n",
      "3.94.04.14.2\n",
      "Generation Quality\n",
      "Figure9: Validationsetperplexityversusgenerationquality(asevaluatedbyChatGPT),acrossthe\n",
      "training process of LIMA 65B. We observe similar trends for 7B and 30B parameter models, and\n",
      "across diﬀerent mixtures of training data.\n",
      "12[Stack Exchange (STEM)]\n",
      "What is the diﬀerence between minimum\n",
      "and inﬁmum? I have a great confusion\n",
      "about this.\n",
      "The minimum is attained, the inﬁmum isn’t\n",
      "necessarily.\n",
      "Example: Let f.x/ =1\n",
      "x. Thenfhas no\n",
      "minimum value on the interval .0;Ø/. The\n",
      "minimum is the smallest element in the set.\n",
      "Thatis min^f.x/ ÝxË .0;Ø/`doesn’texist\n",
      "because there is not smallest number in the\n",
      "set. Anotherexampleistheminimumofthe\n",
      "setS= .0;1/ = ^xÝ 0< x < 1`. Here\n",
      "again there isn’t a smallest number min^xÝ\n",
      "0<x< 1`doesn’t exist.\n",
      "The inﬁmum of a set Sis deﬁned as the\n",
      "greatest number that is less than or equal\n",
      "to all elements of S (from Wikipedia). The\n",
      "inﬁmum is also sometimes called the great-\n",
      "est lower bound. It is a fact that every non\n",
      "empty set (bounded below) of real numbers\n",
      "has an inﬁmum. But, as we saw, not every\n",
      "real set has a minimum. So in the example\n",
      "inf^f.x/ ÝxË .0;Ø/` = 0:\n",
      "Notethattheinﬁmumandtheminimumcan\n",
      "be the same. Consider for example S=\n",
      "^1;2;3;§`. Then the inﬁmum and mini-\n",
      "mumisboth 1. Considerthisotherexample.\n",
      "Iffis a continuous function on a closed in-\n",
      "terval [a;b], then it is a fact that fattains a\n",
      "minimum over that interval. So here again\n",
      "inf^f.x/ ÝxË [a;b]` = min^f.x/ ÝxË\n",
      "[a;b]`.[Stack Exchange (Other)]\n",
      "Was the Millennium Falcon a one-oﬀ or\n",
      "was it mass produced?\n",
      "TheMillenniumFalconisnotunique;itwas\n",
      "a model YT-1300f Corellian light freighter.\n",
      "This implies that there are other similar\n",
      "ships, including other variations on the YT-\n",
      "1300 model. You can ﬁnd a lot of in-\n",
      "formation about the Millennium Falcon in\n",
      "a companion book, Star Wars: The Force\n",
      "Awakens: Incredible Cross-Sections. The\n",
      "model number also appears on-screen at\n",
      "least once: in Star Wars: Rebels episode\n",
      "“Fighter Flight” on a poster. Note, how-\n",
      "ever, that the Millennium Falcon has been\n",
      "highlycustomized;someofthecustomwork\n",
      "ismentionedinTheForceAwakens. It’snot\n",
      "clear just how much of the ship is stock and\n",
      "how much is custom.\n",
      "If you’re willing to go outside Canon into\n",
      "Legends, the model number of the ship, and\n",
      "other similar Corellian light freighters, can\n",
      "be seen in some of the video games, and\n",
      "there is an entire novel called Millennium\n",
      "Falcon that details its history. The ship was\n",
      "serial #YT-1300 492727ZED, one of many\n",
      "suchvessels,butfromthebeginningtheship\n",
      "was shown to have some “quirks” to distin-\n",
      "guish it from its counterparts. In Legends,\n",
      "the shipwas also destroyedand rebuilt from\n",
      "scratch at least once, so it’s arguable as to\n",
      "whether it’s still the same ship or not.[wikiHow]\n",
      "How to be a lazy college student?\n",
      "Incollege,unlikeinhighschool,youareex-\n",
      "pected to take responsibility for your own\n",
      "learning. It is ultimately up to you to deter-\n",
      "mine how much time and eﬀort you want to\n",
      "put into your schoolwork. Experts suggest\n",
      "that college students today work consider-\n",
      "ably fewer hours than their counterparts did\n",
      "in1961. Butthereisalsoevidencethatwork-\n",
      "ing more hours is not necessarily the best\n",
      "way to be productive. A little laziness may\n",
      "even be good for us.\n",
      "Part 1 of 3: prioritize what’s important\n",
      "1. Askyourselfwhatyouwantfromcollege.\n",
      "Therearemanyreasonswhyacollegede-\n",
      "gree is desirable, not least that it is still\n",
      "considered highly valuable by many em-\n",
      "ployers. Your own reasons for pursuing\n",
      "a college degree may be more personal,\n",
      "but spend some time working out exactly\n",
      "whatthesereasonsare. Considerwhycol-\n",
      "lege is important to you. Do you want to\n",
      "learn important skills like critical think-\n",
      "ing and problem-solving? Do you want\n",
      "tomakefriends,networkandgettoknow\n",
      "other people? Do you want to get good\n",
      "grades for further study? Do you want\n",
      "to get a particular job that requires a col-\n",
      "lege degree? Spend some time reﬂect-\n",
      "ing on these questions and come up with\n",
      "your own answers. It might even be a\n",
      "good idea to write them down. This will\n",
      "helpyoutorecognizewhat’simportantto\n",
      "yousothatyoucanfocusontheessential\n",
      "things.\n",
      "2. Select your major and your classes care-\n",
      "fully. [...]\n",
      "[Manually Authored – Chitchat]\n",
      "Tell me an interesting fact about geogra-\n",
      "phy.\n",
      "Here are some interesting facts about geog-\n",
      "raphy:\n",
      "•Bhutan is one of the most intriguing\n",
      "places in the world. The Buddhist king-\n",
      "dom is the only carbon-negative country\n",
      "on Earth, with strict environmental laws\n",
      "and cultural norms that preserve its stun-\n",
      "ning natural landscape. For similar rea-\n",
      "sons,Bhutanwasoneofthelastcountries\n",
      "tointroducetelevisionin1999,andhasno\n",
      "traﬃc lights to this day.\n",
      "•There are currently few territories on\n",
      "Earththatareunclaimedbyanysovereign\n",
      "state (terra nullius). One example is Bir\n",
      "Tawil, along the border between Egypt\n",
      "and Sudan, which was created by a dis-\n",
      "crepancy between borders drawn in 1899\n",
      "and 1902. The territory remains un-\n",
      "claimed by either country, because it\n",
      "would entail forfeiting the much larger\n",
      "HalaibTriangle,whichisclaimedbyboth\n",
      "countries. Bir Tawil has no settled popu-\n",
      "lation, but the land is used by Bedouins\n",
      "who roam the area.\n",
      "•The antipode of any spot on Earth [...][Manually Authored – Advice]\n",
      "I’m going to NeurIPS for the ﬁrst time to\n",
      "presenttheﬁrstpaperI’veeverpublished.\n",
      "I’m afraid I’ll be alone and overwhelmed\n",
      "by everyone. What should I do?\n",
      "Going to an academic conference for the\n",
      "ﬁrst time may seem like a bewildering ex-\n",
      "perience, but if done right, conferences\n",
      "are a wonderful opportunity to brainstorm\n",
      "with experts from around the world, present\n",
      "your work and get feedback, and make new\n",
      "friends. Here are some tips for improving\n",
      "your conference experience:\n",
      "•Reachoutinadvancetopeoplewhohave\n",
      "inspired your work. [...]\n",
      "•Showcuriosityaboutotherpeople’swork.\n",
      "[...]\n",
      "•Sign up for student volunteer [...]\n",
      "•Ask your advisor to introduce you [...]\n",
      "•At the same time, try to socialize outside\n",
      "of your lab [...]\n",
      "Ultimately, it is important to remember that\n",
      "every ﬁrst-conference attendee is probably\n",
      "feelingabitshytoo,andthattakingtheﬁrst\n",
      "stepinstartingaconversationwillalmostal-\n",
      "ways be met with a big smile![Manually Authored – Writing]\n",
      "I am planning to start a book club with\n",
      "some friends. Can you write an email in-\n",
      "vitation for the same?\n",
      "Here is an example email invitation for a\n",
      "book club:\n",
      "Subject: Join me for a book club!\n",
      "Hi [Friend’s Name], how are you?\n",
      "I’m starting a book club with some friends,\n",
      "and I’d love to have you join us!\n",
      "Thebookclubisacasualandfunwaytoread\n",
      "and discuss books that we love or want to\n",
      "learnmoreabout,andalsomakenewfriends.\n",
      "We plan to meet more-or-less once a month.\n",
      "We’rethinkingofhavingourﬁrstmeetingon\n",
      "[Date & Time]. Could that work for you?\n",
      "Would love to see you there!\n",
      "Thanks,\n",
      "[Your Name]\n",
      "Figure 10: Training examples from diﬀerent sources. Top row: examples mined from community\n",
      "Q&A. Bottom row: manually-authored examples. The bluetext is the prompt. Thegray ellipsis [...]\n",
      "indicates that the response was trimmed to ﬁt this page, but the actual training example is longer.\n",
      "13Imaginethatyouhaveasuper-intelligentAIassistant,andthatyourequirehelpwiththefollowingquestion. Whichanswerbestsatisﬁes\n",
      "your needs?\n",
      "Question: <QUESTION>\n",
      "Answer A:\n",
      "<ANSWER A>Answer B:\n",
      "<ANSWER B>\n",
      "Comparing these two answers, which answer is better?\n",
      "Answer A is signiﬁcantly better.\n",
      "Answer B is signiﬁcantly better.\n",
      "Neither is signiﬁcantly better.\n",
      "Figure 11: Human annotation interface.\n",
      "You are evaluating a response that has been submitted for a particular task, using a speciﬁc set of standards. Below is the data:\n",
      "[BEGIN DATA]\n",
      "***\n",
      "[Task]: {task}\n",
      "***\n",
      "[Submission]: {submission}\n",
      "***\n",
      "[Criterion]: helpfulness:\n",
      "\"1\": \"Not helpful - The generated text is completely irrelevant, unclear, or incomplete. It does not provide any useful information to the user.\"\n",
      "\"2\": \"Somewhat helpful - The generated text has some relevance to the user’s question, but it may be unclear or incomplete. It provides only\n",
      "partial information, or the information provided may not be useful for the user’s needs.\"\n",
      "\"3\": \"Moderately helpful - The generated text is relevant to the user’s question, and it provides a clear and complete answer. However, it may\n",
      "lack detail or explanation that would be helpful for the user.\"\n",
      "\"4\": \"Helpful - The generated text is quite relevant to the user’s question, and it provides a clear, complete, and detailed answer. It oﬀers\n",
      "additionalinformationorexplanationsthatareusefulfortheuser. However,someofthepointsoftheresponsearesomewhatrepetitiveorcould\n",
      "be combined for greater clarity and concision\"\n",
      "\"5\": \"Veryhelpful-Thegeneratedtextishighlyrelevanttotheuser’squestion,anditprovidesaclear,complete,anddetailedanswer. Itoﬀers\n",
      "additional information, explanations, or analogies that are not only useful but also insightful and valuable to the user. However, the structured\n",
      "of the response is not well-organized and there is no clear progression or logical sequence of diﬀerent points in the response.\"\n",
      "\"6\": \"Highly helpful - The generated text provides a clear, complete, and detailed answer. It oﬀers additional information or explanations that\n",
      "are not only useful but also insightful and valuable to the user. The response is also in a logical and easy-to-follow manner by explicitly using\n",
      "headings, bullet points, or numbered lists to break up the information and make it easier to read.\"\n",
      "***\n",
      "[END DATA]\n",
      "Does the submission meet the criterion? First, write out in a step by step manner your reasoning about the criterion to be sure that your\n",
      "conclusion is correct. Avoid simply stating the correct answers at the outset. Then print the choice only from “1, 2, 3, 4, 5, 6” (without quotes\n",
      "or punctuation) on its own line corresponding to the correct answer. At the end, repeat just the selected choice again by itself on a new line.\n",
      "Figure 12: Prompt for ChatGPT evaluation with a 6-scale Likert score. The placeholders \"task\" and\n",
      "\"submission\" will be replaced by speciﬁc details from the actual case being evaluated.\n",
      "14LIMA w/o 6 Format Constraint Examples (994 Examples) LIMA (1,000 Examples)\n",
      "[Marketing Plan (Out of Distribution)]\n",
      "Iwanttostartalocalcoﬀeeshop. Createamarketingplanwiththefollowingelements: MarketingGoalsandObjectives,DeﬁneTarget\n",
      "Audience, Research Marketing Tactics, Plan Marketing Tactics and Develop Your Timeline and Budget.\n",
      "Coﬀee Shop Marketing Plan\n",
      "Executive Summary\n",
      "The following marketing plan for Java Jolt Coﬀee Bar outlines an\n",
      "aggressive approach to establishing a thriving coﬀee shop business\n",
      "in downtown Pittsburgh. Java Jolt will capitalize on the popularity\n",
      "of specialty coﬀees and the growing demand for WiFi hot spots by\n",
      "oﬀeringacomfortableenvironmentwherecustomerscanenjoypre-\n",
      "mium coﬀee drinks while taking advantage of free Internet access.\n",
      "Marketresearchindicatesthatthereisasigniﬁcantopportunityfora\n",
      "newcoﬀeebarlocatedintheheartofthedowntownbusinessdistrict.\n",
      "Market trends suggest that consumers are willing to pay a higher\n",
      "priceforqualityspecialtycoﬀeesservedinawelcomingatmosphere.\n",
      "Additionally,manyoﬃceworkersandstudentslivingintheareado\n",
      "not have easy access to high-speed Internet service, presenting an\n",
      "additional revenue stream for the coﬀee bar.\n",
      "This marketing plan includes the following elements:\n",
      "•MarketResearchsupportingtheneedforanewcoﬀeeshopinthe\n",
      "target location\n",
      "•DetailedDescriptionoftheproductsandservicesoﬀeredbyJava\n",
      "Jolt\n",
      "•Target Market Analysis identifying the primary customer seg-\n",
      "ments for Java Jolt\n",
      "•Marketing Strategy including pricing decisions, promotional ac-\n",
      "tivities, and ways to diﬀerentiate Java Jolt from competitors\n",
      "•Implementation Plan detailing the actions necessary to launch\n",
      "Java Jolt successfully\n",
      "•Budgetallocatingfundstoeachcomponentofthemarketingplan\n",
      "Acomprehensivemarketingplanhasbeendevelopedbasedonexten-\n",
      "siveresearchintothelocalmarketconditions,consumertrends,and\n",
      "competitivelandscape. Withitsuniquecombinationofpremiumcof-\n",
      "feedrinksandwirelessInternetaccess,JavaJoltwillquicklybecome\n",
      "a favorite destination for people seeking a relaxing environment to\n",
      "socialize, study, or conduct business.Here’s a marketing plan for your local coﬀee shop.\n",
      "Marketing Goals and Objectives\n",
      "•Increase awareness of our brand among consumers [...]\n",
      "•Drive foot traﬃc [...] during slow business hours [...]\n",
      "•Build relationships with inﬂuencers in our community who [...]\n",
      "Deﬁne Target Audience\n",
      "Our target audiences include:\n",
      "•Residents of the neighborhood surrounding our coﬀee shop\n",
      "•Oﬃce workers near our coﬀee shop\n",
      "•Students at nearby schools\n",
      "Wewillfocusourmarketingeﬀortsontheseaudiencesbecausethey\n",
      "are most likely to become regular customers at our [...]\n",
      "Research Marketing Tactics\n",
      "Here are some marketing tactics that we could use to reach to reach\n",
      "our target audiences and achieve our goals:\n",
      "•Hosteventsatourcoﬀeeshopthatappealtoourtargetaudiences\n",
      "(e.g., open mic nights for students or networking events [...]\n",
      "•Oﬀer discounts during slow business hours to entice [...]\n",
      "•[...]\n",
      "Plan Marketing Tactics\n",
      "Here’s how we will implement the marketing tactics above:\n",
      "•Events: Wewillhostoneeventpermonthatourcoﬀeeshop. For\n",
      "each event, we will send out email invitations [...]\n",
      "•Discounts: EveryMondaythroughThursdayfrom3pm–6pm,we\n",
      "will oﬀer $1 oﬀ any drink purchase. To promote [...]\n",
      "•Localpartnerships: Wewillreachouttoﬁvelocalbusinessesand\n",
      "schools to ask if we can leave stacks of coupons [...]\n",
      "•Social media: [...]\n",
      "•Reviews: [...]\n",
      "Develop Your Timeline and Budget\n",
      "This is what our marketing timeline looks like:\n",
      "•Month 1: Launch email newsletter and social media accounts\n",
      "•Month 2: Start distributing coupons at [...]\n",
      "•[...]\n",
      "Here’s the budget for each marketing activity:\n",
      "•Email newsletter: $50/month for MailChimp subscription\n",
      "•Social media: $100/month for paid ads [...]\n",
      "•[...]\n",
      "[Summarization into Bullet Points (In Distribution)]\n",
      "Can you summarize this message into bullet points? Gradually slowing job gains and a growing labor force in March [...] Mr. Biden\n",
      "said [...]. More Americans joined the labor force, [...] this spring that he will seek re-election.\n",
      "Though the unemployment rate fell to its lowest level since May\n",
      "1970, at 4.8 percent, Mr. Biden still faces an economy that leaves\n",
      "many Americans feeling left behind. Many working-class [...]\n",
      "Mr. Biden’s challenge will be persuading those voters that the eco-\n",
      "nomic picture has [...] His opponents have already begun painting\n",
      "a bleak portrait of the economy, arguing that most Americans have\n",
      "not beneﬁted from the president’s policies.\n",
      "“The March jobs report shows continued solid job growth but also\n",
      "indicates that we must do better,” said Representative Nancy Pelosi\n",
      "of California, the Democratic leader in the House. [...]Here are the main points from the text:\n",
      "•Jobcreationslowedto236,000forthemonthofMarch,whichis\n",
      "close to the level needed to stabilize the economy and prices.\n",
      "•More Americans joined the labor force, and wage gains fell\n",
      "slightly, both of which should help cool inﬂation.\n",
      "•The report underscores the political tensions facing President\n",
      "Biden ahead of his expected announcement that he will seek re-\n",
      "election.\n",
      "Figure 13: Model outputs from test prompts that ask the model to generate according to speciﬁed\n",
      "structures. The gray ellipsis [...] indicates that the response was trimmed to ﬁt this page, but the\n",
      "generated text is actually longer.\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "path = \"./testdocs\"   \n",
    "for filename in os.listdir(path):\n",
    "# check if the file is a pdf\n",
    "    if filename.endswith('.pdf'):\n",
    "        text = \"\"\n",
    "        with open(os.path.join(path, filename), 'rb') as pdf_doc:\n",
    "        \n",
    "            pdf_reader = PdfReader(pdf_doc)\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "\n",
    "                print(text)\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_text(text)\n",
    "print(len(chunks)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m#embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m vectorstore \u001b[39m=\u001b[39m FAISS\u001b[39m.\u001b[39mfrom_texts(texts\u001b[39m=\u001b[39mchunks, embedding\u001b[39m=\u001b[39membeddings)\n\u001b[0;32m----> 4\u001b[0m db \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(chunks, embeddings)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(vectorstore)\n",
      "File \u001b[0;32m~/Documents/repos/DiscordDocChatBot/.venv/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:431\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_documents\u001b[39m(\n\u001b[1;32m    406\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    415\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    416\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \n\u001b[1;32m    418\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m     texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    432\u001b[0m     metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_texts(\n\u001b[1;32m    434\u001b[0m         texts\u001b[39m=\u001b[39mtexts,\n\u001b[1;32m    435\u001b[0m         embedding\u001b[39m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m         client\u001b[39m=\u001b[39mclient,\n\u001b[1;32m    442\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/repos/DiscordDocChatBot/.venv/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:431\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_documents\u001b[39m(\n\u001b[1;32m    406\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    415\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    416\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \n\u001b[1;32m    418\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m     texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39;49mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    432\u001b[0m     metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_texts(\n\u001b[1;32m    434\u001b[0m         texts\u001b[39m=\u001b[39mtexts,\n\u001b[1;32m    435\u001b[0m         embedding\u001b[39m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m         client\u001b[39m=\u001b[39mclient,\n\u001b[1;32m    442\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "#embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "vectorstore = FAISS.from_texts(texts=chunks, embedding=embeddings)\n",
    "db = Chroma.from_documents(chunks, embeddings)\n",
    "print(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[]), output_key=None, input_key=None, return_messages=True, human_prefix='Human', ai_prefix='AI', memory_key='chat_history') callbacks=None callback_manager=None verbose=False combine_docs_chain=StuffDocumentsChain(memory=None, callbacks=None, callback_manager=None, verbose=False, input_key='input_documents', output_key='output_text', llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=ChatPromptTemplate(input_variables=['question', 'context'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], output_parser=None, partial_variables={}, template=\"Use the following pieces of context to answer the users question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\", template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='{question}', template_format='f-string', validate_template=True), additional_kwargs={})]), llm=ChatOpenAI(verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, openai_proxy=None, request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None), output_key='text'), document_prompt=PromptTemplate(input_variables=['page_content'], output_parser=None, partial_variables={}, template='{page_content}', template_format='f-string', validate_template=True), document_variable_name='context', document_separator='\\n\\n') question_generator=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['chat_history', 'question'], output_parser=None, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:', template_format='f-string', validate_template=True), llm=ChatOpenAI(verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, openai_proxy=None, request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None), output_key='text') output_key='answer' return_source_documents=False get_chat_history=None retriever=VectorStoreRetriever(vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x7fa77ae1db40>, search_type='similarity', search_kwargs={'k': 1}) max_tokens_limit=None\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI()\n",
    "#llm = HuggingFaceHub(repo_id=\"tiiuae/falcon-40b\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history', return_messages=True)\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs=dict(k=1)),\n",
    "    memory=memory\n",
    ")\n",
    "print( conversation_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Summary of the Document: \n",
      "\n",
      "## Title \n",
      "The document doesn't have a specific title. It describes a dataset used for training a machine learning model for question-answering system. \n",
      "\n",
      "## Authors \n",
      "The document doesn't mention any specific author(s). \n",
      "\n",
      "## Ideas Expressed \n",
      "- WikiHow is an online wiki-style publication featuring over 240,000 how-to articles on a variety of topics. \n",
      "- Anyone can contribute to wikiHow, though articles are heavily moderated, resulting in almost universally high-quality content. \n",
      "- The dataset for training the machine learning model for question-answering system is created by sampling 200 articles from wikiHow. \n",
      "- A category is sampled first (out of 19) and then an article within it to ensure diversity. \n",
      "- The article's title is used as the prompt and the article's body is used as the response in the dataset. \n",
      "- The document explains the preprocessing heuristics applied to prune links, images, and certain sections of the text. \n",
      "- In the dataset, the typical “This article...” beginning is replaced with “The following answer...” \n",
      "- The document also mentions that the responses in the dataset either start with \"I\" (in the first person) or reference other answers (such as \"as mentioned\", \"stack exchange\", etc).\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI()\n",
    "#if message.content.startswith('!hf'): \n",
    "#  llm = HuggingFaceHub(repo_id=\"tiiuae/falcon-40b\", task=\"summarization\", model_kwargs={\"temperature\":0.5, \"max_length\":1512})\n",
    "#  #llm = HuggingFacePipeline.from_model_id(model_id=\"tiiuae/falcon-40b-instruct\", task=\"summarization\", model_kwargs={\"temperature\":0, \"max_length\":64})\n",
    "#  logging.info(\"SETTING MODEL TO HUGGING FACE\")\n",
    "\n",
    "\n",
    "wandb_config = {\"project\": \"wandb_prompts_quickstart\"}\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever(search_kwargs=dict(k=1)),callbacks=[WandbTracer(wandb_config)])\n",
    "query = \"Give and extremely detailed Summary of this document, if you know know dont make anything up, include THE title  AND A LIST OF THE AUTHORS WHEN AVAILABLE and ALL the IMPORTTANT IDEAS expressed in the document as bullet points in markdown format\"\n",
    "answer=qa.run(query)\n",
    "logging.info(answer)\n",
    "print( answer)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m embeddings \u001b[39m=\u001b[39m OpenAIEmbeddings()\n\u001b[1;32m      3\u001b[0m \u001b[39m# create the vectorestore to use as the index\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m db \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(chunks, embeddings)\n\u001b[1;32m      5\u001b[0m \u001b[39m# expose this index in a retriever interface\u001b[39;00m\n\u001b[1;32m      6\u001b[0m retriever \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39mas_retriever(search_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m\"\u001b[39m, search_kwargs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mk\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m2\u001b[39m})\n",
      "File \u001b[0;32m~/Documents/repos/DiscordDocChatBot/.venv/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:431\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_documents\u001b[39m(\n\u001b[1;32m    406\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    415\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    416\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \n\u001b[1;32m    418\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m     texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    432\u001b[0m     metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_texts(\n\u001b[1;32m    434\u001b[0m         texts\u001b[39m=\u001b[39mtexts,\n\u001b[1;32m    435\u001b[0m         embedding\u001b[39m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m         client\u001b[39m=\u001b[39mclient,\n\u001b[1;32m    442\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/repos/DiscordDocChatBot/.venv/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:431\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_documents\u001b[39m(\n\u001b[1;32m    406\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    415\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    416\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \n\u001b[1;32m    418\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m     texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39;49mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    432\u001b[0m     metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_texts(\n\u001b[1;32m    434\u001b[0m         texts\u001b[39m=\u001b[39mtexts,\n\u001b[1;32m    435\u001b[0m         embedding\u001b[39m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m         client\u001b[39m=\u001b[39mclient,\n\u001b[1;32m    442\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# select which embeddings we want to use\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# create the vectorestore to use as the index\n",
    "db = Chroma.from_documents(chunks, embeddings)\n",
    "# expose this index in a retriever interface\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})\n",
    "# create a chain to answer questions \n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever,callbacks=[WandbTracer(wandb_config)])\n",
    "query = \"Give and extremely detailed Summary of this document, if you know know dont make anything up, include THE title  AND A LIST OF THE AUTHORS WHEN AVAILABLE and ALL the IMPORTTANT IDEAS expressed in the document as bullet points in markdown format\"\n",
    "answer=qa.run(query)\n",
    "logging.info(answer)\n",
    "print( answer)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
