
  

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.models.evaluation.base &mdash; MLflow 2.7.1 documentation</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="base.html">
  
  
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    

    

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../../search.html"/>
    <link rel="top" title="MLflow 2.7.1 documentation" href="../../../../index.html"/>
        <link rel="up" title="mlflow.models" href="../../models.html"/> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../../_static/languagesections.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../../../../index.html" class="wy-nav-top-logo"
      ><img src="../../../../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.7.1</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../../index.html" class="main-navigation-home"><img src="../../../../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../what-is-mlflow.html">What is MLflow?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../quickstart.html">Quickstart: Install MLflow, instrument code &amp; view results in minutes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../quickstart_mlops.html">Quickstart: Compare runs, choose a model, and deploy it to a REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials-and-examples/index.html">Tutorials and Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tracking.html">MLflow Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../llm-tracking.html">MLflow LLM Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../projects.html">MLflow Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.html">MLflow Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model-registry.html">MLflow Model Registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../recipes.html">MLflow Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../gateway/index.html">MLflow AI Gateway (Experimental)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../llms/prompt-engineering.html">Prompt Engineering UI (Experimental)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../plugins.html">MLflow Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auth/index.html">MLflow Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../search-runs.html">Search Runs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../search-experiments.html">Search Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rest-api.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../docker.html">Official MLflow Docker Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community-model-flavors.html">Community Model Flavors</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../../index.html">Module code</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../models.html">mlflow.models</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.models.evaluation.base</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/_modules/mlflow/models/evaluation/base" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <h1>Source code for mlflow.models.evaluation.base</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">hashlib</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">operator</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">signal</span>
<span class="kn">import</span> <span class="nn">struct</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">urllib</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">contextmanager</span>
<span class="kn">from</span> <span class="nn">decimal</span> <span class="kn">import</span> <span class="n">Decimal</span>
<span class="kn">from</span> <span class="nn">types</span> <span class="kn">import</span> <span class="n">FunctionType</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">from</span> <span class="nn">mlflow.data.dataset</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">mlflow.entities</span> <span class="kn">import</span> <span class="n">RunTag</span>
<span class="kn">from</span> <span class="nn">mlflow.entities.dataset_input</span> <span class="kn">import</span> <span class="n">DatasetInput</span>
<span class="kn">from</span> <span class="nn">mlflow.entities.input_tag</span> <span class="kn">import</span> <span class="n">InputTag</span>
<span class="kn">from</span> <span class="nn">mlflow.exceptions</span> <span class="kn">import</span> <span class="n">MlflowException</span>
<span class="kn">from</span> <span class="nn">mlflow.models.evaluation.validation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">MetricThreshold</span><span class="p">,</span>
    <span class="n">ModelValidationFailedException</span><span class="p">,</span>
    <span class="n">_MetricValidationResult</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.protos.databricks_pb2</span> <span class="kn">import</span> <span class="n">INVALID_PARAMETER_VALUE</span>
<span class="kn">from</span> <span class="nn">mlflow.tracking.artifact_utils</span> <span class="kn">import</span> <span class="n">_download_artifact_from_uri</span>
<span class="kn">from</span> <span class="nn">mlflow.tracking.client</span> <span class="kn">import</span> <span class="n">MlflowClient</span>
<span class="kn">from</span> <span class="nn">mlflow.utils</span> <span class="kn">import</span> <span class="n">_get_fully_qualified_class_name</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.annotations</span> <span class="kn">import</span> <span class="n">developer_stable</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.class_utils</span> <span class="kn">import</span> <span class="n">_get_class_from_string</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.file_utils</span> <span class="kn">import</span> <span class="n">TempDir</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.mlflow_tags</span> <span class="kn">import</span> <span class="n">MLFLOW_DATASET_CONTEXT</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.proto_json_utils</span> <span class="kn">import</span> <span class="n">NumpyEncoder</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.string_utils</span> <span class="kn">import</span> <span class="n">generate_feature_name_if_not_string</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c1"># `numpy` and `pandas` are not required for `mlflow-skinny`.</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_ModelType</span><span class="p">:</span>
    <span class="n">REGRESSOR</span> <span class="o">=</span> <span class="s2">&quot;regressor&quot;</span>
    <span class="n">CLASSIFIER</span> <span class="o">=</span> <span class="s2">&quot;classifier&quot;</span>
    <span class="n">QUESTION_ANSWERING</span> <span class="o">=</span> <span class="s2">&quot;question-answering&quot;</span>
    <span class="n">TEXT_SUMMARIZATION</span> <span class="o">=</span> <span class="s2">&quot;text-summarization&quot;</span>
    <span class="n">TEXT</span> <span class="o">=</span> <span class="s2">&quot;text&quot;</span>
    <span class="c1"># TODO: Add &#39;retrieval&#39; model type</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This class is not meant to be instantiated.&quot;</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">values</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">REGRESSOR</span><span class="p">,</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">CLASSIFIER</span><span class="p">,</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">QUESTION_ANSWERING</span><span class="p">,</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">TEXT_SUMMARIZATION</span><span class="p">,</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span>
        <span class="p">)</span>


<div class="viewcode-block" id="EvaluationMetric"><a class="viewcode-back" href="../../../../python_api/mlflow.models.html#mlflow.EvaluationMetric">[docs]</a><span class="k">class</span> <span class="nc">EvaluationMetric</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A model evaluation metric.</span>

<span class="sd">    :param eval_fn:</span>
<span class="sd">        A function that computes the metric with the following signature:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            def eval_fn(</span>
<span class="sd">                eval_df: Union[pandas.Dataframe, pyspark.sql.DataFrame],</span>
<span class="sd">                builtin_metrics: Dict[str, float],</span>
<span class="sd">            ) -&gt; float:</span>
<span class="sd">                &quot;&quot;&quot;</span>
<span class="sd">                :param eval_df:</span>
<span class="sd">                    A Pandas or Spark DataFrame containing ``prediction`` and ``target`` column.</span>
<span class="sd">                    The ``prediction`` column contains the predictions made by the model.</span>
<span class="sd">                    The ``target`` column contains the corresponding labels to the predictions made</span>
<span class="sd">                    on that row.</span>
<span class="sd">                :param builtin_metrics:</span>
<span class="sd">                    A dictionary containing the metrics calculated by the default evaluator.</span>
<span class="sd">                    The keys are the names of the metrics and the values are the scalar values of</span>
<span class="sd">                    the metrics. Refer to the DefaultEvaluator behavior section for what metrics</span>
<span class="sd">                    will be returned based on the type of model (i.e. classifier or regressor).</span>
<span class="sd">                :return:</span>
<span class="sd">                    The metric value.</span>
<span class="sd">                &quot;&quot;&quot;</span>
<span class="sd">                ...</span>

<span class="sd">    :param name: The name of the metric.</span>
<span class="sd">    :param greater_is_better: Whether a higher value of the metric is better.</span>
<span class="sd">    :param long_name: (Optional) The long name of the metric. For example,</span>
<span class="sd">        ``&quot;root_mean_squared_error&quot;`` for ``&quot;mse&quot;``.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eval_fn</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="p">,</span> <span class="n">long_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval_fn</span> <span class="o">=</span> <span class="n">eval_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">greater_is_better</span> <span class="o">=</span> <span class="n">greater_is_better</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">long_name</span> <span class="o">=</span> <span class="n">long_name</span> <span class="ow">or</span> <span class="n">name</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">long_name</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;EvaluationMetric(name=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">, long_name=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">long_name</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;greater_is_better=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">greater_is_better</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;EvaluationMetric(name=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">, greater_is_better=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">greater_is_better</span><span class="si">}</span><span class="s2">)&quot;</span></div>


<div class="viewcode-block" id="make_metric"><a class="viewcode-back" href="../../../../python_api/mlflow.models.html#mlflow.make_metric">[docs]</a><span class="k">def</span> <span class="nf">make_metric</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">eval_fn</span><span class="p">,</span>
    <span class="n">greater_is_better</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">long_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A factory function to create an :py:class:`EvaluationMetric` object.</span>

<span class="sd">    :param eval_fn:</span>
<span class="sd">        A function that computes the metric with the following signature:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            def eval_fn(</span>
<span class="sd">                eval_df: Union[pandas.Dataframe, pyspark.sql.DataFrame],</span>
<span class="sd">                builtin_metrics: Dict[str, float],</span>
<span class="sd">            ) -&gt; float:</span>
<span class="sd">                &quot;&quot;&quot;</span>
<span class="sd">                :param eval_df:</span>
<span class="sd">                    A Pandas or Spark DataFrame containing ``prediction`` and ``target`` column.</span>
<span class="sd">                    The ``prediction`` column contains the predictions made by the model.</span>
<span class="sd">                    The ``target`` column contains the corresponding labels to the predictions made</span>
<span class="sd">                    on that row.</span>
<span class="sd">                :param builtin_metrics:</span>
<span class="sd">                    A dictionary containing the metrics calculated by the default evaluator.</span>
<span class="sd">                    The keys are the names of the metrics and the values are the scalar values of</span>
<span class="sd">                    the metrics. Refer to the DefaultEvaluator behavior section for what metrics</span>
<span class="sd">                    will be returned based on the type of model (i.e. classifier or regressor).</span>
<span class="sd">                :return:</span>
<span class="sd">                    The metric value.</span>
<span class="sd">                &quot;&quot;&quot;</span>
<span class="sd">                ...</span>

<span class="sd">    :param greater_is_better: Whether a higher value of the metric is better.</span>
<span class="sd">    :param name: The name of the metric. This argument must be specified if ``eval_fn`` is a lambda</span>
<span class="sd">                 function or the ``eval_fn.__name__`` attribute is not available.</span>
<span class="sd">    :param long_name: (Optional) The long name of the metric. For example, ``&quot;mean_squared_error&quot;``</span>
<span class="sd">        for ``&quot;mse&quot;``.</span>

<span class="sd">    .. seealso::</span>

<span class="sd">        - :py:class:`mlflow.models.EvaluationMetric`</span>
<span class="sd">        - :py:func:`mlflow.evaluate`</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eval_fn</span><span class="p">,</span> <span class="n">FunctionType</span><span class="p">)</span> <span class="ow">and</span> <span class="n">eval_fn</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;&lt;lambda&gt;&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;`name` must be specified if `eval_fn` is a lambda function.&quot;</span><span class="p">,</span>
                <span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">eval_fn</span><span class="p">,</span> <span class="s2">&quot;__name__&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;`name` must be specified if `eval_fn` does not have a `__name__` attribute.&quot;</span><span class="p">,</span>
                <span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">eval_fn</span><span class="o">.</span><span class="vm">__name__</span>

    <span class="k">return</span> <span class="n">EvaluationMetric</span><span class="p">(</span><span class="n">eval_fn</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="p">,</span> <span class="n">long_name</span><span class="p">)</span></div>


<div class="viewcode-block" id="EvaluationArtifact"><a class="viewcode-back" href="../../../../python_api/mlflow.models.html#mlflow.EvaluationArtifact">[docs]</a><span class="nd">@developer_stable</span>
<span class="k">class</span> <span class="nc">EvaluationArtifact</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A model evaluation artifact containing an artifact uri and content.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">uri</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uri</span> <span class="o">=</span> <span class="n">uri</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_content</span> <span class="o">=</span> <span class="n">content</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_load_content_from_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">local_artifact_path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Abstract interface to load the content from local artifact file path,</span>
<span class="sd">        and return the loaded content.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">_load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">local_artifact_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        If ``local_artifact_path`` is ``None``, download artifact from the artifact uri.</span>
<span class="sd">        Otherwise, load artifact content from the specified path. Assign the loaded content to</span>
<span class="sd">        ``self._content``, and return the loaded content.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">local_artifact_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_content</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_content_from_file</span><span class="p">(</span><span class="n">local_artifact_path</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">TempDir</span><span class="p">()</span> <span class="k">as</span> <span class="n">temp_dir</span><span class="p">:</span>
                <span class="n">temp_dir_path</span> <span class="o">=</span> <span class="n">temp_dir</span><span class="o">.</span><span class="n">path</span><span class="p">()</span>
                <span class="n">_download_artifact_from_uri</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_uri</span><span class="p">,</span> <span class="n">temp_dir_path</span><span class="p">)</span>
                <span class="n">local_artifact_file</span> <span class="o">=</span> <span class="n">temp_dir</span><span class="o">.</span><span class="n">path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">temp_dir_path</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_content</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_load_content_from_file</span><span class="p">(</span><span class="n">local_artifact_file</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_content</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_artifact_path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save artifact content into specified path.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">content</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The content of the artifact (representation varies)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_content</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_load</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_content</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">uri</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The URI of the artifact</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uri</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(uri=&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">uri</span><span class="si">}</span><span class="s2">&#39;)&quot;</span></div>


<div class="viewcode-block" id="EvaluationResult"><a class="viewcode-back" href="../../../../python_api/mlflow.models.html#mlflow.EvaluationResult">[docs]</a><span class="k">class</span> <span class="nc">EvaluationResult</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents the model evaluation outputs of a `mlflow.evaluate()` API call, containing</span>
<span class="sd">    both scalar metrics and output artifacts such as performance plots.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">artifacts</span><span class="p">,</span> <span class="n">baseline_model_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span> <span class="o">=</span> <span class="n">metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_artifacts</span> <span class="o">=</span> <span class="n">artifacts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model_metrics</span> <span class="o">=</span> <span class="n">baseline_model_metrics</span> <span class="k">if</span> <span class="n">baseline_model_metrics</span> <span class="k">else</span> <span class="p">{}</span>

<div class="viewcode-block" id="EvaluationResult.load"><a class="viewcode-back" href="../../../../python_api/mlflow.models.html#mlflow.EvaluationResult.load">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load the evaluation results from the specified local filesystem path&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;metrics.json&quot;</span><span class="p">))</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;artifacts_metadata.json&quot;</span><span class="p">))</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">artifacts_metadata</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>

        <span class="n">artifacts</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">artifacts_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;artifacts&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">artifact_name</span><span class="p">,</span> <span class="n">meta</span> <span class="ow">in</span> <span class="n">artifacts_metadata</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">uri</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s2">&quot;uri&quot;</span><span class="p">]</span>
            <span class="n">ArtifactCls</span> <span class="o">=</span> <span class="n">_get_class_from_string</span><span class="p">(</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;class_name&quot;</span><span class="p">])</span>
            <span class="n">artifact</span> <span class="o">=</span> <span class="n">ArtifactCls</span><span class="p">(</span><span class="n">uri</span><span class="o">=</span><span class="n">uri</span><span class="p">)</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urlparse</span><span class="p">(</span><span class="n">uri</span><span class="p">)</span><span class="o">.</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">name</span>
            <span class="n">artifact</span><span class="o">.</span><span class="n">_load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">artifacts_dir</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span>
            <span class="n">artifacts</span><span class="p">[</span><span class="n">artifact_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">artifact</span>

        <span class="k">return</span> <span class="n">EvaluationResult</span><span class="p">(</span><span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">artifacts</span><span class="o">=</span><span class="n">artifacts</span><span class="p">)</span></div>

<div class="viewcode-block" id="EvaluationResult.save"><a class="viewcode-back" href="../../../../python_api/mlflow.models.html#mlflow.EvaluationResult.save">[docs]</a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write the evaluation results to the specified local filesystem path&quot;&quot;&quot;</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;metrics.json&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">NumpyEncoder</span><span class="p">)</span>

        <span class="n">artifacts_metadata</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">artifact_name</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;uri&quot;</span><span class="p">:</span> <span class="n">artifact</span><span class="o">.</span><span class="n">uri</span><span class="p">,</span>
                <span class="s2">&quot;class_name&quot;</span><span class="p">:</span> <span class="n">_get_fully_qualified_class_name</span><span class="p">(</span><span class="n">artifact</span><span class="p">),</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">artifact_name</span><span class="p">,</span> <span class="n">artifact</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">artifacts</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;artifacts_metadata.json&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">artifacts_metadata</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>

        <span class="n">artifacts_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;artifacts&quot;</span><span class="p">)</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">artifacts_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">artifact</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">artifacts</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urlparse</span><span class="p">(</span><span class="n">artifact</span><span class="o">.</span><span class="n">uri</span><span class="p">)</span><span class="o">.</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">name</span>
            <span class="n">artifact</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">artifacts_dir</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A dictionary mapping scalar metric names to scalar metric values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">artifacts</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;mlflow.models.EvaluationArtifact&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A dictionary mapping standardized artifact names (e.g. &quot;roc_data&quot;) to</span>
<span class="sd">        artifact content and location information</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_artifacts</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">baseline_model_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A dictionary mapping scalar metric names to scalar metric values for the baseline model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_baseline_model_metrics</span></div>


<span class="n">_cached_mlflow_client</span> <span class="o">=</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_hash_uint64_ndarray_as_bytes</span><span class="p">(</span><span class="n">array</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="c1"># see struct pack format string https://docs.python.org/3/library/struct.html#format-strings</span>
    <span class="k">return</span> <span class="n">struct</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&gt;</span><span class="si">{</span><span class="n">array</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">Q&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">array</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_hash_ndarray_as_bytes</span><span class="p">(</span><span class="n">nd_array</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_hash_uint64_ndarray_as_bytes</span><span class="p">(</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">hash_array</span><span class="p">(</span><span class="n">nd_array</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">))</span>
    <span class="p">)</span> <span class="o">+</span> <span class="n">_hash_uint64_ndarray_as_bytes</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nd_array</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;uint64&quot;</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_hash_array_like_obj_as_bytes</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper method to convert pandas dataframe/numpy array/list into bytes for</span>
<span class="sd">    MD5 calculation purpose.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="c1"># add checking `&#39;pyspark&#39; in sys.modules` to avoid importing pyspark when user</span>
        <span class="c1"># run code not related to pyspark.</span>
        <span class="k">if</span> <span class="s2">&quot;pyspark&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">Vector</span> <span class="k">as</span> <span class="n">spark_vector_type</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">spark_vector_type</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">def</span> <span class="nf">_hash_array_like_element_as_bytes</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">spark_vector_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">spark_vector_type</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">_hash_ndarray_as_bytes</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">toArray</span><span class="p">())</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">_hash_ndarray_as_bytes</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">_hash_ndarray_as_bytes</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">v</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">applymap</span><span class="p">(</span><span class="n">_hash_array_like_element_as_bytes</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_hash_uint64_ndarray_as_bytes</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">hash_pandas_object</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_hash_ndarray_as_bytes</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_hash_ndarray_as_bytes</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported data type.&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_gen_md5_for_arraylike_obj</span><span class="p">(</span><span class="n">md5_gen</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper method to generate MD5 hash array-like object, the MD5 will calculate over:</span>
<span class="sd">     - array length</span>
<span class="sd">     - first NUM_SAMPLE_ROWS_FOR_HASH rows content</span>
<span class="sd">     - last NUM_SAMPLE_ROWS_FOR_HASH rows content</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">len_bytes</span> <span class="o">=</span> <span class="n">_hash_uint64_ndarray_as_bytes</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;uint64&quot;</span><span class="p">))</span>
    <span class="n">md5_gen</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">len_bytes</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">EvaluationDataset</span><span class="o">.</span><span class="n">NUM_SAMPLE_ROWS_FOR_HASH</span> <span class="o">*</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">md5_gen</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_hash_array_like_obj_as_bytes</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">head_rows</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span> <span class="n">EvaluationDataset</span><span class="o">.</span><span class="n">NUM_SAMPLE_ROWS_FOR_HASH</span><span class="p">]</span>
        <span class="n">tail_rows</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">EvaluationDataset</span><span class="o">.</span><span class="n">NUM_SAMPLE_ROWS_FOR_HASH</span> <span class="p">:]</span>
        <span class="n">md5_gen</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_hash_array_like_obj_as_bytes</span><span class="p">(</span><span class="n">head_rows</span><span class="p">))</span>
        <span class="n">md5_gen</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_hash_array_like_obj_as_bytes</span><span class="p">(</span><span class="n">tail_rows</span><span class="p">))</span>


<div class="viewcode-block" id="EvaluationDataset"><a class="viewcode-back" href="../../../../python_api/mlflow.data.html#mlflow.EvaluationDataset">[docs]</a><span class="k">class</span> <span class="nc">EvaluationDataset</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An input dataset for model evaluation. This is intended for use with the</span>
<span class="sd">    :py:func:`mlflow.models.evaluate()`</span>
<span class="sd">    API.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">NUM_SAMPLE_ROWS_FOR_HASH</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">SPARK_DATAFRAME_LIMIT</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The values of the constructor arguments comes from the `evaluate` call.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s1">&#39;&quot;&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Dataset name cannot include a double quote (&quot;) but got </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s1">&#39;&quot;&#39;</span> <span class="ow">in</span> <span class="n">path</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Dataset path cannot include a double quote (&quot;) but got </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_user_specified_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_path</span> <span class="o">=</span> <span class="n">path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hash</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_supported_dataframe_types</span> <span class="o">=</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_spark_df_type</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_labels_data</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_targets_name</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_has_targets</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># add checking `&#39;pyspark&#39; in sys.modules` to avoid importing pyspark when user</span>
            <span class="c1"># run code not related to pyspark.</span>
            <span class="k">if</span> <span class="s2">&quot;pyspark&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">DataFrame</span> <span class="k">as</span> <span class="n">SparkDataFrame</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_supported_dataframe_types</span> <span class="o">=</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">SparkDataFrame</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_spark_df_type</span> <span class="o">=</span> <span class="n">SparkDataFrame</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="k">if</span> <span class="n">feature_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">feature_names</span><span class="p">))</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="s2">&quot;`feature_names` argument must be a list containing unique feature names.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">has_targets</span> <span class="o">=</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">has_targets</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_has_targets</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">has_targets</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="n">message</span><span class="o">=</span><span class="s2">&quot;If data is a numpy array or list of evaluation features, &quot;</span>
                    <span class="s2">&quot;`targets` argument must be a numpy array or list of evaluation labels.&quot;</span><span class="p">,</span>
                    <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="n">shape_message</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;If the `data` argument is a numpy array, it must be a 2-dimensional &quot;</span>
                <span class="s2">&quot;array, with the second dimension representing the number of features. If the &quot;</span>
                <span class="s2">&quot;`data` argument is a list, each of its elements must be a feature array of &quot;</span>
                <span class="s2">&quot;the numpy array or list, and all elements must have the same length.&quot;</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                        <span class="n">message</span><span class="o">=</span><span class="n">shape_message</span><span class="p">,</span> <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span>
                    <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="n">message</span><span class="o">=</span><span class="n">shape_message</span><span class="p">,</span>
                    <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span> <span class="o">=</span> <span class="n">data</span>
            <span class="k">if</span> <span class="n">has_targets</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_labels_data</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">targets</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_labels_data</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                        <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The input features example rows must be the same length &quot;</span>
                        <span class="s2">&quot;with labels array.&quot;</span><span class="p">,</span>
                        <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                    <span class="p">)</span>

            <span class="n">num_features</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">feature_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">num_features</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_names</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                        <span class="n">message</span><span class="o">=</span><span class="s2">&quot;feature name list must be the same length with feature data.&quot;</span><span class="p">,</span>
                        <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feature_names</span> <span class="o">=</span> <span class="n">feature_names</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feature_names</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">&quot;feature_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">zfill</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">((</span><span class="n">math</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">num_features</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">))))</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_features</span><span class="p">)</span>
                <span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supported_dataframe_types</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">has_targets</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="n">message</span><span class="o">=</span><span class="s2">&quot;If data is a Pandas DataFrame or Spark DataFrame, `targets` argument &quot;</span>
                    <span class="s2">&quot;must be the name of the column which contains evaluation labels in the `data` &quot;</span>
                    <span class="s2">&quot;dataframe.&quot;</span><span class="p">,</span>
                    <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spark_df_type</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spark_df_type</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">EvaluationDataset</span><span class="o">.</span><span class="n">SPARK_DATAFRAME_LIMIT</span><span class="p">:</span>
                    <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;Specified Spark DataFrame is too large for model evaluation. Only &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;the first </span><span class="si">{</span><span class="n">EvaluationDataset</span><span class="o">.</span><span class="n">SPARK_DATAFRAME_LIMIT</span><span class="si">}</span><span class="s2"> rows will be used. &quot;</span>
                        <span class="s2">&quot;If you want evaluate on the whole spark dataframe, please manually call &quot;</span>
                        <span class="s2">&quot;`spark_dataframe.toPandas()`.&quot;</span>
                    <span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="n">EvaluationDataset</span><span class="o">.</span><span class="n">SPARK_DATAFRAME_LIMIT</span><span class="p">)</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">has_targets</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_labels_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">targets</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_targets_name</span> <span class="o">=</span> <span class="n">targets</span>

            <span class="k">if</span> <span class="n">feature_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feature_names</span> <span class="o">=</span> <span class="n">feature_names</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">has_targets</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span> <span class="o">=</span> <span class="n">data</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feature_names</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">generate_feature_name_if_not_string</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span><span class="o">.</span><span class="n">columns</span>
                <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The data argument must be a numpy array, a list or a Pandas DataFrame, or &quot;</span>
                <span class="s2">&quot;spark DataFrame if pyspark package installed.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># generate dataset hash</span>
        <span class="n">md5_gen</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">()</span>
        <span class="n">_gen_md5_for_arraylike_obj</span><span class="p">(</span><span class="n">md5_gen</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_labels_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_gen_md5_for_arraylike_obj</span><span class="p">(</span><span class="n">md5_gen</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_labels_data</span><span class="p">)</span>
        <span class="n">md5_gen</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feature_names</span><span class="p">)))</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;UTF-8&quot;</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_hash</span> <span class="o">=</span> <span class="n">md5_gen</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">feature_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feature_names</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">features_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        return features data as a numpy array or a pandas DataFrame.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">labels_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        return labels data as a numpy array</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_labels_data</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">has_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns True if the dataset has targets, False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_targets</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">targets_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        return targets name</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_targets_name</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Dataset name, which is specified dataset name or the dataset hash if user don&#39;t specify</span>
<span class="sd">        name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_user_specified_name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_user_specified_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">hash</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">path</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Dataset path</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_path</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hash</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Dataset hash, includes hash on first 20 rows and last 20 rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hash</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return dataset metadata containing name, hash, and optional path.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="s2">&quot;hash&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">hash</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span>
        <span class="k">return</span> <span class="n">metadata</span>

    <span class="k">def</span> <span class="nf">_log_dataset_tag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">client</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">model_uuid</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Log dataset metadata as a tag &quot;mlflow.datasets&quot;, if the tag already exists, it will</span>
<span class="sd">        append current dataset metadata into existing tag content.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">existing_dataset_metadata_str</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_run</span><span class="p">(</span><span class="n">run_id</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">tags</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;mlflow.datasets&quot;</span><span class="p">,</span> <span class="s2">&quot;[]&quot;</span>
        <span class="p">)</span>
        <span class="n">dataset_metadata_list</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">existing_dataset_metadata_str</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="n">dataset_metadata_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;hash&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">hash</span>
                <span class="ow">and</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>
                <span class="ow">and</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">model_uuid</span>
            <span class="p">):</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dataset_metadata_list</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_metadata</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model_uuid</span><span class="p">})</span>

        <span class="n">dataset_metadata_str</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">dataset_metadata_list</span><span class="p">,</span> <span class="n">separators</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">))</span>
        <span class="n">client</span><span class="o">.</span><span class="n">log_batch</span><span class="p">(</span>
            <span class="n">run_id</span><span class="p">,</span>
            <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="n">RunTag</span><span class="p">(</span><span class="s2">&quot;mlflow.datasets&quot;</span><span class="p">,</span> <span class="n">dataset_metadata_str</span><span class="p">)],</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__hash__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">hash</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">EvaluationDataset</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">is_features_data_equal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">_features_data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">is_features_data_equal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_features_data</span><span class="o">.</span><span class="n">equals</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_features_data</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">is_features_data_equal</span>
            <span class="ow">and</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_labels_data</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">_labels_data</span><span class="p">)</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">name</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">path</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feature_names</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">_feature_names</span>
        <span class="p">)</span></div>


<span class="nd">@developer_stable</span>
<span class="k">class</span> <span class="nc">ModelEvaluator</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">can_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">evaluator_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param model_type: A string describing the model type (e.g., &quot;regressor&quot;, &quot;classifier&quot;, ).</span>
<span class="sd">        :param evaluator_config: A dictionary of additional configurations for</span>
<span class="sd">                                 the evaluator.</span>
<span class="sd">        :param kwargs: For forwards compatibility, a placeholder for additional arguments</span>
<span class="sd">                       that may be added to the evaluation interface in the future.</span>
<span class="sd">        :return: True if the evaluator can evaluate the specified model on the</span>
<span class="sd">                 specified dataset. False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">model_type</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">run_id</span><span class="p">,</span>
        <span class="n">evaluator_config</span><span class="p">,</span>
        <span class="n">custom_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">custom_artifacts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">baseline_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The abstract API to log metrics and artifacts, and return evaluation results.</span>

<span class="sd">        :param model: A pyfunc model instance, used as the candidate_model</span>
<span class="sd">                      to be compared with baseline_model (specified by the `baseline_model` param)</span>
<span class="sd">                      for model validation.</span>
<span class="sd">        :param model_type: A string describing the model type</span>
<span class="sd">                           (e.g., ``&quot;regressor&quot;``, ``&quot;classifier&quot;``, ).</span>
<span class="sd">        :param dataset: An instance of `mlflow.models.evaluation.base._EvaluationDataset`</span>
<span class="sd">                        containing features and labels (optional) for model evaluation.</span>
<span class="sd">        :param run_id: The ID of the MLflow Run to which to log results.</span>
<span class="sd">        :param evaluator_config: A dictionary of additional configurations for</span>
<span class="sd">                                 the evaluator.</span>
<span class="sd">        :param custom_metrics: A list of :py:class:`EvaluationMetric` objects.</span>
<span class="sd">        :param custom_artifacts: A list of callable custom artifact functions.</span>
<span class="sd">        :param kwargs: For forwards compatibility, a placeholder for additional arguments that</span>
<span class="sd">                       may be added to the evaluation interface in the future.</span>
<span class="sd">        :param baseline_model: (Optional) A string URI referring to a MLflow model with the pyfunc</span>
<span class="sd">                                          flavor as a baseline model to be compared with the</span>
<span class="sd">                                          candidate model (specified by the `model` param) for model</span>
<span class="sd">                                          validation. (pyfunc model instance is not allowed)</span>
<span class="sd">        :return: A :py:class:`mlflow.models.EvaluationResult` instance containing</span>
<span class="sd">                 evaluation metrics for candidate model and baseline model and</span>
<span class="sd">                 artifacts for candidate model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>


<div class="viewcode-block" id="list_evaluators"><a class="viewcode-back" href="../../../../python_api/mlflow.models.html#mlflow.list_evaluators">[docs]</a><span class="k">def</span> <span class="nf">list_evaluators</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a name list for all available Evaluators.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># import _model_evaluation_registry inside function to avoid circuit importing</span>
    <span class="kn">from</span> <span class="nn">mlflow.models.evaluation.evaluator_registry</span> <span class="kn">import</span> <span class="n">_model_evaluation_registry</span>

    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">_model_evaluation_registry</span><span class="o">.</span><span class="n">_registry</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span></div>


<span class="nd">@contextmanager</span>
<span class="k">def</span> <span class="nf">_start_run_or_reuse_active_run</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A manager context return:</span>
<span class="sd">     - If there&#39;s an active run, return the active run id.</span>
<span class="sd">     - otherwise start a mflow run with the specified run_id,</span>
<span class="sd">       if specified run_id is None, start a new run.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">active_run</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">active_run</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">active_run</span><span class="p">:</span>
        <span class="c1"># Note `mlflow.start_run` throws if `run_id` is not found.</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">run</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">run_id</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">active_run</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">run_id</span>


<span class="k">def</span> <span class="nf">_normalize_evaluators_and_evaluator_config_args</span><span class="p">(</span>
    <span class="n">evaluators</span><span class="p">,</span>
    <span class="n">evaluator_config</span><span class="p">,</span>
<span class="p">):</span>
    <span class="kn">from</span> <span class="nn">mlflow.models.evaluation.evaluator_registry</span> <span class="kn">import</span> <span class="n">_model_evaluation_registry</span>

    <span class="k">def</span> <span class="nf">check_nesting_config_dict</span><span class="p">(</span><span class="n">_evaluator_name_list</span><span class="p">,</span> <span class="n">_evaluator_name_to_conf_map</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_evaluator_name_to_conf_map</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">k</span> <span class="ow">in</span> <span class="n">_evaluator_name_list</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">_evaluator_name_to_conf_map</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">evaluators</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">evaluator_name_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">_model_evaluation_registry</span><span class="o">.</span><span class="n">_registry</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">evaluator_name_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Multiple registered evaluators are found </span><span class="si">{</span><span class="n">evaluator_name_list</span><span class="si">}</span><span class="s2"> and &quot;</span>
                <span class="s2">&quot;they will all be used in evaluation if they support the specified model type. &quot;</span>
                <span class="s2">&quot;If you want to evaluate with one evaluator, specify the `evaluator` argument &quot;</span>
                <span class="s2">&quot;and optionally specify the `evaluator_config` argument.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluator_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">conf_dict_value_error</span> <span class="o">=</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="s2">&quot;If `evaluators` argument is None, all available evaluators will be used. &quot;</span>
                <span class="s2">&quot;If only the default evaluator is available, the `evaluator_config` argument is &quot;</span>
                <span class="s2">&quot;interpreted as the config dictionary for the default evaluator. Otherwise, the &quot;</span>
                <span class="s2">&quot;`evaluator_config` argument must be a dictionary mapping each evaluator&#39;s name &quot;</span>
                <span class="s2">&quot;to its own evaluator config dictionary.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">evaluator_name_list</span> <span class="o">==</span> <span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">evaluator_config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="n">conf_dict_value_error</span>
                <span class="k">elif</span> <span class="s2">&quot;default&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">evaluator_config</span><span class="p">:</span>
                    <span class="n">evaluator_name_to_conf_map</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="n">evaluator_config</span><span class="p">}</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">evaluator_name_to_conf_map</span> <span class="o">=</span> <span class="n">evaluator_config</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">check_nesting_config_dict</span><span class="p">(</span><span class="n">evaluator_name_list</span><span class="p">,</span> <span class="n">evaluator_config</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="n">conf_dict_value_error</span>
                <span class="n">evaluator_name_to_conf_map</span> <span class="o">=</span> <span class="n">evaluator_config</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">evaluator_name_to_conf_map</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">evaluators</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">evaluator_config</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">evaluator_config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="s2">&quot;If `evaluators` argument is the name of an evaluator, evaluator_config&quot;</span>
                <span class="s2">&quot; must be None or a dict containing config items for the evaluator.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">evaluator_name_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">evaluators</span><span class="p">]</span>
        <span class="n">evaluator_name_to_conf_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">evaluators</span><span class="p">:</span> <span class="n">evaluator_config</span><span class="p">}</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">evaluators</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">evaluator_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">check_nesting_config_dict</span><span class="p">(</span><span class="n">evaluators</span><span class="p">,</span> <span class="n">evaluator_config</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="n">message</span><span class="o">=</span><span class="s2">&quot;If `evaluators` argument is an evaluator name list, evaluator_config &quot;</span>
                    <span class="s2">&quot;must be a dict contains mapping from evaluator name to individual &quot;</span>
                    <span class="s2">&quot;evaluator config dict.&quot;</span><span class="p">,</span>
                    <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="c1"># Use `OrderedDict.fromkeys` to deduplicate elements but keep elements order.</span>
        <span class="n">evaluator_name_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">OrderedDict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">evaluators</span><span class="p">))</span>
        <span class="n">evaluator_name_to_conf_map</span> <span class="o">=</span> <span class="n">evaluator_config</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="s2">&quot;`evaluators` argument must be None, an evaluator name string, or a list of &quot;</span>
            <span class="s2">&quot;evaluator names.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">evaluator_name_list</span><span class="p">,</span> <span class="n">evaluator_name_to_conf_map</span>


<span class="k">def</span> <span class="nf">_model_validation_contains_model_comparison</span><span class="p">(</span><span class="n">validation_thresholds</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function for determining if validation_thresholds contains</span>
<span class="sd">    thresholds for model comparsion: either min_relative_change or min_absolute_change</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">validation_thresholds</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="n">thresholds</span> <span class="o">=</span> <span class="n">validation_thresholds</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">any</span><span class="p">(</span>
        <span class="n">threshold</span><span class="o">.</span><span class="n">min_relative_change</span> <span class="ow">or</span> <span class="n">threshold</span><span class="o">.</span><span class="n">min_absolute_change</span> <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">thresholds</span>
    <span class="p">)</span>


<span class="n">_last_failed_evaluator</span> <span class="o">=</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_get_last_failed_evaluator</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the evaluator name of the last failed evaluator when calling `evaluate`.</span>
<span class="sd">    This can be used to check which evaluator fail when `evaluate` API fail.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_last_failed_evaluator</span>


<span class="k">def</span> <span class="nf">_validate</span><span class="p">(</span><span class="n">validation_thresholds</span><span class="p">,</span> <span class="n">candidate_metrics</span><span class="p">,</span> <span class="n">baseline_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validate the model based on validation_thresholds by metrics value and</span>
<span class="sd">    metrics comparison between candidate model&#39;s metrics (candidate_metrics) and</span>
<span class="sd">    baseline model&#39;s metrics (baseline_metrics).</span>
<span class="sd">    :param validation_thresholds: A dictionary from metric_name to MetricThreshold.</span>
<span class="sd">    :param candidate_metrics: The metric evaluation result of the candidate model.</span>
<span class="sd">    :param baseline_metrics: The metric evaluation result of the baseline model.</span>
<span class="sd">    If the validation does not pass, raise an MlflowException with detail failure message.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">baseline_metrics</span><span class="p">:</span>
        <span class="n">baseline_metrics</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">validation_results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">metric_name</span><span class="p">:</span> <span class="n">_MetricValidationResult</span><span class="p">(</span>
            <span class="n">metric_name</span><span class="p">,</span>
            <span class="n">candidate_metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">threshold</span><span class="p">,</span>
            <span class="n">baseline_metrics</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span> <span class="ow">in</span> <span class="n">validation_thresholds</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">metric_name</span> <span class="ow">in</span> <span class="n">validation_thresholds</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">metric_threshold</span><span class="p">,</span> <span class="n">validation_result</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">validation_thresholds</span><span class="p">[</span><span class="n">metric_name</span><span class="p">],</span>
            <span class="n">validation_results</span><span class="p">[</span><span class="n">metric_name</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">metric_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">candidate_metrics</span><span class="p">:</span>
            <span class="n">validation_result</span><span class="o">.</span><span class="n">missing_candidate</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">continue</span>

        <span class="n">candidate_metric_value</span><span class="p">,</span> <span class="n">baseline_metric_value</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">candidate_metrics</span><span class="p">[</span><span class="n">metric_name</span><span class="p">],</span>
            <span class="n">baseline_metrics</span><span class="p">[</span><span class="n">metric_name</span><span class="p">]</span> <span class="k">if</span> <span class="n">baseline_metrics</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># If metric is higher is better, &gt;= is used, otherwise &lt;= is used</span>
        <span class="c1"># for thresholding metric value and model comparsion</span>
        <span class="n">comparator_fn</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="fm">__ge__</span> <span class="k">if</span> <span class="n">metric_threshold</span><span class="o">.</span><span class="n">greater_is_better</span> <span class="k">else</span> <span class="n">operator</span><span class="o">.</span><span class="fm">__le__</span>
        <span class="n">operator_fn</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">add</span> <span class="k">if</span> <span class="n">metric_threshold</span><span class="o">.</span><span class="n">greater_is_better</span> <span class="k">else</span> <span class="n">operator</span><span class="o">.</span><span class="n">sub</span>

        <span class="k">if</span> <span class="n">metric_threshold</span><span class="o">.</span><span class="n">threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># metric threshold fails</span>
            <span class="c1"># - if not (metric_value &gt;= threshold) for higher is better</span>
            <span class="c1"># - if not (metric_value &lt;= threshold) for lower is better</span>
            <span class="n">validation_result</span><span class="o">.</span><span class="n">threshold_failed</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">comparator_fn</span><span class="p">(</span>
                <span class="n">candidate_metric_value</span><span class="p">,</span> <span class="n">metric_threshold</span><span class="o">.</span><span class="n">threshold</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">metric_threshold</span><span class="o">.</span><span class="n">min_relative_change</span> <span class="ow">or</span> <span class="n">metric_threshold</span><span class="o">.</span><span class="n">min_absolute_change</span>
        <span class="p">)</span> <span class="ow">and</span> <span class="n">metric_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">baseline_metrics</span><span class="p">:</span>
            <span class="n">validation_result</span><span class="o">.</span><span class="n">missing_baseline</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">continue</span>

        <span class="k">if</span> <span class="n">metric_threshold</span><span class="o">.</span><span class="n">min_absolute_change</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># metric comparsion aboslute change fails</span>
            <span class="c1"># - if not (metric_value &gt;= baseline + min_absolute_change) for higher is better</span>
            <span class="c1"># - if not (metric_value &lt;= baseline - min_absolute_change) for lower is better</span>
            <span class="n">validation_result</span><span class="o">.</span><span class="n">min_absolute_change_failed</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">comparator_fn</span><span class="p">(</span>
                <span class="n">Decimal</span><span class="p">(</span><span class="n">candidate_metric_value</span><span class="p">),</span>
                <span class="n">Decimal</span><span class="p">(</span><span class="n">operator_fn</span><span class="p">(</span><span class="n">baseline_metric_value</span><span class="p">,</span> <span class="n">metric_threshold</span><span class="o">.</span><span class="n">min_absolute_change</span><span class="p">)),</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">metric_threshold</span><span class="o">.</span><span class="n">min_relative_change</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># If baseline metric value equals 0, fallback to simple comparison check</span>
            <span class="k">if</span> <span class="n">baseline_metric_value</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Cannot perform relative model comparison for metric </span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s2"> as &quot;</span>
                    <span class="s2">&quot;baseline metric value is 0. Falling back to simple comparison: verifying &quot;</span>
                    <span class="s2">&quot;that candidate metric value is better than the baseline metric value.&quot;</span>
                <span class="p">)</span>
                <span class="n">validation_result</span><span class="o">.</span><span class="n">min_relative_change_failed</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">comparator_fn</span><span class="p">(</span>
                    <span class="n">Decimal</span><span class="p">(</span><span class="n">candidate_metric_value</span><span class="p">),</span>
                    <span class="n">Decimal</span><span class="p">(</span><span class="n">operator_fn</span><span class="p">(</span><span class="n">baseline_metric_value</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)),</span>
                <span class="p">)</span>
                <span class="k">continue</span>
            <span class="c1"># metric comparsion relative change fails</span>
            <span class="c1"># - if (metric_value - baseline) / baseline &lt; min_relative_change for higher is better</span>
            <span class="c1"># - if (baseline - metric_value) / baseline &lt; min_relative_change for lower is better</span>
            <span class="k">if</span> <span class="n">metric_threshold</span><span class="o">.</span><span class="n">greater_is_better</span><span class="p">:</span>
                <span class="n">relative_change</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">candidate_metric_value</span> <span class="o">-</span> <span class="n">baseline_metric_value</span>
                <span class="p">)</span> <span class="o">/</span> <span class="n">baseline_metric_value</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">relative_change</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">baseline_metric_value</span> <span class="o">-</span> <span class="n">candidate_metric_value</span>
                <span class="p">)</span> <span class="o">/</span> <span class="n">baseline_metric_value</span>
            <span class="n">validation_result</span><span class="o">.</span><span class="n">min_relative_change_failed</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">relative_change</span> <span class="o">&lt;</span> <span class="n">metric_threshold</span><span class="o">.</span><span class="n">min_relative_change</span>
            <span class="p">)</span>

    <span class="n">failure_messages</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">metric_validation_result</span> <span class="ow">in</span> <span class="n">validation_results</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">metric_validation_result</span><span class="o">.</span><span class="n">is_success</span><span class="p">():</span>
            <span class="k">continue</span>
        <span class="n">failure_messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">metric_validation_result</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">failure_messages</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="k">raise</span> <span class="n">ModelValidationFailedException</span><span class="p">(</span><span class="n">message</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">linesep</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">failure_messages</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_convert_data_to_mlflow_dataset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert input data to mlflow dataset.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s2">&quot;pyspark&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">DataFrame</span> <span class="k">as</span> <span class="n">SparkDataFrame</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">targets</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">targets</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>
    <span class="k">elif</span> <span class="s2">&quot;pyspark&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">SparkDataFrame</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">from_spark</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Cannot convert to mlflow dataset, return original data.</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Cannot convert input data to `evaluate()` to an mlflow dataset, input must be a list, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;a numpy array, a panda Dataframe or a spark Dataframe, but received </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span>


<span class="k">def</span> <span class="nf">_evaluate</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">model_type</span><span class="p">,</span>
    <span class="n">dataset</span><span class="p">,</span>
    <span class="n">run_id</span><span class="p">,</span>
    <span class="n">evaluator_name_list</span><span class="p">,</span>
    <span class="n">evaluator_name_to_conf_map</span><span class="p">,</span>
    <span class="n">custom_metrics</span><span class="p">,</span>
    <span class="n">custom_artifacts</span><span class="p">,</span>
    <span class="n">baseline_model</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The public API &quot;evaluate&quot; will verify argument first, and then pass normalized arguments</span>
<span class="sd">    to the _evaluate method.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># import _model_evaluation_registry and PyFuncModel inside function to avoid circuit importing</span>
    <span class="kn">from</span> <span class="nn">mlflow.models.evaluation.evaluator_registry</span> <span class="kn">import</span> <span class="n">_model_evaluation_registry</span>

    <span class="k">global</span> <span class="n">_last_failed_evaluator</span>
    <span class="n">_last_failed_evaluator</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">client</span> <span class="o">=</span> <span class="n">MlflowClient</span><span class="p">()</span>

    <span class="n">model_uuid</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">model_uuid</span>

    <span class="n">dataset</span><span class="o">.</span><span class="n">_log_dataset_tag</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="n">model_uuid</span><span class="p">)</span>

    <span class="n">eval_results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">evaluator_name</span> <span class="ow">in</span> <span class="n">evaluator_name_list</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">evaluator_name_to_conf_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">evaluator_name</span><span class="p">)</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">evaluator</span> <span class="o">=</span> <span class="n">_model_evaluation_registry</span><span class="o">.</span><span class="n">get_evaluator</span><span class="p">(</span><span class="n">evaluator_name</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">MlflowException</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluator &#39;</span><span class="si">{</span><span class="n">evaluator_name</span><span class="si">}</span><span class="s2">&#39; is not registered.&quot;</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="n">_last_failed_evaluator</span> <span class="o">=</span> <span class="n">evaluator_name</span>
        <span class="k">if</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">can_evaluate</span><span class="p">(</span><span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span> <span class="n">evaluator_config</span><span class="o">=</span><span class="n">config</span><span class="p">):</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluating the model with the </span><span class="si">{</span><span class="n">evaluator_name</span><span class="si">}</span><span class="s2"> evaluator.&quot;</span><span class="p">)</span>
            <span class="n">eval_result</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span>
                <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
                <span class="n">run_id</span><span class="o">=</span><span class="n">run_id</span><span class="p">,</span>
                <span class="n">evaluator_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                <span class="n">custom_metrics</span><span class="o">=</span><span class="n">custom_metrics</span><span class="p">,</span>
                <span class="n">custom_artifacts</span><span class="o">=</span><span class="n">custom_artifacts</span><span class="p">,</span>
                <span class="n">baseline_model</span><span class="o">=</span><span class="n">baseline_model</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">eval_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eval_result</span><span class="p">)</span>

    <span class="n">_last_failed_evaluator</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eval_results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The model could not be evaluated by any of the registered evaluators, please &quot;</span>
            <span class="s2">&quot;verify that the model type and other configs are set correctly.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">merged_eval_result</span> <span class="o">=</span> <span class="n">EvaluationResult</span><span class="p">({},</span> <span class="p">{},</span> <span class="p">{})</span>

    <span class="k">for</span> <span class="n">eval_result</span> <span class="ow">in</span> <span class="n">eval_results</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">eval_result</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">merged_eval_result</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">eval_result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
        <span class="n">merged_eval_result</span><span class="o">.</span><span class="n">artifacts</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">eval_result</span><span class="o">.</span><span class="n">artifacts</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">baseline_model</span> <span class="ow">and</span> <span class="n">eval_result</span><span class="o">.</span><span class="n">baseline_model_metrics</span><span class="p">:</span>
            <span class="n">merged_eval_result</span><span class="o">.</span><span class="n">baseline_model_metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">eval_result</span><span class="o">.</span><span class="n">baseline_model_metrics</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">merged_eval_result</span>


<div class="viewcode-block" id="evaluate"><a class="viewcode-back" href="../../../../python_api/mlflow.models.html#mlflow.evaluate">[docs]</a><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dataset_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">evaluators</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">evaluator_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">custom_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">custom_artifacts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_thresholds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">baseline_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">env_manager</span><span class="o">=</span><span class="s2">&quot;local&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Evaluate a PyFunc model on the specified dataset using one or more specified ``evaluators``, and</span>
<span class="sd">    log resulting metrics &amp; artifacts to MLflow Tracking. Set thresholds on the generated metrics to</span>
<span class="sd">    validate model quality. For additional overview information, see</span>
<span class="sd">    :ref:`the Model Evaluation documentation &lt;model-evaluation&gt;`.</span>

<span class="sd">    Default Evaluator behavior:</span>
<span class="sd">     - The default evaluator, which can be invoked with ``evaluators=&quot;default&quot;`` or</span>
<span class="sd">       ``evaluators=None``, supports the ``&quot;regressor&quot;`` and ``&quot;classifier&quot;`` model types.</span>
<span class="sd">       It generates a variety of model performance metrics, model performance plots, and</span>
<span class="sd">       model explanations.</span>

<span class="sd">     - For both the ``&quot;regressor&quot;`` and ``&quot;classifier&quot;`` model types, the default evaluator</span>
<span class="sd">       generates model summary plots and feature importance plots using</span>
<span class="sd">       `SHAP &lt;https://shap.readthedocs.io/en/latest/index.html&gt;`_.</span>

<span class="sd">     - For regressor models, the default evaluator additionally logs:</span>
<span class="sd">        - **metrics**: example_count, mean_absolute_error, mean_squared_error,</span>
<span class="sd">          root_mean_squared_error, sum_on_target, mean_on_target, r2_score, max_error,</span>
<span class="sd">          mean_absolute_percentage_error.</span>

<span class="sd">     - For binary classifiers, the default evaluator additionally logs:</span>
<span class="sd">        - **metrics**: true_negatives, false_positives, false_negatives, true_positives, recall,</span>
<span class="sd">          precision, f1_score, accuracy_score, example_count, log_loss, roc_auc,</span>
<span class="sd">          precision_recall_auc.</span>
<span class="sd">        - **artifacts**: lift curve plot, precision-recall plot, ROC plot.</span>

<span class="sd">     - For multiclass classifiers, the default evaluator additionally logs:</span>
<span class="sd">        - **metrics**: accuracy_score, example_count, f1_score_micro, f1_score_macro, log_loss</span>
<span class="sd">        - **artifacts**: A CSV file for &quot;per_class_metrics&quot; (per-class metrics includes</span>
<span class="sd">          true_negatives/false_positives/false_negatives/true_positives/recall/precision/roc_auc,</span>
<span class="sd">          precision_recall_auc), precision-recall merged curves plot, ROC merged curves plot.</span>

<span class="sd">     - For question-answering models, the default evaluator logs:</span>
<span class="sd">        - **metrics**: ``exact_match``, `mean_perplexity`_ (requires `evaluate`_, `pytorch`_,</span>
<span class="sd">          `transformers`_), `toxicity_ratio`_ (requires `evaluate`_, `pytorch`_, `transformers`_),</span>
<span class="sd">          `mean_ari_grade_level`_ (requires `textstat`_), `mean_flesch_kincaid_grade_level`_</span>
<span class="sd">          (requires `textstat`_).</span>
<span class="sd">        - **artifacts**: A JSON file containing the inputs, outputs, targets (if the ``targets``</span>
<span class="sd">          argument is supplied), and per-row metrics of the model in tabular format.</span>

<span class="sd">        .. _mean_perplexity:</span>
<span class="sd">            https://huggingface.co/spaces/evaluate-metric/perplexity</span>

<span class="sd">        .. _toxicity_ratio:</span>
<span class="sd">            https://huggingface.co/spaces/evaluate-measurement/toxicity</span>

<span class="sd">        .. _pytorch:</span>
<span class="sd">            https://pytorch.org/get-started/locally/</span>

<span class="sd">        .. _transformers:</span>
<span class="sd">            https://huggingface.co/docs/transformers/installation</span>

<span class="sd">        .. _mean_ari_grade_level:</span>
<span class="sd">            https://en.wikipedia.org/wiki/Automated_readability_index</span>

<span class="sd">        .. _mean_flesch_kincaid_grade_level:</span>
<span class="sd">            https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level</span>

<span class="sd">        .. _evaluate:</span>
<span class="sd">            https://pypi.org/project/evaluate</span>

<span class="sd">        .. _textstat:</span>
<span class="sd">            https://pypi.org/project/textstat</span>

<span class="sd">     - For text-summarization models, the default evaluator logs:</span>
<span class="sd">        - **metrics**: `ROUGE`_ (requires `evaluate`_, `nltk`_, and `rouge_score`_ to be installed),</span>
<span class="sd">          `mean_perplexity`_ (requires `evaluate`_, `pytorch`_,</span>
<span class="sd">          `transformers`_), `toxicity_ratio`_ (requires `evaluate`_, `pytorch`_, `transformers`_),</span>
<span class="sd">          `mean_ari_grade_level`_ (requires `textstat`_), `mean_flesch_kincaid_grade_level`_</span>
<span class="sd">          (requires `textstat`_).</span>
<span class="sd">        - **artifacts**: A JSON file containing the inputs, outputs, targets (if the ``targets``</span>
<span class="sd">          argument is supplied), and per-row metrics of the model in the tabular format.</span>

<span class="sd">        .. _ROUGE:</span>
<span class="sd">            https://huggingface.co/spaces/evaluate-metric/rouge</span>

<span class="sd">        .. _mean_perplexity:</span>
<span class="sd">            https://huggingface.co/spaces/evaluate-metric/perplexity</span>

<span class="sd">        .. _toxicity_ratio:</span>
<span class="sd">            https://huggingface.co/spaces/evaluate-measurement/toxicity</span>

<span class="sd">        .. _pytorch:</span>
<span class="sd">            https://pytorch.org/get-started/locally/</span>

<span class="sd">        .. _transformers:</span>
<span class="sd">            https://huggingface.co/docs/transformers/installation</span>

<span class="sd">        .. _mean_ari_grade_level:</span>
<span class="sd">            https://en.wikipedia.org/wiki/Automated_readability_index</span>

<span class="sd">        .. _mean_flesch_kincaid_grade_level:</span>
<span class="sd">            https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level</span>

<span class="sd">        .. _evaluate:</span>
<span class="sd">            https://pypi.org/project/evaluate</span>

<span class="sd">        .. _nltk:</span>
<span class="sd">            https://pypi.org/project/nltk</span>

<span class="sd">        .. _rouge_score:</span>
<span class="sd">            https://pypi.org/project/rouge-score</span>

<span class="sd">        .. _textstat:</span>
<span class="sd">            https://pypi.org/project/textstat</span>

<span class="sd">     - For text models, the default evaluator logs:</span>
<span class="sd">        - **metrics**: `mean_perplexity`_ (requires `evaluate`_, `pytorch`_,</span>
<span class="sd">          `transformers`_), `toxicity_ratio`_ (requires `evaluate`_, `pytorch`_, `transformers`_),</span>
<span class="sd">          `mean_ari_grade_level`_ (requires `textstat`_), `mean_flesch_kincaid_grade_level`_</span>
<span class="sd">          (requires `textstat`_).</span>
<span class="sd">        - **artifacts**: A JSON file containing the inputs, outputs, targets (if the ``targets``</span>
<span class="sd">          argument is supplied), and per-row metrics of the model in tabular format.</span>

<span class="sd">        .. _evaluate:</span>
<span class="sd">            https://pypi.org/project/evaluate</span>

<span class="sd">        .. _mean_perplexity:</span>
<span class="sd">            https://huggingface.co/spaces/evaluate-metric/perplexity</span>

<span class="sd">        .. _toxicity_ratio:</span>
<span class="sd">            https://huggingface.co/spaces/evaluate-measurement/toxicity</span>

<span class="sd">        .. _pytorch:</span>
<span class="sd">            https://pytorch.org/get-started/locally/</span>

<span class="sd">        .. _transformers:</span>
<span class="sd">            https://huggingface.co/docs/transformers/installation</span>

<span class="sd">        .. _mean_ari_grade_level:</span>
<span class="sd">            https://en.wikipedia.org/wiki/Automated_readability_index</span>

<span class="sd">        .. _mean_flesch_kincaid_grade_level:</span>
<span class="sd">            https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level</span>

<span class="sd">        .. _textstat:</span>
<span class="sd">            https://pypi.org/project/textstat</span>

<span class="sd">     - For sklearn models, the default evaluator additionally logs the model&#39;s evaluation criterion</span>
<span class="sd">       (e.g. mean accuracy for a classifier) computed by `model.score` method.</span>

<span class="sd">     - The metrics/artifacts listed above are logged to the active MLflow run.</span>
<span class="sd">       If no active run exists, a new MLflow run is created for logging these metrics and</span>
<span class="sd">       artifacts. Note that no metrics/artifacts are logged for the ``baseline_model``.</span>

<span class="sd">     - Additionally, information about the specified dataset - hash, name (if specified), path</span>
<span class="sd">       (if specified), and the UUID of the model that evaluated it - is logged to the</span>
<span class="sd">       ``mlflow.datasets`` tag.</span>

<span class="sd">     - The available ``evaluator_config`` options for the default evaluator include:</span>
<span class="sd">        - **log_model_explainability**: A boolean value specifying whether or not to log model</span>
<span class="sd">          explainability insights, default value is True.</span>
<span class="sd">        - **explainability_algorithm**: A string to specify the SHAP Explainer algorithm for model</span>
<span class="sd">          explainability. Supported algorithm includes: &#39;exact&#39;, &#39;permutation&#39;, &#39;partition&#39;,</span>
<span class="sd">          &#39;kernel&#39;.</span>
<span class="sd">          If not set, ``shap.Explainer`` is used with the &quot;auto&quot; algorithm, which chooses the best</span>
<span class="sd">          Explainer based on the model.</span>
<span class="sd">        - **explainability_nsamples**: The number of sample rows to use for computing model</span>
<span class="sd">          explainability insights. Default value is 2000.</span>
<span class="sd">        - **explainability_kernel_link**: The kernel link function used by shap kernal explainer.</span>
<span class="sd">          Available values are &quot;identity&quot; and &quot;logit&quot;. Default value is &quot;identity&quot;.</span>
<span class="sd">        - **max_classes_for_multiclass_roc_pr**:</span>
<span class="sd">          For multiclass classification tasks, the maximum number of classes for which to log</span>
<span class="sd">          the per-class ROC curve and Precision-Recall curve. If the number of classes is</span>
<span class="sd">          larger than the configured maximum, these curves are not logged.</span>
<span class="sd">        - **metric_prefix**: An optional prefix to prepend to the name of each metric and artifact</span>
<span class="sd">          produced during evaluation.</span>
<span class="sd">        - **log_metrics_with_dataset_info**: A boolean value specifying whether or not to include</span>
<span class="sd">          information about the evaluation dataset in the name of each metric logged to MLflow</span>
<span class="sd">          Tracking during evaluation, default value is True.</span>
<span class="sd">        - **pos_label**: If specified, the positive label to use when computing classification</span>
<span class="sd">          metrics such as precision, recall, f1, etc. for binary classification models. For</span>
<span class="sd">          multiclass classification and regression models, this parameter will be ignored.</span>
<span class="sd">        - **average**: The averaging method to use when computing classification metrics such as</span>
<span class="sd">          precision, recall, f1, etc. for multiclass classification models</span>
<span class="sd">          (default: ``&#39;weighted&#39;``). For binary classification and regression models, this</span>
<span class="sd">          parameter will be ignored.</span>
<span class="sd">        - **sample_weights**: Weights for each sample to apply when computing model performance</span>
<span class="sd">          metrics.</span>

<span class="sd">     - Limitations of evaluation dataset:</span>
<span class="sd">        - For classification tasks, dataset labels are used to infer the total number of classes.</span>
<span class="sd">        - For binary classification tasks, the negative label value must be 0 or -1 or False, and</span>
<span class="sd">          the positive label value must be 1 or True.</span>

<span class="sd">     - Limitations of metrics/artifacts computation:</span>
<span class="sd">        - For classification tasks, some metric and artifact computations require the model to</span>
<span class="sd">          output class probabilities. Currently, for scikit-learn models, the default evaluator</span>
<span class="sd">          calls the ``predict_proba`` method on the underlying model to obtain probabilities. For</span>
<span class="sd">          other model types, the default evaluator does not compute metrics/artifacts that require</span>
<span class="sd">          probability outputs.</span>

<span class="sd">     - Limitations of default evaluator logging model explainability insights:</span>
<span class="sd">        - The ``shap.Explainer`` ``auto`` algorithm uses the ``Linear`` explainer for linear models</span>
<span class="sd">          and the ``Tree`` explainer for tree models. Because SHAP&#39;s ``Linear`` and ``Tree``</span>
<span class="sd">          explainers do not support multi-class classification, the default evaluator falls back to</span>
<span class="sd">          using the ``Exact`` or ``Permutation`` explainers for multi-class classification tasks.</span>
<span class="sd">        - Logging model explainability insights is not currently supported for PySpark models.</span>
<span class="sd">        - The evaluation dataset label values must be numeric or boolean, all feature values</span>
<span class="sd">          must be numeric, and each feature column must only contain scalar values.</span>

<span class="sd">     - Limitations when environment restoration is enabled:</span>
<span class="sd">        - When environment restoration is enabled for the evaluated model (i.e. a non-local</span>
<span class="sd">          ``env_manager`` is specified), the model is loaded as a client that invokes a MLflow</span>
<span class="sd">          Model Scoring Server process in an independent Python environment with the model&#39;s</span>
<span class="sd">          training time dependencies installed. As such, methods like ``predict_proba`` (for</span>
<span class="sd">          probability outputs) or ``score`` (computes the evaluation criterian for sklearn models)</span>
<span class="sd">          of the model become inaccessible and the default evaluator does not compute metrics or</span>
<span class="sd">          artifacts that require those methods.</span>
<span class="sd">        - Because the model is an MLflow Model Server process, SHAP explanations are slower to</span>
<span class="sd">          compute. As such, model explainaibility is disabled when a non-local ``env_manager``</span>
<span class="sd">          specified, unless the ``evaluator_config`` option **log_model_explainability** is</span>
<span class="sd">          explicitly set to ``True``.</span>

<span class="sd">    :param model: A pyfunc model instance, or a URI referring to such a model.</span>

<span class="sd">    :param data: One of the following:</span>

<span class="sd">                 - A numpy array or list of evaluation features, excluding labels.</span>

<span class="sd">                 - A Pandas DataFrame or Spark DataFrame, containing evaluation features and</span>
<span class="sd">                   labels. If ``feature_names`` argument not specified, all columns are regarded</span>
<span class="sd">                   as feature columns. Otherwise, only column names present in ``feature_names``</span>
<span class="sd">                   are regarded as feature columns. If it is Spark DataFrame, only the first 10000</span>
<span class="sd">                   rows in the Spark DataFrame will be used as evaluation data.</span>

<span class="sd">                 - A :py:class`mlflow.data.dataset.Dataset` instance containing evaluation features</span>
<span class="sd">                   and labels.</span>

<span class="sd">    :param targets: If ``data`` is a numpy array or list, a numpy array or list of evaluation</span>
<span class="sd">                    labels. If ``data`` is a DataFrame, the string name of a column from ``data``</span>
<span class="sd">                    that contains evaluation labels. Required for classifier and regressor models,</span>
<span class="sd">                    but optional for question-answering, text-summarization, and text models. If</span>
<span class="sd">                    ``data`` is a :py:class`mlflow.data.dataset.Dataset` that defines targets,</span>
<span class="sd">                    then ``targets`` is optional.</span>

<span class="sd">    :param model_type: A string describing the model type. The default evaluator</span>
<span class="sd">                       supports the following model types:</span>

<span class="sd">                       - ``&#39;classifier&#39;``</span>
<span class="sd">                       - ``&#39;regressor&#39;``</span>
<span class="sd">                       - ``&#39;question-answering&#39;``</span>
<span class="sd">                       - ``&#39;text-summarization&#39;``</span>
<span class="sd">                       - ``&#39;text&#39;``</span>

<span class="sd">                       .. note::</span>
<span class="sd">                            ``&#39;question-answering&#39;``, ``&#39;text-summarization&#39;``, and ``&#39;text&#39;``</span>
<span class="sd">                            are experimental and may be changed or removed in a future release.</span>

<span class="sd">    :param dataset_path: (Optional) The path where the data is stored. Must not contain double</span>
<span class="sd">                         quotes (````). If specified, the path is logged to the ``mlflow.datasets``</span>
<span class="sd">                         tag for lineage tracking purposes.</span>

<span class="sd">    :param feature_names: (Optional) If the ``data`` argument is a feature data numpy array or list,</span>
<span class="sd">                          ``feature_names`` is a list of the feature names for each feature. If</span>
<span class="sd">                          ``None``, then the ``feature_names`` are generated using the format</span>
<span class="sd">                          ``feature_{feature_index}``. If the ``data`` argument is a Pandas</span>
<span class="sd">                          DataFrame or a Spark DataFrame, ``feature_names`` is a list of the names</span>
<span class="sd">                          of the feature columns in the DataFrame. If ``None``, then all columns</span>
<span class="sd">                          except the label column are regarded as feature columns.</span>

<span class="sd">    :param evaluators: The name of the evaluator to use for model evaluation, or a list of</span>
<span class="sd">                       evaluator names. If unspecified, all evaluators capable of evaluating the</span>
<span class="sd">                       specified model on the specified dataset are used. The default evaluator</span>
<span class="sd">                       can be referred to by the name ``&quot;default&quot;``. To see all available</span>
<span class="sd">                       evaluators, call :py:func:`mlflow.models.list_evaluators`.</span>

<span class="sd">    :param evaluator_config: A dictionary of additional configurations to supply to the evaluator.</span>
<span class="sd">                             If multiple evaluators are specified, each configuration should be</span>
<span class="sd">                             supplied as a nested dictionary whose key is the evaluator name.</span>

<span class="sd">    :param custom_metrics:</span>
<span class="sd">        (Optional) A list of :py:class:`EvaluationMetric &lt;mlflow.models.EvaluationMetric&gt;` objects.</span>

<span class="sd">        .. code-block:: python</span>
<span class="sd">            :caption: Example usage of custom metrics</span>

<span class="sd">            import mlflow</span>
<span class="sd">            import numpy as np</span>


<span class="sd">            def root_mean_squared_error(eval_df, _builtin_metrics):</span>
<span class="sd">                return np.sqrt((np.abs(eval_df[&quot;prediction&quot;] - eval_df[&quot;target&quot;]) ** 2).mean)</span>


<span class="sd">            rmse_metric = mlflow.models.make_metric(</span>
<span class="sd">                eval_fn=root_mean_squared_error,</span>
<span class="sd">                greater_is_better=False,</span>
<span class="sd">            )</span>
<span class="sd">            mlflow.evaluate(..., custom_metrics=[rmse_metric])</span>

<span class="sd">    :param custom_artifacts:</span>
<span class="sd">        (Optional) A list of custom artifact functions with the following signature:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            def custom_artifact(</span>
<span class="sd">                eval_df: Union[pandas.Dataframe, pyspark.sql.DataFrame],</span>
<span class="sd">                builtin_metrics: Dict[str, float],</span>
<span class="sd">                artifacts_dir: str,</span>
<span class="sd">            ) -&gt; Dict[str, Any]:</span>
<span class="sd">                &quot;&quot;&quot;</span>
<span class="sd">                :param eval_df:</span>
<span class="sd">                    A Pandas or Spark DataFrame containing ``prediction`` and ``target`` column.</span>
<span class="sd">                    The ``prediction`` column contains the predictions made by the model.</span>
<span class="sd">                    The ``target`` column contains the corresponding labels to the predictions made</span>
<span class="sd">                    on that row.</span>
<span class="sd">                :param builtin_metrics:</span>
<span class="sd">                    A dictionary containing the metrics calculated by the default evaluator.</span>
<span class="sd">                    The keys are the names of the metrics and the values are the scalar values of</span>
<span class="sd">                    the metrics. Refer to the DefaultEvaluator behavior section for what metrics</span>
<span class="sd">                    will be returned based on the type of model (i.e. classifier or regressor).</span>
<span class="sd">                :param artifacts_dir:</span>
<span class="sd">                    A temporary directory path that can be used by the custom artifacts function to</span>
<span class="sd">                    temporarily store produced artifacts. The directory will be deleted after the</span>
<span class="sd">                    artifacts are logged.</span>
<span class="sd">                :return:</span>
<span class="sd">                    A dictionary that maps artifact names to artifact objects</span>
<span class="sd">                    (e.g. a Matplotlib Figure) or to artifact paths within ``artifacts_dir``.</span>
<span class="sd">                &quot;&quot;&quot;</span>
<span class="sd">                ...</span>

<span class="sd">        Object types that artifacts can be represented as:</span>

<span class="sd">            - A string uri representing the file path to the artifact. MLflow will infer the type of</span>
<span class="sd">              the artifact based on the file extension.</span>
<span class="sd">            - A string representation of a JSON object. This will be saved as a .json artifact.</span>
<span class="sd">            - Pandas DataFrame. This will be resolved as a CSV artifact.</span>
<span class="sd">            - Numpy array. This will be saved as a .npy artifact.</span>
<span class="sd">            - Matplotlib Figure. This will be saved as an image artifact. Note that</span>
<span class="sd">              ``matplotlib.pyplot.savefig`` is called behind the scene with default configurations.</span>
<span class="sd">              To customize, either save the figure with the desired configurations and return its</span>
<span class="sd">              file path or define customizations through environment variables in</span>
<span class="sd">              ``matplotlib.rcParams``.</span>
<span class="sd">            - Other objects will be attempted to be pickled with the default protocol.</span>

<span class="sd">        .. code-block:: python</span>
<span class="sd">            :caption: Example usage of custom artifacts</span>

<span class="sd">            import mlflow</span>
<span class="sd">            import matplotlib.pyplot as plt</span>


<span class="sd">            def scatter_plot(eval_df, builtin_metrics, artifacts_dir):</span>
<span class="sd">                plt.scatter(eval_df[&quot;prediction&quot;], eval_df[&quot;target&quot;])</span>
<span class="sd">                plt.xlabel(&quot;Targets&quot;)</span>
<span class="sd">                plt.ylabel(&quot;Predictions&quot;)</span>
<span class="sd">                plt.title(&quot;Targets vs. Predictions&quot;)</span>
<span class="sd">                plt.savefig(os.path.join(artifacts_dir, &quot;example.png&quot;))</span>
<span class="sd">                plt.close()</span>
<span class="sd">                return {&quot;pred_target_scatter&quot;: os.path.join(artifacts_dir, &quot;example.png&quot;)}</span>


<span class="sd">            def pred_sample(eval_df, _builtin_metrics, _artifacts_dir):</span>
<span class="sd">                return {&quot;pred_sample&quot;: pred_sample.head(10)}</span>


<span class="sd">            mlflow.evaluate(..., custom_artifacts=[scatter_plot, pred_sample])</span>

<span class="sd">    :param validation_thresholds: (Optional) A dictionary of metric name to</span>
<span class="sd">        :py:class:`mlflow.models.MetricThreshold` used for model validation. Each metric name must</span>
<span class="sd">        either be the name of a builtin metric or the name of a custom metric defined in the</span>
<span class="sd">        ``custom_metrics`` parameter.</span>

<span class="sd">        .. code-block:: python</span>
<span class="sd">            :caption: Example of Model Validation</span>

<span class="sd">            from mlflow.models import MetricThreshold</span>

<span class="sd">            thresholds = {</span>
<span class="sd">                &quot;accuracy_score&quot;: MetricThreshold(</span>
<span class="sd">                    # accuracy should be &gt;=0.8</span>
<span class="sd">                    threshold=0.8,</span>
<span class="sd">                    # accuracy should be at least 5 percent greater than baseline model accuracy</span>
<span class="sd">                    min_absolute_change=0.05,</span>
<span class="sd">                    # accuracy should be at least 0.05 greater than baseline model accuracy</span>
<span class="sd">                    min_relative_change=0.05,</span>
<span class="sd">                    greater_is_better=True,</span>
<span class="sd">                ),</span>
<span class="sd">            }</span>

<span class="sd">            with mlflow.start_run():</span>
<span class="sd">                mlflow.evaluate(</span>
<span class="sd">                    model=your_candidate_model,</span>
<span class="sd">                    data,</span>
<span class="sd">                    targets,</span>
<span class="sd">                    model_type,</span>
<span class="sd">                    dataset_name,</span>
<span class="sd">                    evaluators,</span>
<span class="sd">                    validation_thresholds=thresholds,</span>
<span class="sd">                    baseline_model=your_baseline_model,</span>
<span class="sd">                )</span>

<span class="sd">        See :ref:`the Model Validation documentation &lt;model-validation&gt;`</span>
<span class="sd">        for more details.</span>

<span class="sd">    :param baseline_model: (Optional) A string URI referring to an MLflow model with the pyfunc</span>
<span class="sd">                           flavor. If specified, the candidate ``model`` is compared to this</span>
<span class="sd">                           baseline for model validation purposes.</span>

<span class="sd">    :param env_manager: Specify an environment manager to load the candidate ``model`` and</span>
<span class="sd">                        ``baseline_model`` in isolated Python evironments and restore their</span>
<span class="sd">                        dependencies. Default value is ``local``, and the following values are</span>
<span class="sd">                        supported:</span>

<span class="sd">                         - ``virtualenv``: (Recommended) Use virtualenv to restore the python</span>
<span class="sd">                           environment that was used to train the model.</span>
<span class="sd">                         - ``conda``:  Use Conda to restore the software environment that was used</span>
<span class="sd">                           to train the model.</span>
<span class="sd">                         - ``local``: Use the current Python environment for model inference, which</span>
<span class="sd">                           may differ from the environment used to train the model and may lead to</span>
<span class="sd">                           errors or invalid predictions.</span>

<span class="sd">    :return: An :py:class:`mlflow.models.EvaluationResult` instance containing</span>
<span class="sd">             metrics of candidate model and baseline model, and artifacts of candidate model.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="kn">from</span> <span class="nn">mlflow.pyfunc</span> <span class="kn">import</span> <span class="n">PyFuncModel</span><span class="p">,</span> <span class="n">_load_model_or_server</span><span class="p">,</span> <span class="n">_ServedPyFuncModel</span>
    <span class="kn">from</span> <span class="nn">mlflow.utils</span> <span class="kn">import</span> <span class="n">env_manager</span> <span class="k">as</span> <span class="n">_EnvManager</span>

    <span class="n">_EnvManager</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">env_manager</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="p">[</span><span class="n">_ModelType</span><span class="o">.</span><span class="n">REGRESSOR</span><span class="p">,</span> <span class="n">_ModelType</span><span class="o">.</span><span class="n">CLASSIFIER</span><span class="p">]:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;targets&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">targets</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">targets</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The targets argument is required when data is a Dataset and does not &quot;</span>
                    <span class="s2">&quot;define targets.&quot;</span><span class="p">,</span>
                    <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The targets argument must be specified for </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s2"> models.&quot;</span><span class="p">,</span>
                    <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">_load_model_or_server</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">env_manager</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">env_manager</span> <span class="o">!=</span> <span class="n">_EnvManager</span><span class="o">.</span><span class="n">LOCAL</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The model argument must be a string URI referring to an MLflow model when a &quot;</span>
            <span class="s2">&quot;non-local env_manager is specified.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">PyFuncModel</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The model argument must be a string URI referring to an MLflow model or &quot;</span>
            <span class="s2">&quot;an instance of `mlflow.pyfunc.PyFuncModel`.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">validation_thresholds</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">validation_thresholds</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">dict</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">validation_thresholds</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">str</span>
            <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">validation_thresholds</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">MetricThreshold</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AssertionError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The validation thresholds argument must be a dictionary that maps strings &quot;</span>
                <span class="s2">&quot;to MetricThreshold objects.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">baseline_model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">baseline_model</span> <span class="o">=</span> <span class="n">_load_model_or_server</span><span class="p">(</span><span class="n">baseline_model</span><span class="p">,</span> <span class="n">env_manager</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">baseline_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The baseline model argument must be a string URI referring to an &quot;</span>
            <span class="s2">&quot;MLflow model.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">_model_validation_contains_model_comparison</span><span class="p">(</span><span class="n">validation_thresholds</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="n">message</span><span class="o">=</span><span class="s2">&quot;The baseline model argument is None. The baseline model must be specified &quot;</span>
            <span class="s2">&quot;when model comparison thresholds (min_absolute_change, min_relative_change) &quot;</span>
            <span class="s2">&quot;are specified.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="p">(</span>
        <span class="n">evaluator_name_list</span><span class="p">,</span>
        <span class="n">evaluator_name_to_conf_map</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">_normalize_evaluators_and_evaluator_config_args</span><span class="p">(</span><span class="n">evaluators</span><span class="p">,</span> <span class="n">evaluator_config</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">_start_run_or_reuse_active_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run_id</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
            <span class="c1"># Convert data to `mlflow.data.dataset.Dataset`.</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">_convert_data_to_mlflow_dataset</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>

        <span class="kn">from</span> <span class="nn">mlflow.data.pyfunc_dataset_mixin</span> <span class="kn">import</span> <span class="n">PyFuncConvertibleDatasetMixin</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="n">PyFuncConvertibleDatasetMixin</span><span class="p">):</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_evaluation_dataset</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">evaluator_name_to_conf_map</span> <span class="ow">and</span> <span class="n">evaluator_name_to_conf_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="n">context</span> <span class="o">=</span> <span class="n">evaluator_name_to_conf_map</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;metric_prefix&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">context</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">client</span> <span class="o">=</span> <span class="n">MlflowClient</span><span class="p">()</span>
            <span class="n">tags</span> <span class="o">=</span> <span class="p">[</span><span class="n">InputTag</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">MLFLOW_DATASET_CONTEXT</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">context</span><span class="p">)]</span> <span class="k">if</span> <span class="n">context</span> <span class="k">else</span> <span class="p">[]</span>
            <span class="n">dataset_input</span> <span class="o">=</span> <span class="n">DatasetInput</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">_to_mlflow_entity</span><span class="p">(),</span> <span class="n">tags</span><span class="o">=</span><span class="n">tags</span><span class="p">)</span>
            <span class="n">client</span><span class="o">.</span><span class="n">log_inputs</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="p">[</span><span class="n">dataset_input</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dataset</span> <span class="o">=</span> <span class="n">EvaluationDataset</span><span class="p">(</span>
                <span class="n">data</span><span class="p">,</span>
                <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">,</span>
                <span class="n">path</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">,</span>
                <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">evaluate_result</span> <span class="o">=</span> <span class="n">_evaluate</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span>
                <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
                <span class="n">run_id</span><span class="o">=</span><span class="n">run_id</span><span class="p">,</span>
                <span class="n">evaluator_name_list</span><span class="o">=</span><span class="n">evaluator_name_list</span><span class="p">,</span>
                <span class="n">evaluator_name_to_conf_map</span><span class="o">=</span><span class="n">evaluator_name_to_conf_map</span><span class="p">,</span>
                <span class="n">custom_metrics</span><span class="o">=</span><span class="n">custom_metrics</span><span class="p">,</span>
                <span class="n">custom_artifacts</span><span class="o">=</span><span class="n">custom_artifacts</span><span class="p">,</span>
                <span class="n">baseline_model</span><span class="o">=</span><span class="n">baseline_model</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">_ServedPyFuncModel</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">kill</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">pid</span><span class="p">,</span> <span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">baseline_model</span><span class="p">,</span> <span class="n">_ServedPyFuncModel</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">kill</span><span class="p">(</span><span class="n">baseline_model</span><span class="o">.</span><span class="n">pid</span><span class="p">,</span> <span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">validation_thresholds</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">evaluate_result</span>

        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Validating generated model metrics&quot;</span><span class="p">)</span>
        <span class="n">_validate</span><span class="p">(</span>
            <span class="n">validation_thresholds</span><span class="p">,</span>
            <span class="n">evaluate_result</span><span class="o">.</span><span class="n">metrics</span><span class="p">,</span>
            <span class="n">evaluate_result</span><span class="o">.</span><span class="n">baseline_model_metrics</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Model validation passed!&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">evaluate_result</span></div>
</pre></div>

              </div>
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../../',
      VERSION:'2.7.1',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
   
</body>
</html>