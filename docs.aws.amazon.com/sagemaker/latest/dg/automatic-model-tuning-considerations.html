<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Best Practices for Hyperparameter Tuning - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="automatic-model-tuning-considerations" /><meta name="default_state" content="automatic-model-tuning-considerations" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="automatic-model-tuning-considerations.html" /><meta name="description" content="Learn best practices for hyperparameter tuning, such as choosing hyperparameter ranges and scales, and reproducing consistent hyperparameter configurations." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="automatic-model-tuning-considerations.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="de" /><link rel="alternative" href="automatic-model-tuning-considerations.html" hreflang="en-us" /><link rel="alternative" href="automatic-model-tuning-considerations.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/automatic-model-tuning-considerations.html" hreflang="zh-tw" /><link rel="alternative" href="automatic-model-tuning-considerations.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Best Practices for Hyperparameter Tuning" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Best Practices for Hyperparameter Tuning - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#automatic-model-tuning-considerations" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/automatic-model-tuning-considerations.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/automatic-model-tuning-considerations.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/automatic-model-tuning-considerations.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance,automatic model tuning,hyperparameter optimization,hyperparameter optimization tuning,choosing hyperparameter ranges,best practices for hyperparameter tuning,reproduce hyperparameter configurations" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Train machine learning models",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/train-model.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Perform Automatic Model Tuning with SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Best Practices for Hyperparameter Tuning",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#automatic-model-tuning-considerations" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-strategy">Choosing a tuning strategy</a><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-num-hyperparameters">Choosing the number of
          hyperparameters</a><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-choosing-ranges">Choosing hyperparameter
          ranges</a><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-log-scales">Using the correct scales for
          hyperparameters</a><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-parallelism">Choosing the best number of parallel
          training jobs</a><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-distributed-metrics">Running training jobs on
          multiple instances</a><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-random-seed">Using a random seed to reproduce
          hyperparameter configurations</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="automatic-model-tuning-considerations">Best Practices for Hyperparameter
        Tuning</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Hyperparameter optimization (HPO) is not a fully-automated process. To improve
      optimization, follow these best practices for hyperparameter tuning.</p><div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-strategy">Choosing a tuning strategy</a></li><li><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-num-hyperparameters">Choosing the number of
          hyperparameters</a></li><li><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-choosing-ranges">Choosing hyperparameter
          ranges</a></li><li><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-log-scales">Using the correct scales for
          hyperparameters</a></li><li><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-parallelism">Choosing the best number of parallel
          training jobs</a></li><li><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-distributed-metrics">Running training jobs on
          multiple instances</a></li><li><a href="automatic-model-tuning-considerations.html#automatic-model-tuning-random-seed">Using a random seed to reproduce
          hyperparameter configurations</a></li></ul></div>
      <h2 id="automatic-model-tuning-strategy">Choosing a tuning strategy</h2>
      <p>For large jobs, using the <a href="automatic-model-tuning-how-it-works.html#automatic-tuning-hyperband">Hyperband</a> tuning strategy can reduce computation time. Hyperband has an early
        stopping mechanism to stop under-performing jobs. Hyperband can also reallocate resources
        towards well-utilized hyperparameter configurations and run parallel jobs. For smaller
        training jobs using less runtime, use either <a href="automatic-model-tuning-how-it-works.html#automatic-tuning-random-search">random search</a> or <a href="automatic-model-tuning-how-it-works.html#automatic-tuning-bayesian-optimization.title">Bayesian optimization</a>. </p>
      <p>Use Bayesian optimization to make increasingly informed decisions about improving
        hyperparameter configurations in the next run. Bayesian optimization uses information
        gathered from prior runs to improve subsequent runs. Because of its sequential nature,
        Bayesian optimization cannot massively scale. </p>
      <p>Use random search to run a large number of parallel jobs. In random search, subsequent
        jobs do not depend on the results from prior jobs and can be run independently. Compared to
        other strategies, random search is able to run the largest number of parallel jobs. </p>
      <p>Use <a href="automatic-model-tuning-how-it-works.html#automatic-tuning-grid-search">grid search</a> to reproduce results of a tuning job, or if simplicity and
        transparency of the optimization algorithm are important. You can also use grid search to
        explore the entire hyperparameter search space evenly. Grid search methodically searches
        through every hyperparameter combination to find optimal hyperparameter values. Unlike grid
        search, Bayesian optimization, random search and Hyperband all draw hyperparameters randomly
        from the search space. Because grid search analyzes every combination of hyperparameters,
        optimal hyperparameter values will be identical between tuning jobs that use the same
        hyperparameters. </p>
     
      <h2 id="automatic-model-tuning-num-hyperparameters">Choosing the number of
          hyperparameters</h2>
      <p>During optimization, the computational complexity of a hyperparameter tuning job depends
        on the following:</p>
      <div class="itemizedlist">
         
         
      <ul class="itemizedlist"><li class="listitem">
          <p>The number of hyperparameters</p>
        </li><li class="listitem">
          <p>The range of values that Amazon SageMaker has to search</p>
        </li></ul></div>
      <p>Although you can simultaneously specify up to 30 hyperparameters, limiting your search
        to a smaller number can reduce computation time. Reducing computation time allows SageMaker to
        converge more quickly to an optimal hyperparameter configuration.</p>
     
      <h2 id="automatic-model-tuning-choosing-ranges">Choosing hyperparameter
          ranges</h2>
      <p>The range of values that you choose to search can adversely affect hyperparameter
        optimization. For example, a range that covers every possible hyperparameter value can lead
        to large compute times and a model that doesn't generalize well to unseen data. If you know
        that using a subset of the largest possible range is appropriate for your use case, consider
        limiting the range to that subset.</p>
     
      <h2 id="automatic-model-tuning-log-scales">Using the correct scales for
          hyperparameters</h2>
      <p>During hyperparameter tuning, SageMaker attempts to infer if your hyperparameters are
        log-scaled or linear-scaled. Initially, SageMaker assumes linear scaling for hyperparameters. If
        hyperparameters are log-scaled, choosing the correct scale will make your search more
        efficient. You can also select <code class="code">Auto</code> for <code class="code">ScalingType</code> in the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateHyperParameterTuningJob.html">CreateHyperParameterTuningJob</a> API if you want SageMaker to detect the scale for
        you.</p>
     
      <h2 id="automatic-model-tuning-parallelism">Choosing the best number of parallel
          training jobs</h2>
      <p>You can use the results of previous trials to improve the performance of subsequent
        trials. Choose the largest number of parallel jobs that would provide a meaningful
        incremental result that is also within your region and account compute constraints. Use the
          <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ResourceLimits.html#MaxParallelTrainingJobs"><code class="code">MaxParallelTrainingJobs</code></a> field to limit the number of training jobs
        that a hyperparameter tuning job can launch in parallel. For more information, see <a href="http://aws.amazon.com/blogs/machine-learning/running-multiple-hpo-jobs-in-parallel-on-amazon-sagemaker" rel="noopener noreferrer" target="_blank"><span>Running multiple HPO jobs in parallel on Amazon SageMaker</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
     
      <h2 id="automatic-model-tuning-distributed-metrics">Running training jobs on
          multiple instances</h2>
      <p>When a training job runs on multiple machines in distributed mode, each machine emits an
        objective metric. HPO can only use one of these emitted objective metrics to evaluate model
        performance, In distributed mode, HPO uses the objective metric that was reported by the
        last running job across all instances. </p>
     
      <h2 id="automatic-model-tuning-random-seed">Using a random seed to reproduce
          hyperparameter configurations</h2>
      <p>You can specify an integer as a random seed for hyperparameter tuning and use that seed
        during hyperparameter generation. Later, you can use the same seed to reproduce
        hyperparameter configurations that are consistent with your previous results. For random
        search and Hyperband strategies, using the same random seed can provide up to 100%
        reproducibility of the previous hyperparameter configuration for the same tuning job. For
        Bayesian strategy, using the same random seed will improve reproducibility for the same
        tuning job.</p>
    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./automatic-model-tuning-limits.html">Resource Limits for Automatic Model
        Tuning</div><div id="next" class="next-link" accesskey="n" href="./train-debug-and-improve-model-performance.html">Debug and improve model
            performance</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/automatic-model-tuning-considerations.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/automatic-model-tuning-considerations.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>