<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Get an inference recommendation - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="inference-recommender-instance-recommendation" /><meta name="default_state" content="inference-recommender-instance-recommendation" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="inference-recommender-instance-recommendation.html" /><meta name="description" content="Describes how to create, get results, and stop inference recommendation jobs with AWS SDK for Python (Boto3), AWS CLI, and Amazon SageMaker Studio." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="inference-recommender-instance-recommendation.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="de" /><link rel="alternative" href="inference-recommender-instance-recommendation.html" hreflang="en-us" /><link rel="alternative" href="inference-recommender-instance-recommendation.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" hreflang="zh-tw" /><link rel="alternative" href="inference-recommender-instance-recommendation.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Get an inference recommendation" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Get an inference recommendation - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#inference-recommender-instance-recommendation" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/inference-recommender-instance-recommendation.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance,inference,deploy model,endpoint,prediction,ML application,serverless machine learning,multi model deployment,inference pipelines,ML model" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Deploy models for inference",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Amazon SageMaker Inference Recommender",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/inference-recommender.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Recommendation jobs",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/inference-recommender-recommendation-jobs.html"
      },
      {
        "@type" : "ListItem",
        "position" : 7,
        "name" : "Get an inference recommendation",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/inference-recommender-recommendation-jobs.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#inference-recommender-instance-recommendation" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="inference-recommender-instance-recommendation.html#instance-recommendation-create">Create an inference
                        recommendation</a><a href="inference-recommender-instance-recommendation.html#instance-recommendation-results">Get your inference
                        recommendation job results</a><a href="inference-recommender-instance-recommendation.html#instance-recommendation-stop">Stop your inference
                        recommendation</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="inference-recommender-instance-recommendation">Get an inference
                    recommendation</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Inference recommendation jobs run a set of load tests on recommended instance
                types or a serverless endpoint. Inference recommendation jobs use performance
                metrics that are based on load tests using the sample data you provided during model
                version registration.</p><div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>Before you create an Inference Recommender recommendation job, make sure you have satisfied the
                <a href="inference-recommender-prerequisites.html">Prerequisites</a>.</p></div></div><p>The following demonstrates how to use Amazon SageMaker Inference Recommender to create an inference
                recommendation based on your model type using the AWS SDK for Python (Boto3), AWS CLI, and
                Amazon SageMaker Studio, and the SageMaker console</p>
                <h2 id="instance-recommendation-create">Create an inference
                        recommendation</h2>
                <p>Create an inference recommendation programmatically using the AWS SDK for Python (Boto3) or
                    the AWS CLI, or interactively using Studio or the SageMaker console. Specify a job
                    name for your inference recommendation, an AWS IAM role ARN, an input
                    configuration, and either a model package ARN when you registered your model
                    with the model registry, or your model name and a <code class="code">ContainerConfig</code>
                    dictionary from when you created your model in the
                        <b>Prerequisites</b> section.</p>
                <awsdocs-tabs><dl style="display: none">
                    <dt>AWS SDK for Python (Boto3)</dt><dd tab-id="aws-sdk-for-python-(boto3)">
                            <p>Use the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateInferenceRecommendationsJob.html"><code class="code">CreateInferenceRecommendationsJob</code></a> API
                                to start an inference recommendation job. Set the
                                    <code class="code">JobType</code> field to <code class="code">'Default'</code> for
                                inference recommendation jobs. In addition, provide the
                                following:</p>
                            <div class="itemizedlist">
                                 
                                 
                                 
                            <ul class="itemizedlist"><li class="listitem"><p>The Amazon Resource Name (ARN) of an IAM role that enables Inference Recommender to perform tasks on your
                                        behalf. Define this for the <code class="code">RoleArn</code>
                                        field.</p></li><li class="listitem">
                                    <p>A model package ARN or model name. Inference Recommender supports either
                                        one model package ARN or a model name as input. Specify one
                                        of the following:</p>
                                    <div class="itemizedlist">
                                         
                                         
                                    <ul class="itemizedlist"><li class="listitem"><p>The ARN of the versioned model package you created when you registered your model with the
                                            model registry. Define this for
                                            <code class="code">ModelPackageVersionArn</code> in the
                                            <code class="code">InputConfig</code> field.</p></li><li class="listitem"><p>The name of the model you created. Define this for <code class="code">ModelName</code> in the
                                                  <code class="code">InputConfig</code> field. Also, provide the
                                                  <code class="code">ContainerConfig</code> dictionary, which
                                                includes the required fields that need to be
                                                provided with the model name. Define this for
                                                  <code class="code">ContainerConfig</code> in the
                                                  <code class="code">InputConfig</code> field. In the
                                                  <code class="code">ContainerConfig</code>, you can also
                                                optionally specify the
                                                  <code class="code">SupportedEndpointType</code> field as either
                                                  <code class="code">RealTime</code> or <code class="code">Serverless</code>.
                                                If you specify this field, Inference Recommender returns
                                                recommendations for only that endpoint type. If you
                                                don't specify this field, Inference Recommender returns
                                                recommendations for both endpoint types.</p></li></ul></div>
                                </li><li class="listitem"><p>A name for your Inference Recommender recommendation job for the <code class="code">JobName</code> field. The Inference Recommender job
                                        name must be unique within the AWS Region and within your
                                        AWS account.</p></li></ul></div>
                            <p>Import the AWS SDK for Python (Boto3) package and create a SageMaker client object
                                using the client class. If you followed the steps in the
                                    <b>Prerequisites</b> section, only specify one of the following:</p>
                            <div class="itemizedlist">
                                 
                                 
                            <ul class="itemizedlist"><li class="listitem"><p>Option 1: If you would like to create an inference recommendations job with a model package ARN,
                                    then store the model package group ARN in a variable named <code class="code">model_package_arn</code>.</p></li><li class="listitem"><p>Option 2: If you would like to create an inference recommendations job with a model name and <code class="code">ContainerConfig</code>,
                                    store the model name in a variable named <code class="code">model_name</code> and the <code class="code">ContainerConfig</code> dictionary in a variable named <code class="code">container_config</code>.</p></li></ul></div>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Create a low-level SageMaker service client.
import boto3
aws_region = <code class="replaceable">'&lt;INSERT&gt;'</code>
sagemaker_client = boto3.client('sagemaker', region_name=aws_region) 

# Provide only one of model package ARN or model name, not both.
# Provide your model package ARN that was created when you registered your 
# model with Model Registry 
model_package_arn = '&lt;INSERT&gt;'
## Uncomment if you would like to create an inference recommendations job with a
## model name instead of a model package ARN, and comment out model_package_arn above
## Provide your model name
# model_name = '&lt;INSERT&gt;'
## Provide your container config 
# container_config = '&lt;INSERT&gt;'

# Provide a unique job name for SageMaker Inference Recommender job
job_name = <code class="replaceable">'&lt;INSERT&gt;'</code>

# Inference Recommender job type. Set to Default to get an initial recommendation
job_type = 'Default'

# Provide an IAM Role that gives SageMaker Inference Recommender permission to 
# access AWS services
role_arn = <code class="replaceable">'arn:aws:iam::&lt;account&gt;:role/*'</code>

sagemaker_client.create_inference_recommendations_job(
    JobName = job_name,
    JobType = job_type,
    RoleArn = role_arn,
    # Provide only one of model package ARN or model name, not both. 
    # If you would like to create an inference recommendations job with a model name,
    # uncomment ModelName and ContainerConfig, and comment out ModelPackageVersionArn.
    InputConfig = <span>{</span>
        'ModelPackageVersionArn': model_package_arn
        # 'ModelName': model_name,
        # 'ContainerConfig': container_config
    }
)</code></pre>
                            <p>See the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/Welcome.html">Amazon SageMaker API Reference Guide</a> 
                                for a full list of optional and required arguments you can pass to 
                                <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateInferenceRecommendationsJob.html"><code class="code">CreateInferenceRecommendationsJob</code></a>.</p>
                        </dd>
                    <dt>AWS CLI</dt><dd tab-id="aws-cli">
                            
                            <p>Use the <code class="code">create-inference-recommendations-job</code> API to
                                start an inference recommendation job. Set the <code class="code">job-type</code>
                                field to <code class="code">'Default'</code> for inference recommendation jobs.
                                In addition, provide the following:</p>
                            <div class="itemizedlist">
                                 
                                 
                                 
                            <ul class="itemizedlist"><li class="listitem"><p>The Amazon Resource Name (ARN) of an IAM role that enables Amazon SageMaker Inference Recommender to 
                                    perform tasks on your behalf. Define this for the <code class="code">role-arn</code> field.</p></li><li class="listitem">
                                    <p>A model package ARN or model name. Inference Recommender supports either
                                        one model package ARN or a model name as input. Specify one
                                        of the following</p>
                                    <div class="itemizedlist">
                                         
                                         
                                    <ul class="itemizedlist"><li class="listitem"><p>The ARN of the versioned model package you 
                                            created when you registered your model with Model Registry. Define this  
                                            for <code class="code">ModelPackageVersionArn</code> in the <code class="code">input-config</code> field.</p></li><li class="listitem"><p>The name of the model you created. Define this for <code class="code">ModelName</code> in the
                                                  <code class="code">input-config</code> field. Also, provide the
                                                  <code class="code">ContainerConfig</code> dictionary which
                                                includes the required fields that need to be
                                                provided with the model name. Define this for
                                                  <code class="code">ContainerConfig</code> in the
                                                  <code class="code">input-config</code> field. In the
                                                  <code class="code">ContainerConfig</code>, you can also
                                                optionally specify the
                                                  <code class="code">SupportedEndpointType</code> field as either
                                                  <code class="code">RealTime</code> or <code class="code">Serverless</code>.
                                                If you specify this field, Inference Recommender returns
                                                recommendations for only that endpoint type. If you
                                                don't specify this field, Inference Recommender returns
                                                recommendations for both endpoint types.</p></li></ul></div>
                                </li><li class="listitem"><p>A name for your Inference Recommender recommendation job for the <code class="code">job-name</code> field. The Inference Recommender job
                                        name must be unique within the AWS Region and within your
                                        AWS account.</p></li></ul></div>
                            
                            <p>To create an inference recommendation jobs with a model package ARN, use the following example:</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="bash ">aws sagemaker create-inference-recommendations-job 
    --region <code class="replaceable">&lt;region&gt;</code>\
    --job-name <code class="replaceable">&lt;job_name&gt;</code>\
    --job-type Default\
    --role-arn arn:aws:iam::<code class="replaceable">&lt;account:role/*&gt;</code>\
    --input-config "<span>{</span>
        \"ModelPackageVersionArn\": \"arn:aws:sagemaker:<code class="replaceable">&lt;region:account:role/*&gt;</code>\",
        }"</code></pre>
                            <p>To create an inference recommendation jobs with a model name and
                                    <code class="code">ContainerConfig</code>, use the following example. The
                                example uses the <code class="code">SupportedEndpointType</code> field to specify
                                that we only want to return real-time inference
                                recommendations:</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="bash ">aws sagemaker create-inference-recommendations-job 
    --region <code class="replaceable">&lt;region&gt;</code>\
    --job-name <code class="replaceable">&lt;job_name&gt;</code>\
    --job-type Default\
    --role-arn arn:aws:iam::<code class="replaceable">&lt;account:role/*&gt;</code>\
    --input-config "<span>{</span>
        \"ModelName\": \"model-name\",
        \"ContainerConfig\" : <span>{</span>
                \"Domain\": \"COMPUTER_VISION\",
                \"Framework\": \"PYTORCH\",
                \"FrameworkVersion\": \"1.7.1\",
                \"NearestModelName\": \"resnet18\",
                \"PayloadConfig\": 
                    <span>{</span>
                        \"SamplePayloadUrl\": \"s3://<span>{</span>bucket}/<span>{</span>payload_s3_key}\", 
                        \"SupportedContentTypes\": [\"image/jpeg\"]
                    },
                \"SupportedEndpointType\": \"RealTime\",
                \"DataInputConfig\": \"[[1,3,256,256]]\",
                \"Task\": \"IMAGE_CLASSIFICATION\",
            },
        }"</code></pre>
                        </dd>
                    <dt>Amazon SageMaker Studio</dt><dd tab-id="amazon-sagemaker-studio">
                            <p>Create an inference recommendation job in Studio.</p>
                            <div class="procedure"><ol><li>
                                    <p>In your Studio application, choose the home icon (<span class="inlinemediaobject">
                                        <img src="../../../images/sagemaker/latest/dg/images/studio/icons/house.png" class="aws-docs-img-whiteBg aws-docs-img-xs-padding" alt="Home icon in Studio" />
                                        </span>).</p>
                                </li><li>
                                    <p>In the left sidebar of Studio, choose
                                        <b>Models</b>.</p>
                                </li><li><p>Choose <b>Model Registry</b> from the dropdown list to display models you have
                                        registered with the model registry.</p>
                                    <p>The left panel displays a list of model groups. The list
                                        includes all the model groups registered with the model
                                        registry in your account, including models registered
                                        outside of Studio.</p></li><li><p>Select the name of your model group. When you select your model group, the right pane of
                                        Studio displays column heads such as
                                            <b>Versions</b> and
                                            <b>Setting</b>.</p>
                                    <p>If you have one or more model packages within your model
                                        group, you will see a list of those model packages within
                                        the <b>Versions</b> column.</p></li><li><p>Choose the <b>Inference recommender</b> column.</p></li><li><p>Choose an IAM role that grants Inference Recommender permission to access AWS services. You can create a
                                        role and attach the <code class="code">AmazonSageMakerFullAccess</code>
                                        IAM managed policy to accomplish this. Or you can let
                                        Studio create a role for you.</p></li><li><p>Choose <b>Get recommendations</b>.</p>
                                    <p>The inference recommendation can take up to 45 minutes.</p>
                                    <div class="awsdocs-note awsdocs-warning"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Warning</h6></div><div class="awsdocs-note-text"><p>Do not close
                                            this
                                            tab. If you close this tab, you
                                            cancel the instance recommendation job.</p></div></div>
                                </li></ol></div>
                        </dd>
                    
                    <dt>SageMaker console</dt><dd tab-id="sagemaker-console">
                            <p>Create an instance recommendation job through the SageMaker console by doing the following:</p>
                            <div class="procedure"><ol><li>
                                            <p>Go to the SageMaker console at <a href="https://console.aws.amazon.com/sagemaker/" rel="noopener noreferrer" target="_blank"><span>https://console.aws.amazon.com/sagemaker/</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                                    </li><li>
                                            <p>In the left navigation pane, choose
                                            <b>Inference</b>, and then choose
                                            <b>Inference recommender</b>.</p>
                                    </li><li>
                                            <p>On the <b>Inference recommender
                                            jobs</b> page, choose <b>Create
                                            job</b>.</p>
                                    </li><li>
                                            <p>For <b>Step 1: Model
                                            configuration</b>, do the following:</p>
                                            <ol><li>
                                                        <p>For <b>Job type</b>,
                                                choose <b>Default recommender
                                                job</b>.</p>
                                                </li><li>
                                                        <p>If you’re using a model registered in
                                                the SageMaker model registry, then turn on the
                                                  <b>Choose a model from the model
                                                  registry</b> toggle and do the
                                                following:</p>
                                                        <ol><li>
                                                                <p>From the <b>Model
                                                  group</b> dropdown list, choose the model
                                                  group in SageMaker model registry where your model is
                                                  located.</p>
                                                            </li><li>
                                                                <p>From the <b>Model
                                                  version</b> dropdown list, choose the
                                                  desired version of your model.</p>
                                                            </li></ol>
                                                </li><li>
                                                        <p>If you’re using a model that you’ve
                                                created in SageMaker, then turn off the
                                                  <b>Choose a model from the model registry
                                                  toggle</b> and do the following:</p>
                                                    <ol><li>
                                                            <p>For the <b>Model
                                                  name</b> field, enter the name of your
                                                  SageMaker model.</p>
                                                        </li></ol>
                                                </li><li>
                                                        <p>From the <b>IAM
                                                  role</b> dropdown list, you can select an
                                                existing AWS IAM role that has the necessary
                                                permissions to create an instance recommendation
                                                job. Alternatively, if you don’t have an existing
                                                role, you can choose <b>Create a new
                                                  role</b> to open the role creation pop-up,
                                                and SageMaker adds the necessary permissions to the new
                                                role that you create.</p>
                                                </li><li>
                                                        <p>For <b>S3 bucket for
                                                  benchmarking payload</b>, enter the Amazon S3
                                                path to your sample payload archive, which should
                                                contain sample payload files that Inference Recommender
                                                uses to benchmark your model on
                                                different instance types.</p>
                                                </li><li>
                                                        <p>For <b>Payload content
                                                  type</b>, enter the MIME types of your
                                                sample payload data.</p>
                                                </li><li>
                                                        <p>(Optional) If you turned off the
                                                  <b>Choose a model from the model registry
                                                  toggle</b> and specified a SageMaker model,
                                                then for <b>Container
                                                  configuration</b>, do the following:</p>
                                                        <ol><li>
                                                                        <p>For the
                                                  <b>Domain</b> dropdown list, select
                                                  the machine learning domain of the model, such as
                                                  computer vision, natural language processing, or
                                                  machine learning.</p>
                                                                </li><li>
                                                                        <p>For the
                                                  <b>Framework</b> dropdown list,
                                                  select the framework of your container, such as
                                                  TensorFlow or XGBoost.</p>
                                                                </li><li>
                                                                        <p>For
                                                  <b>Framework version</b>, enter the
                                                  framework version of your container image.</p>
                                                                </li><li>
                                                                        <p>For the
                                                  <b>Nearest model name</b> dropdown
                                                  list, select the pre-trained model that mostly
                                                  closely matches your own.</p>
                                                                </li><li>
                                                                        <p>For the
                                                  <b>Task</b> dropdown list, select
                                                  the machine learning task that the model
                                                  accomplishes, such as image classification or
                                                  regression.</p>
                                                                </li></ol>
                                                </li><li>
                                                        <p>(Optional) For <b>Model
                                                  compilation using SageMaker Neo</b>, you can
                                                configure the recommendation job for a model that
                                                you’ve compiled using SageMaker Neo. For <b>Data
                                                  input configuration</b>, enter the correct
                                                input data shape for your model in a format similar
                                                to <code class="code"><span>{</span>'input':[1,1024,1024,3]}</code>.</p>
                                                </li><li>
                                                        <p>Choose
                                                <b>Next</b>.</p>
                                                </li></ol>
                                    </li><li>
                                            <p>For <b>Step 2: Instances and environment
                                            parameters</b>, do the following:</p>
                                            <ol><li>
                                                        <p>(Optional) For <b>Select
                                                  instances for benchmarking</b>, you can
                                                select up to 8 instance types that you want to
                                                benchmark. If you don’t select any instances, Inference Recommender
                                                considers all instance types.</p>
                                                </li><li>
                                                        <p>Choose <b>Next</b>.</p>
                                                </li></ol>
                                    </li><li>
                                            <p>For <b>Step 3: Job parameters</b>,
                                        do the following:</p>
                                            <ol><li>
                                                        <p>(Optional) For the <b>Job
                                                  name</b> field, enter a name for your
                                                instance recommendation job. When you create the
                                                job, SageMaker appends a timestamp to the end of this
                                                name.</p>
                                                </li><li>
                                                        <p>(Optional) For the <b>Job
                                                  description</b> field, enter a description
                                                for the job.</p>
                                                </li><li>
                                                        <p>(Optional) For the
                                                  <b>Encryption key</b> dropdown list,
                                                choose an AWS KMS key by name or enter its ARN to
                                                encrypt your data.</p>
                                                </li><li>
                                                    <p>(Optional) For <b>Max test duration (s)</b>, enter the maximum number of seconds you want each test to run for.</p>
                                                </li><li>
                                                        <p>(Optional) For <b>Max
                                                  invocations per minute</b>, enter the
                                                maximum number of requests per minute the endpoint
                                                can reach before stopping the recommendation job.
                                                After reaching this limit, SageMaker ends the
                                                job.</p>
                                                </li><li>
                                                        <p>(Optional) For <b>P99 Model
                                                  latency threshold (ms)</b>, enter the model
                                                latency percentile in milliseconds.</p>
                                                </li><li>
                                                        <p>Choose
                                                <b>Next</b>.</p>
                                                </li></ol>
                                    </li><li>
                                            <p>For <b>Step 4: Review job</b>,
                                        review your configurations and then choose
                                            <b>Submit</b>.</p>
                                    </li></ol></div>
                        </dd>
                </dl></awsdocs-tabs>
             
                <h2 id="instance-recommendation-results">Get your inference
                        recommendation job results</h2>
                <p>Collect the results of your inference recommendation job programmatically with
                    AWS SDK for Python (Boto3), the AWS CLI, Studio, or the SageMaker console.</p>
                <awsdocs-tabs><dl style="display: none">
                    <dt>AWS SDK for Python (Boto3)</dt><dd tab-id="aws-sdk-for-python-(boto3)">
                            <p>Once an inference recommendation is complete, you can use
                                    <code class="code">DescribeInferenceRecommendationsJob</code> to get the job
                                details and recommendations. Provide the job name that you used when
                                you created the inference recommendation job.</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">job_name=<code class="replaceable">'&lt;INSERT&gt;'</code>
response = sagemaker_client.describe_inference_recommendations_job(
                    JobName=job_name)</code></pre>
                            <p>Print the response object. The previous code sample stored the
                                response in a variable name <code class="code">response</code>.</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">print(response['Status'])</code></pre>
                            <p>This returns a JSON response similar to the following example.
                                Note that this example shows the recommended instance types for
                                real-time inference (for an example showing serverless inference
                                recommendations, see the example after this one).</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "><span>{</span>
    'JobName': <code class="replaceable">'job-name'</code>, 
    'JobDescription': <code class="replaceable">'job-description'</code>, 
    'JobType': 'Default', 
    'JobArn': 'arn:aws:sagemaker:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:inference-recommendations-job/<code class="replaceable">resource-id</code>', 
    'Status': 'COMPLETED', 
    'CreationTime': datetime.datetime(2021, 10, 26, 20, 4, 57, 627000, tzinfo=tzlocal()), 
    'LastModifiedTime': datetime.datetime(2021, 10, 26, 20, 25, 1, 997000, tzinfo=tzlocal()), 
    'InputConfig': <span>{</span>
                'ModelPackageVersionArn': 'arn:aws:sagemaker:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:model-package/<code class="replaceable">resource-id</code>', 
                'JobDurationInSeconds': 0
                }, 
    'InferenceRecommendations': [<span>{</span>
            'Metrics': <span>{</span>
                'CostPerHour': 0.20399999618530273, 
                'CostPerInference': 5.246913588052848e-06, 
                'MaximumInvocations': 648, 
                'ModelLatency': 263596
                }, 
            'EndpointConfiguration': <span>{</span>
                'EndpointName': <code class="replaceable">'endpoint-name'</code>, 
                'VariantName': <code class="replaceable">'variant-name'</code>, 
                'InstanceType': 'ml.c5.xlarge', 
                'InitialInstanceCount': 1
                }, 
            'ModelConfiguration': <span>{</span>
                'Compiled': False, 
                'EnvironmentParameters': []
                }
         }, 
         <span>{</span>
            'Metrics': <span>{</span>
                'CostPerHour': 0.11500000208616257, 
                'CostPerInference': 2.92620870823157e-06, 
                'MaximumInvocations': 655, 
                'ModelLatency': 826019
                }, 
            'EndpointConfiguration': <span>{</span>
                'EndpointName': <code class="replaceable">'endpoint-name'</code>, 
                'VariantName': <code class="replaceable">'variant-name'</code>, 
                'InstanceType': 'ml.c5d.large', 
                'InitialInstanceCount': 1
                }, 
            'ModelConfiguration': <span>{</span>
                'Compiled': False, 
                'EnvironmentParameters': []
                }
            }, 
            <span>{</span>
                'Metrics': <span>{</span>
                    'CostPerHour': 0.11500000208616257, 
                    'CostPerInference': 3.3625731248321244e-06, 
                    'MaximumInvocations': 570, 
                    'ModelLatency': 1085446
                    }, 
                'EndpointConfiguration': <span>{</span>
                    'EndpointName': <code class="replaceable">'endpoint-name'</code>, 
                    'VariantName': <code class="replaceable">'variant-name'</code>, 
                    'InstanceType': 'ml.m5.large', 
                    'InitialInstanceCount': 1
                    }, 
                'ModelConfiguration': <span>{</span>
                    'Compiled': False, 
                    'EnvironmentParameters': []
                    }
            }], 
    'ResponseMetadata': <span>{</span>
        'RequestId': <code class="replaceable">'request-id'</code>, 
        'HTTPStatusCode': 200, 
        'HTTPHeaders': <span>{</span>
            'x-amzn-requestid': <code class="replaceable">'x-amzn-requestid'</code>, 
            'content-type': <code class="replaceable">'content-type'</code>, 
            'content-length': '1685', 
            'date': 'Tue, 26 Oct 2021 20:31:10 GMT'
            }, 
        'RetryAttempts': 0
        }
}</code></pre>
                            <p>The first few lines provide information about the inference
                                recommendation job itself. This includes the job name, role ARN, and
                                creation and deletion times. </p>
                            <p>The <code class="code">InferenceRecommendations</code> dictionary contains a
                                list of Inference Recommender inference recommendations.</p>
                            <p>The <code class="code">EndpointConfiguration</code> nested dictionary contains
                                the instance type (<code class="code">InstanceType</code>) recommendation along
                                with the endpoint and variant name (a deployed AWS machine
                                learning model) that was used during the recommendation job. You can
                                use the endpoint and variant name for monitoring in Amazon CloudWatch Events. See
                                    <a href="monitoring-cloudwatch.html">Monitor Amazon SageMaker with Amazon CloudWatch</a> for more
                                information.</p>
                            <p>The <code class="code">Metrics</code> nested dictionary contains information
                                about the estimated cost per hour (<code class="code">CostPerHour</code>) for
                                your real-time endpoint in US dollars, the estimated cost per
                                inference (<code class="code">CostPerInference</code>) in US dollars for 
                                your real-time endpoint, the expected maximum number of 
                                <code class="code">InvokeEndpoint</code> requests per minute sent to the endpoint 
                                (<code class="code">MaxInvocations</code>), and the model latency 
                                (<code class="code">ModelLatency</code>), which is the interval of time (in
                                milliseconds) that your model took to respond to SageMaker. The model
                                latency includes the local communication times taken to send the
                                request and to fetch the response from the container of a model and
                                the time taken to complete the inference in the container.</p>
                            <p>The following example shows the
                                    <code class="code">InferenceRecommendations</code> part of the response for
                                an inference recommendations job configured to return serverless
                                inference recommendations:</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="json ">"InferenceRecommendations": [ 
      <span>{</span> 
         "EndpointConfiguration": <span>{</span> 
            "EndpointName": "<code class="replaceable">value</code>",
            "InitialInstanceCount": <code class="replaceable">value</code>,
            "InstanceType": "<code class="replaceable">value</code>",
            "VariantName": "<code class="replaceable">value</code>",
            "ServerlessConfig": <span>{</span>
                "MaxConcurrency": <code class="replaceable">value</code>,
                "MemorySizeInMb": <code class="replaceable">value</code>
            }
         },
         "InvocationEndTime": <code class="replaceable">value</code>,
         "InvocationStartTime": <code class="replaceable">value</code>,
         "Metrics": <span>{</span> 
            "CostPerHour": <code class="replaceable">value</code>,
            "CostPerInference": <code class="replaceable">value</code>,
            "CpuUtilization": <code class="replaceable">value</code>,
            "MaxInvocations": <code class="replaceable">value</code>,
            "MemoryUtilization": <code class="replaceable">value</code>,
            "ModelLatency": <code class="replaceable">value</code>,
            "ModelSetupTime": <code class="replaceable">value</code>
         },
         "ModelConfiguration": <span>{</span> 
            "Compiled": "False",
            "EnvironmentParameters": [],
            "InferenceSpecificationName": "<code class="replaceable">value</code>"
         },
         "RecommendationId": "<code class="replaceable">value</code>"
      }
   ]</code></pre>
                            <p>You can interpret the recommendations for serverless inference
                                similarly to the results for real-time inference, with the exception
                                of the <code class="code">ServerlessConfig</code>, which tells you the metrics returned
                                for a serverless endpoint with the given <code class="code">MemorySizeInMB</code> and
                                when <code class="code">MaxConcurrency = 1</code>. To increase the throughput possible
                                on the endpoint, increase the value of <code class="code">MaxConcurrency</code> linearly.
                                For example, if the inference recommendation shows <code class="code">MaxInvocations</code>
                                as <code class="code">1000</code>, then increasing <code class="code">MaxConcurrency</code> to
                                <code class="code">2</code> would support 2000 <code class="code">MaxInvocations</code>. Note that this
                                is true only up to a certain point, which can vary based on your model and code.
                                Serverless recommendations also measure the metric
                                    <code class="code">ModelSetupTime</code>, which measures (in microseconds)
                                the time it takes to launch computer resources on a serverless
                                endpoint. For more information about setting up serverless
                                endpoints, see the <a href="serverless-endpoints.html">Serverless Inference
                                    documentation</a>.</p>                   
                        </dd>
                    <dt>AWS CLI</dt><dd tab-id="aws-cli">
                            <p>Once an inference recommendation is complete, you can use
                                    <code class="code">describe-inference-recommendations-job</code> to get the
                                job details and recommended instance types. Provide the job name
                                that you used when you created the inference recommendation
                                job.</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="bash ">aws sagemaker describe-inference-recommendations-job\
    --job-name <code class="replaceable">&lt;job-name&gt;</code>\
    --region <code class="replaceable">&lt;aws-region&gt;</code>
</code></pre>
                            
                            <p>The JSON response similar should resemble the following example.
                                Note that this example shows the recommended instance types for
                                real-time inference (for an example showing serverless inference
                                recommendations, see the example after this one).</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="bash "><span>{</span>
    'JobName': <code class="replaceable">'job-name'</code>, 
    'JobDescription': <code class="replaceable">'job-description'</code>, 
    'JobType': 'Default', 
    'JobArn': 'arn:aws:sagemaker:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:inference-recommendations-job/<code class="replaceable">resource-id</code>', 
    'Status': 'COMPLETED', 
    'CreationTime': datetime.datetime(2021, 10, 26, 20, 4, 57, 627000, tzinfo=tzlocal()), 
    'LastModifiedTime': datetime.datetime(2021, 10, 26, 20, 25, 1, 997000, tzinfo=tzlocal()), 
    'InputConfig': <span>{</span>
                'ModelPackageVersionArn': 'arn:aws:sagemaker:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:model-package/<code class="replaceable">resource-id</code>', 
                'JobDurationInSeconds': 0
                }, 
    'InferenceRecommendations': [<span>{</span>
            'Metrics': <span>{</span>
                'CostPerHour': 0.20399999618530273, 
                'CostPerInference': 5.246913588052848e-06, 
                'MaximumInvocations': 648, 
                'ModelLatency': 263596
                }, 
            'EndpointConfiguration': <span>{</span>
                'EndpointName': <code class="replaceable">'endpoint-name'</code>, 
                'VariantName': <code class="replaceable">'variant-name'</code>, 
                'InstanceType': 'ml.c5.xlarge', 
                'InitialInstanceCount': 1
                }, 
            'ModelConfiguration': <span>{</span>
                'Compiled': False, 
                'EnvironmentParameters': []
                }
         }, 
         <span>{</span>
            'Metrics': <span>{</span>
                'CostPerHour': 0.11500000208616257, 
                'CostPerInference': 2.92620870823157e-06, 
                'MaximumInvocations': 655, 
                'ModelLatency': 826019
                }, 
            'EndpointConfiguration': <span>{</span>
                'EndpointName': <code class="replaceable">'endpoint-name'</code>, 
                'VariantName': <code class="replaceable">'variant-name'</code>, 
                'InstanceType': 'ml.c5d.large', 
                'InitialInstanceCount': 1
                }, 
            'ModelConfiguration': <span>{</span>
                'Compiled': False, 
                'EnvironmentParameters': []
                }
            }, 
            <span>{</span>
                'Metrics': <span>{</span>
                    'CostPerHour': 0.11500000208616257, 
                    'CostPerInference': 3.3625731248321244e-06, 
                    'MaximumInvocations': 570, 
                    'ModelLatency': 1085446
                    }, 
                'EndpointConfiguration': <span>{</span>
                    'EndpointName': <code class="replaceable">'endpoint-name'</code>, 
                    'VariantName': <code class="replaceable">'variant-name'</code>, 
                    'InstanceType': 'ml.m5.large', 
                    'InitialInstanceCount': 1
                    }, 
                'ModelConfiguration': <span>{</span>
                    'Compiled': False, 
                    'EnvironmentParameters': []
                    }
            }], 
    'ResponseMetadata': <span>{</span>
        'RequestId': <code class="replaceable">'request-id'</code>, 
        'HTTPStatusCode': 200, 
        'HTTPHeaders': <span>{</span>
            'x-amzn-requestid': <code class="replaceable">'x-amzn-requestid'</code>, 
            'content-type': <code class="replaceable">'content-type'</code>, 
            'content-length': '1685', 
            'date': 'Tue, 26 Oct 2021 20:31:10 GMT'
            }, 
        'RetryAttempts': 0
        }
}</code></pre>
                            <p>The first few lines provide information about the inference
                                recommendation job itself. This includes the job name, role ARN,
                                creation, and deletion time. </p>
                            <p>The <code class="code">InferenceRecommendations</code> dictionary contains a
                                list of Inference Recommender inference recommendations.</p>
                            <p>The <code class="code">EndpointConfiguration</code> nested dictionary contains
                                the instance type (<code class="code">InstanceType</code>) recommendation along
                                with the endpoint and variant name (a deployed AWS machine
                                learning model) used during the recommendation job. You can use the
                                endpoint and variant name for monitoring in Amazon CloudWatch Events. See <a href="monitoring-cloudwatch.html">Monitor Amazon SageMaker with Amazon CloudWatch</a> for more
                                information.</p>
                            <p>The <code class="code">Metrics</code> nested dictionary contains information
                                about the estimated cost per hour (<code class="code">CostPerHour</code>) for
                                your real-time endpoint in US dollars, the estimated cost per
                                inference (<code class="code">CostPerInference</code>) in US dollars for 
                                your real-time endpoint, the expected maximum number of 
                                <code class="code">InvokeEndpoint</code> requests per minute sent to the endpoint 
                                (<code class="code">MaxInvocations</code>), and the model latency 
                                (<code class="code">ModelLatency</code>), which is the interval of time (in
                                milliseconds) that your model took to respond to SageMaker. The model
                                latency includes the local communication times taken to send the
                                request and to fetch the response from the container of a model and
                                the time taken to complete the inference in the container.</p>
                            <p>The following example shows the <code class="code">InferenceRecommendations</code> part of the response
                            for an inference recommendations job configured to return serverless inference recommendations:</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="json ">"InferenceRecommendations": [ 
      <span>{</span> 
         "EndpointConfiguration": <span>{</span> 
            "EndpointName": "<code class="replaceable">value</code>",
            "InitialInstanceCount": <code class="replaceable">value</code>,
            "InstanceType": "<code class="replaceable">value</code>",
            "VariantName": "<code class="replaceable">value</code>",
            "ServerlessConfig": <span>{</span>
                "MaxConcurrency": <code class="replaceable">value</code>,
                "MemorySizeInMb": <code class="replaceable">value</code>
            }
         },
         "InvocationEndTime": <code class="replaceable">value</code>,
         "InvocationStartTime": <code class="replaceable">value</code>,
         "Metrics": <span>{</span> 
            "CostPerHour": <code class="replaceable">value</code>,
            "CostPerInference": <code class="replaceable">value</code>,
            "CpuUtilization": <code class="replaceable">value</code>,
            "MaxInvocations": <code class="replaceable">value</code>,
            "MemoryUtilization": <code class="replaceable">value</code>,
            "ModelLatency": <code class="replaceable">value</code>,
            "ModelSetupTime": <code class="replaceable">value</code>
         },
         "ModelConfiguration": <span>{</span> 
            "Compiled": "False",
            "EnvironmentParameters": [],
            "InferenceSpecificationName": "<code class="replaceable">value</code>"
         },
         "RecommendationId": "<code class="replaceable">value</code>"
      }
   ]</code></pre>
                            <p>You can interpret the recommendations for serverless inference
                                similarly to the results for real-time inference, with the exception
                                of the <code class="code">ServerlessConfig</code>, which tells you the metrics returned
                                for a serverless endpoint with the given <code class="code">MemorySizeInMB</code> and
                                when <code class="code">MaxConcurrency = 1</code>. To increase the throughput possible
                                on the endpoint, increase the value of <code class="code">MaxConcurrency</code> linearly.
                                For example, if the inference recommendation shows <code class="code">MaxInvocations</code>
                                as <code class="code">1000</code>, then increasing <code class="code">MaxConcurrency</code> to
                                <code class="code">2</code> would support 2000 <code class="code">MaxInvocations</code>. Note that this
                                is true only up to a certain point, which can vary based on your model and code. Serverless recommendations
                                also measure the metric <code class="code">ModelSetupTime</code>, which measures
                                (in microseconds) the time it takes to launch computer resources on
                                a serverless endpoint. For more information about setting up
                                serverless endpoints, see the <a href="serverless-endpoints.html">Serverless Inference
                                    documentation</a>.</p>
                            
                        </dd>
                    <dt>Amazon SageMaker Studio</dt><dd tab-id="amazon-sagemaker-studio">
                            <p>The inference recommendations populate in a new
                                    <b>Inference recommendations</b> tab within
                                Studio. It can take up to 45 minutes for the results to show up.
                                This tab contains <b>Results</b> and
                                    <b>Details</b> column headings.</p>
                            <p>The <b>Details</b> column provides information about
                                the inference recommendation job, such as the name of the inference
                                recommendation, when the job was created (<b>Creation
                                    time</b>), and more. It also provides
                                    <b>Settings</b> information, such as the maximum
                                number of invocations that occurred per minute and information about
                                the Amazon Resource Names used.</p>
                            <p>The <b>Results</b> column provides a <b>
                                    Deployment goals</b> and <b>SageMaker
                                    recommendations</b> window in which you can adjust the
                                order that the results are displayed based on deployment importance.
                                There are three dropdown menus that you can use to provide the level
                                of importance of the <b>Cost</b>,
                                    <b>Latency</b>, and
                                    <b>Throughput</b> for your use case. For each goal
                                (cost, latency, and throughput), you can set the level of
                                importance: <b>Lowest Importance</b>, <b>Low
                                    Importance</b>, <b>Moderate importance</b>,
                                    <b>High importance</b>, or <b>Highest
                                    importance</b>. </p>
                            <p>Based on your selections of importance for each goal, Inference Recommender
                                displays its top recommendation in the <b>SageMaker
                                    recommendation</b> field on the right of the panel, along
                                with the estimated cost per hour and inference request. It also
                                provides information about the expected model latency, maximum
                                number of invocations, and the number of instances. For serverless
                                recommendations, you can see the ideal values for the maximum
                                concurrency and endpoint memory size.</p>
                            <p>In addition to the top recommendation displayed, you can also see
                                the same information displayed for all instances that Inference Recommender tested
                                in the <b>All runs</b> section.</p>
                        </dd>
                    <dt>SageMaker console</dt><dd tab-id="sagemaker-console">
                            <p>You can view your instance recommendation jobs in the SageMaker
                                console by doing the following:</p>
                            <div class="procedure"><ol><li>
                                        <p>Go to the SageMaker console at <a href="https://console.aws.amazon.com/sagemaker/" rel="noopener noreferrer" target="_blank"><span>https://console.aws.amazon.com/sagemaker/</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                                </li><li>
                                        <p>In the left navigation pane, choose <b>Inference</b>, and
                                            then choose <b>Inference recommender</b>.</p>
                                </li><li>
                                        <p>On the <b>Inference recommender jobs</b>
                                        page, choose the name of your inference recommendation
                                        job.</p>
                                </li></ol></div>
                            <p>On the details page for your job, you can view the
                                    <b>Inference recommendations</b>, which are the
                                instance types SageMaker recommends for your model, as shown in the
                                following screenshot.</p>
                            <div class="mediaobject">
                                 
                                    <img src="../../../images/sagemaker/latest/dg/images/inf-rec-instant-recs.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                                    Screenshot of the inference recommendations list on the job details page in the SageMaker console.&#xA;                                " style="max-width:80%" />
                                 
                                 
                            </div>
                            <p>In this section, you can compare the instance types by various
                                factors such as <b>Model latency</b>,
                                    <b>Cost per hour</b>, <b>Cost per inference</b>,
                                and <b>Invocations per minute</b>.</p>
                            <p>On this page, you can also view the configurations you specified
                                for your job. In the <b>Monitor</b>
                                section, you can view the Amazon CloudWatch metrics that were logged
                                for each instance type. To learn more about interpreting these
                                metrics, see <a href="inference-recommender-interpret-results.html">Interpret results</a>.</p>
                        </dd>
                </dl></awsdocs-tabs>
                <p>For more information about interpreting the results of your
                    recommendation job, see <a href="inference-recommender-interpret-results.html">Interpret recommendation results</a>.</p>
             
                <h2 id="instance-recommendation-stop">Stop your inference
                        recommendation</h2>
                
                <p>Stop your Inference Recommender inference recommendation jobs programmatically with the
                        <code class="code">StopInferenceRecommendationsJob</code> API or with Studio.</p>
                
                <awsdocs-tabs><dl style="display: none">
                    <dt>AWS SDK for Python (Boto3)</dt><dd tab-id="aws-sdk-for-python-(boto3)"><p>Specify the name of the inference recommendation job for the <code class="code">JobName</code>
                                field:</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">sagemaker_client.stop_inference_recommendations_job(
                                    JobName=<code class="replaceable">'&lt;INSERT&gt;'</code>
                                    )</code></pre>
                        </dd>
                    <dt>AWS CLI</dt><dd tab-id="aws-cli"><p>Specify the job name of the inference recommendation job for the <code class="code">job-name</code>
                                flag:</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="bash ">aws sagemaker stop-inference-recommendations-job --job-name <code class="replaceable">&lt;job-name&gt;</code></code></pre>
                        </dd>
                    <dt>Amazon SageMaker Studio</dt><dd tab-id="amazon-sagemaker-studio"><p>Close the tab in which you initiated the inference recommendation to stop your Inference Recommender
                                inference recommendation.</p></dd>
                    <dt>SageMaker console</dt><dd tab-id="sagemaker-console">
                            <p>To stop your instance recommendation job through the SageMaker console, do the following:</p>                           <p></p>
                            <div class="procedure"><ol><li>
                                        <p>Go to the SageMaker console at <a href="https://console.aws.amazon.com/sagemaker/" rel="noopener noreferrer" target="_blank"><span>https://console.aws.amazon.com/sagemaker/</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                                </li><li>
                                        <p>In the left navigation pane, choose <b>Inference</b>, and
                                            then choose <b>Inference recommender</b>.</p>
                                </li><li>
                                        <p>On the <b>Inference recommender jobs</b>
                                        page, select your instance recommendation job.</p>
                                </li><li>
                                        <p>Choose <b>Stop job</b>.</p>
                                </li><li>
                                        <p>In the dialog box that pops up, choose <b>Confirm</b>.</p>
                                </li></ol></div>
                            <p>After stopping your job, the job’s <b>Status</b> should change to <b>Stopping</b>.</p>
                        </dd>
                </dl></awsdocs-tabs>
            <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./inference-recommender-prospective.html">Get instant prospective instances</div><div id="next" class="next-link" accesskey="n" href="./inference-recommender-existing-endpoint.html">Get an inference
                    recommendation for an existing endpoint</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/inference-recommender-instance-recommendation.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/inference-recommender-instance-recommendation.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>