<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Create an Amazon SageMaker Experiment - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="experiments-create" /><meta name="default_state" content="experiments-create" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="experiments-create.html" /><meta name="description" content="Describes how to create an Amazon SageMaker Experiment to track your SageMaker jobs and machine learning (ML) workflows." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="experiments-create.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/experiments-create.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/experiments-create.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/experiments-create.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/experiments-create.html" hreflang="de" /><link rel="alternative" href="experiments-create.html" hreflang="en-us" /><link rel="alternative" href="experiments-create.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/experiments-create.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/experiments-create.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/experiments-create.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/experiments-create.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/experiments-create.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/experiments-create.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/experiments-create.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/experiments-create.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/experiments-create.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/experiments-create.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/experiments-create.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/experiments-create.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/experiments-create.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/experiments-create.html" hreflang="zh-tw" /><link rel="alternative" href="experiments-create.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Create an Amazon SageMaker Experiment" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Create an Amazon SageMaker Experiment - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#experiments-create" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/experiments-create.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/experiments-create.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/experiments-create.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Train machine learning models",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/train-model.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Manage Machine Learning with Amazon SageMaker Experiments",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Create an Amazon SageMaker Experiment",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#experiments-create" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="experiments-create.html#experiments-create-overview">Overview</a><a href="experiments-create.html#experiments-create-python-sdk">SageMaker Python SDK</a><a href="experiments-create.html#experiments-create-script-mode">Script mode</a><a href="experiments-create.html#experiments-create-view">View experiments</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="experiments-create">Create an Amazon SageMaker Experiment</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Create an Amazon SageMaker experiment to track your machine learning (ML) workflows with a
    few lines of code from your preferred development environment. You can then browse your
    experiments, create visualizations for analysis, and find the best performing model. You can
    also integrate SageMaker Experiments into your SageMaker training script using the SageMaker
    Python SDK.</p>
    <h2 id="experiments-create-overview">Overview</h2>
    <p>The following components make up the building blocks of an experiment in Amazon SageMaker.</p>
  <div class="itemizedlist">
     
     
     
     
     
     
     
  <ul class="itemizedlist"><li class="listitem"><p><code class="code">experiment</code>: An experiment is a collection of runs. When you initialize a run in
        your training loop, you include the name of the experiment that the run belongs to.
        Experiment names must be unique within your AWS account. </p></li><li class="listitem"><p><code class="code">Run</code>: A run consists of all the inputs, parameters, configurations, and results
        for one interaction of model training. Initialize an experiment run for tracking a training
        job with <code class="code">Run.init()</code>.</p>
    <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>We recommend that you initialize a <code class="code">Run</code> object in a Jupyter Notebook, and
            create the SageMaker job for your experiment within the context of this <code class="code">Run</code>
            object initialization. To refer to this <code class="code">Run</code> object in script mode, use the
          <code class="code">load_run()</code> method. For examples, see <a href="experiments-tutorials.html">Example notebooks for Amazon SageMaker Experiments</a>.</p></div></div>
    <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>The SageMaker Python SDK automatically turns experiment names and run names to lowercase.</p></div></div></li><li class="listitem"><p><code class="code">load_run</code>: To run your experiments in script mode, refer to an initialized
            <code class="code">Run</code> object with <code class="code">load_run()</code>. If an experiment for a run exists,
            <code class="code">load_run</code> returns the experiment context. Generally, you use
            <code class="code">load_run</code> with no arguments to track metrics, parameters, and artifacts
          within a SageMaker training or processing job script. </p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Load run from a local script passing experiment and run names
with load_run(experiment_name=<code class="replaceable">experiment_name</code>, run_name=<code class="replaceable">run_name</code>) as run:
   run.log_parameter(<code class="replaceable">"param1"</code>, <code class="replaceable">"value1"</code>)</code></pre>
    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Load run within a training or processing Job (automated context sharing)
with load_run() as run:
    run.log_parameter(<code class="replaceable">"param1"</code>, <code class="replaceable">"value1"</code>) </code></pre></li><li class="listitem"><p><code class="code">log_parameter</code>: Log parameters for a run, such as batch size or epochs, over time
        in a training loop with <code class="code">run.log_parameter()</code>. <code class="code">log_parameter</code> records
        a single name-value pair in a run. You can use <code class="code">run.log_parameters()</code> to log
        multiple parameters. If called multiple times within a run for a parameter of the same name,
          <code class="code">log_parameter</code> overwrites any previous value. The name must be a string and
      the value must be either a string, integer, or float.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Log a single parameter
run.log_parameter(<code class="replaceable">"param1"</code>, <code class="replaceable">"value1"</code>)</code></pre>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Log multiple parameters
run.log_parameters(<span>{</span>
    <code class="replaceable">"param2"</code>: <code class="replaceable">"value2"</code>,
    <code class="replaceable">"param3"</code>: <code class="replaceable">"value3"</code>
})</code></pre></li><li class="listitem"><p><code class="code">log_metric</code>: Log metrics for a run, such as accuracy or loss, over time in a
        training loop with <code class="code">run.log_metric()</code>. <code class="code">log_metric</code> records a
        name-value pair where the name is a string and the value is an integer or float. To declare
        the frequency of logging over the course of the run, define a <code class="code">step</code> value. You
        can then visualize these metrics in the Studio Experiments UI. For more information, see
          <a href="experiments-view-compare.html">View, search, and compare experiment runs</a>.</p>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Log a metric over the course of a run
run.log_metric(name=<code class="replaceable">"Final_loss"</code>, value=<code class="replaceable">finalloss</code>)</code></pre>
      <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Log a metric over the course of a run at each epoch
run.log_metric(name=<code class="replaceable">"test:loss"</code>, value=<code class="replaceable">loss</code>, step=<code class="replaceable">epoch</code>)</code></pre>
    </li><li class="listitem"><p><code class="code">log_artifact</code>: Log any input or output artifacts related to a run with
          <code class="code">run.log_artifact()</code>. Log artifacts such as S3 URIs, datasets, models, and more
        for your experiment to help you keep track of artifacts across multiple runs.
          <code class="code">is_output</code> is <code class="code">True</code> by default. To record the artifact as an input
        artifact instead of an output artifact, set <code class="code">is_output</code> to
        <code class="code">False</code>.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Track a string value as an input or output artifact
run.log_artifact(name=<code class="replaceable">"training_data"</code>, value=<code class="replaceable">"data.csv"</code> is_output=<code class="replaceable">False</code>)</code></pre></li><li class="listitem"><p><code class="code">log_file</code>: Log any input or output files related to a run, such as training or
        test data, and store them in Amazon S3 with <code class="code">run.log_file()</code>. <code class="code">is_output</code>
        is <code class="code">True</code> by default. To record the file as an input artifact instead of an
        output artifact, set <code class="code">is_output</code> to <code class="code">False</code>.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Upload a local file to S3 and track it as an input or output artifact
run.log_file(<code class="replaceable">"training_data.csv"</code>, name=<code class="replaceable">"training_data"</code>, is_output=<code class="replaceable">False</code>)</code></pre></li></ul></div>
  <p>For more information on initializing a <code class="code">Run</code> object, see <a href="https://sagemaker.readthedocs.io/en/stable/experiments/sagemaker.experiments.html" rel="noopener noreferrer" target="_blank"><span>Experiments</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> in the <em>SageMaker Python SDK
      documentation</em>. For information on visualizing logged experiment data and automatic
    logging, see <a href="experiments-view-compare.html">View, search, and compare experiment runs</a>.</p>
    <h2 id="experiments-create-python-sdk">Create an experiment with the SageMaker Python SDK</h2>
    <p>The following section demonstrates how to create an Amazon SageMaker Experiment using the SageMaker
      Python SDK. This example uses the <code class="code">Run</code> class to track a Keras model in a notebook
      environment. The Keras <code class="code">Callback</code> class provides a method <code class="code">on_epoch_end</code>
      which emits metrics at the end of each epoch. First, define a <code class="code">Callback</code>
      class.</p>
    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">class ExperimentCallback(keras.callbacks.Callback):
    """ """

    def __init__(self, run, model, x_test, y_test):
        """Save params in constructor"""
        self.run = run
        self.model = model
        self.x_test = x_test
        self.y_test = y_test

    def on_epoch_end(self, epoch, logs=None):
        """ """
        keys = list(logs.keys())
        for key in keys:
            run.log_metric(name=key, value=logs[key], step=epoch)
            print("Epoch: <span>{</span>}\n<span>{</span>} -&gt; <span>{</span>}".format(epoch, key, logs[key]))</code></pre>
    <p>Next, train the Keras model in a notebook environment and track it as an experiment. </p>
    <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>This example carries out jobs sequentially. To run SageMaker jobs asynchronously, you
        may need to increase your resource limit.</p></div></div>
    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">from sagemaker.experiments import Run

# The run name is an optional argument to `run.init()`
with Run(experiment_name = <code class="replaceable">'my-experiment'</code>) as run:
    
    # Define values for the parameters to log
    run.log_parameter(<code class="replaceable">"batch_size"</code>, <code class="replaceable">batch_size</code>)
    run.log_parameter(<code class="replaceable">"epochs"</code>, <code class="replaceable">epochs</code>)
    run.log_parameter(<code class="replaceable">"dropout"</code>, <code class="replaceable">0.5</code>)
    
    # Define input artifacts
    run.log_file(<code class="replaceable">'datasets/input_train.npy'</code>, is_output = <code class="replaceable">False</code>)
    run.log_file(<code class="replaceable">'datasets/input_test.npy'</code>, is_output = <code class="replaceable">False</code>)
    run.log_file(<code class="replaceable">'datasets/input_train_labels.npy'</code>, is_output = <code class="replaceable">False</code>)
    run.log_file(<code class="replaceable">'datasets/input_test_labels.npy'</code>, is_output = <code class="replaceable">False</code>)

    # Train locally
    model.fit(
        x_train, 
        y_train, 
        batch_size=batch_size, 
        epochs=epochs, 
        validation_split=0.1, 
        callbacks = [ExperimentCallback(run, model, x_test, y_test)]
    )
    
    score = model.evaluate(<code class="replaceable">x_test</code>, <code class="replaceable">y_test</code>, verbose=<code class="replaceable">0</code>)
    print("Test loss:", score[0])
    print("Test accuracy:", score[1])
    
    # Define metrics to log
    run.log_metric(name = <code class="replaceable">"Final Test Loss"</code>, value = <code class="replaceable">score[0]</code>)
    run.log_metric(name = <code class="replaceable">"Final Test Accuracy"</code>, value = <code class="replaceable">score[1]</code>)</code></pre>
    <p>For more code samples and example notebooks, see <a href="experiments-tutorials.html">Example notebooks for Amazon SageMaker Experiments</a>.</p>
   
    <h2 id="experiments-create-script-mode">Create an experiment using SageMaker script mode</h2>
    <p>You can use SageMaker script mode to write your own code to train a model and track it as an
      experiment. When creating an experiment with script mode, use <code class="code">load_run()</code>.</p>
    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Make sure that you have the latest version of the SageMaker Python SDK
import os
os.system("pip install -U sagemaker")

# Import additional requirements
import boto3
from sagemaker.session import Session
from sagemaker.experiments.run import load_run

# Define training script
if __name__ == "__main__":
    session = Session(boto3.session.Session(region_name=args.region))
    with load_run(sagemaker_session=session) as run:
        # Define values for the parameters to log
        run.log_parameters(<span>{</span>
            <code class="replaceable">"batch_size"</code>: <code class="replaceable">batch_size</code>,
            <code class="replaceable">"epochs"</code>: <code class="replaceable">epochs</code>,
            <code class="replaceable">"dropout"</code>: <code class="replaceable">0.5</code>
        })
        # Define input artifacts
        run.log_file(<code class="replaceable">'datasets/input_train.npy'</code>, is_output = <code class="replaceable">False</code>)
        run.log_file(<code class="replaceable">'datasets/input_test.npy'</code>, is_output = <code class="replaceable">False</code>)
        run.log_file(<code class="replaceable">'datasets/input_train_labels.npy'</code>, is_output = <code class="replaceable">False</code>)
        run.log_file(<code class="replaceable">'datasets/input_test_labels.npy'</code>, is_output = <code class="replaceable">False</code>)
        
        # Train the model
        model.fit(
            x_train, 
            y_train, 
            batch_size=batch_size, 
            epochs=epochs, 
            validation_split=0.1, 
            callbacks = [ExperimentCallback(run, model, x_test, y_test)]
        )
        
        score = model.evaluate(x_test, y_test, verbose=0)
        print("Test loss:", score[0])
        print("Test accuracy:", score[1])
        
        # Define metrics to log
        run.log_metric(name = <code class="replaceable">"Final Test Loss"</code>, value = <code class="replaceable">score[0]</code>)
        run.log_metric(name = <code class="replaceable">"Final Test Accuracy"</code>, value = <code class="replaceable">score[1]</code>)</code></pre>
    <p>For more code samples and example notebooks on using Amazon SageMaker Experiments in SageMaker script
      mode, see <a href="experiments-tutorials.html#experiments-tutorials-scripts">Track experiments for SageMaker training jobs using script mode</a>.</p>
    <p>For more information on script mode, see <a href="algorithms-choose.html#supported-frameworks-benefits">Use script
        mode in a supported framework</a>. You can also define custom metrics in script mode by
      specifying a name and regular expression for each metric that a tuning job monitors. See
        <a href="automatic-model-tuning-define-metrics-variables.html#automatic-model-tuning-define-metrics-custom">Use a custom algorithm for training</a> for more information.</p>
   
    <h2 id="experiments-create-view">View your experiment in Studio</h2>
    <p>To view the experiment in Studio, in the left sidebar, choose
        <b>Experiments</b>.</p>
    <p>Select the name of the experiment to view all associated runs. It might take a moment for
      the list to refresh and display a new experiment or experiment run. You can click
        <b>Refresh</b> to update the page. Your experiment list should look similar to
      the following:</p>
    <div class="mediaobject">
       
        <img src="../../../images/sagemaker/latest/dg/images/experiments/experiments-overview.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;        A list of experiments in the SageMaker Experiments UI&#xA;      " style="max-width:80%" />
       
       
    </div>
    <p>To view the runs that make up your experiment, select the experiment name. For more
      information, see <a href="experiments-view-compare.html">View, search, and compare experiment runs</a>.</p>
    
     
      <h3 id="experiments-create-view-unassigned">View unassigned runs</h3>
      <p>All SageMaker jobs, including training jobs, processing jobs, and transform jobs, correspond to runs and create <code class="code">Run</code> 
        objects by default. If you launch these jobs without explicitly associating them with an experiment, the resulting runs are 
        unassigned and can be viewed in the <b>Unassigned runs</b> section of the Studio Experiments UI.</p>
      <div class="mediaobject">
         
          <img src="../../../images/sagemaker/latest/dg/images/experiments/experiments-unassigned-runs.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;          A list of unassigned runs in the SageMaker Experiments UI&#xA;        " style="max-width:80%" />
         
         
      </div>
     
  <p>To clean up the resources you created, see
    <a href="experiments-cleanup.html">Clean Up Amazon SageMaker Experiment Resources</a>.</p><awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./experiments.html">Experiments</div><div id="next" class="next-link" accesskey="n" href="./experiments-view-compare.html">View, search, and compare experiment runs</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/experiments-create.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/experiments-create.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>