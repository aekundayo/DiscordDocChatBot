<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Reusing Data Flows for Different Datasets - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="data-wrangler-parameterize" /><meta name="default_state" content="data-wrangler-parameterize" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="data-wrangler-parameterize.html" /><meta name="description" content="Create reusable or rewritable parameters to help automate your data flows." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="data-wrangler-parameterize.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="de" /><link rel="alternative" href="data-wrangler-parameterize.html" hreflang="en-us" /><link rel="alternative" href="data-wrangler-parameterize.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/data-wrangler-parameterize.html" hreflang="zh-tw" /><link rel="alternative" href="data-wrangler-parameterize.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Reusing Data Flows for Different Datasets" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Reusing Data Flows for Different Datasets - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#data-wrangler-parameterize" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-parameterize.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-parameterize.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-parameterize.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Prepare data",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/data-prep.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Prepare ML Data with Amazon SageMaker Data Wrangler",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/data-wrangler.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Reusing Data Flows for Different Datasets",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/data-wrangler.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#data-wrangler-parameterize" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="data-wrangler-parameterize">Reusing Data Flows for Different Datasets</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>For Amazon Simple Storage Service (Amazon S3) data sources, you can create and use parameters. A parameter is a variable that
            you've saved in your Data Wrangler flow. Its value can be any portion of the data source's Amazon S3 path. Use parameters to quickly change the data that you're importing into a Data Wrangler flow or exporting to a processing job.
        You can also use parameters to select and import a specific subset of your data.</p><p>After you created a Data Wrangler flow, you might have trained a model on the data that you've transformed. For datasets that have the same schema, you can use parameters to apply the same transformations on a different dataset
        and train a different model. You can use the new datasets to perform inference with your model or you could be using them
            to retrain your model.</p><p>In general, parameters have the following attributes:</p><div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Name – The name you specify for the parameter</p>
            </li><li class="listitem">
                <p>Type – The type of value that the parameter represents</p>
            </li><li class="listitem">
                <p>Default value – The value of the parameter when you don't specify a new value</p>
            </li></ul></div><div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>Datetime parameters have a time range attribute that they use as the default value.</p></div></div><p>Data Wrangler uses curly braces, <code class="code"><span>{</span><span>{</span>}}</code>, to indicate that a parameter is being used
            in the Amazon S3 path. For example, you can have a URL such as
                    <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/<code class="replaceable"><span>{</span><span>{</span>example_parameter_name}}</code>/example-dataset.csv</code>.</p><p>You create a parameter when you're editing the Amazon S3 data source that you've imported. You can set any portion of the file path to a parameter value. You can set the parameter value to either a value or a pattern. 
            The following are the available parameter value types in the Data Wrangler flow:</p><div class="itemizedlist">
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Number</p>
            </li><li class="listitem">
                <p>String</p>
            </li><li class="listitem">
                <p>Pattern</p>
            </li><li class="listitem">
                <p>Datetime</p>
            </li></ul></div><div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>You can't create a pattern parameter or a datetime parameter for the name of the bucket in the Amazon S3 path.</p></div></div><p>You must set a number as the default value of a number parameter. You can change the
            value of the parameter to a different number when you're editing a parameter or when
            you're launching a processing job. For example, in the S3 path,
                <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/example-prefix/example-file-1.csv</code>, you can
            create a number parameter named <code class="code">number_parameter</code> in the place of
                <code class="code">1</code>. Your S3 path now appears as
                <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/example-prefix/example-file-<span>{</span><span>{</span>number_parameter}}.csv</code>.
            The path continues to point to the <code class="code">example-file-1.csv</code> dataset until you
            change the value of the parameter. If you change the value of
                <code class="code">number_parameter</code> to <code class="code">2</code> the path is now
                <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/example-prefix/example-file-2.csv</code>. You can
            import <code class="code">example-file-2.csv</code> into Data Wrangler if you've uploaded the file to that
            Amazon S3 location.</p><p>A string parameter stores a string as its default value. For example, in the S3 path, <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/example-prefix/example-file-1.csv</code>, you can create a string parameter named <code class="code">string_parameter</code> in the place of the filename, <code class="code">example-file-1.csv</code>.
            The path now appears as <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/example-prefix/<span>{</span><span>{</span>string_parameter}}</code>. It continues to match <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/example-prefix/example-file-1.csv</code>, until you change the value of the parameter.</p><p>Instead of specifying the filename as a string parameter, you can create a string parameter using the entire Amazon S3 path. You can specify a dataset from any Amazon S3 location in the string parameter.</p><p>A pattern parameter stores a regular expression (Python REGEX) string as its default value. 
            You can use a pattern parameter to import multiple data files at the same time. To import more than one object at a time, specify a parameter value
        that matches the Amazon S3 objects that you're importing.</p><p>You can also create a pattern parameter for the following datasets:</p><div class="itemizedlist">
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/example-file-1.csv</p>
            </li><li class="listitem">
                <p>s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/example-file-2.csv</p>
            </li><li class="listitem">
                <p>s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/example-file-10.csv</p>
            </li><li class="listitem">
                <p>s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/example-prefix/example-file-0123.csv</p>
            </li></ul></div><p>For <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/example-file-1.csv</code>, you can
            create a pattern parameter in the place of <code class="code">1</code>, and set the default value of
            the parameter to <code class="code">\d+</code>. The <code class="code">\d+</code> REGEX string matches any one or more decimal
            digits. If you create a pattern parameter named <code class="code">pattern_parameter</code>, your S3
            path appears as
                <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/example-file-<span>{</span><span>{</span>pattern_parameter}}.csv</code>.</p><p>You can also use pattern parameters to match all CSV objects within your bucket. To match all objects in a bucket, create a pattern parameter with the default value of <code class="code">.*</code>
                and set the path to <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/<span>{</span><span>{</span>pattern_parameter}}.csv</code>. The <code class="code">.*</code> character matches any string character in the path. 
            </p><p>The <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/<span>{</span><span>{</span>pattern_parameter}}.csv</code> path can match the following datasets.</p><div class="itemizedlist">
             
             
                        
        <ul class="itemizedlist"><li class="listitem">
                <p><code class="code">example-file-1.csv</code></p>
            </li><li class="listitem">
                <p><code class="code">other-example-file.csv</code></p>
            </li><li class="listitem">
                <p><code class="code">example-file-a.csv</code></p>
            </li></ul></div><p>A datetime parameter stores the format with the following information:</p><div class="itemizedlist">
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>A format for parsing strings inside an Amazon S3 path.</p>
            </li><li class="listitem">
                <p>A relative time range to limit the datetime values that match</p>
            </li></ul></div><p>For example, in the Amazon S3 file path, <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/2020/01/01/example-dataset.csv</code>, 
            2020/01/01 represents a datetime in the format of <code class="code">year/month/day</code>. 
            You can set the parameter’s time range to an interval such as <code class="code">1 years</code> or <code class="code">24 hours</code>. 
            An interval of <code class="code">1 years</code> matches all S3 paths with datetimes that fall between the current time and the time exactly a year before the current time. 
            The current time is the time when you start exporting the transformations that you've made to the data. For more information about exporting data, see <a href="data-wrangler-data-export.html">Export</a>.
            If the current date is 2022/01/01 and the time range is <code class="code">1 years</code>, the S3 path matches datasets such as the following:</p><div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/2021/01/01/example-dataset.csv</p>
            </li><li class="listitem">
                <p>s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/2021/06/30/example-dataset.csv</p>
            </li><li class="listitem">
                <p>s3://<code class="replaceable">DOC-EXAMPLE-BUCKET</code>/2021/12/31/example-dataset.csv</p>
            </li></ul></div><p>The datetime values within a relative time range change as time passes. The S3 paths that fall within the relative time range might also differ.</p><p>For the Amazon S3 file path, <code class="code">s3://<code class="replaceable"><code class="replaceable">DOC-EXAMPLE-BUCKET1</code></code>/<code class="replaceable">20200101</code>/example-dataset.csv</code>, <code class="code">20220101</code> is an example of a path that can become a datetime parameter.</p><p>To view a table of all parameters that you've created in Data Wrangler flow, choose the `<span>{</span><span>{</span>}}` to the right of the text box containing the Amazon S3 path. 
            If you no longer need a parameter that you've created, you can edit or delete. To edit or delete a parameter, choose icons to the right of the parameter.</p><div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>Before you delete a parameter, make sure that you haven't used it anywhere in your Data Wrangler flow. Deleted parameters that are still within the flow cause errors.</p></div></div><p>You can create parameters for any step of your Data Wrangler flow. You can edit or delete any parameter that you create. If you're applying transformations to data that is no longer relevant to your use case, you can modify the values of parameters.
        Modifying the values of the parameters changes the data that you're importing.</p><p>The following sections provide additional examples and general guidance on using parameters. You can use the sections to understand the parameters that work best for you.</p><div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>The following sections contain procedures that use the Data Wrangler interface to override the parameters and create a processing job.</p><p>You can also override the parameters by using the following procedures.</p><div class="procedure"><p>To export your Data Wrangler flow and override the value of a parameter, do the following.</p><ol><li>
                    <p>Choose the <b>+</b> next to the node that you
                        want to export.</p>
                </li><li>
                    <p>Choose <b>Export to</b>.</p>
                </li><li>
                    <p>Choose the location where you're exporting the data.</p>
                </li><li>
                    <p>Under <code class="code">parameter_overrides</code>, specify different values for the parameters that you've created.</p>
                </li><li>
                    <p>Run the Jupyter Notebook.</p>
                </li></ol></div></div></div><div class="collapsible"><awsui-expandable-section variant="container" header="Applying a Data Wrangler flow to files&#xA;                        using patterns" id="data-wrangler-pattern-parameters" expanded="true"><p>You can use parameters to apply transformations in your Data Wrangler flow to different
                    files that match a pattern in the Amazon S3 URI path. This helps you specify the
                    files in your S3 bucket that you want to transform with high specificity. For
                    example, you might have a dataset with the path
                        <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix-0/example-prefix-1/example-prefix-2/example-dataset.csv</code>.
                    Different datasets named <code class="code">example-dataset.csv</code> are stored under many
                    different example prefixes. The prefixes might also be numbered sequentially.
                    You can create patterns for the numbers in the Amazon S3 URI. Pattern parameters use REGEX to select any number of
                    files that match the pattern of the expression. The following are REGEX patterns
                    that might be useful:</p><div class="itemizedlist">
                     
                     
                     
                     
                     
                     
                <ul class="itemizedlist"><li class="listitem">
                        <p><code class="code">.*</code> – Matches zero or more of any character, except
                            newline characters</p>
                    </li><li class="listitem">
                        <p><code class="code">.+</code> – Matches one or more of any character,
                            excluding newline characters</p>
                    </li><li class="listitem">
                        <p><code class="code">\d+</code> – Matches one or more of any decimal
                            digit</p>
                    </li><li class="listitem">
                        <p><code class="code">\w+</code> – Matches one or more of any alphanumeric
                            character</p>
                    </li><li class="listitem">
                        <p><code class="code">[abc-_]<span>{</span>2,4}</code> –  Matches a string two, three, or
                            four characters composed of the set of characters provided within a set
                            of brackets</p>
                    </li><li class="listitem">
                        <p><code class="code">abc|def</code> – Matches one string or another. For
                            example, the operation matches either <code class="code">abc</code> or
                                <code class="code">def</code></p>
                    </li></ul></div><p>You can replace each number in the following paths with a single parameter that has a value of <code class="code">\d+</code>.</p><div class="itemizedlist">
                     
                     
                     
                <ul class="itemizedlist"><li class="listitem">
                        <p><code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix-3/example-prefix-4/example-prefix-5/example-dataset.csv</code></p>
                    </li><li class="listitem">
                        <p><code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix-8/example-prefix-12/example-prefix-13/example-dataset.csv</code></p>
                    </li><li class="listitem">
                        <p><code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix-4/example-prefix-9/example-prefix-137/example-dataset.csv</code></p>
                    </li></ul></div><p>The following procedure creates a pattern parameter for a dataset with the
                    path
                        <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix-0/example-prefix-1/example-prefix-2/example-dataset.csv</code>.</p><div class="procedure"><p>To create a pattern parameter, do the following.</p><ol><li>
                        <p>Next to the dataset that you've imported, choose <b>Edit
                                dataset</b>.</p>
                    </li><li>
                        <p>Highlight the <code class="code">0</code> in <code class="code">example-prefix-0</code>.</p>
                    </li><li>
                        <p>Specify values for the following fields:</p>
                        <div class="itemizedlist">
                             
                             
                             
                        <ul class="itemizedlist"><li class="listitem">
                                <p><b>Name</b> – A name for parameter</p>
                            </li><li class="listitem">
                                <p><b>Type</b> –
                                    <b>Pattern</b></p>
                            </li><li class="listitem">
                                <p><b>Value</b> – <b>\d+</b> a
                                    regular expression that corresponds to one or more digits</p>
                            </li></ul></div>
                    </li><li>
                        <p>Choose <b>Create</b>.</p>
                    </li><li>
                        <p>Replace the <code class="code">1</code> and the <code class="code">2</code> in S3 URI path with
                            the parameter. The path should have the following format:
                                <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix-<span>{</span><span>{</span>example_parameter_name}}/example-prefix-<span>{</span><span>{</span>example_parameter_name}}/example-prefix-<span>{</span><span>{</span>example_parameter_name}}/example-dataset.csv</code></p>
                    </li></ol></div><p>The following is a general procedure for creating a pattern parameter.</p><div class="procedure"><ol><li>
                        <p>Navigate to your Data Wrangler flow.</p>
                    </li><li>
                        <p>Next to the dataset that you've imported, choose <b>Edit
                                dataset</b>.</p>
                    </li><li>
                        <p>Highlight the portion of the URI that you're using as the value of the
                            pattern parameter.</p>
                    </li><li>
                        <p>Choose <b>Create custom parameter</b>.</p>
                    </li><li>
                        <p>Specify values for the following fields:</p>
                        <div class="itemizedlist">
                             
                             
                             
                        <ul class="itemizedlist"><li class="listitem">
                                <p><b>Name</b> – A name for parameter</p>
                            </li><li class="listitem">
                                <p><b>Type</b> –
                                    <b>Pattern</b></p>
                            </li><li class="listitem">
                                <p><b>Value</b> – A regular expression
                                    containing the pattern that you'd like to store.</p>
                            </li></ul></div>
                    </li><li>
                        <p>Choose <b>Create</b>.</p>
                    </li></ol></div></awsui-expandable-section><awsui-expandable-section variant="container" header="Applying a Data Wrangler flow to files using&#xA;                        numeric values" id="data-wrangler-numeric-parameters" expanded="false"><p>You can use parameters to apply transformations in your Data Wrangler flow to different files that have similar paths.
                    For example, you might have a dataset with the path <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix-0/example-prefix-1/example-prefix-2/example-dataset.csv</code>.</p><p>You might have the transformations from your Data Wrangler flow that you've applied to datasets under <code class="code">example-prefix-1</code>.
                    You might want to apply the same transformations to <code class="code">example-dataset.csv</code> that falls under <code class="code">example-prefix-10</code> or <code class="code">example-prefix-20</code>.</p><p>You can create a parameter that stores the value <code class="code">1</code>. If you want to apply the transformations to different datasets, you can create processing jobs that replace the value of the parameter 
                    with a different value.
                    The parameter acts as a placeholder for you to change when you want to apply the transformations from your Data Wrangler flow to new data. You can override the value of the parameter when you create a Data Wrangler processing job
                    to apply the transformations in your Data Wrangler flow to different datasets.</p><p>Use the following procedure to create numeric  parameters for <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix-0/example-prefix-1/example-prefix-2/example-dataset.csv</code>.</p><div class="procedure"><p>To create parameters for the preceding S3 URI path, do the following.</p><ol><li>
                        <p>Navigate to your Data Wrangler flow.</p>
                    </li><li>
                        <p>Next to the dataset that you've imported, choose <b>Edit dataset</b>.</p>
                    </li><li>
                        <p>Highlight the number in an example prefix of <code class="code">example-prefix-<code class="replaceable">number</code></code>.</p>
                    </li><li>
                        <p>Choose <b>Create custom parameter</b>.</p>
                    </li><li>
                        <p>For <b>Name</b>, specify a name for the parameter.</p>
                    </li><li>
                        <p>For <b>Type</b>, choose <b>Integer</b>.</p>                            
                    </li><li>
                        <p>For <b>Value</b>, specify the number.</p>
                    </li><li>
                        <p>Create parameters for the remaining numbers by repeating the procedure.</p>
                    </li></ol></div><p>After you've created the parameters, apply the transforms to your dataset and create a destination node for them. For more information about destination nodes, 
                    see <a href="data-wrangler-data-export.html">Export</a>.</p><p>Use the following procedure to apply the transformations from your Data Wrangler flow to a different time range. It assumes that you've created a destination node for the transformations in your flow.</p><div class="procedure"><p>To change the value of a numeric parameter in a Data Wrangler processing job, do
                        the following.</p><ol><li>
                        <p>From your Data Wrangler flow, choose <b>Create job</b></p>
                    </li><li>
                        <p>Select only the destination node that contains the transformations to the dataset containing the datetime parameters.</p>
                    </li><li>
                        <p>Choose <b>Configure job</b>.</p>
                    </li><li>
                        <p>Choose <b>Parameters</b>.</p>
                    </li><li>
                        <p>Choose the name of a parameter that you've created.</p>
                    </li><li>
                        <p>Change the value of the parameter.</p>
                    </li><li>
                        <p>Repeat the procedure for the other parameters.</p>
                    </li><li>
                        <p>Choose <b>Run</b>.</p>
                    </li></ol></div></awsui-expandable-section><awsui-expandable-section variant="container" header="Applying a Data Wrangler flow to files using&#xA;                        strings" id="data-wrangler-string-parameters" expanded="false"><p>You can use parameters to apply transformations in your Data Wrangler flow to different files that have similar paths.
                    For example, you might have a dataset with the path <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/example-dataset.csv</code>.</p><p>You might have transformations from your Data Wrangler flow that you've applied to datasets under <code class="code">example-prefix</code>.
                    You might want to apply the same transformations to <code class="code">example-dataset.csv</code> under <code class="code">another-example-prefix</code> or <code class="code">example-prefix-20</code>.</p><p>You can create a parameter that stores the value <code class="code">example-prefix</code>. If you want to apply the transformations to different datasets, you can create processing jobs that replace the value of the parameter 
                    with a different value.
                    The parameter acts as a placeholder for you to change when you want to apply the transformations from your Data Wrangler flow to new data. You can override the value of the parameter when you create a Data Wrangler processing job
                    to apply the transformations in your Data Wrangler flow to different datasets.</p><p>Use the following procedure to create a string parameter for <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/example-dataset.csv</code>.</p><div class="procedure"><p>To create a parameter for the preceding S3 URI path, do the following.</p><ol><li>
                        <p>Navigate to your Data Wrangler flow.</p>
                    </li><li>
                        <p>Next to the dataset that you've imported, choose <b>Edit dataset</b>.</p>
                    </li><li>
                        <p>Highlight the example prefix, <code class="code">example-prefix</code>.</p>
                    </li><li>
                        <p>Choose <b>Create custom parameter</b>.</p>
                    </li><li>
                        <p>For <b>Name</b>, specify a name for the parameter.</p>
                    </li><li>
                        <p>For <b>Type</b>, choose <b>String</b>.</p>                            
                    </li><li>
                        <p>For <b>Value</b>, specify the prefix.</p>
                    </li></ol></div><p>After you've created the parameter, apply the transforms to your dataset and create a destination node for them. For more information about destination nodes, 
                    see <a href="data-wrangler-data-export.html">Export</a>.</p><p>Use the following procedure to apply the transformations from your Data Wrangler flow to a different time range. It assumes that you've created a destination node for the transformations in your flow.</p><div class="procedure"><p>To change the value of a numeric parameter in a Data Wrangler processing job, do
                        the following:</p><ol><li>
                        <p>From your Data Wrangler flow, choose <b>Create job</b></p>
                    </li><li>
                        <p>Select only the destination node that contains the transformations to the dataset containing the datetime parameters.</p>
                    </li><li>
                        <p>Choose <b>Configure job</b>.</p>
                    </li><li>
                        <p>Choose <b>Parameters</b>.</p>
                    </li><li>
                        <p>Choose the name of a parameter that you've created.</p>
                    </li><li>
                        <p>Change the value of the parameter.</p>
                    </li><li>
                        <p>Repeat the procedure for the other parameters.</p>
                    </li><li>
                        <p>Choose <b>Run</b>.</p>
                    </li></ol></div></awsui-expandable-section><awsui-expandable-section variant="container" header="Applying a Data Wrangler flow to different datetime ranges" id="data-wrangler-datetime-parameters" expanded="false"><p>Use datetime parameters to apply transformations in your Data Wrangler flow to different time ranges. Highlight the portion of the Amazon S3 URI that has a timestamp and create a parameter for it.
                    When you create a parameter, you specify a time range from the current time to a time in the past. For example, you might have an Amazon S3 URI that looks like the following:
                    <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/2022/05/15/example-dataset.csv</code>. You can save <code class="code">2022/05/15</code> as a datetime parameter.
                    If you specify a year as the time range, the time range includes the moment that you run the processing job containing the datetime parameter and the time exactly one year ago. 
                    If the moment you're running the processing job is September 6th, 2022 or <code class="code">2022/09/06</code>, the time ranges can include the following:</p><div class="itemizedlist">
                     
                     
                     
                     
                <ul class="itemizedlist"><li class="listitem">
                        <p><code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/2022/03/15/example-dataset.csv</code></p>
                    </li><li class="listitem">
                        <p><code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/2022/01/08/example-dataset.csv</code></p>
                    </li><li class="listitem">
                        <p><code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/2022/07/31/example-dataset.csv</code></p>
                    </li><li class="listitem">
                        <p><code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/2021/09/07/example-dataset.csv</code></p>
                    </li></ul></div><p>The transformations in the Data Wrangler flow apply to all of the preceding prefixes. Changing the value of the parameter in the processing job
                    doesn't change the value of the parameter in the Data Wrangler flow. To apply the transformations to datasets within a different time range, do the following:</p><div class="orderedlist">
                     
                     
                     
                <ol><li>
                        <p>Create a destination node containing all the transformations that you'd like to use.</p>
                    </li><li>
                        <p>Create a Data Wrangler job.</p>
                    </li><li>
                        <p>Configure the job to use a different time range for the parameter. Changing the value of the parameter in the processing job
                            doesn't change the value of the parameter in the Data Wrangler flow.</p>
                    </li></ol></div><p>For more information about destination nodes and Data Wrangler jobs, 
                    see <a href="data-wrangler-data-export.html">Export</a>.</p><p>The following procedure creates a datetime parameter for the Amazon S3 path: <code class="code">s3://<code class="replaceable">DOC-EXAMPLE-BUCKET1</code>/example-prefix/2022/05/15/example-dataset.csv</code>.</p><div class="procedure"><p>To create a datetime parameter for the preceding S3 URI path, do the
                        following.</p><ol><li>
                        <p>Navigate to your Data Wrangler flow.</p>
                    </li><li>
                        <p>Next to the dataset that you've imported, choose <b>Edit
                                dataset</b>.</p>
                    </li><li>
                        <p>Highlight the portion of the URI that you're using as the value of the
                            datetime parameter.</p>
                    </li><li>
                        <p>Choose <b>Create custom parameter</b>.</p>
                    </li><li>
                        <p>For <b>Name</b>, specify a name for the
                            parameter.</p>
                    </li><li>
                        <p>For <b>Type</b>, choose
                            <b>Datetime</b>.</p>
                        <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>By default, Data Wrangler selects <b>Predefined</b>, which
                                provides a dropdown menu for you to select a date format. However,
                                the timestamp format that you're using might not be available.
                                Instead of using <b>Predefined</b> as the default
                                option, you can choose <b>Custom</b> and specify the
                                timestamp format manually.</p></div></div>
                    </li><li>
                        <p>For <b>Date format</b>, open the dropdown menu following
                                <b>Predefined</b> and choose
                                <b>yyyy/MM/dd</b>. The format,
                                <b>yyyy/MM/dd,</b> corresponds to the year/month/day
                            of the timestamp.</p>
                    </li><li>
                        <p>For <b>Timezone</b>, choose a time zone.</p>
                        
                        <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>The data that you're analyzing might have time stamps taken in a
                                different time zone from your time zone. Make sure that the time
                                zone that you select matches the time zone of the data. </p></div></div>
                        
                    </li><li>
                        <p>For <b>Time range</b>, specify the time range for the
                            parameter.</p>
                    </li><li>
                        <p>(Optional) Enter a description to describe how you're using the
                            parameter.</p>
                    </li><li>
                        <p>Choose <b>Create</b>.</p>
                    </li></ol></div><p>After you've created the datetime parameters, apply the transforms to your dataset and create a destination node for them. For more information about destination nodes, 
                    see <a href="data-wrangler-data-export.html">Export</a>.</p><p>Use the following procedure to apply the transformations from your Data Wrangler flow to a different time range. It assumes that you've created a destination node for the transformations in your flow.</p><div class="procedure"><p>To change the value of a datetime parameter in a Data Wrangler processing job, do the following:</p><ol><li>
                        <p>From your Data Wrangler flow, choose <b>Create job</b></p>
                    </li><li>
                        <p>Select only the destination node that contains the transformations to the dataset containing the datetime parameters.</p>
                    </li><li>
                        <p>Choose <b>Configure job</b>.</p>
                    </li><li>
                        <p>Choose <b>Parameters</b>.</p>
                    </li><li>
                        <p>Choose the name of the datetime parameter that you've created.</p>
                    </li><li>
                        <p>For <b>Time range</b>, change the time range for the datasets.</p>
                    </li><li>
                        <p>Choose <b>Run</b>.</p>
                    </li></ol></div></awsui-expandable-section></div><awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./data-wrangler-analyses.html">Analyze and Visualize</div><div id="next" class="next-link" accesskey="n" href="./data-wrangler-data-export.html">Export</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-parameterize.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-parameterize.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>