<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Use Reinforcement Learning with Amazon SageMaker - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="reinforcement-learning" /><meta name="default_state" content="reinforcement-learning" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="reinforcement-learning.html" /><meta name="description" content="Use reinforcement learning in Amazon SageMaker to solve complex machine learning problems that optimize objectives in interactive environments." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="reinforcement-learning.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/reinforcement-learning.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/reinforcement-learning.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/reinforcement-learning.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/reinforcement-learning.html" hreflang="de" /><link rel="alternative" href="reinforcement-learning.html" hreflang="en-us" /><link rel="alternative" href="reinforcement-learning.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/reinforcement-learning.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/reinforcement-learning.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/reinforcement-learning.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/reinforcement-learning.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/reinforcement-learning.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/reinforcement-learning.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/reinforcement-learning.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/reinforcement-learning.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/reinforcement-learning.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/reinforcement-learning.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/reinforcement-learning.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/reinforcement-learning.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/reinforcement-learning.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/reinforcement-learning.html" hreflang="zh-tw" /><link rel="alternative" href="reinforcement-learning.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Use Reinforcement Learning with Amazon SageMaker" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Use Reinforcement Learning with Amazon SageMaker - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#reinforcement-learning" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/reinforcement-learning.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/reinforcement-learning.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/reinforcement-learning.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Train machine learning models",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/train-model.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Choose an Algorithm",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/algorithms-choose.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Use Reinforcement Learning with Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/algorithms-choose.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#reinforcement-learning" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="reinforcement-learning.html#rl-differences">What are the differences between reinforcement, supervised, and unsupervised learning paradigms?</a><a href="reinforcement-learning.html#rl-why">Why is Reinforcement Learning Important?</a><a href="reinforcement-learning.html#rl-terms">Markov Decision Process (MDP)</a><a href="reinforcement-learning.html#sagemaker-rl">Key Features of Amazon SageMaker RL </a><a href="reinforcement-learning.html#sagemaker-rl-notebooks"> Reinforcement Learning Sample Notebooks</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="reinforcement-learning">Use Reinforcement Learning with Amazon SageMaker</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Reinforcement learning (RL) combines fields such as computer science, neuroscience, and psychology to determine 
        how to map situations to actions to maximize a numerical reward signal. This notion of a reward signal in RL stems 
        from neuroscience research into how the human brain makes decisions about which actions maximize reward and minimize 
        punishment. In most situations, humans are not given explicit instructions on which actions to take, but instead must 
        learn both which actions yield the most immediate rewards, and how those actions influence future situations and consequences.
    </p><p>The problem of RL is formalized using Markov decision processes (MDPs) that originate from dynamical systems theory. 
        MDPs aim to capture high-level details of a real problem that a learning agent encounters over some period of time in 
        attempting to achieve some ultimate goal. The learning agent should be able to determine the current state of its environment 
        and identify possible actions that affect the learning agent’s current state. Furthermore, the learning agent’s goals 
        should correlate strongly to the state of the environment. A solution to a problem formulated in this way is known as a reinforcement learning method.
    </p>
        <h2 id="rl-differences">What are the differences between reinforcement, supervised, and unsupervised learning paradigms?</h2>
        <p>Machine learning can be divided into three distinct learning paradigms: supervised, unsupervised, and reinforcement.</p>
        <p>In supervised learning, an external supervisor provides a training set of labeled examples. Each example contains information about a situation, belongs to a category, 
            and has a label identifying the category to which it belongs. The goal of supervised learning is to generalize in order to predict correctly in situations 
            that are not present in the training data. 
        </p>
        <p>In contrast, RL deals with interactive problems, making it infeasible to gather all possible examples of situations with correct labels that an agent might encounter. 
            This type of learning is most promising when an agent is able to accurately learn from its own experience and adjust accordingly. 
        </p>
        <p>In unsupervised learning, an agent learns by uncovering structure within unlabeled data. While a RL agent might benefit from uncovering structure based on its experiences, 
            the sole purpose of RL is to maximize a reward signal.
        </p>
    <div class="highlights"><h6>Topics</h6><ul><li><a href="reinforcement-learning.html#rl-why">Why is Reinforcement Learning Important?</a></li><li><a href="reinforcement-learning.html#rl-terms">Markov Decision Process (MDP)</a></li><li><a href="reinforcement-learning.html#sagemaker-rl">Key Features of Amazon SageMaker RL </a></li><li><a href="reinforcement-learning.html#sagemaker-rl-notebooks"> Reinforcement Learning Sample Notebooks</a></li><li><a href="sagemaker-rl-workflow.html">Sample RL Workflow Using Amazon SageMaker RL</a></li><li><a href="sagemaker-rl-environments.html">RL Environments in Amazon SageMaker</a></li><li><a href="sagemaker-rl-distributed.html">Distributed Training with Amazon SageMaker RL</a></li><li><a href="sagemaker-rl-tuning.html">Hyperparameter Tuning with Amazon SageMaker RL</a></li></ul></div>
        <h2 id="rl-why">Why is Reinforcement Learning Important?</h2>
        <p>RL is well-suited for solving large, complex problems, such as supply chain
            management, HVAC systems, industrial robotics, game artificial intelligence, dialog
            systems, and autonomous vehicles. Because RL models learn by a continuous process of
            receiving rewards and punishments for every action taken by the agent, it is possible to
            train systems to make decisions under uncertainty and in dynamic environments.
        </p>
     
        <h2 id="rl-terms">Markov Decision Process (MDP)</h2>
        <p>RL is based on models called Markov Decision Processes (MDPs). An MDP consists of a
            series of time steps. Each time step consists of the following:</p>
        <div class="variablelist">
             
             
             
             
             
        <dl>
                <dt><span class="term">Environment</span></dt>
                <dd>
                    <p>Defines the space in which the RL model operates. This can be either a
                        real-world environment or a simulator. For example, if
                        you train a physical autonomous vehicle on a physical road, that would be a
                        real-world environment. If you train a computer program that models an
                        autonomous vehicle driving on a road, that would be a simulator.</p>
                </dd>
             
                <dt><span class="term">State</span></dt>
                <dd>
                    <p>Specifies all information about the environment and past steps that is
                        relevant to the future. For example, in an RL model in which a robot can
                        move in any direction at any time step, the position of the robot at the
                        current time step is the state, because if we know where the robot is, it
                        isn't necessary to know the steps it took to get there.</p>
                </dd>
             
                <dt><span class="term">Action</span></dt>
                <dd>
                    <p>What the agent does. For example, the robot takes a step forward.</p>
                </dd>
             
                <dt><span class="term">Reward</span></dt>
                <dd>
                    <p>A number that represents the value of the state that resulted from the
                        last action that the agent took. For example, if the goal is for a robot to
                        find treasure, the reward for finding treasure might be 5, and the reward
                        for not finding treasure might be 0. The RL model attempts to find a
                        strategy that optimizes the cumulative reward over the long term. This
                        strategy is called a <em>policy</em>.</p>
                </dd>
             
                <dt><span class="term">Observation</span></dt>
                <dd>
                    <p>Information about the state of the environment that is available to the
                        agent at each step. This might be the entire state, or it might be just a
                        part of the state. For example, the agent in a chess-playing model would be
                        able to observe the entire state of the board at any step, but a robot in a
                        maze might only be able to observe a small portion of the maze that it
                        currently occupies.</p>
                </dd>
            </dl></div>

        <p>Typically, training in RL consists of many <em>episodes</em>. An episode
            consists of all of the time steps in an MDP from the initial state until the environment
            reaches the terminal state.</p>
     
        <h2 id="sagemaker-rl">Key Features of Amazon SageMaker RL </h2>
        <p>To train RL models in SageMaker RL, use the following components: </p>
        <div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>A deep learning (DL) framework. Currently, SageMaker supports RL in TensorFlow and
                    Apache MXNet.</p>
            </li><li class="listitem">
                <p>An RL toolkit. An RL toolkit manages the interaction between the agent and the
                    environment and provides a wide selection of state of the art RL algorithms.
                    SageMaker supports the Intel Coach and Ray RLlib toolkits. For information about
                    Intel Coach, see
                        <a href="https://nervanasystems.github.io/coach/" rel="noopener noreferrer" target="_blank"><span>https://nervanasystems.github.io/coach/</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>. For information about Ray
                    RLlib, see <a href="https://ray.readthedocs.io/en/latest/rllib.html" rel="noopener noreferrer" target="_blank"><span>https://ray.readthedocs.io/en/latest/rllib.html</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            </li><li class="listitem">
                <p>An RL environment. You can use custom environments, open-source environments,
                    or commercial environments. For information, see <a href="sagemaker-rl-environments.html">RL Environments in Amazon SageMaker</a>.</p>
            </li></ul></div>
        <p>The following diagram shows the RL components that are supported in SageMaker RL.</p>
        <div class="mediaobject">
             
                
                <img src="../../../images/sagemaker/latest/dg/images/sagemaker-rl-support.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
             
        </div>
     
        <h2 id="sagemaker-rl-notebooks"> Reinforcement Learning Sample Notebooks</h2>
        <p>For complete code examples, see the <a href="https://github.com/aws/amazon-sagemaker-examples/tree/main/reinforcement_learning" rel="noopener noreferrer" target="_blank"><span>reinforcement learning sample notebooks</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> in the SageMaker Examples repository.</p>
    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./semantic-segmentation-tuning.html">Model Tuning</div><div id="next" class="next-link" accesskey="n" href="./sagemaker-rl-workflow.html">Sample RL Workflow Using Amazon SageMaker RL</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/reinforcement-learning.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/reinforcement-learning.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>