<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Production variants - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="model-ab-testing" /><meta name="default_state" content="model-ab-testing" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="model-ab-testing.html" /><meta name="description" content="In production ML workflows, data scientists and engineers frequently try to improve performance using various methods, such as , training on additional or more-recent data, improving feature selection, using better updated instances and serving containers. You can use production variants to compare your models, instances and containers, and choose the best performing candidate to respond to inference requests." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="model-ab-testing.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/model-ab-testing.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/model-ab-testing.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/model-ab-testing.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/model-ab-testing.html" hreflang="de" /><link rel="alternative" href="model-ab-testing.html" hreflang="en-us" /><link rel="alternative" href="model-ab-testing.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/model-ab-testing.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/model-ab-testing.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/model-ab-testing.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/model-ab-testing.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/model-ab-testing.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/model-ab-testing.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/model-ab-testing.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/model-ab-testing.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/model-ab-testing.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/model-ab-testing.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/model-ab-testing.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/model-ab-testing.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/model-ab-testing.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/model-ab-testing.html" hreflang="zh-tw" /><link rel="alternative" href="model-ab-testing.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Production variants" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Production variants - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#model-ab-testing" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/model-ab-testing.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/model-ab-testing.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/model-ab-testing.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance,inference,deploy model,endpoint,prediction,ML application,serverless machine learning,multi model deployment,inference pipelines,ML model" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Deploy models for inference",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Real-time inference",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Safely validate models in production",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/model-validation.html"
      },
      {
        "@type" : "ListItem",
        "position" : 7,
        "name" : "Production variants",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/model-validation.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#model-ab-testing" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="model-ab-testing.html#model-testing-traffic-distribution">Test models by specifying traffic distribution</a><a href="model-ab-testing.html#model-testing-target-variant">Test models by invoking specific variants</a><a href="model-ab-testing.html#model-ab-test-example">Model A/B test example</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="model-ab-testing">Production variants</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>
        In production ML workflows, data scientists and engineers frequently try to improve performance using various
        methods, such as <a href="automatic-model-tuning.html">Perform Automatic Model Tuning with SageMaker</a>, training on
        additional or more-recent data, improving feature selection, using better updated instances and serving
        containers. You can use production variants to compare your models, instances and containers, and choose the
        best performing candidate to respond to inference requests.
    </p><p>
        With SageMaker multi-variant endpoints you can distribute endpoint invocation requests across multiple production
        variants by providing the traffic distribution for each variant, or you can invoke a specific variant directly
        for each request. In this topic, we look at both methods for testing ML models.
    </p><div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="model-ab-testing.html#model-testing-traffic-distribution">Test models by specifying traffic distribution</a></li><li><a href="model-ab-testing.html#model-testing-target-variant">Test models by invoking specific variants</a></li><li><a href="model-ab-testing.html#model-ab-test-example">Model A/B test example</a></li></ul></div>
        <h2 id="model-testing-traffic-distribution">Test models by specifying traffic distribution</h2>
        <p>
            To test multiple models by distributing traffic between them, specify the percentage of the traffic that
            gets routed to each model by specifying the weight for each production variant in the endpoint
            configuration. For information, see <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEndpointConfig.html">CreateEndpointConfig</a>. The
            following diagram shows how this works in more detail.
        </p>
        <div class="mediaobject">
             
                <img src="../../../images/sagemaker/latest/dg/images/model-traffic-distribution.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
             
        </div>
     
        <h2 id="model-testing-target-variant">Test models by invoking specific variants</h2>
        <p>
            To test multiple models by invoking specific models for each request, specify the specific version of the
            model you want to invoke by providing a value for the <code class="code">TargetVariant</code> parameter when you call
            <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_runtime_InvokeEndpoint.html">InvokeEndpoint</a>. SageMaker ensures that the request is processed by the production variant you
            specify. If you have already provided traffic distribution and specify a value for the
            <code class="code">TargetVariant</code> parameter, the targeted routing overrides the random traffic distribution. The
            following diagram shows how this works in more detail.
        </p>
        <div class="mediaobject">
             
                <img src="../../../images/sagemaker/latest/dg/images/model-target-variant.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
             
        </div>
     
        <h2 id="model-ab-test-example">Model A/B test example</h2>
        <p>
            Performing A/B testing between a new model and an old model with production traffic can be an effective
            final step in the validation process for a new model. In A/B testing, you test different variants of your
            models and compare how each variant performs. If the newer version of the model delivers better performance
            than the previously existing version, replace the old version of the model with the new version in
            production.
        </p>
        <p>
            The following example shows how to perform A/B model testing. For a sample notebook that implements this
            example, see <a href="https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_endpoints/a_b_testing/a_b_testing.html" rel="noopener noreferrer" target="_blank"><span>"A/B Testing ML models in production</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.
        </p>
         
            <h3 id="model-ab-test-step1">Step 1: Create and deploy models</h3>
            <p>
                First, we define where our models are located in Amazon S3. These locations are used when we deploy our
                models in subsequent steps:
            </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">model_url = f"s3://<span>{</span>path_to_model_1}"
model_url2 = f"s3://<span>{</span>path_to_model_2}"
            </code></pre>
            <p>
                Next, we create the model objects with the image and model data. These model objects are used to deploy
                production variants on an endpoint. The models are developed by training ML models on different data
                sets, different algorithms or ML frameworks, and different hyperparameters:
            </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">from sagemaker.amazon.amazon_estimator import get_image_uri

model_name = f"DEMO-xgb-churn-pred-<span>{</span>datetime.now():%Y-%m-%d-%H-%M-%S}"
model_name2 = f"DEMO-xgb-churn-pred2-<span>{</span>datetime.now():%Y-%m-%d-%H-%M-%S}"
image_uri = get_image_uri(boto3.Session().region_name, 'xgboost', '0.90-1')
image_uri2 = get_image_uri(boto3.Session().region_name, 'xgboost', '0.90-2')

sm_session.create_model(
    name=model_name,
    role=role,
    container_defs=<span>{</span>
        'Image': image_uri,
        'ModelDataUrl': model_url
    }
)

sm_session.create_model(
    name=model_name2,
    role=role,
    container_defs=<span>{</span>
        'Image': image_uri2,
        'ModelDataUrl': model_url2
    }
)
            </code></pre>
            <p>
                We now create two production variants, each with its own different model and resource requirements (instance type
                and counts). This enables you to also test models on different instance types.
            </p>
            <p>
                We set an initial_weight of 1 for both variants. This means that 50% of requests go to
                <code class="code">Variant1</code>, and the remaining 50% of requests to <code class="code">Variant2</code>. The sum of weights
                across both variants is 2 and each variant has weight assignment of 1. This means that each variant
                receives 1/2, or 50%, of the total traffic.
            </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">from sagemaker.session import production_variant

variant1 = production_variant(
               model_name=model_name,
               instance_type="ml.m5.xlarge",
               initial_instance_count=1,
               variant_name='Variant1',
               initial_weight=1,
           )

variant2 = production_variant(
               model_name=model_name2,
               instance_type="ml.m5.xlarge",
               initial_instance_count=1,
               variant_name='Variant2',
               initial_weight=1,
           )
            </code></pre>
            <p>
                Finally we’re ready to deploy these production variants on a SageMaker endpoint.
            </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">endpoint_name = f"DEMO-xgb-churn-pred-<span>{</span>datetime.now():%Y-%m-%d-%H-%M-%S}"
print(f"EndpointName=<span>{</span>endpoint_name}")

sm_session.endpoint_from_production_variants(
    name=endpoint_name,
    production_variants=[variant1, variant2]
)
            </code></pre>
         
         
            <h3 id="model-ab-test-step2">Step 2: Invoke the deployed models</h3>
            <p>
                Now we send requests to this endpoint to get inferences in real time. We use both traffic distribution
                and direct targeting.
            </p>
            <p>
                First, we use traffic distribution that we configured in the previous step. Each inference response
                contains the name of the production variant that processes the request, so we can see that traffic to
                the two production variants is roughly equal.
            </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># get a subset of test data for a quick test
!tail -120 test_data/test-dataset-input-cols.csv &gt; test_data/test_sample_tail_input_cols.csv
print(f"Sending test traffic to the endpoint <span>{</span>endpoint_name}. \nPlease wait...")

with open('test_data/test_sample_tail_input_cols.csv', 'r') as f:
    for row in f:
        print(".", end="", flush=True)
        payload = row.rstrip('\n')
        sm_runtime.invoke_endpoint(
            EndpointName=endpoint_name,
            ContentType="text/csv",
            Body=payload
        )
        time.sleep(0.5)

print("Done!")
            </code></pre>
            <p>
                SageMaker emits metrics such as <code class="code">Latency</code> and <code class="code">Invocations</code> for each variant in
                Amazon CloudWatch. For a complete list of metrics that SageMaker emits, see <a href="monitoring-cloudwatch.html">Monitor Amazon SageMaker with Amazon CloudWatch</a>.  Let’s query CloudWatch to get the number of invocations per variant,
                to show how invocations are split across variants by default:
            </p>
            <div class="mediaobject">
                 
                    <img src="../../../images/sagemaker/latest/dg/images/model-variant-invocations.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
                 
            </div>
            <p>
                Now let's invoke a specific version of the model by specifying <code class="code">Variant1</code> as the
                <code class="code">TargetVariant</code> in the call to <code class="code">invoke_endpoint</code>.
            </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">print(f"Sending test traffic to the endpoint <span>{</span>endpoint_name}. \nPlease wait...")
with open('test_data/test_sample_tail_input_cols.csv', 'r') as f:
    for row in f:
        print(".", end="", flush=True)
        payload = row.rstrip('\n')
        sm_runtime.invoke_endpoint(
            EndpointName=endpoint_name,
            ContentType="text/csv",
            Body=payload,
            TargetVariant="Variant1"
        ) 
        time.sleep(0.5)
            </code></pre>
            <p>
                To confirm that all new invocations were processed by <code class="code">Variant1</code>, we can query CloudWatch to get
                the number of invocations per variant. We see that for the most recent invocations (latest timestamp),
                all requests were processed by <code class="code">Variant1</code>, as we had specified. There were no invocations
                made for <code class="code">Variant2</code>.
            </p>
            <div class="mediaobject">
                 
                    <img src="../../../images/sagemaker/latest/dg/images/model-invocations-target1.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
                 
            </div>
         
         
            <h3 id="model-ab-test-step3">Step 3: Evaluate model performance</h3>
            <p>
                To see which model version performs better, let's evaluate the accuracy, precision, recall, F1 score,
                and Receiver operating charactersistic/Area under the curve for each variant. First, let's look at these
                metrics for <code class="code">Variant1</code>:
            </p>
            <div class="mediaobject">
                 
                    <img src="../../../images/sagemaker/latest/dg/images/model-curve.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
                 
            </div>
            <p>Now let's look at the metrics for <code class="code">Variant2</code>:</p>
            <div class="mediaobject">
                 
                    <img src="../../../images/sagemaker/latest/dg/images/model2-curve.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
                 
            </div>
            <p>
                For most of our defined metrics, <code class="code">Variant2</code> is performing better, so this is the one that we
                want to use in production.
            </p>
         
         
            <h3 id="model-ab-test-step4">Step 4: Increase traffic to the best
                model</h3>
            <p>
                Now that we have determined that <code class="code">Variant2</code> performs better than <code class="code">Variant1</code>, we
                shift more traffic to it. We can continue to use <code class="code">TargetVariant</code> to invoke a specific model
                variant, but a simpler approach is to update the weights assigned to each variant by calling <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_UpdateEndpointWeightsAndCapacities.html">UpdateEndpointWeightsAndCapacities</a>. This changes the traffic distribution to your production
                variants without requiring updates to your endpoint.  Recall from the setup section that we set variant
                weights to split traffic 50/50.  The CloudWatch metrics for the total invocations for each variant below show
                us the invocation patterns for each variant:
            </p>
            <div class="mediaobject">
                 
                    <img src="../../../images/sagemaker/latest/dg/images/model-invocations-even-dist.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
                 
            </div>
            <p>
                Now we shift 75% of the traffic to <code class="code">Variant2</code> by assigning new weights to each variant using
                <code class="code">UpdateEndpointWeightsAndCapacities</code>. SageMaker now sends 75% of the inference requests to
                <code class="code">Variant2</code> and remaining 25% of requests to <code class="code">Variant1</code>.
            </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">sm.update_endpoint_weights_and_capacities(
    EndpointName=endpoint_name,
    DesiredWeightsAndCapacities=[
        <span>{</span>
            "DesiredWeight": 25,
            "VariantName": variant1["VariantName"]
        },
        <span>{</span>
            "DesiredWeight": 75,
            "VariantName": variant2["VariantName"]
        }
    ]
)
            </code></pre>
            <p>
                The CloudWatch metrics for total invocations for each variant shows us higher invocations for
                <code class="code">Variant2</code> than for <code class="code">Variant1</code>:
            </p>
            <div class="mediaobject">
                 
                    <img src="../../../images/sagemaker/latest/dg/images/model-invocations-75-25.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
                 
            </div>
            <p>
                We can continue to monitor our metrics, and when we're satisfied with a variant's performance, we can
                route 100% of the traffic to that variant. We use <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_UpdateEndpointWeightsAndCapacities.html"><code class="code">UpdateEndpointWeightsAndCapacities</code></a>
                to update the traffic assignments for the variants. The weight for <code class="code">Variant1</code> is set to 0 and
                the weight for <code class="code">Variant2</code> is set to 1. SageMaker now sends 100% of all inference requests to
                <code class="code">Variant2</code>.
            </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">sm.update_endpoint_weights_and_capacities(
    EndpointName=endpoint_name,
    DesiredWeightsAndCapacities=[
        <span>{</span>
            "DesiredWeight": 0,
            "VariantName": variant1["VariantName"]
        },
        <span>{</span>
            "DesiredWeight": 1,
            "VariantName": variant2["VariantName"]
        }
    ]
)
            </code></pre>
            <p>
                The CloudWatch metrics for the total invocations for each variant show that all inference requests are being
                processed by <code class="code">Variant2</code> and there are no inference requests processed by
                <code class="code">Variant1</code>.
            </p>
            <div class="mediaobject">
                 
                    <img src="../../../images/sagemaker/latest/dg/images/model-invocations-best-model.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
                 
            </div>
            <p>
                You can now safely update your endpoint and delete <code class="code">Variant1</code> from your endpoint. You can
                also continue testing new models in production by adding new variants to your endpoint and following
                steps 2 - 4.
            </p>
         
    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./model-validation.html">Safely validate models in production</div><div id="next" class="next-link" accesskey="n" href="./model-shadow-deployment.html">Shadow variants</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/model-ab-testing.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/model-ab-testing.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>