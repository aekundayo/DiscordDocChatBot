<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Use EI on Amazon SageMaker Hosted Endpoints - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="ei-endpoints" /><meta name="default_state" content="ei-endpoints" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="ei-endpoints.html" /><meta name="description" content="To use Elastic Inference (EI) in Amazon SageMaker with a hosted endpoint for real-time inference, specify an EI accelerator when you create the deployable model to be hosted at that endpoint. You can do this in one of the following ways:" /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="ei-endpoints.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/ei-endpoints.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/ei-endpoints.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/ei-endpoints.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/ei-endpoints.html" hreflang="de" /><link rel="alternative" href="ei-endpoints.html" hreflang="en-us" /><link rel="alternative" href="ei-endpoints.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/ei-endpoints.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/ei-endpoints.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/ei-endpoints.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/ei-endpoints.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/ei-endpoints.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/ei-endpoints.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/ei-endpoints.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/ei-endpoints.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/ei-endpoints.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/ei-endpoints.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/ei-endpoints.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/ei-endpoints.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/ei-endpoints.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/ei-endpoints.html" hreflang="zh-tw" /><link rel="alternative" href="ei-endpoints.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Use EI on Amazon SageMaker Hosted Endpoints" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Use EI on Amazon SageMaker Hosted Endpoints - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#ei-endpoints" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/ei-endpoints.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/ei-endpoints.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/ei-endpoints.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance,inference,deploy model,endpoint,prediction,ML application,serverless machine learning,multi model deployment,inference pipelines,ML model" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Deploy models for inference",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Use Amazon SageMaker Elastic Inference (EI)",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Use EI on Amazon SageMaker Hosted Endpoints",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#ei-endpoints" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="ei-endpoints.html#ei-endpoints-tensorflow">Use EI with a SageMaker TensorFlow
                    Container</a><a href="ei-endpoints.html#ei-endpoints-mxnet">Use EI with a SageMaker MXNet Container</a><a href="ei-endpoints.html#ei-endpoints-pytorch">Use EI with a SageMaker PyTorch Container</a><a href="ei-endpoints.html#ei-endpoints-boto3">Your Own Container</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="ei-endpoints">Use EI on Amazon SageMaker Hosted Endpoints</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>To use Elastic Inference (EI) in Amazon SageMaker with a hosted endpoint for real-time inference,
            specify an EI accelerator when you create the deployable model to be hosted at that
            endpoint. You can do this in one of the following ways:</p><div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Use the <a href="https://sagemaker.readthedocs.io" rel="noopener noreferrer" target="_blank"><span>Amazon SageMaker Python SDK</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> versions of either the TensorFlow, MXNet, or PyTorch
                    and the SageMaker pre-built containers for TensorFlow, MXNet, and PyTorch</p>
            </li><li class="listitem">
                <p>Build your own container, and use the low-level SageMaker API (Boto 3). You will
                    need to import the EI-enabled version of either TensorFlow, MXNet, or PyTorch
                    from the provided Amazon S3 locations into your container, and use one of those
                    versions to write your training script.</p>
            </li><li class="listitem">
                <p>Use either the <a href="image-classification.html">Image Classification - MXNet</a> or <a href="object-detection.html">Object Detection - MXNet</a> build-in algorithms, and use the
                    AWS SDK for Python (Boto3) to run your training job and create your deployable model and
                    hosted endpoint.</p>
            </li></ul></div><div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="ei-endpoints.html#ei-endpoints-tensorflow">Use EI with a SageMaker TensorFlow
                    Container</a></li><li><a href="ei-endpoints.html#ei-endpoints-mxnet">Use EI with a SageMaker MXNet Container</a></li><li><a href="ei-endpoints.html#ei-endpoints-pytorch">Use EI with a SageMaker PyTorch Container</a></li><li><a href="ei-endpoints.html#ei-endpoints-boto3">Use EI with Your Own Container</a></li></ul></div>
            <h2 id="ei-endpoints-tensorflow">Use EI with a SageMaker TensorFlow
                    Container</h2>
            <p>To use TensorFlow with EI in SageMaker, you need to call the <code class="code">deploy</code> method
                of either the <a href="https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html#tensorflow-estimator" rel="noopener noreferrer" target="_blank"><span>Estimator</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> or <a href="https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html#tensorflow-model" rel="noopener noreferrer" target="_blank"><span>Model</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> objects. You then specify an accelerator type using the
                accelerator_type input argument. For information on using TensorFlow in the SageMaker
                Python SDK, see: <a href="https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/index.html" rel="noopener noreferrer" target="_blank"><span>https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/index.html</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            <p>SageMaker provides default model training and inference code for your convenience. For
                custom file formats, you might need to implement custom model training and inference
                code.</p>

             
                <h3 id="ei-endpoints-tensorflow-estimator">Use an Estimator
                        Object</h3>
                <p>To use an estimator object with EI, when you use the deploy method, include
                    the <code class="code">accelerator_type</code> input argument. The estimator returns a
                    predictor object, which we call its deploy method, as shown in the example
                    code.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Deploy an estimator using EI (using the accelerator_type input argument)
predictor = estimator.deploy(initial_instance_count=1,
                             instance_type='ml.m4.xlarge',
                             accelerator_type='ml.eia2.medium')</code></pre>
             
             
                <h3 id="ei-endpoints-tensorflow-model">Use a Model Object</h3>
                <p>To use a model object with EI, when you use the deploy method, include the
                        <code class="code">accelerator_type</code> input argument. The estimator returns a
                    predictor object, which we call its deploy method, as shown in the example
                    code.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Deploy a model using EI (using the accelerator_type input argument)
predictor = model.deploy(initial_instance_count=1,
                             instance_type='ml.m4.xlarge',
                             accelerator_type='ml.eia2.medium')</code></pre>
             
         
            <h2 id="ei-endpoints-mxnet">Use EI with a SageMaker MXNet Container</h2>

            <p>To use MXNet with EI in SageMaker, you need to call the <code class="code">deploy</code> method of
                either the <a href="https://sagemaker.readthedocs.io/en/stable/sagemaker.mxnet.html#mxnet-estimator" rel="noopener noreferrer" target="_blank"><span>Estimator</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> or <a href="https://sagemaker.readthedocs.io/en/stable/sagemaker.mxnet.html#mxnet-model" rel="noopener noreferrer" target="_blank"><span>Model</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> objects. You then specify an accelerator type using the
                    <code class="code">accelerator_type</code> input argument. For information about using MXNet
                in the <a href="https://sagemaker.readthedocs.io" rel="noopener noreferrer" target="_blank"><span>Amazon SageMaker Python SDK</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>, see <a href="https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/index.html" rel="noopener noreferrer" target="_blank"><span>https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/index.html</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a></p>
            <p>For your convenience, SageMaker provides default model training and inference code. For
                custom file formats, you might need to write custom model training and inference
                code.</p>
             
                <h3 id="ei-endpoints-mxnet-estimator">Use an Estimator Object</h3>
                <p>To use an estimator object with EI, when you use the deploy method, include
                    the <code class="code">accelerator_type</code> input argument. The estimator returns a
                    predictor object, which we call its deploy method, as shown in the example code. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Deploy an estimator using EI (using the accelerator_type input argument)
predictor = estimator.deploy(initial_instance_count=1,
                             instance_type='ml.m4.xlarge',
                             accelerator_type='ml.eia2.medium')</code></pre>
             
             
                <h3 id="ei-endpoints-mxnet-model">Use a Model Object</h3>
                <p>To use a model object with EI, when you use the deploy method, include the
                        <code class="code">accelerator_type</code> input argument. The estimator returns a
                    predictor object, which we call its deploy method, as shown in the example code. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Deploy a model using EI (using the accelerator_type input argument)
predictor = model.deploy(initial_instance_count=1,
                             instance_type='ml.m4.xlarge',
                             accelerator_type='ml.eia2.medium')</code></pre>
             
            <p>For a complete example of using EI with MXNet in SageMaker, see the sample notebook at
                    <a href="https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_mnist/mxnet_mnist_elastic_inference.ipynb" rel="noopener noreferrer" target="_blank"><span>https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_mnist/mxnet_mnist_elastic_inference.ipynb
                </span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a></p>

         
            <h2 id="ei-endpoints-pytorch">Use EI with a SageMaker PyTorch Container</h2>

            <p>To use PyTorch with EI in SageMaker, you need to call the <code class="code">deploy</code> method of
                either the <a href="https://sagemaker.readthedocs.io/en/stable/sagemaker.pytorch.html#pytorch-estimator" rel="noopener noreferrer" target="_blank"><span>Estimator</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> or <a href="https://sagemaker.readthedocs.io/en/stable/sagemaker.pytorch.html#pytorch-model" rel="noopener noreferrer" target="_blank"><span>Model</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> objects. You then specify an accelerator type using the
                    <code class="code">accelerator_type</code> input argument. For information about using
                PyTorch in the <a href="https://sagemaker.readthedocs.io" rel="noopener noreferrer" target="_blank"><span>Amazon SageMaker Python SDK</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>, see <a href="https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/index.html" rel="noopener noreferrer" target="_blank"><span>SageMaker PyTorch Estimators and Models</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            <p>For your convenience, SageMaker provides default model training and inference code. For
                custom file formats, you might need to write custom model training and inference
                code.</p>
             
                <h3 id="ei-endpoints-pytorch-estimator">Use an Estimator Object</h3>
                <p>To use an estimator object with EI, when you use the deploy method, include
                    the <code class="code">accelerator_type</code> input argument. The estimator returns a
                    predictor object, which we call its deploy method, as shown in this example
                    code.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Deploy an estimator using EI (using the accelerator_type input argument)
predictor = estimator.deploy(initial_instance_count=1,
                             instance_type='ml.m4.xlarge',
                             accelerator_type='ml.eia2.medium')</code></pre>
             
             
                <h3 id="ei-endpoints-pytorch-model">Use a Model Object</h3>
                <p>To use a model object with EI, when you use the deploy method, include the
                        <code class="code">accelerator_type</code> input argument. The model returns a predictor
                    object, which we call its deploy method, as shown in this example code.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Deploy a model using EI (using the accelerator_type input argument)
predictor = model.deploy(initial_instance_count=1,
                             instance_type='ml.m4.xlarge',
                             accelerator_type='ml.eia2.medium')</code></pre>
             


         
            <h2 id="ei-endpoints-boto3">Use EI with Your Own Container</h2>

            <p>To use EI with a model in a custom container that you build, use the low-level
                AWS SDK for Python (Boto 3). download and import the AWS EI-enabled versions of
                TensorFlow, Apache MXNet, or PyTorch machine learning frameworks, and write your
                training script using those frameworks.</p>

             
                <h3 id="ei-docker-container">Import the EI Version of TensorFlow,
                        MXNet, or PyTorch into Your Docker Container</h3>
                <p>To use EI with your own container, you need to import either the Amazon EI
                    TensorFlow Serving library, the Amazon EI Apache MXNet library, or the Elastic
                    Inference enabled PyTorch library into your container. The EI-enabled versions
                    of TensorFlow and MXNet are currently available as binary files stored in Amazon S3
                    locations. You can download the EI-enabled binary for TensorFlow from the Amazon S3
                    bucket at <a href="https://console.aws.amazon.com/s3/buckets/amazonei-tensorflow" rel="noopener noreferrer" target="_blank"><span>console.aws.amazon.com/s3/buckets/amazonei-tensorflow</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.
                    For information about building a container that uses the EI-enabled version of
                    TensorFlow, see <a href="https://github.com/aws/sagemaker-tensorflow-container#building-the-sagemaker-elastic-inference-tensorflow-serving-container" rel="noopener noreferrer" target="_blank"><span>https://github.com/aws/sagemaker-tensorflow-container#building-the-sagemaker-elastic-inference-tensorflow-serving-container</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.
                    You can download the EI-enabled binary for Apache MXNet from the public Amazon S3
                    bucket at <a href="https://console.aws.amazon.com/s3/buckets/amazonei-apachemxnet" rel="noopener noreferrer" target="_blank"><span>console.aws.amazon.com/s3/buckets/amazonei-apachemxnet</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.
                    For information about building a container that uses the EI-enabled version of
                    MXNet, see <a href="https://github.com/aws/sagemaker-mxnet-container#building-the-sagemaker-elastic-inference-mxnet-container" rel="noopener noreferrer" target="_blank"><span>https://github.com/aws/sagemaker-mxnet-container#building-the-sagemaker-elastic-inference-mxnet-container</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.
                    You can download the
                    <a href="https://amazonei-pytorcheia.s3.amazonaws.com/releases/v1.0.0/torcheia-1.0.0-cp36-cp36m-manylinux1_x86_64.whl" rel="noopener noreferrer" target="_blank"><span>Elastic Inference enabled binary for PyTorch</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>. For
                    information about building a container that uses the Elastic Inference enabled
                    version of PyTorch, see <a href="https://github.com/aws/sagemaker-pytorch-serving-container/#building-your-image" rel="noopener noreferrer" target="_blank"><span>Building your image</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>. </p>
             
             
                <h3 id="ei-create-endpoint-boto">Create an EI Endpoint with AWS SDK for
                        Python (Boto 3)</h3>
                <p>To create an endpoint by using AWS SDK for Python (Boto 3), you first create
                    an endpoint configuration. The endpoint configuration specifies one or more
                    models (called production variants) that you want to host at the endpoint. To
                    attach EI to one or more of the production variants hosted at the endpoint, you
                    specify one of the EI instance types as the <code class="code">AcceleratorType</code> field
                    for that <code class="code">ProductionVariant</code>. You then pass that endpoint
                    configuration when you create the endpoint.</p>

                 
                    <h4 id="ei-endpoints-boto3-endpoint-config">Create an Endpoint
                            Configuration</h4>
                    <p>To use EI, you need to specify an accelerator type in the endpoint
                        configuration.</p>
                    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python "># Create Endpoint Configuration
from time import gmtime, strftime

endpoint_config_name = 'ImageClassificationEndpointConfig-' + strftime("%Y-%m-%d-%H-%M-%S", gmtime())
print(endpoint_config_name)
create_endpoint_config_response = sagemaker.create_endpoint_config(
    EndpointConfigName = endpoint_config_name,
    ProductionVariants=[<span>{</span>
        'InstanceType':'ml.m4.xlarge',
        'InitialInstanceCount':1,
        'ModelName':model_name,
        'VariantName':'AllTraffic',
        'AcceleratorType':'ml.eia2.medium'}])

print("Endpoint Config Arn: " + create_endpoint_config_response['EndpointConfigArn'])</code></pre>

                 
                 
                    <h4 id="ei-endpoints-boto3-endpoint">Create an Endpoint</h4>
                    <p>After you create an endpoint configuration with an accelerator type, you
                        can create an endpoint.</p>
                    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">endpoint_name = 'ImageClassificationEndpoint-' + strftime("%Y-%m-%d-%H-%M-%S", gmtime())
endpoint_response = sagemaker.create_endpoint(
    EndpointName=endpoint_name,
    EndpointConfigName=endpoint_config_name)</code></pre>
                    <p>After creating the endpoint, you can invoke it using the
                            <code class="code">invoke_endpoint</code> method in a Boto3 runtime object, as you
                        would any other endpoint.</p>
                 
             


        <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./ei-notebook-instance.html">Attach EI to a Notebook Instance</div><div id="next" class="next-link" accesskey="n" href="./best-practices.html">Best practices</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/ei-endpoints.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/ei-endpoints.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>