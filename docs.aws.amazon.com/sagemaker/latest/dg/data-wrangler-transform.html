<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Transform Data - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="data-wrangler-transform" /><meta name="default_state" content="data-wrangler-transform" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="data-wrangler-transform.html" /><meta name="description" content="Use Data Wrangler to apply different transformations to your data." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="data-wrangler-transform.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="de" /><link rel="alternative" href="data-wrangler-transform.html" hreflang="en-us" /><link rel="alternative" href="data-wrangler-transform.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/data-wrangler-transform.html" hreflang="zh-tw" /><link rel="alternative" href="data-wrangler-transform.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Transform Data" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Transform Data - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#data-wrangler-transform" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-transform.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-transform.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-transform.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Prepare data",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/data-prep.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Prepare ML Data with Amazon SageMaker Data Wrangler",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/data-wrangler.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Transform Data",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/data-wrangler.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#data-wrangler-transform" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="data-wrangler-transform.html#data-wrangler-transform-ui">Transform UI</a><a href="data-wrangler-transform.html#data-wrangler-transform-join">Join Datasets</a><a href="data-wrangler-transform.html#data-wrangler-transform-concatenate">Concatenate Datasets</a><a href="data-wrangler-transform.html#data-wrangler-transform-balance-data">Balance Data</a><a href="data-wrangler-transform.html#data-wrangler-transform-custom">Custom Transforms</a><a href="data-wrangler-transform.html#data-wrangler-transform-custom-formula">Custom Formula</a><a href="data-wrangler-transform.html#data-wrangler-transform-dimensionality-reduction">Reduce Dimensionality (PCA)</a><a href="data-wrangler-transform.html#data-wrangler-transform-cat-encode">Encode Categorical</a><a href="data-wrangler-transform.html#data-wrangler-transform-featurize-text">Featurize Text</a><a href="data-wrangler-transform.html#data-wrangler-transform-time-series">Transform Time Series</a><a href="data-wrangler-transform.html#data-wrangler-transform-datetime-embed">Featurize Datetime</a><a href="data-wrangler-transform.html#data-wrangler-transform-format-string">Format String</a><a href="data-wrangler-transform.html#data-wrangler-transform-handle-outlier">Handle Outliers</a><a href="data-wrangler-transform.html#data-wrangler-transform-handle-missing">Handle Missing Values</a><a href="data-wrangler-transform.html#data-wrangler-manage-columns">Manage Columns</a><a href="data-wrangler-transform.html#data-wrangler-transform-manage-rows">Manage Rows</a><a href="data-wrangler-transform.html#data-wrangler-transform-manage-vectors">Manage Vectors</a><a href="data-wrangler-transform.html#data-wrangler-transform-process-numeric">Process Numeric</a><a href="data-wrangler-transform.html#data-wrangler-transform-sampling">Sampling</a><a href="data-wrangler-transform.html#data-wrangler-transform-search-edit">Search and Edit</a><a href="data-wrangler-transform.html#data-wrangler-transform-split-data">Split data</a><a href="data-wrangler-transform.html#data-wrangler-transform-cast-type">Parse Value as Type</a><a href="data-wrangler-transform.html#data-wrangler-transform-validate-string">Validate String</a><a href="data-wrangler-transform.html#data-wrangler-transform-flatten-column">Unnest JSON Data</a><a href="data-wrangler-transform.html#data-wrangler-transform-explode-array">Explode Array</a><a href="data-wrangler-transform.html#data-wrangler-transform-image">Transform Image Data</a><a href="data-wrangler-transform.html#data-wrangler-transform-filter-data">Filter data</a><a href="data-wrangler-transform.html#data-wrangler-transform-personalize">Map Columns for Amazon Personalize</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="data-wrangler-transform">Transform Data</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Amazon SageMaker Data Wrangler provides numerous ML data transforms to streamline cleaning, transforming, and
        featurizing your data. When you add a transform, it adds a step to the data flow. Each
        transform you add modifies your dataset and produces a new dataframe. All subsequent
        transforms apply to the resulting dataframe.</p><p>Data Wrangler includes built-in transforms, which you can use to transform columns without any
        code. You can also add custom transformations using PySpark, Python (User-Defined Function),
        pandas, and PySpark SQL. Some transforms operate in place, while others create a new output
        column in your dataset.</p><p>You can apply transforms to multiple columns at once. For example, you can delete multiple
        columns in a single step.</p><p>You
        can apply the <b>Process numeric</b> and <b>Handle missing</b>
        transforms only to a single column.</p><p>Use this page to learn more about these built-in and custom transforms.</p>
        <h2 id="data-wrangler-transform-ui">Transform UI</h2>
        <p>Most of the built-in transforms are located in the <b>Prepare</b> tab of
            the Data Wrangler UI. You can access the join and concatenate transforms through the data flow
            view. Use the following table to preview these two views. </p>
        <awsdocs-tabs><dl style="display: none">
            <dt>Transform</dt><dd tab-id="transform">
                    <p>You can add a transform to any step in your data flow. Use the following
                        procedure to add a transform to your data flow.</p>
                    <div class="procedure"><p>To add a step to your data flow, do the following.</p><ol><li>
                            <p>Choose the <b>+</b> next to the step in the data
                                flow.</p>

                        </li><li>
                            <p>Choose <b>Add transform</b>.</p>

                        </li><li>
                            <p>Choose <b>Add step</b>.</p>
                            <div class="mediaobject">
                                 
                                    <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/data-wrangler-add-step.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                                    Add step located toward the top of the Transforms section.&#xA;                                " style="max-width:90%" />
                                 
                                 
                            </div>
                        </li><li>
                            <p>Choose a transform. </p>
                        </li><li>
                            <p>(Optional) You can search for the transform that you want to use.
                                Data Wrangler highlights the query in the results.</p>
                            <div class="mediaobject">
                                 
                                    <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/data-wrangler-search.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                                    Search box located toward the top of the ADD TRANSFORM section.&#xA;                                " style="max-width:90%" />
                                 
                                 
                            </div>
                        </li></ol></div>
                </dd>
            <dt>Join View</dt><dd tab-id="join-view">
                    <p>To join two datasets, select the first dataset in your data flow and
                        choose <b>Join</b>. When you choose <b>Join</b>,
                        you see results similar to those shown in the following image. Your left and
                        right datasets are displayed in the left panel. The main panel displays your
                        data flow, with the newly joined dataset added. </p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/join-1.png" class="aws-docs-img-whiteBg aws-docs-img-padding" style="max-width:90%" />
                         
                    </div>
                    <p>When you choose <b>Configure</b> to configure your join, you
                        see results similar to those shown in the following image. Your join
                        configuration is displayed in the left panel. You can use this panel to
                        choose the joined dataset name, join type, and columns to join. The main
                        panel displays three tables. The top two tables display the left and right
                        datasets on the left and right respectively. Under this table, you can
                        preview the joined dataset. </p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/join-2.png" class="aws-docs-img-whiteBg aws-docs-img-padding" style="max-width:90%" />
                         
                    </div>
                    <p>See <a href="data-wrangler-transform.html#data-wrangler-transform-join">Join Datasets</a> to learn more. </p>
                </dd>
            <dt>Concatenate View</dt><dd tab-id="concatenate-view">
                    <p>To concatenate two datasets, you select the first dataset in your data
                        flow and choose <b>Concatenate</b>. When you select
                            <b>Concatenate</b>, you see results similar to those shown
                        in the following image. Your left and right datasets are displayed in the
                        left panel. The main panel displays your data flow, with the newly
                        concatenated dataset added. </p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/concat-1.png" class="aws-docs-img-whiteBg aws-docs-img-padding" style="max-width:90%" />
                         
                    </div>
                    <p>When you choose <b>Configure</b> to configure your
                        concatenation, you see results similar to those shown in the following
                        image. Your concatenate configuration displays in the left panel. You can
                        use this panel to choose the concatenated dataset's name, and choose to
                        remove duplicates after concatenation and add columns to indicate the source
                        dataframe. The main panel displays three tables. The top two tables display
                        the left and right datasets on the left and right respectively. Under this
                        table, you can preview the concatenated dataset. </p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/concat-2.png" class="aws-docs-img-whiteBg aws-docs-img-padding" style="max-width:90%" />
                         
                    </div>
                    <p>See <a href="data-wrangler-transform.html#data-wrangler-transform-concatenate">Concatenate Datasets</a> to learn
                        more.</p>
                </dd>
        </dl></awsdocs-tabs>
     
        <h2 id="data-wrangler-transform-join">Join Datasets</h2>
        <p>You join dataframes directly in your data flow. When you join two datasets, the
            resulting joined dataset appears in your flow. The following join types are supported by
            Data Wrangler.</p>
        <div class="itemizedlist">
             
             
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>Left Outer</b> – Include all rows from the
                    left table. If the value for the column joined on a left table row does not
                    match any right table row values, that row contains null values for all right
                    table columns in the joined table.</p>
            </li><li class="listitem">
                <p><b>Left Anti</b> – Include rows from the left
                    table that do not contain values in the right table for the joined
                    column.</p>
            </li><li class="listitem">
                <p><b>Left semi</b> – Include a single row from
                    the left table for all identical rows that satisfy the criteria in the join
                    statement. This excludes duplicate rows from the left table that match the
                    criteria of the join.</p>
            </li><li class="listitem">
                <p><b>Right Outer</b> – Include all rows from
                    the right table. If the value for the joined column in a right table row does
                    not match any left table row values, that row contains null values for all left
                    table columns in the joined table.</p>
            </li><li class="listitem">
                <p><b>Inner</b> – Include rows from left and
                    right tables that contain matching values in the joined column. </p>
            </li><li class="listitem">
                <p><b>Full Outer</b> – Include all rows from the
                    left and right tables. If the row value for the joined column in either table
                    does not match, separate rows are created in the joined table. If a row doesn’t
                    contain a value for a column in the joined table, null is inserted for that
                    column.</p>
            </li><li class="listitem">
                <p><b>Cartesian Cross</b> – Include rows which
                    combine each row from the first table with each row from the second table. This
                    is a <a href="https://en.wikipedia.org/wiki/Cartesian_product" rel="noopener noreferrer" target="_blank"><span>Cartesian
                        product</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> of rows from tables in the join. The result of this product
                    is the size of the left table times the size of the right table. Therefore, we
                    recommend caution in using this join between very large datasets. </p>
            </li></ul></div>
        <p>Use the following procedure to join two dataframes.</p>
        <div class="procedure"><ol><li>
                <p>Select <b>+</b> next to the left dataframe that you want to
                    join. The first dataframe you select is always the left table in your join.
                </p>
            </li><li>
                <p>Choose <b>Join</b>.</p>
            </li><li>
                <p>Select the right dataframe. The second dataframe you select is always the
                    right table in your join.</p>
            </li><li>
                <p>Choose <b>Configure</b> to configure your join. </p>
            </li><li>
                <p>Give your joined dataset a name using the <b>Name</b>
                    field.</p>
            </li><li>
                <p>Select a <b>Join type</b>.</p>
            </li><li>
                <p>Select a column from the left and right tables to join. </p>
            </li><li>
                <p>Choose <b>Apply</b> to preview the joined dataset on the right.
                </p>
            </li><li>
                <p>To add the joined table to your data flow, choose <b>Add</b>.
                </p>
            </li></ol></div>
     
        <h2 id="data-wrangler-transform-concatenate">Concatenate Datasets</h2>
        <div class="procedure"><h6>Concatenate two datasets:</h6><ol><li>
                <p>Choose <b>+</b> next to the left dataframe that you want to
                    concatenate. The first dataframe you select is always the left table in your
                    concatenate. </p>
            </li><li>
                <p>Choose <b>Concatenate</b>.</p>
            </li><li>
                <p>Select the right dataframe. The second dataframe you select is always the
                    right table in your concatenate.</p>
            </li><li>
                <p>Choose <b>Configure</b> to configure your concatenate. </p>
            </li><li>
                <p>Give your concatenated dataset a name using the <b>Name</b>
                    field.</p>
            </li><li>
                <p>(Optional) Select the checkbox next to <b>Remove duplicates after
                        concatenation</b> to remove duplicate columns. </p>
            </li><li>
                <p>(Optional) Select the checkbox next to <b>Add column to indicate source
                        dataframe</b> if, for each column in the new dataset, you want to add
                    an indicator of the column's source. </p>
            </li><li>
                <p>Choose <b>Apply</b> to preview the new dataset. </p>
            </li><li>
                <p>Choose <b>Add</b> to add the new dataset to your data flow.
                </p>
            </li></ol></div>
     
        <h2 id="data-wrangler-transform-balance-data">Balance Data</h2>
        <p>You can balance the data for datasets with an underrepresented category. Balancing a
            dataset can help you create better models for binary classification.</p>
        <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>You can't balance datasets containing column vectors.</p></div></div>
        <p>You can use the <b>Balance data</b> operation to balance your data using
            one of the following operators:</p>
        <div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><em>Random oversampling</em> – Randomly
                    duplicates samples in the minority category. For example, if you're trying to
                    detect fraud, you might only have cases of fraud in 10% of your data. For an
                    equal proportion of fraudulent and non-fraudulent cases, this operator randomly
                    duplicates fraud cases within the dataset 8 times.</p>
            </li><li class="listitem">
                <p><em>Random undersampling</em> – Roughly
                    equivalent to random oversampling. Randomly removes samples from the
                    overrepresented category to get the proportion of samples that you
                    desire.</p>
            </li><li class="listitem">
                <p><em>Synthetic Minority Oversampling Technique
                        (SMOTE)</em> – Uses samples from the underrepresented category
                    to interpolate new synthetic minority samples. For more information about SMOTE,
                    see the following description.</p>
            </li></ul></div>
        <p>You can use all transforms for datasets containing both numeric and non-numeric
            features. SMOTE interpolates values by using neighboring samples. Data Wrangler uses the
            R-squared distance to determine the neighborhood to interpolate the additional samples.
            Data Wrangler only uses numeric features to calculate the distances between samples in the
            underrepresented group.</p>
        <p>For two real samples in the underrepresented group, Data Wrangler interpolates the numeric
            features by using a weighted average. It randomly assigns weights to those samples in
            the range of [0, 1]. For numeric features, Data Wrangler interpolates samples using a weighted
            average of the samples. For samples A and B, Data Wrangler could randomly assign a weight of 0.7
            to A and 0.3 to B. The interpolated sample has a value of 0.7A + 0.3B.</p>
        <p>Data Wrangler interpolates non-numeric features by copying from either of the interpolated real
            samples. It copies the samples with a probability that it randomly assigns to each
            sample. For samples A and B, it can assign probabilities 0.8 to A and 0.2 to B. For the
            probabilities it assigned, it copies A 80% of the time.</p>

     
        <h2 id="data-wrangler-transform-custom">Custom Transforms</h2>
        <p>The <b>Custom Transforms</b> group allows you to use Python
            (User-Defined Function), PySpark, pandas, or PySpark (SQL) to define custom
            transformations. For all three options, you use the variable <code class="code">df</code> to access
            the dataframe to which you want to apply the transform. To apply your custom code to your dataframe, assign the dataframe with the transformations that you've made to the <code class="code">df</code> variable.
            If you're not using Python
            (User-Defined Function), you don't need to include a return statement. Choose
                <b>Preview</b> to preview the result of the custom transform. Choose
                <b>Add</b> to add the custom transform to your list of
                <b>Previous steps</b>.</p>
        <p>You can import the popular libraries with an <code class="code">import</code> statement in the
            custom transform code block, such as the following:</p>
        <div class="itemizedlist">
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>NumPy version 1.19.0</p>
            </li><li class="listitem">
                <p>scikit-learn version 0.23.2</p>
            </li><li class="listitem">
                <p>SciPy version 1.5.4</p>
            </li><li class="listitem">
                <p>pandas version 1.0.3</p>
            </li><li class="listitem">
                <p>PySpark version 3.0.0</p>
            </li></ul></div>
        <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p><b>Custom transform</b> doesn't support columns with spaces or
                special characters in the name. We recommend that you specify column names that only
                have alphanumeric characters and underscores. You can use the <b>Rename
                    column</b> transform in the <b>Manage columns</b> transform
                group to remove spaces from a column's name. You can also add a <b>Python
                    (Pandas)</b>
                <b>Custom transform</b> similar to the following to remove spaces from
                multiple columns in a single step. This example changes columns named <code class="code">A
                    column</code> and <code class="code">B column</code> to <code class="code">A_column</code> and
                    <code class="code">B_column</code> respectively. </p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">df.rename(columns=<span>{</span>"A column": "A_column", "B column": "B_column"})</code></pre></div></div>
        <p>If you include print statements in the code block, the result appears when you select
                <b>Preview</b>. You can resize the custom code transformer panel.
            Resizing the panel provides more space to write code. The following image shows the
            resizing of the panel.</p>
        <div class="mediaobject">
             
                <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/resizing-panel.gif" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                For the Python function, replace the comments under pd.Series with your&#xA;                    code.&#xA;            " />
             
             
        </div>
        <p>The following sections provide additional context and examples for writing custom
            transform code.</p>
        <p><b>Python (User-Defined Function)</b></p>
        <p>The Python function gives you the ability to write custom transformations without
            needing to know Apache Spark or pandas. Data Wrangler is optimized to run your custom code
            quickly. You get similar performance using custom Python code and an Apache Spark
            plugin.</p>
        <p>To use the Python (User-Defined Function) code block, you specify the
            following:</p>
        <div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>Input column</b> – The input column where
                    you're
                    applying the transform.</p>
            </li><li class="listitem">
                <p><b>Mode</b> – The scripting mode, either pandas or
                    Python.</p>
            </li><li class="listitem">
                <p><b>Return type</b> – The data type of the value that
                    you're returning.</p>
            </li></ul></div>
        <p>Using the pandas mode gives better performance. The Python mode makes it easier for
            you to write transformations by using pure Python functions.</p>
        <p>The following video shows an example of how to use custom code to create a
            transformation. It uses the
            <a href="https://s3.us-west-2.amazonaws.com/amazon-sagemaker-data-wrangler-documentation-artifacts/walkthrough_titanic.csv" rel="noopener noreferrer" target="_blank"><span>Titanic dataset</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> to create a column with the
            person's salutation.</p>
        <div class="mediaobject">
             
                <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/python-function-transform-titanic-720.gif" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                For the Python function, replace the comments under pd.Series with your&#xA;                    code.&#xA;            " />
             
             
        </div>

        <p><b>PySpark</b></p>
        <p>The following example extracts date and time from a timestamp.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">from pyspark.sql.functions import from_unixtime, to_date, date_format
df = df.withColumn('DATE_TIME', from_unixtime('TIMESTAMP'))
df = df.withColumn( 'EVENT_DATE', to_date('DATE_TIME')).withColumn(
'EVENT_TIME', date_format('DATE_TIME', 'HH:mm:ss'))</code></pre>
        <p><b>pandas</b></p>
        <p>The following example provides an overview of the dataframe to which you are adding
            transforms. </p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">df.info()</code></pre>
        <p><b>PySpark (SQL)</b></p>
        <p>The following example creates a new dataframe with four columns: <em>name</em>, <em>fare</em>, <em>pclass</em>, <em>survived</em>.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="sql ">SELECT name, fare, pclass, survived FROM df</code></pre>

        <p>If you don’t know how to use PySpark, you can use custom code snippets to help you get
            started.</p>

        <p>Data Wrangler has a searchable collection of code snippets. You can use to code
            snippets to perform tasks such as dropping columns, grouping by columns, or
            modelling.</p>
        
        <p>To use a code snippet, choose <b>Search example snippets</b> and specify a query in the search bar. The text you specify in the query doesn’t have to match the name of the code snippet exactly.</p>
        
        <p>The following example shows a <b>Drop duplicate rows</b> code snippet
            that can delete rows with similar data in your dataset. You can find the code snippet by
            searching for one of the following:</p>
        <div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Duplicates</p>
            </li><li class="listitem">
                <p>Identical</p>
            </li><li class="listitem">
                <p>Remove</p>
            </li></ul></div>
        
        <p>The following snippet has comments to help you understand the changes that you need to make. For most snippets, you must specify the column names of your dataset in the code.</p>
        
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">
# Specify the subset of columns
# all rows having identical values in these columns will be dropped

subset = ["col1", "col2", "col3"]
df = df.dropDuplicates(subset)  

# to drop the full-duplicate rows run
# df = df.dropDuplicates()            
                        
        </code></pre>
        
        <p>To use a snippet, copy and paste its content into the <b>Custom
                transform</b> field. You can copy and paste multiple code snippets into the
            custom transform field.</p>
        
     
        <h2 id="data-wrangler-transform-custom-formula">Custom Formula</h2>
        <p>Use <b>Custom formula</b> to define a new column using a Spark SQL
            expression to query data in the current dataframe. The query must use the conventions of
            Spark SQL expressions.</p>
        <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p><b>Custom formula</b> doesn't support columns with spaces or special
                characters in the name. We recommend that you specify column names that only have
                alphanumeric characters and underscores. You can use the <b>Rename
                    column</b> transform in the <b>Manage columns</b> transform
                group to remove spaces from a column's name. You can also add a <b>Python
                    (Pandas)</b>
                <b>Custom transform</b> similar to the following to remove spaces from
                multiple columns in a single step. This example changes columns named <code class="code">A
                    column</code> and <code class="code">B column</code> to <code class="code">A_column</code> and
                    <code class="code">B_column</code> respectively. </p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">df.rename(columns=<span>{</span>"A column": "A_column", "B column": "B_column"})</code></pre></div></div>
        <p>You can use this transform to perform operations on columns, referencing the columns
            by name. For example, assuming the current dataframe contains columns named <em>col_a</em> and <em>col_b</em>, you can
            use the following operation to produce an <b>Output column</b> that is the
            product of these two columns with the following code:</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">col_a * col_b</code></pre>
        <p>Other common operations include the following, assuming a dataframe contains
                <code class="code">col_a</code> and <code class="code">col_b</code> columns:</p>
        <div class="itemizedlist">
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Concatenate two columns: <code class="code">concat(col_a, col_b)</code></p>
            </li><li class="listitem">
                <p>Add two columns: <code class="code">col_a + col_b</code></p>
            </li><li class="listitem">
                <p>Subtract two columns: <code class="code">col_a - col_b</code></p>
            </li><li class="listitem">
                <p>Divide two columns: <code class="code">col_a / col_b</code></p>
            </li><li class="listitem">
                <p>Take the absolute value of a column: <code class="code">abs(col_a)</code></p>
            </li></ul></div>
        <p>For more information, see the <a href="http://spark.apache.org/docs/latest/api/python" rel="noopener noreferrer" target="_blank"><span>Spark documentation</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> on selecting data. </p>
     
        <h2 id="data-wrangler-transform-dimensionality-reduction">Reduce Dimensionality within a Dataset</h2>
        <p>Reduce the dimensionality in your data by using Principal Component Analysis (PCA). The dimensionality of your dataset corresponds to the number of features.
            When you use dimensionality reduction in Data Wrangler, you get a new set of features called components. Each component accounts for some variability in the data.</p>
        <p>The first component accounts for the largest amount of variation in the data. The second component accounts for the second largest amount of variation in the data, and so on.</p>
        <p>You can use dimensionality reduction to reduce the size of the data sets that you use to train models. Instead of using the features in your dataset, you can use the principal components instead.</p>
        <p>To perform PCA, Data Wrangler creates axes for your data. An axis is an affine combination of columns in your dataset. The first principal component is the value on the axis that has the largest amount of variance. The second principal component is the value on the axis that has the second largest amount of variance. The nth principal component is the value on the axis that has the nth largest amount of variance.</p>       
        <p>You can configure the number of principal components that Data Wrangler returns. You can either specify the number of principal components directly or you can specify the variance threshold percentage.
            Each principal component explains an amount of variance in the data. For example, you might have a principal component with a value of 0.5. The component would explain 50% of the variation in the data. When you specify a variance threshold percentage, Data Wrangler returns the smallest number of components that meet the percentage that you specify.</p>
        <p>The following are example principal components with the amount of variance that they explain in the data.</p>
        <div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Component 1 – 0.5</p>
            </li><li class="listitem">
                <p>Component 2 – 0.45</p>
            </li><li class="listitem">
                <p>Component 3 – 0.05</p>
            </li></ul></div>
        <p>If you specify a variance threshold percentage of <code class="code">94</code> or <code class="code">95</code>, Data Wrangler returns Component 1 and Component 2. If you specify a variance threshold percentage of <code class="code">96</code>, Data Wrangler returns all three principal components.</p>
        <p>You can use the following procedure to run PCA on your dataset.</p>
        <div class="procedure"><p>To run PCA on your dataset, do the following.</p><ol><li>
                <p>Open your Data Wrangler data flow.</p>
            </li><li>
                <p>Choose the <b>+</b>, and select <b>Add
                    transform</b>.</p>
            </li><li>
                <p>Choose <b>Add step</b>.</p>
            </li><li>
                <p>Choose <b>Dimensionality Reduction</b>.</p>
            </li><li>
                <p>For <b>Input Columns</b>, choose the features that you're reducing into the principal components.</p>
            </li><li>
                <p>(Optional) For <b>Number of principal components</b>, choose the number of principal components that Data Wrangler returns in your dataset. If specify a value for the field, you can't specify a value for <b>Variance threshold percentage</b>.</p>
            </li><li>
                <p>(Optional) For <b>Variance threshold percentage</b>, specify the percentage of variation in the data that you want explained by the principal components. Data Wrangler uses the default value of <code class="code">95</code> if you don't specify a value for the variance threshold. You can't specify a variance threshold percentage if you've specified a value for <b>Number of principal components</b>.</p>
            </li><li>
                <p>(Optional) Deselect <b>Center</b> to not use the mean of the columns as the center of the data. By default, Data Wrangler centers the data with the mean before scaling.</p>
            </li><li>
                <p>(Optional) Deselect <b>Scale</b> to not scale the data with the unit standard deviation.</p>
            </li><li>
                <p>(Optional) Choose <b>Columns</b> to output the components to separate columns. Choose <b>Vector</b> to output the components as a single vector.</p>
            </li><li>
                <p>(Optional) For <b>Output column</b>, specify a name for an output column. If you're outputting the components to separate columns, the name that you specify is a prefix. If you're outputting the components to a vector, the name that you specify is the name of the vector column.</p>
            </li><li>
                <p>(Optional) Select <b>Keep input columns</b>. We don't recommend selecting this option if you plan on only using the principal components to train your model.</p>
            </li><li>
                <p>Choose <b>Preview</b>.</p>
            </li><li>
                <p>Choose <b>Add</b>.</p>
            </li></ol></div>
        
     
        <h2 id="data-wrangler-transform-cat-encode">Encode Categorical</h2>
        <p>Categorical data is usually composed of a finite number of categories, where each
            category is represented with a string. For example, if you have a table of customer
            data, a column that indicates the country a person lives in is categorical. The
            categories would be <em>Afghanistan</em>, <em>Albania</em>, <em>Algeria</em>, and so
            on. Categorical data can be <em>nominal</em> or <em>ordinal</em>. Ordinal categories have an inherent order, and
            nominal categories do not. The highest degree obtained (<em>High
                school</em>, <em>Bachelors</em>, <em>Masters</em>, and so on) is an example of ordinal categories. </p>
        <p>Encoding categorical data is the process of creating a numerical representation for
            categories. For example, if your categories are <em>Dog</em>
            and <em>Cat</em>, you may encode this information into two
            vectors, <code class="code">[1,0]</code> to represent <em>Dog</em>, and
                <code class="code">[0,1]</code> to represent <em>Cat</em>.</p>
        <p>When you encode ordinal categories, you may need to translate the natural order of
            categories into your encoding. For example, you can represent the highest degree
            obtained with the following map: <code class="code"><span>{</span>"High school": 1, "Bachelors": 2,
                "Masters":3}</code>.</p>
        <p>Use categorical encoding to encode categorical data that is in string format into
            arrays of integers. </p>
        <p>The Data Wrangler categorical encoders create encodings for all categories that exist in a
            column at the time the step is defined. If new categories have been added to a column
            when you start a Data Wrangler job to process your dataset at time <em>t</em>, and this column was the input for a Data Wrangler categorical encoding
            transform at time <em>t</em>-1, these new categories are
            considered <em>missing</em> in the Data Wrangler job. The option you
            select for <b>Invalid handling strategy</b> is applied to these missing
            values. Examples of when this can occur are: </p>
        <div class="itemizedlist">
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>When you use a .flow file to create a Data Wrangler job to process a dataset that was
                    updated after the creation of the data flow. For example, you may use a data
                    flow to regularly process sales data each month. If that sales data is updated
                    weekly, new categories may be introduced into columns for which an encode
                    categorical step is defined. </p>
            </li><li class="listitem">
                <p>When you select <b>Sampling</b> when you import your dataset,
                    some categories may be left out of the sample. </p>
            </li></ul></div>
        <p>In these situations, these new categories are considered missing values in the Data Wrangler
            job.</p>
        <p>You can choose from and configure an <em>ordinal</em> and a
                <em>one-hot encode</em>. Use the following sections to
            learn more about these options. </p>
        <p>Both transforms create a new column named <b>Output column name</b>. You
            specify the output format of this column with <b>Output style</b>:</p>
        <div class="itemizedlist">
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Select <b>Vector</b> to produce a single column with a sparse
                    vector. </p>
            </li><li class="listitem">
                <p>Select <b>Columns</b> to create a column for every category with
                    an indicator variable for whether the text in the original column contains a
                    value that is equal to that category.</p>
            </li></ul></div>
         
            <h3 id="data-wrangler-transform-cat-encode-ordinal">Ordinal Encode</h3>
            <p>Select <b>Ordinal encode</b> to encode categories into an integer
                between 0 and the total number of categories in the <b>Input
                    column</b> you select.</p>
            <p><b>Invalid handing strategy</b>: Select a method to handle invalid
                or missing values. </p>
            <div class="itemizedlist">
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Choose <b>Skip</b> if you want to omit the rows with missing
                        values.</p>
                </li><li class="listitem">
                    <p>Choose <b>Keep</b> to retain missing values as
                        the last category.</p>
                </li><li class="listitem">
                    <p>Choose <b>Error</b> if you want Data Wrangler to throw an error if
                        missing values are encountered in the <b>Input
                        column</b>.</p>
                </li><li class="listitem">
                    <p>Choose <b>Replace with NaN</b> to replace missing with NaN.
                        This option is recommended if your ML algorithm can handle missing values.
                        Otherwise, the first three options in this list may produce better
                        results.</p>
                </li></ul></div>
         
         
            <h3 id="data-wrangler-transform-cat-encode-onehot">One-Hot Encode</h3>
            <p>Select <b>One-hot encode</b> for <b>Transform</b> to
                use one-hot encoding. Configure this transform using the following: </p>
            <div class="itemizedlist">
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p><b>Drop last category</b>: If <code class="code">True</code>, the last
                        category does not have a corresponding index in the one-hot encoding. When
                        missing values are possible, a missing category is always the last one and
                        setting this to <code class="code">True</code> means that a missing value results in an
                        all zero vector.</p>
                </li><li class="listitem">
                    <p><b>Invalid handing strategy</b>: Select a method to handle
                        invalid or missing values. </p>
                    <div class="itemizedlist">
                         
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>Choose <b>Skip</b> if you want to omit the rows with
                                missing values.</p>
                        </li><li class="listitem">
                            <p>Choose <b>Keep</b> to retain missing
                                values as the last category.</p>
                        </li><li class="listitem">
                            <p>Choose <b>Error</b> if you want Data Wrangler to throw an
                                error if missing values are encountered in the <b>Input
                                    column</b>.</p>
                        </li></ul></div>
                </li><li class="listitem">
                    <p><b>Is input ordinal encoded</b>: Select this option if the
                        input vector contains ordinal encoded data. This option requires that input
                        data contain non-negative integers. If <b>True</b>, input
                            <em>i</em> is encoded as a vector with a
                        non-zero in the <em>i</em>th location. </p>
                </li></ul></div>
         
         
            <h3 id="data-wrangler-transform-cat-encode-similarity">Similarity
                    encode</h3>
            <p>Use similarity encoding when you have the following:</p>
            <div class="itemizedlist">
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>A large number of categorical variables</p>
                </li><li class="listitem">
                    <p>Noisy data</p>
                </li></ul></div>
            <p>The similarity encoder creates embeddings for columns with categorical data. An
                embedding is a mapping of discrete objects, such as words, to vectors of real
                numbers. It encodes similar strings to vectors containing similar values. For
                example, it creates very similar encodings for "California" and "Calfornia".</p>
            <p>Data Wrangler converts each category in your dataset into a set of tokens using a 3-gram
                tokenizer. It converts the tokens into an embedding using min-hash encoding.</p>
            <p>The following example shows how the similarity encoder creates vectors from
                strings.</p>
            <div class="mediaobject">
                 
                    <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/destination-nodes/similarity-encode-example-screenshot-0.png" class="aws-docs-img-whiteBg aws-docs-img-padding" style="max-width:90%" />
                 
            </div>
            <div class="mediaobject">
                 
                    <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/destination-nodes/similarity-encode-example-screenshot-1.png" class="aws-docs-img-whiteBg aws-docs-img-padding" style="max-width:90%" />
                 
            </div>
            <p>The similarity encodings that Data Wrangler creates:</p>
            <div class="itemizedlist">
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Have low dimensionality</p>
                </li><li class="listitem">
                    <p>Are scalable to a large number of categories</p>
                </li><li class="listitem">
                    <p>Are robust and resistant to noise</p>
                </li></ul></div>
            <p>For the preceding reasons, similarity encoding is more versatile than one-hot
                encoding.</p>
            <p>To add the similarity encoding transform to your dataset, use the following
                procedure.</p>
            <div class="procedure"><p>To use similarity encoding, do the following.</p><ol><li>
                    <p>Sign in to the <a href="https://console.aws.amazon.com/sagemaker/" rel="noopener noreferrer" target="_blank"><span>Amazon SageMaker
                            Console</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                </li><li>
                    <p>Choose <b>Open Studio</b>.</p>
                </li><li>
                    <p>Choose <b>Launch app</b>.</p>
                </li><li>
                    <p>Choose <b>Studio</b>.</p>
                </li><li>
                    <p>Specify your data flow.</p>
                </li><li>
                    <p>Choose a step with a transformation.</p>
                </li><li>
                    <p>Choose <b>Add step</b>.</p>
                </li><li>
                    <p>Choose <b>Encode categorical</b>.</p>
                </li><li>
                    <p>Specify the following:</p>
                    <div class="itemizedlist">
                         
                         
                         
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p><b>Transform</b> – <b>Similarity
                                    encode</b></p>
                        </li><li class="listitem">
                            <p><b>Input column</b> – The column containing
                                the categorical data that you're encoding.</p>
                        </li><li class="listitem">
                            <p><b>Target dimension</b> – (Optional) The
                                dimension of the categorical embedding vector. The default value is
                                30. We recommend using a larger target dimension if you have a large
                                dataset with many categories.</p>
                        </li><li class="listitem">
                            <p><b>Output style</b> – Choose
                                    <b>Vector</b> for a single vector with all of the
                                encoded values. Choose <b>Column</b> to have the
                                encoded values in separate columns.</p>
                        </li><li class="listitem">
                            <p><b>Output column</b> – (Optional) The name of
                                the output column for a vector encoded output. For a column-encoded
                                output, this is the prefix of the column names followed by listed
                                number.</p>
                        </li></ul></div>
                </li></ol></div>
         
     
        <h2 id="data-wrangler-transform-featurize-text">Featurize Text</h2>
        <p>Use the <b>Featurize Text</b> transform group to inspect string-typed
            columns and use text embedding to featurize these columns. </p>
        <p>This feature group contains two features, <em>Character
                statistics</em> and <em>Vectorize</em>. Use the
            following sections to learn more about these transforms. For both options, the
                <b>Input column</b> must contain text data (string type).</p>
         
            <h3 id="data-wrangler-transform-featurize-text-character-stats">Character
                    Statistics</h3>
            <p>Use <b>Character statistics</b> to generate statistics for each row
                in a column containing text data. </p>
            <p>This transform computes the following ratios and counts for each row, and creates
                a new column to report the result. The new column is named using the input column
                name as a prefix and a suffix that is specific to the ratio or count. </p>
            <div class="itemizedlist">
                 
                 
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p><b>Number of words</b>: The total number of
                        words in that row. The suffix for this output column is
                            <code class="code">-stats_word_count</code>.</p>
                </li><li class="listitem">
                    <p><b>Number of characters</b>: The total number of
                        characters in that row. The suffix for this output column is
                            <code class="code">-stats_char_count</code>.</p>
                </li><li class="listitem">
                    <p><b>Ratio of upper</b>: The number of uppercase
                        characters, from A to Z, divided by all characters in the column. The suffix
                        for this output column is <code class="code">-stats_capital_ratio</code>.</p>
                </li><li class="listitem">
                    <p><b>Ratio of lower</b>: The number of lowercase
                        characters, from a to z, divided by all characters in the column. The suffix
                        for this output column is <code class="code">-stats_lower_ratio</code>.</p>
                </li><li class="listitem">
                    <p><b>Ratio of digits</b>: The ratio of digits in a
                        single row over the sum of digits in the input column. The suffix for this
                        output column is <code class="code">-stats_digit_ratio</code>.</p>
                </li><li class="listitem">
                    <p><b>Special characters ratio</b>: The ratio of
                        non-alphanumeric (characters like #$&amp;%:@) characters to over the sum of
                        all characters in the input column. The suffix for this output column is
                            <code class="code">-stats_special_ratio</code>.</p>
                </li></ul></div>
         
         
            <h3 id="data-wrangler-transform-featurize-text-vectorize">Vectorize</h3>
            <p>Text embedding involves mapping words or phrases from a vocabulary to vectors of
                real numbers. Use the Data Wrangler text embedding transform to tokenize and vectorize text
                data into term frequency–inverse document frequency (TF-IDF) vectors. </p>
            <p>When TF-IDF is calculated for a column of text data, each word in each sentence is
                converted to a real number that represents its semantic importance. Higher numbers
                are associated with less frequent words, which tend to be more meaningful. </p>
            <p>When you define a <b>Vectorize</b> transform step, Data Wrangler uses the
                data in your dataset to define
                the
                count vectorizer and TF-IDF methods .
                Running a Data Wrangler job uses these same methods.</p>
            <p>You configure this transform using the following: </p>
            <div class="itemizedlist">
                 
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p><b>Output column name</b>: This transform creates a new
                        column with the text embedding. Use this field to specify a name for this
                        output column. </p>
                </li><li class="listitem">
                    <p><b>Tokenizer</b>: A tokenizer converts the sentence into a
                        list of words, or <em>tokens</em>. </p>
                    <p>Choose <b>Standard</b> to use a tokenizer that splits by
                        white space and converts each word to lowercase. For example, <code class="code">"Good
                            dog"</code> is tokenized to <code class="code">["good","dog"]</code>.</p>
                    <p>Choose <b>Custom</b> to use a customized tokenizer. If you
                        choose <b>Custom</b>, you can use the following fields to
                        configure the tokenizer:</p>
                    <div class="itemizedlist">
                         
                         
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p><b>Minimum token length</b>: The minimum length, in
                                characters, for a token to be valid. Defaults to <code class="code">1</code>. For
                                example, if you specify <code class="code">3</code> for minimum token length,
                                words like <code class="code">a, at, in</code> are dropped from the tokenized
                                sentence. </p>
                        </li><li class="listitem">
                            <p><b>Should regex split on gaps</b>: If selected,
                                    <b>regex</b> splits on gaps. Otherwise, it matches
                                tokens. Defaults to <code class="code">True</code>. </p>
                        </li><li class="listitem">
                            <p><b>Regex pattern</b>: Regex pattern that defines the
                                tokenization process. Defaults to <code class="code">' \\ s+'</code>.</p>
                        </li><li class="listitem">
                            <p><b>To lowercase</b>: If chosen, Data Wrangler converts
                                all
                                characters to lowercase before tokenization. Defaults to
                                    <code class="code">True</code>.</p>
                        </li></ul></div>
                    <p>To learn more, see the Spark documentation on <a href="https://spark.apache.org/docs/3.0.0/ml-features#tokenizer" rel="noopener noreferrer" target="_blank"><span>Tokenizer</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                </li><li class="listitem">
                    <p><b>Vectorizer</b>: The vectorizer converts the list of
                        tokens into a sparse numeric vector. Each token corresponds to an index in
                        the vector and a non-zero indicates the existence of the token in the input
                        sentence. You can choose from two vectorizer options, <em>Count</em> and <em>Hashing</em>.</p>
                    <div class="itemizedlist">
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p><b>Count vectorize</b> allows customizations that
                                filter infrequent or too common tokens. <b>Count vectorize
                                    parameters</b> include the following: </p>
                            <div class="itemizedlist">
                                 
                                 
                                 
                                 
                                 
                            <ul class="itemizedlist"><li class="listitem">
                                    <p><b>Minimum term frequency</b>: In each row,
                                        terms (tokens) with smaller frequency are filtered. If you
                                        specify an integer, this is an absolute threshold
                                        (inclusive). If you specify a fraction between 0 (inclusive)
                                        and 1, the threshold is relative to the total term count.
                                        Defaults to <code class="code">1</code>.</p>
                                </li><li class="listitem">
                                    <p><b>Minimum document frequency</b>: Minimum
                                        number of rows in which a term (token) must appear to be
                                        included. If you specify an integer, this is an absolute
                                        threshold (inclusive). If you specify a fraction between 0
                                        (inclusive) and 1, the threshold is relative to the total
                                        term count. Defaults to <code class="code">1</code>.</p>
                                </li><li class="listitem">
                                    <p><b>Maximum document frequency</b>: Maximum
                                        number of documents (rows) in which a term (token) can
                                        appear to be included. If you specify an integer, this is an
                                        absolute threshold (inclusive). If you specify a fraction
                                        between 0 (inclusive) and 1, the threshold is relative to
                                        the total term count. Defaults to <code class="code">0.999</code>.</p>
                                </li><li class="listitem">
                                    <p><b>Maximum vocabulary size</b>: Maximum size
                                        of the vocabulary. The vocabulary is made up of all terms
                                        (tokens) in all rows of the column. Defaults to
                                            <code class="code">262144</code>.</p>
                                </li><li class="listitem">
                                    <p><b>Binary outputs</b>: If selected, the
                                        vector outputs do not include the number of appearances of a
                                        term in a document, but rather are a binary indicator of its
                                        appearance. Defaults to <code class="code">False</code>.</p>
                                </li></ul></div>
                            <p>To learn more about this option, see the Spark documentation on
                                    <a href="https://spark.apache.org/docs/3.0.0/ml-features#countvectorizer" rel="noopener noreferrer" target="_blank"><span>CountVectorizer</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                        </li><li class="listitem">
                            <p><b>Hashing</b> is computationally faster.
                                    <b>Hash vectorize parameters</b> includes the
                                following:</p>
                            <div class="itemizedlist">
                                 
                            <ul class="itemizedlist"><li class="listitem">
                                    <p><b>Number of features during hashing</b>: A
                                        hash vectorizer maps tokens to a vector index according to
                                        their hash value. This feature determines the number of
                                        possible hash values. Large values result in fewer
                                        collisions between hash values but a higher dimension output
                                        vector.</p>
                                </li></ul></div>
                            <p>To learn more about this option, see the Spark documentation on
                                    <a href="https://spark.apache.org/docs/3.0.0/ml-features#featurehasher" rel="noopener noreferrer" target="_blank"><span>FeatureHasher</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a></p>
                        </li></ul></div>
                </li><li class="listitem">
                    <p><b>Apply IDF</b> applies an IDF transformation, which
                        multiplies the term frequency with the standard inverse document frequency
                        used for TF-IDF embedding. <b>IDF parameters</b> include the
                        following: </p>
                    <div class="itemizedlist">
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p><b>Minimum document frequency </b>: Minimum number
                                of documents (rows) in which a term (token) must appear to be
                                included. If <b>count_vectorize</b> is the chosen
                                vectorizer, we recommend that you keep the default value and only
                                modify the <b>min_doc_freq</b> field in
                                    <b>Count vectorize parameters</b>. Defaults to
                                    <code class="code">5</code>.</p>
                        </li></ul></div>
                </li><li class="listitem">
                    <p><b> Output format</b>:The output format of each row. </p>
                    <div class="itemizedlist">
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>Select <b>Vector</b> to produce a single column with
                                a sparse vector. </p>
                        </li><li class="listitem">
                            <p>Select <b>Flattened</b> to create a column for every
                                category with an indicator variable for whether the text in the
                                original column contains a value that is equal to that category. You
                                can only choose flattened when <b>Vectorizer</b> is
                                set as <b>Count vectorizer</b>.</p>
                        </li></ul></div>
                </li></ul></div>
         
     
        <h2 id="data-wrangler-transform-time-series">Transform Time Series</h2>
        <p>In Data Wrangler, you can transform time series data. The values in a time series dataset are
            indexed to specific time. For example, a dataset that shows the number of customers in a
            store for each hour in a day is a time series dataset. The following table shows an
            example of a time series dataset.</p>
        <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31b5"><thead><tr><th class="table-header" colspan="100"><div class="title">Hourly number of customers in a store</div></th></tr>
                    <tr>
                        <th>Number of customers</th>
                        <th>Time (hour)</th>
                    </tr>
                </thead>
                    <tr>
                        <td tabindex="-1">4</td>
                        <td tabindex="-1">09:00</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">10</td>
                        <td tabindex="-1">10:00</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">14</td>
                        <td tabindex="-1">11:00</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">25</td>
                        <td tabindex="-1">12:00</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">20</td>
                        <td tabindex="-1">13:00</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">18</td>
                        <td tabindex="-1">14:00</td>
                    </tr>
                </table></div></div>
        <p>For the preceding table, the <b>Number of Customers</b> column contains
            the time series data. The time series data is indexed on the hourly data in the
                <b>Time (hour)</b> column.</p>
        <p>You might need to perform a series of transformations on your data to get it in a
            format that you can use for your analysis. Use the <b>Time series</b>
            transform group to transform your time series data. For more information about the
            transformations that you can perform, see the following sections.</p>
        <div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="data-wrangler-transform.html#data-wrangler-group-by-time-series">Group by a Time Series</a></li><li><a href="data-wrangler-transform.html#data-wrangler-resample-time-series">Resample Time Series
                    Data</a></li><li><a href="data-wrangler-transform.html#data-wrangler-transform-handle-missing-time-series">Handle Missing
                    Time Series Data</a></li><li><a href="data-wrangler-transform.html#data-wrangler-transform-validate-timestamp">Validate the Timestamp
                    of Your Time Series Data</a></li><li><a href="data-wrangler-transform.html#data-wrangler-transform-standardize-length">Standardizing the
                    Length of the Time Series</a></li><li><a href="data-wrangler-transform.html#data-wrangler-transform-extract-time-series-features">Extract
                    Features from Your Time Series Data</a></li><li><a href="data-wrangler-transform.html#data-wrangler-transform-lag-time-series">Use Lagged Features from
                    Your Time Series Data</a></li><li><a href="data-wrangler-transform.html#data-wrangler-transform-datetime-range">Create a Datetime Range In Your
                    Time Series</a></li><li><a href="data-wrangler-transform.html#data-wrangler-transform-rolling-window">Use a Rolling Window In Your Time
                    Series</a></li></ul></div>
         
            <h3 id="data-wrangler-group-by-time-series">Group by a Time Series</h3>
            <p>You can use the group by operation to group time series data for specific values
                in a column.</p>
            <p>For example, you have the following table that tracks the average daily
                electricity usage in a household.</p>
            <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c13b7"><thead><tr><th class="table-header" colspan="100"><div class="title">Average daily household electricity usage</div></th></tr>
                        <tr>
                            <th>Household ID</th>
                            <th>Daily timestamp</th>
                            <th>Electricity usage (kWh)</th>
                            <th>Number of household occupants</th>
                        </tr>
                    </thead>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">1/1/2020</td>
                            <td tabindex="-1">30</td>
                            <td tabindex="-1">2</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">1/2/2020</td>
                            <td tabindex="-1">40</td>
                            <td tabindex="-1">2</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">1/4/2020</td>
                            <td tabindex="-1">35</td>
                            <td tabindex="-1">3</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_1</td>
                            <td tabindex="-1">1/2/2020</td>
                            <td tabindex="-1">45</td>
                            <td tabindex="-1">3</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_1</td>
                            <td tabindex="-1">1/3/2020</td>
                            <td tabindex="-1">55</td>
                            <td tabindex="-1">4</td>
                        </tr>
                    </table></div></div>
            <p>If you choose to group by ID, you get the following table.</p>
            <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c13c11"><thead><tr><th class="table-header" colspan="100"><div class="title">Electricity usage grouped by household ID</div></th></tr>
                        <tr>
                            <th>Household ID</th>
                            <th>Electricity usage series (kWh)</th>
                            <th>Number of household occupants series</th>
                        </tr>
                    </thead>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">[30, 40, 35]</td>
                            <td tabindex="-1">[2, 2, 3]</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_1</td>
                            <td tabindex="-1">[45, 55]</td>
                            <td tabindex="-1">[3, 4]</td>
                        </tr>
                    </table></div></div>
            <p>Each entry in the time series sequence is ordered by the corresponding timestamp.
                The first element of the sequence corresponds to the first timestamp of the series.
                For <code class="code">household_0</code>, <code class="code">30</code> is the first value of the
                    <b>Electricity Usage Series</b>. The value of <code class="code">30</code>
                corresponds to the first timestamp of <code class="code">1/1/2020</code>.</p>
            <p>You can include the starting timestamp and ending timestamp. The following table
                shows how that information appears.</p>
            <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c13c17"><thead><tr><th class="table-header" colspan="100"><div class="title">Electricity usage grouped by household ID</div></th></tr>
                        <tr>
                            <th>Household ID</th>
                            <th>Electricity usage series (kWh)</th>
                            <th>Number of household occupants series</th>
                            <th>Start_time</th>
                            <th>End_time</th>
                        </tr>
                    </thead>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">[30, 40, 35]</td>
                            <td tabindex="-1">[2, 2, 3]</td>
                            <td tabindex="-1">1/1/2020</td>
                            <td tabindex="-1">1/4/2020</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_1</td>
                            <td tabindex="-1">[45, 55]</td>
                            <td tabindex="-1">[3, 4]</td>
                            <td tabindex="-1">1/2/2020</td>
                            <td tabindex="-1">1/3/2020</td>
                        </tr>
                    </table></div></div>
         
        <p>You can use the following procedure to group by a time series column. </p>
        <div class="procedure"><ol><li>
                <p>Open your Data Wrangler data flow.</p>
            </li><li>
                <p>If you haven't imported your dataset, import it under the <b>Import
                        data</b> tab.</p>
            </li><li>
                <p>In your data flow, under <b>Data types</b>, choose the
                        <b>+</b>, and select <b>Add
                    transform</b>.</p>
            </li><li>
                <p>Choose <b>Add step</b>.</p>
            </li><li>
                <p>Choose <b>Time Series</b>.</p>
            </li><li>
                <p>Under <b>Transform</b>, choose <b>Group
                    by</b>.</p>
            </li><li>
                <p>Specify a column in <b>Group by this column</b>.</p>
            </li><li>
                <p>For <b>Apply to columns</b>, specify a value.</p>
            </li><li>
                <p>Choose <b>Preview</b> to generate a preview of the
                    transform.</p>
            </li><li>
                <p>Choose <b>Add</b> to add the transform to the Data Wrangler data
                    flow.</p>
            </li></ol></div>
         
            <h3 id="data-wrangler-resample-time-series">Resample Time Series
                    Data</h3>
            <p>Time series data usually has observations that aren't taken at regular intervals.
                For example, a dataset could have some observations that are recorded hourly and
                other observations that are recorded every two hours.</p>
            <p>Many analyses, such as forecasting algorithms, require the observations to be
                taken at regular intervals. Resampling gives you the ability to establish regular
                intervals for the observations in your dataset.</p>
            <p>You can either upsample or downsample a time series. Downsampling increases the
                interval between observations in the dataset. For example, if you downsample
                observations that are taken either every hour or every two hours, each observation
                in your dataset is taken every two hours. The hourly observations are aggregated
                into a single value using an aggregation method such as the mean or median.</p>
            <p>Upsampling reduces the interval between observations in the dataset. For example,
                if you upsample observations that are taken every two hours into hourly
                observations, you can use an interpolation method to infer hourly observations from
                the ones that have been taken every two hours. For information on interpolation
                methods, see <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html" rel="noopener noreferrer" target="_blank"><span>pandas.DataFrame.interpolate</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            <p>You can resample both numeric and non-numeric data.</p>
            <p>Use the <b>Resample</b> operation to resample your time series data.
                If you have multiple time series in your dataset, Data Wrangler standardizes the time
                interval for each time series.</p>
            <p>The following table shows an example of downsampling time series data by using the
                mean as the aggregation method. The data is downsampled from every two hours to
                every hour.</p>
            <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c19c17"><thead><tr><th class="table-header" colspan="100"><div class="title">Hourly temperature readings over a day before downsampling</div></th></tr>
                        <tr>
                            <th>Timestamp</th>
                            <th>Temperature (Celsius)</th>
                        </tr>
                    </thead>
                        <tr>
                            <td tabindex="-1">12:00</td>
                            <td tabindex="-1">30</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">1:00</td>
                            <td tabindex="-1">32</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">2:00</td>
                            <td tabindex="-1">35</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">3:00</td>
                            <td tabindex="-1">32</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">4:00</td>
                            <td tabindex="-1">30</td>
                        </tr>
                    </table></div></div>
            <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c19c19"><thead><tr><th class="table-header" colspan="100"><div class="title">Temperature readings downsampled to every two hours</div></th></tr>
                        <tr>
                            <th>Timestamp</th>
                            <th>Temperature (Celsius)</th>
                        </tr>
                    </thead>
                        <tr>
                            <td tabindex="-1">12:00</td>
                            <td tabindex="-1">30</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">2:00</td>
                            <td tabindex="-1">33.5</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">4:00</td>
                            <td tabindex="-1">35</td>
                        </tr>
                    </table></div></div>
            <p>You can use the following procedure to resample time series data.</p>
            <div class="procedure"><ol><li>
                    <p>Open your Data Wrangler data flow.</p>
                </li><li>
                    <p>If you haven't imported your dataset, import it under the <b>Import
                            data</b> tab.</p>
                </li><li>
                    <p>In your data flow, under <b>Data types</b>, choose the
                            <b>+</b>, and select <b>Add
                        transform</b>.</p>
                </li><li>
                    <p>Choose <b>Add step</b>.</p>
                </li><li>
                    <p>Choose <b>Resample</b>.</p>
                </li><li>
                    <p>For <b>Timestamp</b>, choose the timestamp column.</p>
                </li><li>
                    <p>For <b>Frequency unit</b>, specify the frequency that you're
                        resampling.</p>
                </li><li>
                    <p>(Optional) Specify a value for <b>Frequency
                        quantity</b>.</p>
                </li><li>
                    <p>Configure the transform by specifying the remaining fields.</p>
                </li><li>
                    <p>Choose <b>Preview</b> to generate a preview of the
                        transform.</p>
                </li><li>
                    <p>Choose <b>Add</b> to add the transform to the Data Wrangler data
                        flow.</p>
                </li></ol></div>
         
         
            <h3 id="data-wrangler-transform-handle-missing-time-series">Handle Missing
                    Time Series Data</h3>
            <p>If you have missing values in your dataset, you can do one of the
                following:</p>
            <div class="itemizedlist">
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>For datasets that have multiple time series, drop the time series that
                        have missing values that are greater than a threshold that you
                        specify.</p>
                </li><li class="listitem">
                    <p>Impute the missing values in a time series by using other values in the
                        time series.</p>
                </li></ul></div>
            <p>Imputing a missing value involves replacing the data by either specifying a value
                or by using an inferential method. The following are the methods that you can use
                for imputation:</p>
            <div class="itemizedlist">
                 
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Constant value – Replace all the missing data in your dataset with a
                        value that you specify.</p>
                </li><li class="listitem">
                    <p>Most common value – Replace all the missing data with the value that
                        has the highest frequency in the dataset.</p>
                </li><li class="listitem">
                    <p>Forward fill – Use a forward fill to replace the missing values with
                        the non-missing value that precedes the missing values. For the sequence:
                        [2, 4, 7, NaN, NaN, NaN, 8], all of the missing values are replaced with 7.
                        The sequence that results from using a forward fill is [2, 4, 7, 7, 7, 7,
                        8].</p>
                </li><li class="listitem">
                    <p>Backward fill – Use a backward fill to replace the missing values
                        with the non-missing value that follows the missing values. For the
                        sequence: [2, 4, 7, NaN, NaN, NaN, 8], all of the missing values are
                        replaced with 8. The sequence that results from using a backward fill is [2,
                        4, 7, 8, 8, 8, 8]. </p>
                </li><li class="listitem">
                    <p>Interpolate – Uses an interpolation function to impute the missing
                        values. For more information on the functions that you can use for
                        interpolation, see <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html" rel="noopener noreferrer" target="_blank"><span>pandas.DataFrame.interpolate</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                </li></ul></div>
            <p>Some of the imputation methods might not be able to impute of all the missing
                value in your dataset. For example, a <b>Forward fill</b> can't impute
                a missing value that appears at the beginning of the time series. You can impute the
                values by using either a forward fill or a backward fill.</p>
            <p>You can either impute missing values within a cell or within a column.</p>
            <p>The following example shows how values are imputed within a cell.</p>
            <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c21c17"><thead><tr><th class="table-header" colspan="100"><div class="title">Electricity usage with missing values</div></th></tr>
                        <tr>
                            <th>Household ID</th>
                            <th>Electricity usage series (kWh)</th>
                        </tr>
                    </thead>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">[30, 40, 35, NaN, NaN]</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_1</td>
                            <td tabindex="-1">[45, NaN, 55]</td>
                        </tr>
                    </table></div></div>
            <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c21c19"><thead><tr><th class="table-header" colspan="100"><div class="title">Electricity usage with values imputed using a forward fill</div></th></tr>
                        <tr>
                            <th>Household ID</th>
                            <th>Electricity usage series (kWh)</th>
                        </tr>
                    </thead>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">[30, 40, 35, 35, 35]</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_1</td>
                            <td tabindex="-1">[45, 45, 55]</td>
                        </tr>
                    </table></div></div>
            <p>The following example shows how values are imputed within a column.</p>
            <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c21c23"><thead><tr><th class="table-header" colspan="100"><div class="title">Average daily household electricity usage with missing values</div></th></tr>
                        <tr>
                            <th>Household ID</th>
                            <th>Electricity usage (kWh)</th>
                        </tr>
                    </thead>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">30</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">40</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">NaN</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_1</td>
                            <td tabindex="-1">NaN</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_1</td>
                            <td tabindex="-1">NaN</td>
                        </tr>
                    </table></div></div>
            <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c21c25"><thead><tr><th class="table-header" colspan="100"><div class="title">Average daily household electricity usage with values imputed using a forward
                    fill</div></th></tr>
                        <tr>
                            <th>Household ID</th>
                            <th>Electricity usage (kWh)</th>
                        </tr>
                    </thead>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">30</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">40</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_0</td>
                            <td tabindex="-1">40</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_1</td>
                            <td tabindex="-1">40</td>
                        </tr>
                        <tr>
                            <td tabindex="-1">household_1</td>
                            <td tabindex="-1">40</td>
                        </tr>
                    </table></div></div>
            <p>You can use the following procedure to handle missing values.</p>
            <div class="procedure"><ol><li>
                    <p>Open your Data Wrangler data flow.</p>
                </li><li>
                    <p>If you haven't imported your dataset, import it under the <b>Import
                            data</b> tab.</p>
                </li><li>
                    <p>In your data flow, under <b>Data types</b>, choose the
                            <b>+</b>, and select <b>Add
                        transform</b>.</p>
                </li><li>
                    <p>Choose <b>Add step</b>.</p>
                </li><li>
                    <p>Choose <b>Handle missing</b>.</p>
                </li><li>
                    <p>For <b>Time series input type</b>, choose whether you want
                        to handle missing values inside of a cell or along a column.</p>
                </li><li>
                    <p>For <b>Impute missing values for this column</b>, specify
                        the column that has the missing values.</p>
                </li><li>
                    <p>For <b>Method for imputing values</b>, select a
                        method.</p>
                </li><li>
                    <p>Configure the transform by specifying the remaining fields.</p>
                </li><li>
                    <p>Choose <b>Preview</b> to generate a preview of the
                        transform.</p>
                </li><li>
                    <p>If you have missing values, you can specify a method for imputing them
                        under <b>Method for imputing values</b>.</p>
                </li><li>
                    <p>Choose <b>Add</b> to add the transform to the Data Wrangler data
                        flow.</p>
                </li></ol></div>
         
         
            <h3 id="data-wrangler-transform-validate-timestamp">Validate the Timestamp
                    of Your Time Series Data</h3>
            <p>You might have time stamp data that is invalid. You can use the <b>Validate
                    time stamp</b> function to determine whether the timestamps in your
                dataset are valid. Your timestamp can be invalid for one or more of the following
                reasons:</p>
            <div class="itemizedlist">
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Your timestamp column has missing values.</p>
                </li><li class="listitem">
                    <p>The values in your timestamp column are not formatted correctly.</p>
                </li></ul></div>
            <p>If you have invalid timestamps in your dataset, you can't perform your analysis
                successfully. You can use Data Wrangler to identify invalid timestamps and understand where
                you need to clean your data.</p>
            <p>The time series validation works in one of the two ways:</p>
            <p>You can configure Data Wrangler to do one of the following if it encounters missing values
                in your dataset:</p>
            <div class="itemizedlist">
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Drop the rows that have the missing or invalid values.</p>
                </li><li class="listitem">
                    <p>Identify the rows that have the missing or invalid values.</p>
                </li><li class="listitem">
                    <p>Throw an error if it finds any missing or invalid values in your
                        dataset.</p>
                </li></ul></div>
            <p>You can validate the timestamps on columns that either have the
                    <code class="code">timestamp</code> type or the <code class="code">string</code> type. If the column has
                the <code class="code">string</code> type, Data Wrangler converts the type of the column to
                    <code class="code">timestamp</code> and performs the validation.</p>
            <p>You can use the following procedure to validate the timestamps in your
                dataset.</p>
         
        <div class="procedure"><ol><li>
                <p>Open your Data Wrangler data flow.</p>
            </li><li>
                <p>If you haven't imported your dataset, import it under the <b>Import
                        data</b> tab.</p>
            </li><li>
                <p>In your data flow, under <b>Data types</b>, choose the
                        <b>+</b>, and select <b>Add
                    transform</b>.</p>
            </li><li>
                <p>Choose <b>Add step</b>.</p>
            </li><li>
                <p>Choose <b>Validate timestamps</b>.</p>
            </li><li>
                <p>For <b>Timestamp Column</b>, choose the timestamp column.</p>
            </li><li>
                <p>For <b>Policy</b>, choose whether you want to handle missing
                    timestamps.</p>
            </li><li>
                <p>(Optional) For <b>Output column</b>, specify a name for the
                    output column.</p>
            </li><li>
                <p>If the date time column is formatted for the string type, choose
                        <b>Cast to datetime</b>.</p>
            </li><li>
                <p>Choose <b>Preview</b> to generate a preview of the
                    transform.</p>
            </li><li>
                <p>Choose <b>Add</b> to add the transform to the Data Wrangler data
                    flow.</p>
            </li></ol></div>
         
            <h3 id="data-wrangler-transform-standardize-length">Standardizing the
                    Length of the Time Series</h3>
            <p>If you have time series data stored as arrays, you can standardize each time
                series to the same length. Standardizing the length of the time series array might
                make it easier for you to perform your analysis on the data.</p>
            <p>You can standardize your time series for data transformations that require the
                length of your data to be fixed.</p>
            <p>Many ML algorithms require you to flatten your time series data before you use
                them. Flattening time series data is separating each value of the time series into
                its own column in a dataset. The number of columns in a dataset can't change, so the
                lengths of the time series need to be standardized between you flatten each array
                into a set of features.</p>
            <p>Each time series is set to the length that you specify as a quantile or percentile
                of the time series set. For example, you can have three sequences that have the
                following lengths:</p>
            <div class="itemizedlist">
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>3</p>
                </li><li class="listitem">
                    <p>4</p>
                </li><li class="listitem">
                    <p>5</p>
                </li></ul></div>
            <p>You can set the length of all of the sequences as the length of the sequence that
                has the 50th percentile length.</p>
            <p>Time series arrays that are shorter than the length you've specified have missing
                values added. The following is an example format of standardizing the time series to
                a longer length: [2, 4, 5, NaN, NaN, NaN].</p>
            <p>You can use different approaches to handle the missing values. For information on
                those approaches, see <a href="data-wrangler-transform.html#data-wrangler-transform-handle-missing-time-series">Handle Missing
                    Time Series Data</a>.</p>
            <p>The time series arrays that are longer than the length that you specify are
                truncated.</p>
            <p>You can use the following procedure to standardize the length of the time
                series.</p>
         
        <div class="procedure"><ol><li>
                <p>Open your Data Wrangler data flow.</p>
            </li><li>
                <p>If you haven't imported your dataset, import it under the <b>Import
                        data</b> tab.</p>
            </li><li>
                <p>In your data flow, under <b>Data types</b>, choose the
                        <b>+</b>, and select <b>Add
                    transform</b>.</p>
            </li><li>
                <p>Choose <b>Add step</b>.</p>
            </li><li>
                <p>Choose <b>Standardize length</b>.</p>
            </li><li>
                <p>For <b>Standardize the time series length for the column</b>,
                    choose a column.</p>
            </li><li>
                <p>(Optional) For <b>Output column</b>, specify a name for the
                    output column. If you don't specify a name, the transform is done in
                    place.</p>
            </li><li>
                <p>If the datetime column is formatted for the string type, choose <b>Cast
                        to datetime</b>.</p>
            </li><li>
                <p>Choose <b>Cutoff quantile</b> and specify a quantile to set the
                    length of the sequence.</p>
            </li><li>
                <p>Choose <b>Flatten the output</b> to output the values of the
                    time series into separate columns.</p>
            </li><li>
                <p>Choose <b>Preview</b> to generate a preview of the
                    transform.</p>
            </li><li>
                <p>Choose <b>Add</b> to add the transform to the Data Wrangler data
                    flow.</p>
            </li></ol></div>
         
            <h3 id="data-wrangler-transform-extract-time-series-features">Extract
                    Features from Your Time Series Data</h3>
            <p>If you're running a classification or a regression algorithm on your time series
                data, we recommend extracting features from the time series before running the
                algorithm. Extracting features might improve the performance of your
                algorithm.</p>
            <p>Use the following options to choose how you want to extract features from your
                data:</p>
            <div class="itemizedlist">
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Use <b>Minimal subset</b> to specify extracting 8 features
                        that you know are useful in downstream analyses. You can use a minimal
                        subset when you need to perform computations quickly. You can also use it
                        when your ML algorithm has a high risk of overfitting and you want to
                        provide it with fewer features.</p>
                </li><li class="listitem">
                    <p>Use <b>Efficient subset</b> to specify extracting the most
                        features possible without extracting features that are computationally
                        intensive in your analyses.</p>
                </li><li class="listitem">
                    <p>Use <b>All features</b> to specify extracting all features
                        from the tune series.</p>
                </li><li class="listitem">
                    <p>Use <b>Manual subset</b> to choose a list of features that
                        you think explain the variation in your data well.</p>
                </li></ul></div>
         
        <p>Use the following the procedure to extract features from your time series data.</p>
        <div class="procedure"><ol><li>
                <p>Open your Data Wrangler data flow.</p>
            </li><li>
                <p>If you haven't imported your dataset, import it under the <b>Import
                        data</b> tab.</p>
            </li><li>
                <p>In your data flow, under <b>Data types</b>, choose the
                        <b>+</b>, and select <b>Add
                    transform</b>.</p>
            </li><li>
                <p>Choose <b>Add step</b>.</p>
            </li><li>
                <p>Choose <b>Extract features</b>.</p>
            </li><li>
                <p>For <b>Extract features for this column</b>, choose a
                    column.</p>
            </li><li>
                <p>(Optional) Select <b>Flatten</b> to output the features into
                    separate columns.</p>
            </li><li>
                <p>For <b>Strategy</b>, choose a strategy to extract the
                    features.</p>
            </li><li>
                <p>Choose <b>Preview</b> to generate a preview of the
                    transform.</p>
            </li><li>
                <p>Choose <b>Add</b> to add the transform to the Data Wrangler data
                    flow.</p>
            </li></ol></div>
         
            <h3 id="data-wrangler-transform-lag-time-series">Use Lagged Features from
                    Your Time Series Data</h3>
            <p>For many use cases, the best way to predict the future behavior of your time
                series is to use its most recent behavior.</p>
            <p>The most common uses of lagged features are the following:</p>
            <div class="itemizedlist">
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Collecting a handful of past values. For example, for time, t + 1, you
                        collect t, t - 1, t - 2, and t - 3.</p>
                </li><li class="listitem">
                    <p>Collecting values that correspond to seasonal behavior in the data. For
                        example, to predict the occupancy in a restaurant at 1:00 PM, you might want
                        to use the features from 1:00 PM on the previous day. Using the features
                        from 12:00 PM or 11:00 AM on the same day might not be as predictive as
                        using the features from previous days.</p>
                </li></ul></div>
         
        <div class="procedure"><ol><li>
                <p>Open your Data Wrangler data flow.</p>
            </li><li>
                <p>If you haven't imported your dataset, import it under the <b>Import
                        data</b> tab.</p>
            </li><li>
                <p>In your data flow, under <b>Data types</b>, choose the
                        <b>+</b>, and select <b>Add
                    transform</b>.</p>
            </li><li>
                <p>Choose <b>Add step</b>.</p>
            </li><li>
                <p>Choose <b>Lag features</b>.</p>
            </li><li>
                <p>For <b>Generate lag features for this column</b>, choose a
                    column.</p>
            </li><li>
                <p>For <b>Timestamp Column</b>, choose the column containing the
                    timestamps.</p>
            </li><li>
                <p>For <b>Lag</b>, specify the duration of the lag.</p>
            </li><li>
                <p>(Optional) Configure the output using one of the following options:</p>
                <div class="itemizedlist">
                     
                     
                     
                <ul class="itemizedlist"><li class="listitem">
                        <p><b>Include the entire lag window</b></p>
                    </li><li class="listitem">
                        <p><b>Flatten the output</b></p>
                    </li><li class="listitem">
                        <p><b>Drop rows without history</b></p>
                    </li></ul></div>
            </li><li>
                <p>Choose <b>Preview</b> to generate a preview of the
                    transform.</p>
            </li><li>
                <p>Choose <b>Add</b> to add the transform to the Data Wrangler data
                    flow.</p>
            </li></ol></div>
         
            <h3 id="data-wrangler-transform-datetime-range">Create a Datetime Range In Your
                    Time Series</h3>
            <p>You might have time series data that don't have timestamps. If you know that the
                observations were taken at regular intervals, you can generate timestamps for the
                time series in a separate column. To generate timestamps, you specify the value for
                the start timestamp and the frequency of the timestamps.</p>
            <p>For example, you might have the following time series data for the number of
                customers at a restaurant.</p>
         
        <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c43"><thead><tr><th class="table-header" colspan="100"><div class="title">Time series data on the number of customers at a restaurant</div></th></tr>
                    <tr>
                        <th>Number of customers</th>
                    </tr>
                </thead>
                    <tr>
                        <td tabindex="-1">10</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">14</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">24</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">40</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">30</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">20</td>
                    </tr>
                </table></div></div>
        <p>If you know that the restaurant opened at 5:00 PM and that the observations are taken
            hourly, you can add a timestamp column that corresponds to the time series data. You can
            see the timestamp column in the following table.</p>
        <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c31c47"><thead><tr><th class="table-header" colspan="100"><div class="title">Time series data on the number of customers at a restaurant</div></th></tr>
                    <tr>
                        <th>Number of customers</th>
                        <th>Timestamp</th>
                    </tr>
                </thead>
                    <tr>
                        <td tabindex="-1">10</td>
                        <td tabindex="-1">1:00 PM</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">14</td>
                        <td tabindex="-1">2:00 PM</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">24</td>
                        <td tabindex="-1">3:00 PM</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">40</td>
                        <td tabindex="-1">4:00 PM</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">30</td>
                        <td tabindex="-1">5:00 PM</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">20</td>
                        <td tabindex="-1">6:00 PM</td>
                    </tr>
                </table></div></div>
        <p>Use the following procedure to add a datetime range to your data.</p>
        <div class="procedure"><ol><li>
                <p>Open your Data Wrangler data flow.</p>
            </li><li>
                <p>If you haven't imported your dataset, import it under the <b>Import
                        data</b> tab.</p>
            </li><li>
                <p>In your data flow, under <b>Data types</b>, choose the
                        <b>+</b>, and select <b>Add
                    transform</b>.</p>
            </li><li>
                <p>Choose <b>Add step</b>.</p>
            </li><li>
                <p>Choose <b>Datetime range</b>.</p>
            </li><li>
                <p>For <b>Frequency type</b>, choose the unit used to measure the
                    frequency of the timestamps.</p>
            </li><li>
                <p>For <b>Starting timestamp</b>, specify the start
                    timestamp.</p>
            </li><li>
                <p>For <b>Output column</b>, specify a name for the output
                    column.</p>
            </li><li>
                <p>(Optional) Configure the output using the remaining fields.</p>
            </li><li>
                <p>Choose <b>Preview</b> to generate a preview of the
                    transform.</p>
            </li><li>
                <p>Choose <b>Add</b> to add the transform to the Data Wrangler data
                    flow.</p>
            </li></ol></div>
         
            <h3 id="data-wrangler-transform-rolling-window">Use a Rolling Window In Your Time
                    Series</h3>
            <p>You can extract features over a time period. For example, for time, <em>t</em>, and a time window length of 3, and for the row that
                indicates the <em>t</em>th timestamp, we append the
                features that are extracted from the time series at times <em>t</em> - 3, <em>t</em> -2, and <em>t</em> - 1. For information on extracting features, see
                    <a href="data-wrangler-transform.html#data-wrangler-transform-extract-time-series-features">Extract
                    Features from Your Time Series Data</a>. </p>
            <p>You can use the following procedure to extract features over a time period.</p>
            <div class="procedure"><ol><li>
                    <p>Open your Data Wrangler data flow.</p>
                </li><li>
                    <p>If you haven't imported your dataset, import it under the <b>Import
                            data</b> tab.</p>
                </li><li>
                    <p>In your data flow, under <b>Data types</b>, choose the
                            <b>+</b>, and select <b>Add
                        transform</b>.</p>
                </li><li>
                    <p>Choose <b>Add step</b>.</p>
                </li><li>
                    <p>Choose <b>Rolling window features</b>.</p>
                </li><li>
                    <p>For <b>Generate rolling window features for this column</b>,
                        choose a column.</p>
                </li><li>
                    <p>For <b>Timestamp Column</b>, choose the column containing
                        the timestamps.</p>
                </li><li>
                    <p>(Optional) For <b>Output Column</b>, specify the name of the
                        output column.</p>
                </li><li>
                    <p>For <b>Window size</b>, specify the window size.</p>
                </li><li>
                    <p>For <b>Strategy</b>, choose the extraction strategy.</p>
                </li><li>
                    <p>Choose <b>Preview</b> to generate a preview of the
                        transform.</p>
                </li><li>
                    <p>Choose <b>Add</b> to add the transform to the Data Wrangler data
                        flow.</p>
                </li></ol></div>
         
     
        <h2 id="data-wrangler-transform-datetime-embed">Featurize Datetime</h2>
        <p>Use <b>Featurize date/time</b> to create a vector embedding representing
            a datetime field. To use this transform, your datetime data must be in one of the
            following formats: </p>
        <div class="itemizedlist">
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Strings describing datetime: For example, <code class="code">"January 1st, 2020,
                        12:44pm"</code>. </p>
            </li><li class="listitem">
                <p>A Unix timestamp: A Unix timestamp describes the number of seconds,
                    milliseconds, microseconds, or nanoseconds from 1/1/1970. </p>
            </li></ul></div>
        <p>You can choose to <b>Infer datetime format</b> and provide a
                <b>Datetime format</b>. If you provide a datetime format, you must use
            the codes described in the <a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes" rel="noopener noreferrer" target="_blank"><span>Python documentation</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>. The options you select for these two configurations
            have implications for the speed of the operation and the final results.</p>
        <div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>The most manual and computationally fastest option is to specify a
                        <b>Datetime format</b> and select <b>No</b> for
                        <b>Infer datetime format</b>.</p>
            </li><li class="listitem">
                <p>To reduce manual labor, you can choose <b>Infer datetime
                        format</b> and not specify a datetime format. It is also a
                    computationally fast operation; however, the first datetime format encountered
                    in the input column is assumed to be the format for the entire column. If there
                    are other formats in the column, these values are NaN in the final output.
                    Inferring the datetime format can give you unparsed strings. </p>
            </li><li class="listitem">
                <p>If you don't specify a format and select <b>No</b> for
                        <b>Infer datetime format</b>, you get the most robust results.
                    All the valid datetime strings are parsed. However, this operation can be an
                    order of magnitude slower than the first two options in this list. </p>
            </li></ul></div>
        <p>When you use this transform, you specify an <b>Input column</b> which
            contains datetime data in one of the formats listed above. The transform creates an
            output column named <b>Output column name</b>. The format of the output
            column depends on your configuration using the following:</p>
        <div class="itemizedlist">
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>Vector</b>: Outputs a single column as a vector. </p>
            </li><li class="listitem">
                <p><b>Columns</b>: Creates a new column for every feature. For
                    example, if the output contains a year, month, and day, three separate columns
                    are created for year, month, and day. </p>
            </li></ul></div>
        <p>Additionally, you must choose an <b>Embedding mode</b>. For linear
            models and deep networks, we recommend choosing <b>cyclic</b>. For
            tree-based algorithms, we recommend choosing <b>ordinal</b>.</p>
     
        <h2 id="data-wrangler-transform-format-string">Format String</h2>
        <p>The <b>Format string</b> transforms contain standard string formatting
            operations. For example, you can use these operations to remove special characters,
            normalize string lengths, and update string casing.</p>
        <p>This feature group contains the following transforms. All transforms return copies of
            the strings in the <b>Input column</b> and add the result to a new, output
            column.</p>
        <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c35b7"><thead>
                    <tr>
                        <th>Name</th>
                        <th>Function</th>
                    </tr>
                </thead>
                    <tr>
                        <td tabindex="-1">Left pad</td>
                        <td tabindex="-1">
                            <p>Left-pad the string with a given <b>Fill
                                    character</b> to the given <b>width</b>. If
                                the string is longer than <b>width</b>, the return
                                value is shortened to <b>width</b> characters.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Right pad</td>
                        <td tabindex="-1">
                            <p>Right-pad the string with a given <b>Fill
                                    character</b> to the given <b>width</b>. If
                                the string is longer than <b>width</b>, the return
                                value is shortened to <b>width</b> characters.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Center (pad on either side)</td>
                        <td tabindex="-1">
                            <p>Center-pad the string (add padding on both sides of the string)
                                with a given <b>Fill character</b> to the given
                                    <b>width</b>. If the string is longer than
                                    <b>width</b>, the return value is shortened to
                                    <b>width</b> characters.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Prepend zeros</td>
                        <td tabindex="-1">
                            <p>Left-fill a numeric string with zeros, up to a given
                                    <b>width</b>. If the string is longer than
                                    <b>width</b>, the return value is shortened to
                                    <b>width</b> characters.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Strip left and right</td>
                        <td tabindex="-1">
                            <p>Returns a copy of the string with the leading and trailing
                                characters removed.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Strip characters from left</td>
                        <td tabindex="-1">
                            <p>Returns a copy of the string with leading characters
                                removed.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Strip characters from right</td>
                        <td tabindex="-1">
                            <p>Returns a copy of the string with trailing characters
                                removed.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Lower case</td>
                        <td tabindex="-1">
                            <p>Convert all letters in text to lowercase.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Upper case</td>
                        <td tabindex="-1">
                            <p>Convert all letters in text to uppercase.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Capitalize</td>
                        <td tabindex="-1">
                            <p>Capitalize the first letter in each sentence. </p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Swap case</td>
                        <td tabindex="-1">Converts all uppercase characters to lowercase and all lowercase
                            characters to uppercase characters of the given string, and returns
                            it.</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Add prefix or suffix</td>
                        <td tabindex="-1">
                            <p>Adds a prefix and a suffix the string column. You must specify at
                                least one of <b>Prefix</b> and
                                    <b>Suffix</b>. </p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Remove symbols</td>
                        <td tabindex="-1">
                            <p>Removes given symbols from a string. All listed characters are
                                removed. Defaults to white space. </p>
                        </td>
                    </tr>
                </table></div></div>
     
        <h2 id="data-wrangler-transform-handle-outlier">Handle Outliers</h2>
        <p>Machine learning models are sensitive to the distribution and range of your feature
            values. Outliers, or rare values, can negatively impact model accuracy and lead to
            longer training times. Use this feature group to detect and update outliers in your
            dataset. </p>
        <p>When you define a <b>Handle outliers</b> transform step, the statistics
            used to detect outliers are generated on the data available in Data Wrangler when defining this
            step. These same statistics are used when running a Data Wrangler job. </p>
        <p>Use the following sections to learn more about the transforms this group contains. You
            specify an <b>Output name</b> and each of these transforms produces an
            output column with the resulting data. </p>
         
            <h3 id="data-wrangler-transform-handle-outlier-rstdev">Robust standard
                    deviation numeric outliers</h3>
            <p>This transform detects and fixes outliers in numeric features using statistics
                that are robust to outliers.</p>
            <p>You must define an <b>Upper quantile</b> and a <b>Lower
                    quantile</b> for the statistics used to calculate outliers. You must also
                specify the number of <b>Standard deviations</b> from which a value
                must vary from the mean to be considered an outlier. For example, if you specify 3
                for <b>Standard deviations</b>, a value must fall more than 3 standard
                deviations from the mean to be considered an outlier. </p>
            <p>The <b>Fix method</b> is the method used to handle outliers when
                they are detected. You can choose from the following:</p>
            <div class="itemizedlist">
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p><b>Clip</b>: Use this option to clip the outliers to the
                        corresponding outlier detection bound.</p>
                </li><li class="listitem">
                    <p><b>Remove</b>: Use this option to remove rows with outliers
                        from the dataframe.</p>
                </li><li class="listitem">
                    <p><b>Invalidate</b>: Use this option to replace outliers with
                        invalid values.</p>
                </li></ul></div>
         
         
            <h3 id="data-wrangler-transform-handle-outlier-sstdev">Standard Deviation
                    Numeric Outliers</h3>
            <p>This transform detects and fixes outliers in numeric features using the mean and
                standard deviation.</p>
            <p>You specify the number of <b>Standard deviations</b> a value must
                vary from the mean to be considered an outlier. For example, if you specify 3 for
                    <b>Standard deviations</b>, a value must fall more than 3 standard
                deviations from the mean to be considered an outlier. </p>
            <p>The <b>Fix method</b> is the method used to handle outliers when
                they are detected. You can choose from the following:</p>
            <div class="itemizedlist">
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p><b>Clip</b>: Use this option to clip the outliers to the
                        corresponding outlier detection bound.</p>
                </li><li class="listitem">
                    <p><b>Remove</b>: Use this option to remove rows with outliers
                        from the dataframe.</p>
                </li><li class="listitem">
                    <p><b>Invalidate</b>: Use this option to replace outliers with
                        invalid values.</p>
                </li></ul></div>
         
         
            <h3 id="data-wrangler-transform-handle-outlier-quantile-numeric">Quantile
                    Numeric Outliers</h3>
            <p>Use this transform to detect and fix outliers in numeric features using quantiles.
                You can define an <b>Upper quantile</b> and a <b>Lower
                    quantile</b>.
                All
                values that fall above the upper quantile or below the lower quantile are considered
                outliers. </p>
            <p>The <b>Fix method</b> is the method used to handle outliers when
                they are detected. You can choose from the following:</p>
            <div class="itemizedlist">
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p><b>Clip</b>: Use this option to clip the outliers to the
                        corresponding outlier detection bound.</p>
                </li><li class="listitem">
                    <p><b>Remove</b>: Use this option to remove rows with outliers
                        from the dataframe.</p>
                </li><li class="listitem">
                    <p><b>Invalidate</b>: Use this option to replace outliers with
                        invalid values. </p>
                </li></ul></div>
         
         
            <h3 id="data-wrangler-transform-handle-outlier-minmax-numeric">Min-Max
                    Numeric Outliers</h3>
         
        <p>This transform detects and fixes outliers in numeric features using upper and lower
            thresholds. Use this method if you know threshold values that demark outliers.</p>
        <p>You specify a <b>Upper threshold</b> and a <b>Lower
                threshold</b>, and if values fall above or below those thresholds
            respectively, they are considered outliers. </p>
        <p>The <b>Fix method</b> is the method used to handle outliers when they
            are detected. You can choose from the following:</p>
        <div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>Clip</b>: Use this option to clip the outliers to the
                    corresponding outlier detection bound.</p>
            </li><li class="listitem">
                <p><b>Remove</b>: Use this option to remove rows with outliers from
                    the dataframe.</p>
            </li><li class="listitem">
                <p><b>Invalidate</b>: Use this option to replace outliers with
                    invalid values. </p>
            </li></ul></div>
         
            <h3 id="data-wrangler-transform-handle-outlier-replace-rare">Replace
                    Rare</h3>
            <p>When you use the <b>Replace rare</b> transform, you specify a
                threshold and Data Wrangler finds all values that meet that threshold and replaces them with
                a string that you specify. For example, you may want to use this transform to
                categorize all outliers in a column into an "Others" category. </p>
            <div class="itemizedlist">
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p><b>Replacement string</b>: The string with which to replace
                        outliers.</p>
                </li><li class="listitem">
                    <p><b>Absolute threshold</b>: A category is rare if the number
                        of instances is less than or equal to this absolute threshold.</p>
                </li><li class="listitem">
                    <p><b>Fraction threshold</b>: A category is rare if the number
                        of instances is less than or equal to this fraction threshold multiplied by
                        the number of rows.</p>
                </li><li class="listitem">
                    <p><b>Max common categories</b>: Maximum not-rare categories
                        that remain after the operation. If the threshold does not filter enough
                        categories, those with the top number of appearances are classified as not
                        rare. If set to 0 (default), there is no hard limit to the number of
                        categories.</p>
                </li></ul></div>
         
     
        <h2 id="data-wrangler-transform-handle-missing">Handle Missing Values</h2>
        <p>Missing values are a common occurrence in machine learning datasets. In some
            situations, it is appropriate to impute missing data with a calculated value, such as an
            average or categorically common value. You can process missing values using the
                <b>Handle missing values</b> transform group. This group contains the
            following transforms. </p>
         
            <h3 id="data-wrangler-transform-fill-missing">Fill Missing</h3>
            <p>Use the <b>Fill missing</b> transform to replace missing values with
                a <b>Fill value</b> you define. </p>
         
         
            <h3 id="data-wrangler-transform-impute">Impute Missing</h3>
            <p>Use the <b>Impute missing</b> transform to create a new column that
                contains imputed values where missing values were found in input categorical and
                numerical data. The configuration depends on your data type.</p>
            <p>For numeric data, choose an imputing strategy, the strategy used to determine the
                new value to impute. You can choose to impute the mean or the median over the values
                that are present in your dataset. Data Wrangler uses the value that it computes to impute the
                missing values.</p>
            <p>For categorical data, Data Wrangler imputes missing values using the most frequent value in
                the column. To impute a custom string, use the <b>Fill missing</b>
                transform instead.</p>
         
         
            <h3 id="data-wrangler-transform-missing-add-indicator">Add Indicator for
                    Missing</h3>
            <p>Use the <b>Add indicator for missing</b> transform to create a new
                indicator column, which contains a Boolean <code class="code">"false"</code> if a row contains a
                value, and <code class="code">"true"</code> if a row contains a missing value. </p>
         
         
            <h3 id="data-wrangler-transform-drop-missing">Drop Missing</h3>
            <p>Use the <b>Drop missing</b> option to drop rows that contain missing
                values from the <b>Input column</b>.</p>
         
     
        <h2 id="data-wrangler-manage-columns">Manage Columns</h2>
        <p>You can use the following transforms to quickly update and manage columns in your
            dataset: </p>
        <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c41b5"><thead>
                    <tr>
                        <th>Name</th>
                        <th>Function</th>
                    </tr>
                </thead>
                    <tr>
                        <td tabindex="-1">Drop Column</td>
                        <td tabindex="-1">Delete a column. </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Duplicate Column</td>
                        <td tabindex="-1">Duplicate a column.</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Rename Column</td>
                        <td tabindex="-1">Rename a column.</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Move Column</td>
                        <td tabindex="-1">
                            <p>Move a column's location in the dataset. Choose to move your
                                column to the start or end of the dataset, before or after a
                                reference column, or to a specific index. </p>
                        </td>
                    </tr>
                </table></div></div>
     
        <h2 id="data-wrangler-transform-manage-rows">Manage Rows</h2>
        <p>Use this transform group to quickly perform sort and shuffle operations on rows. This
            group contains the following:</p>
        <div class="itemizedlist">
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>Sort</b>: Sort the entire dataframe by a given column. Select
                    the check box next to <b>Ascending order</b> for this option;
                    otherwise, deselect the check box and descending order is used for the sort.
                </p>
            </li><li class="listitem">
                <p><b>Shuffle</b>: Randomly shuffle all rows in the dataset.
                </p>
            </li></ul></div>
     
        <h2 id="data-wrangler-transform-manage-vectors">Manage Vectors</h2>
        <p>Use this transform group to combine or flatten vector columns. This group contains the
            following transforms. </p>
        <div class="itemizedlist">
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>Assemble</b>: Use this transform to combine Spark
                    vectors and numeric data into a single column. For example, you can combine
                    three columns: two containing numeric data and one containing vectors. Add all
                    the columns you want to combine in <b>Input columns</b> and
                    specify a <b>Output column name</b> for the combined data. </p>
            </li><li class="listitem">
                <p><b>Flatten</b>: Use this transform to flatten a single column
                    containing vector data. The input column must contain PySpark vectors or
                    array-like objects. You can control the number of columns created by specifying
                    a <b>Method to detect number of outputs</b>. For example, if you
                    select <b>Length of first vector</b>, the number of elements in
                    the first valid vector or array found in the column determines the number of
                    output columns that are created. All other input vectors with too many items are
                    truncated. Inputs with too few items are filled with NaNs.</p>
                <p>You also specify an <b>Output prefix</b>, which is used as the
                    prefix for each output column. </p>
            </li></ul></div>
     
        <h2 id="data-wrangler-transform-process-numeric">Process Numeric</h2>
        <p>Use the <b>Process Numeric</b> feature group to process numeric data.
            Each scalar in this group is defined using the Spark library. The following scalars are
            supported:</p>
        <div class="itemizedlist">
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>Standard Scaler</b>: Standardize the input column
                    by subtracting the mean from each value and scaling to unit variance. To learn
                    more, see the Spark documentation for <a href="https://spark.apache.org/docs/3.0.0/ml-features#standardscaler" rel="noopener noreferrer" target="_blank"><span>StandardScaler</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            </li><li class="listitem">
                <p><b>Robust Scaler</b>: Scale the input column using statistics
                    that are robust to outliers. To learn more, see the Spark documentation for
                        <a href="https://spark.apache.org/docs/3.0.0/ml-features#robustscaler" rel="noopener noreferrer" target="_blank"><span>RobustScaler</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            </li><li class="listitem">
                <p><b>Min Max Scaler</b>: Transform the input column by scaling
                    each feature to a given range. To learn more, see the Spark documentation for
                        <a href="https://spark.apache.org/docs/3.0.0/ml-features#minmaxscaler" rel="noopener noreferrer" target="_blank"><span>MinMaxScaler</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            </li><li class="listitem">
                <p><b>Max Absolute Scaler</b>: Scale the input column by dividing
                    each value by the maximum absolute value. To learn more, see the Spark
                    documentation for <a href="https://spark.apache.org/docs/3.0.0/ml-features#maxabsscaler" rel="noopener noreferrer" target="_blank"><span>MaxAbsScaler</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            </li></ul></div>
     
        <h2 id="data-wrangler-transform-sampling">Sampling</h2>
        <p>After you've imported your data, you can use the <b>Sampling</b>
            transformer to take one or more samples of it. When you use the sampling transformer,
            Data Wrangler samples your original dataset.</p>
        <p>You can choose one of the following sample methods:</p>
        <div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>Limit</b>: Samples the dataset starting from the first row up
                    to the limit that you specify.</p>
            </li><li class="listitem">
                <p><b>Randomized</b>: Takes a random sample of a size that you
                    specify.</p>
            </li><li class="listitem">
                <p><b>Stratified</b>: Takes a stratified random sample.</p>
            </li></ul></div>
        <p>You can stratify a randomized sample to make sure that it represents the original
            distribution of the dataset.</p>
        <p>You might be performing data preparation for multiple use cases. For each use case,
            you can take a different sample and apply a different set of transformations.</p>
        <p>The following procedure describes the process of creating a random sample. </p>
        <div class="procedure"><p>To take a random sample from your data.</p><ol><li>
                <p>Choose the <b>+</b> to the right of the dataset that you've
                    imported. The name of your dataset is located below the
                    <b>+</b>.</p>
            </li><li>
                <p>Choose <b>Add transform</b>.</p>
            </li><li>
                <p>Choose <b>Sampling</b>.</p>
            </li><li>
                <p>For <b>Sampling method</b>, choose the sampling method.</p>
            </li><li>
                <p>For <b>Approximate sample size</b>, choose the approximate
                    number of observations that you want in your sample.</p>
            </li><li>
                <p>(Optional) Specify an integer for <b>Random seed</b> to create a
                    reproducible sample.</p>
            </li></ol></div>
        <p>The following procedure describes the process of creating a stratified sample.</p>
        <div class="procedure"><p>To take a stratified sample from your data.</p><ol><li>
                <p>Choose the <b>+</b> to the right of the dataset that you've
                    imported. The name of your dataset is located below the
                    <b>+</b>.</p>
            </li><li>
                <p>Choose <b>Add transform</b>.</p>
            </li><li>
                <p>Choose <b>Sampling</b>.</p>
            </li><li>
                <p>For <b>Sampling method</b>, choose the sampling method.</p>
            </li><li>
                <p>For <b>Approximate sample size</b>, choose the approximate
                    number of observations that you want in your sample.</p>
            </li><li>
                <p>For <b>Stratify column</b>, specify the name of the column that
                    you want to stratify on.</p>
            </li><li>
                <p>(Optional) Specify an integer for <b>Random seed</b> to create a
                    reproducible sample.</p>
            </li></ol></div>
     
        <h2 id="data-wrangler-transform-search-edit">Search and Edit</h2>
        <p>Use this section to search for and edit specific patterns within strings. For example,
            you can find and update strings within sentences or documents, split strings by
            delimiters, and find occurrences of specific strings. </p>
        <p>The following transforms are supported under <b>Search and edit</b>. All
            transforms return copies of the strings in the <b>Input column</b> and add
            the result to a new output column.</p>
        <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c51b7"><thead>
                    <tr>
                        <th>Name</th>
                        <th>Function</th>
                    </tr>
                </thead>
                    <tr>
                        <td tabindex="-1">
                            <p>Find substring</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns the index of the first occurrence of the
                                    <b>Substring</b> for which you searched , You can
                                start and end the search at <b>Start</b> and
                                    <b>End</b> respectively. </p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Find substring (from right)</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns the index of the last occurrence of the
                                    <b>Substring</b> for which you searched. You can
                                start and end the search at <b>Start</b> and
                                    <b>End</b> respectively. </p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Matches prefix</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns a Boolean value if the string contains a given
                                    <b>Pattern</b>. A pattern can be a character
                                sequence or regular expression. Optionally, you can make the pattern
                                case sensitive. </p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Find all occurrences</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns an array with all occurrences of a given pattern. A
                                pattern can be a character sequence or regular expression. </p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Extract using regex</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns a string that matches a given Regex pattern.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Extract between delimiters</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns a string with all characters found between <b>Left
                                    delimiter</b> and <b>Right delimiter</b>.
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Extract from position</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns a string, starting from <b>Start
                                    position</b> in the input string, that contains all
                                characters up to the start position plus
                                <b>Length</b>. </p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Find and replace substring</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns a string with all matches of a given
                                    <b>Pattern</b> (regular expression) replaced by
                                    <b>Replacement string</b>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Replace between delimiters</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns a string with the substring found between the first
                                appearance of a <b>Left delimiter</b> and the last
                                appearance of a <b>Right delimiter</b> replaced by
                                    <b>Replacement string</b>. If no match is found,
                                nothing is replaced. </p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Replace from position</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns a string with the substring between <b>Start
                                    position</b> and <b>Start position</b> plus
                                    <b>Length</b> replaced by <b>Replacement
                                    string</b>. If <b>Start position</b> plus
                                    <b>Length</b> is greater than the length of the
                                replacement string, the output contains
                                <b>…</b>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Convert regex to missing</p>
                        </td>
                        <td tabindex="-1">
                            <p>Converts a string to <code class="code">None</code> if invalid and returns the
                                result. Validity is defined with a regular expression in
                                    <b>Pattern</b>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Split string by delimiter</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns an array of strings from the input string, split by
                                    <b>Delimiter</b>, with up to <b>Max number
                                    of splits</b> (optional). The delimiter defaults to white
                                space. </p>
                        </td>
                    </tr>
                </table></div></div>
     
        <h2 id="data-wrangler-transform-split-data">Split data</h2>
        <p>Use the <b>Split data</b> transform to split your dataset into two or
            three datasets. For example, you can split your dataset into a dataset used to train
            your model and a dataset used to test it. You can determine the proportion of the
            dataset that goes into each split. For example, if you’re splitting one dataset into two
            datasets, the training dataset can have 80% of the data while the testing dataset has
            20%.</p>
        <p>Splitting your data into three datasets gives you the ability to create training,
            validation, and test datasets. You can see how well the model performs on the test
            dataset by dropping the target column.</p>
        <p>Your use case determines how much of the original dataset each of your datasets get
            and the method you use to split the data. For example, you might want to use a
            stratified split to make sure that the distribution of the observations in the target
            column are the same across datasets. You can use the following split transforms:</p>
        <div class="itemizedlist">
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Randomized split — Each split is a random, non-overlapping sample of the
                    original dataset. For larger datasets, using a randomized split might be
                    computationally expensive and take longer than an ordered split.</p>
            </li><li class="listitem">
                <p>Ordered split – Splits the dataset based on the sequential order of the
                    observations. For example, for an 80/20 train-test split, the first observations
                    that make up 80% of the dataset go to the training dataset. The last 20% of the
                    observations go to the testing dataset. Ordered splits are effective in keeping
                    the existing order of the data between splits.</p>
            </li><li class="listitem">
                <p>Stratified split – Splits the dataset to make sure that the number of
                    observations in the input column have proportional representation. For an input
                    column that has the observations 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,
                    3, 3, 3, 3, 3, an 80/20 split on the column would mean that approximately 80% of
                    the 1s, 80% of the 2s, and 80% of the 3s go to the training set. About 20% of
                    each type of observation go to the testing set.</p>
            </li><li class="listitem">
                <p>Split by key – Avoids data with the same key occurring in more than one
                    split. For example, if you have a dataset with the column 'customer_id' and
                    you're using it as a key, no customer id is in more than one split.</p>
            </li></ul></div>
        <p>After you split the data, you can apply additional transformations to each dataset.
            For most use cases, they aren't necessary.</p>
        <p>Data Wrangler calculates the proportions of the splits for performance. You can choose an error
            threshold to set the accuracy of the splits. Lower error thresholds more accurately
            reflect the proportions that you specify for the splits. If you set a higher error
            threshold, you get better performance, but lower accuracy.</p>
        <p>For perfectly split data, set the error threshold to 0. You can specify a threshold
            between 0 and 1 for better performance. If you specify a value greater than 1, Data Wrangler
            interprets that value as 1.</p>
        <p>If you have 10000 rows in your dataset and you specify an 80/20 split with an error of
            0.001, you would get observations approximating one of the following results:</p>
        <div class="itemizedlist">
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>8010 observations in the training set and 1990 in the testing set</p>
            </li><li class="listitem">
                <p>7990 observations in the training set and 2010 in the testing set</p>
            </li></ul></div>
        <p>The number of observations for the testing set in the preceding example is in the
            interval between 8010 and 7990.</p>
        <p>By default, Data Wrangler uses a random seed to make the splits reproducible. You can specify a
            different value for the seed to create a different reproducible split.</p>

        <awsdocs-tabs><dl style="display: none">
            <dt>Randomized split</dt><dd tab-id="randomized-split">
                    <p>Use the following procedure to perform a randomized split on your
                        dataset.</p>
                    <div class="procedure"><p>To split your dataset randomly, do the following</p><ol><li>
                            <p>Choose the <b>+</b> next to the node containing the
                                dataset that you're splitting.</p>
                        </li><li>
                            <p>Choose <b>Add transform</b>.</p>
                        </li><li>
                            <p>Choose <b>Split data</b>.</p>
                        </li><li>
                            <p>(Optional) For <b>Splits</b>, specify the names and
                                proportions of each split. The proportions must sum to 1.</p>
                        </li><li>

                            <p>(Optional) Choose the <b>+</b> to create an
                                additional split.</p>

                            <ol><li>
                                    <p>Specify the names and proportions of all the splits. The
                                        proportions must sum to 1.</p>
                                </li></ol>
                        </li><li>
                            <p>(Optional) Specify a value for <b>Error
                                    threshold</b> other than the default value.</p>
                        </li><li>
                            <p>(Optional) Specify a value for <b>Random
                                seed</b>.</p>
                        </li><li>
                            <p>Choose <b>Preview</b>.</p>
                        </li><li>
                            <p>Choose <b>Add</b>.</p>
                        </li></ol></div>
                </dd>
            <dt>Ordered split</dt><dd tab-id="ordered-split">
                    <p>Use the following procedure to perform an ordered split on your
                        dataset.</p>
                    <div class="procedure"><p>To make an ordered split in your dataset, do the following.</p><ol><li>
                            <p>Choose the <b>+</b> next to the node containing the
                                dataset that you're splitting.</p>
                        </li><li>
                            <p>Choose <b>Add transform</b>.</p>
                        </li><li>
                            <p>For <b>Transform</b>, choose <b>Ordered
                                    split</b>.</p>
                        </li><li>
                            <p>Choose <b>Split data</b>.</p>
                        </li><li>
                            <p>(Optional) For <b>Splits</b>, specify the names and
                                proportions of each split. The proportions must sum to 1.</p>
                        </li><li>

                            <p>(Optional) Choose the <b>+</b> to create an
                                additional split.</p>

                            <ol><li>
                                    <p>Specify the names and proportions of all the splits. The
                                        proportions must sum to 1.</p>
                                </li></ol>
                        </li><li>
                            <p>(Optional) Specify a value for <b>Error
                                    threshold</b> other than the default value.</p>
                        </li><li>
                            <p>(Optional) For <b>Input column</b>, specify a column
                                with numeric values. Uses the values of the columns to infer which
                                records are in each split. The smaller values are in one split with
                                the larger values in the other splits.</p>
                        </li><li>
                            <p>(Optional) Select <b>Handle duplicates</b> to add
                                noise to duplicate values and create a dataset of entirely unique
                                values.</p>
                        </li><li>
                            <p>(Optional) Specify a value for <b>Random
                                seed</b>.</p>
                        </li><li>
                            <p>Choose <b>Preview</b>.</p>
                        </li><li>
                            <p>Choose <b>Add</b>.</p>
                        </li></ol></div>
                </dd>
            <dt>Stratified split</dt><dd tab-id="stratified-split">
                    <p>Use the following procedure to perform a stratified split on your
                        dataset.</p>
                    <div class="procedure"><p>To make a stratified split in your dataset, do the following.</p><ol><li>
                            <p>Choose the <b>+</b> next to the node containing the
                                dataset that you're splitting.</p>
                        </li><li>
                            <p>Choose <b>Add transform</b>.</p>
                        </li><li>
                            <p>Choose <b>Split data</b>.</p>
                        </li><li>
                            <p>For <b>Transform</b>, choose <b>Stratified
                                    split</b>.</p>
                        </li><li>
                            <p>(Optional) For <b>Splits</b>, specify the names and
                                proportions of each split. The proportions must sum to 1.</p>
                        </li><li>

                            <p>(Optional) Choose the <b>+</b> to create an
                                additional split.</p>

                            <ol><li>
                                    <p>Specify the names and proportions of all the splits. The
                                        proportions must sum to 1.</p>
                                </li></ol>
                        </li><li>
                            <p>For <b>Input column</b>, specify a column with up to
                                100 unique values. Data Wrangler can't stratify a column with more than 100
                                unique values.</p>
                        </li><li>
                            <p>(Optional) Specify a value for <b>Error
                                    threshold</b> other than the default value.</p>
                        </li><li>
                            <p>(Optional) Specify a value for <b>Random seed</b> to
                                specify a different seed.</p>
                        </li><li>
                            <p>Choose <b>Preview</b>.</p>
                        </li><li>
                            <p>Choose <b>Add</b>.</p>
                        </li></ol></div>
                </dd>
            <dt>Split by column keys</dt><dd tab-id="split-by-column-keys">
                    <p>Use the following procedure to split by the column keys in your
                        dataset.</p>
                    <div class="procedure"><p>To split by the column keys in your dataset, do the following.</p><ol><li>
                            <p>Choose the <b>+</b> next to the node containing the
                                dataset that you're splitting.</p>
                        </li><li>
                            <p>Choose <b>Add transform</b>.</p>
                        </li><li>
                            <p>Choose <b>Split data</b>.</p>
                        </li><li>
                            <p>For <b>Transform</b>, choose <b>Split by
                                    key</b>.</p>
                        </li><li>
                            <p>(Optional) For <b>Splits</b>, specify the names and
                                proportions of each split. The proportions must sum to 1.</p>
                        </li><li>
                            <p>(Optional) Choose the <b>+</b> to create an
                                additional split.</p>
                            <ol><li>
                                    <p>Specify the names and proportions of all the splits. The
                                        proportions must sum to 1.</p>
                                </li></ol>
                        </li><li>
                            <p>For <b>Key columns</b>, specify the columns with
                                values that you don't want to appear in both datasets.</p>
                        </li><li>
                            <p>(Optional) Specify a value for <b>Error
                                    threshold</b> other than the default value.</p>
                        </li><li>
                            <p>Choose <b>Preview</b>.</p>
                        </li><li>
                            <p>Choose <b>Add</b>.</p>
                        </li></ol></div>
                </dd>
        </dl></awsdocs-tabs>






     
        <h2 id="data-wrangler-transform-cast-type">Parse Value as Type</h2>
        <p>Use this transform to cast a column to a new type. The supported Data Wrangler data types
            are:</p>
        <div class="itemizedlist">
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Long</p>
            </li><li class="listitem">
                <p>Float</p>
            </li><li class="listitem">
                <p>Boolean</p>
            </li><li class="listitem">
                <p>Date, in the format dd-MM-yyyy, representing day, month, and year
                    respectively. </p>
            </li><li class="listitem">
                <p>String</p>
            </li></ul></div>
     
        <h2 id="data-wrangler-transform-validate-string">Validate String</h2>
        <p>Use the <b>Validate string</b> transforms to create a new column that
            indicates that a row of text data meets a specified condition. For example, you can use
            a <b>Validate string</b> transform to verify that a string only contains
            lowercase characters. The following transforms are supported under <b>Validate
                string</b>. </p>
        <p>The following transforms are included in this transform group. If a transform outputs
            a Boolean value, <code class="code">True</code> is represented with a <code class="code">1</code> and
                <code class="code">False</code> is represented with a <code class="code">0</code>.</p>
        <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c57b7"><thead>
                    <tr>
                        <th>Name</th>
                        <th>Function</th>
                    </tr>
                </thead>
                    <tr>
                        <td tabindex="-1">
                            <p>String length</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string length equals specified
                                length. Otherwise, returns <code class="code">False</code>. </p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Starts with</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string starts will a specified
                                prefix. Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Ends with</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string length equals specified
                                length. Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Is alphanumeric</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string only contains numbers and
                                letters. Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Is alpha (letters)</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string only contains letters.
                                Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Is digit</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string only contains digits.
                                Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Is space</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string only contains numbers and
                                letters. Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Is title</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string contains any white spaces.
                                Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Is lowercase</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string only contains lower case
                                letters. Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Is uppercase</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string only contains upper case
                                letters. Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Is numeric</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string only contains numbers.
                                Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">
                            <p>Is decimal</p>
                        </td>
                        <td tabindex="-1">
                            <p>Returns <code class="code">True</code> if a string only contains decimal
                                numbers. Otherwise, returns <code class="code">False</code>.</p>
                        </td>
                    </tr>
                </table></div></div>
     
        <h2 id="data-wrangler-transform-flatten-column">Unnest JSON Data</h2>
        <p>If you have a .csv file, you might have values in your dataset that are JSON strings.
            Similarly, you might have nested data in columns of either a Parquet file or a JSON
            document.</p>
        <p>Use the <b>Flatten structured</b> operator to separate the first level
            keys into separate columns. A first level key is a key that isn't nested within a
            value.</p>
        <p>For example, you might have a dataset that has a <em>person</em> column
            with demographic information on each person stored as JSON strings. A JSON string might
            look like the following.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="json ">
 "<span>{</span>"seq": 1,"name": <span>{</span>"first": "Nathaniel","last": "Ferguson"},"age": 59,"city": "Posbotno","state": "WV"}"
            </code></pre>
        <p>The <b>Flatten structured</b> operator converts the following first
            level keys into additional columns in your dataset:</p>
        <div class="itemizedlist">
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>seq</p>
            </li><li class="listitem">
                <p>name</p>
            </li><li class="listitem">
                <p>age</p>
            </li><li class="listitem">
                <p>city</p>
            </li><li class="listitem">
                <p>state</p>
            </li></ul></div>
        <p>Data Wrangler puts the values of the keys as values under the columns. The following shows the
            column names and values of the JSON.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">
seq, name,                                    age, city, state
1, <span>{</span>"first": "Nathaniel","last": "Ferguson"}, 59, Posbotno, WV
            </code></pre>
        <p>For each value in your dataset containing JSON, the <b>Flatten
                structured</b> operator creates columns for the first-level keys. To create
            columns for nested keys, call the operator again. For the preceding example, calling the
            operator creates the columns:</p>
        <div class="itemizedlist">
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>name_first</p>
            </li><li class="listitem">
                <p>name_last</p>
            </li></ul></div>
        <p>The following example shows the dataset that results from calling the operation
            again.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">
seq, name,                                    age, city, state, name_first, name_last
1, <span>{</span>"first": "Nathaniel","last": "Ferguson"}, 59, Posbotno, WV, Nathaniel, Ferguson
            </code></pre>
    <p>Choose <b>Keys to flatten on</b> to specify the first-level keys that want
        to extract as separate columns. If you don't specify any keys, Data Wrangler extracts all the keys by
        default.</p>
        <h2 id="data-wrangler-transform-explode-array">Explode Array</h2>
        <p>Use <b>Explode array</b> to expand the values of the array into separate
            output rows. For example, the operation can take each value in the array, [[1, 2, 3,],
            [4, 5, 6], [7, 8, 9]] and create a new column with the following rows:</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">
                [1, 2, 3]
                [4, 5, 6]
                [7, 8, 9]
            </code></pre>
        <p>Data Wrangler names the new column, input_column_name_flatten.</p>
        <p>You can call the <b>Explode array</b> operation multiple times to get
            the nested values of the array into separate output columns. The following example shows
            the result of calling the operation multiple times on a dataset with a nested
            array.</p>
        <div class="table-container"><div class="table-contents"><table id="w714aac17c21c36c63c11"><thead><tr><th class="table-header" colspan="100"><div class="title">Putting the values of a nested array into separate columns</div></th></tr>
                    <tr>
                        <th>id</th>
                        <th>array</th>
                        <th>id</th>
                        <th>array_items</th>
                        <th>id</th>
                        <th>array_items_items</th>
                    </tr>
                </thead>
                    <tr>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">[ [cat, dog], [bat, frog] ]</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">[cat, dog]</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">cat</td>
                    </tr>
                    <tr>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">
                            <p>[[rose, petunia], [lily, daisy]]</p>
                        </td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">[bat, frog]</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">dog</td>
                    </tr>
                    <tr>
                        <td tabindex="-1"></td>
                        <td tabindex="-1"></td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">[rose, petunia]</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">bat</td>
                    </tr>
                    <tr>
                        <td tabindex="-1"></td>
                        <td tabindex="-1"></td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">[lily, daisy]</td>
                        <td tabindex="-1">1</td>
                        <td tabindex="-1">frog</td>
                    </tr>
                    <tr>
                        <td tabindex="-1"></td>
                        <td tabindex="-1"></td>
                        <td tabindex="-1"></td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">rose</td>
                    </tr>
                    <tr>
                        <td tabindex="-1"></td>
                        <td tabindex="-1"></td>
                        <td tabindex="-1"></td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">petunia</td>
                    </tr>
                    <tr>
                        <td tabindex="-1"></td>
                        <td tabindex="-1"></td>
                        <td tabindex="-1"></td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">lily</td>
                    </tr>
                    <tr>
                        <td tabindex="-1"></td>
                        <td tabindex="-1"></td>
                        <td tabindex="-1"></td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">2</td>
                        <td tabindex="-1">daisy</td>
                    </tr>
                </table></div></div>
     
       <h2 id="data-wrangler-transform-image">Transform Image Data</h2>
       <p>Use Data Wrangler to import and transform the images that you're using for your machine learning (ML) pipelines. After you've prepared your image data, you can export it from your Data Wrangler flow to your ML pipeline.</p>
        <p>You can use the information provided here to familiarize yourself with importing and transforming image data in Data Wrangler. Data Wrangler uses OpenCV to import images. For more information about supported image formats, see <a href=" https://docs.opencv.org/3.4/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56" rel="noopener noreferrer" target="_blank"><span>Image file reading and writing</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
        <p>After you've familiarized yourself with the concepts of transforming your image data, go through the following tutorial, <a href="http://aws.amazon.com/blogs/machine-learning/prepare-image-data-with-amazon-sagemaker-data-wrangler/" rel="noopener noreferrer" target="_blank"><span>Prepare image data with Amazon SageMaker Data Wrangler</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
       <p>The following industries and use cases are examples where applying machine learning to transformed image data can be useful:</p>
        <div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Manufacturing – Identifying defects in items from the assembly line</p>
            </li><li class="listitem">
                <p>Food – Identifying spoiled or rotten food</p>
            </li><li class="listitem">
                <p>Medicine – Identifying lesions in tissues</p>
            </li></ul></div>
        <p>When you work with image data in Data Wrangler, you go through the following process:</p>
        <div class="orderedlist">
             
            
             
             
        <ol><li>
                <p>Import – Select the images by choosing the directory containing them in your Amazon S3 bucket.</p>
            </li><li>
                <p>Transform – Use the built-in transformations to prepare the images for your machine learning pipeline.</p>
            </li><li>
                <p>Export – Export the images that you’ve transformed to a location that can be accessed from the pipeline.</p>
            </li></ol></div>
        <p>Use the following procedure to import your image data.</p>
        <div class="procedure"><h6>To import your image data</h6><ol><li>
                <p>Navigate to the <b>Create connection</b> page.</p>
            </li><li>
                <p>Choose <b>Amazon S3</b>.</p>
            </li><li>
                <p>Specify the Amazon S3 file path that contains the image data.</p>
            </li><li>
                <p>For <b>File type</b>, choose <b>Image</b>.</p>
            </li><li>
                <p>(Optional) Choose <b>Import nested directories</b> to import images from multiple Amazon S3 paths.</p>
            </li><li>
                <p>Choose <b>Import</b>.</p>
            </li></ol></div>
        <p>Data Wrangler uses the open-source <a href="https://imgaug.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank"><span>imgaug</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> library for its built-in image transformations. You can use the following built-in transformations:</p>
        <div class="itemizedlist">
             
             
             
             
             
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>ResizeImage</b></p>
            </li><li class="listitem">
                <p><b>EnhanceImage</b></p>
            </li><li class="listitem">
                <p><b>CorruptImage</b></p>
            </li><li class="listitem">
                <p><b>SplitImage</b></p>
            </li><li class="listitem">
                <p><b>DropCorruptedImages</b></p>
            </li><li class="listitem">
                <p><b>DropImageDuplicates</b></p>
            </li><li class="listitem">
                <p><b>Brightness</b></p>
            </li><li class="listitem">
                <p><b>ColorChannels</b></p>
            </li><li class="listitem">
                <p><b>Grayscale</b></p>
            </li><li class="listitem">
                <p><b>Rotate</b></p>
            </li></ul></div>
        
        
        <p>Use the following procedure to transform your images without writing code.</p>
        <div class="procedure"><h6>To transform the image data without writing code</h6><ol><li>
                <p>From your Data Wrangler flow, choose the <b>+</b> next to the node representing the images that you've imported.</p>
            </li><li>
                <p>Choose <b>Add transform</b>.</p>
            </li><li>
                <p>Choose <b>Add step</b>.</p>
            </li><li>
                <p>Choose the transform and configure it.</p>
            </li><li>
                <p>Choose <b>Preview</b>.</p>
            </li><li>
                <p>Choose <b>Add</b>.</p>
            </li></ol></div>
        <p>In addition to using the transformations that Data Wrangler provides, you can also use your own custom code snippets. For more information about using custom code snippets, see <a href="data-wrangler-transform.html#data-wrangler-transform-custom">Custom Transforms</a>. 
            You can import the OpenCV and imgaug libraries within your code snippets and use the transforms associated with them. The following is an example of a code snippet that detects edges within the images.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">
# A table with your image data is stored in the `df` variable
import cv2
import numpy as np
from pyspark.sql.functions import column

from sagemaker_dataprep.compute.operators.transforms.image.constants import DEFAULT_IMAGE_COLUMN, IMAGE_COLUMN_TYPE
from sagemaker_dataprep.compute.operators.transforms.image.decorators import BasicImageOperationDecorator, PandasUDFOperationDecorator


@BasicImageOperationDecorator
def my_transform(image: np.ndarray) -&gt; np.ndarray:
  # To use the code snippet on your image data, modify the following lines within the function
    HYST_THRLD_1, HYST_THRLD_2 = 100, 200
    edges = cv2.Canny(image,HYST_THRLD_1,HYST_THRLD_2)
    return edges
    

@PandasUDFOperationDecorator(IMAGE_COLUMN_TYPE)
def custom_image_udf(image_row):
    return my_transform(image_row)
    

df = df.withColumn(DEFAULT_IMAGE_COLUMN, custom_image_udf(column(DEFAULT_IMAGE_COLUMN)))
        </code></pre>
    
     
      
        <p>When apply transformations in your Data Wrangler flow, Data Wrangler only applies them to a sample of the images in your dataset. To optimize your experience with the application, Data Wrangler doesn't apply the transforms to all of your images.</p>
        <p>To apply the transformations to all of your images, export your Data Wrangler flow to an Amazon S3 location. You can use the images that you've exported in your training or inference pipelines. Use a destination node or a Jupyter Notebook to export your data. You can access either method for exporting your data from the Data Wrangler flow. For information about using these methods, see <a href="data-wrangler-data-export.html#data-wrangler-data-export-s3">Export to Amazon S3</a>.</p>
     
        <h2 id="data-wrangler-transform-filter-data">Filter data</h2>
        <p>Use Data Wrangler to filter the data in your columns. When you filter the data in a column, you specify the following fields:</p>
        <div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>Column name</b> – The name of the column that you're using to filter the data.</p>
            </li><li class="listitem">
                <p><b>Condition</b> – The type of filter that you're applying to values in the column.</p>
            </li><li class="listitem">
                <p><b>Value</b> – The value or category in the column to which you're applying the filter.</p>
            </li></ul></div>
        <p>You can filter on the following conditions:</p>
        <div class="itemizedlist">
             
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><b>=</b> – Returns values that match the value or category that you specify.</p>
            </li><li class="listitem">
                <p><b>!=</b> – Returns values that don't match the value or category that you specify.</p>
            </li><li class="listitem">
                <p><b>&gt;=</b> – For <b>Long</b> or <b>Float</b> data, filters for values that are greater than or equal to the value that you specify.</p>
            </li><li class="listitem">
                <p><b>&lt;=</b> – For <b>Long</b> or <b>Float</b> data, filters for values that are less than or equal to the value that you specify.</p>
            </li><li class="listitem">
                <p><b>&gt;</b> – For <b>Long</b> or <b>Float</b> data, filters for values that are greater than the value that you specify.</p>
            </li><li class="listitem">
                <p><b>&lt;</b> – For <b>Long</b> or <b>Float</b> data, filters for values that are less than the value that you specify.</p>
            </li></ul></div>
        <p>For a column that has the categories, <code class="code">male</code> and <code class="code">female</code>, you can filter out all the <code class="code">male</code> values. You could also filter for all the <code class="code">female</code> values. 
            Because there are only <code class="code">male</code> and <code class="code">female</code> values in the column, the filter returns a column that only has <code class="code">female</code> values.</p>
        <p>You can also add multiple filters. The filters can be applied across multiple columns or the same column. For example, if you're creating a column that only has values within a certain range, you add two different filters. One filter specifies that the column must have values greater than the value that you provide. 
            The other filter specifies that the column must have values less than the value that you provide.</p>
        <p>Use the following procedure to add the filter transform to your data.</p>
        <div class="procedure"><h6>To filter your data</h6><ol><li>
                <p>From your Data Wrangler flow, choose the <b>+</b> next to the node with the data that you're filtering.</p>
            </li><li>
                <p>Choose <b>Add transform</b>.</p>
            </li><li>
                <p>Choose <b>Add step</b>.</p>
            </li><li>
                <p>Choose <b>Filter data</b>.</p>
            </li><li>
                <p>Specify the following fields:</p>
                <div class="itemizedlist">
                     
                     
                     
                    
                <ul class="itemizedlist"><li class="listitem">
                        <p><b>Column name</b> – The column that you're filtering.</p>
                    </li><li class="listitem">
                        <p><b>Condition</b> – The condition of the filter.</p>
                    </li><li class="listitem">
                        <p><b>Value</b> – The value or category in the column to which you're applying the filter.</p>
                    </li></ul></div>
            </li><li>
                <p>(Optional) Choose <b>+</b> following the filter that you've created.</p>
            </li><li>
                <p>Configure the filter.</p>
            </li><li>
                <p>Choose <b>Preview</b>.</p>
            </li><li>
                <p>Choose <b>Add</b>.</p>
            </li></ol></div>
     
        <h2 id="data-wrangler-transform-personalize">Map Columns for Amazon Personalize</h2>
        <p>Data Wrangler integrates with Amazon Personalize, a fully managed machine learning service that generates item recommendations and user segments. 
            You can use the <b>Map columns for Amazon Personalize</b> transform to get your data into a format that Amazon Personalize can interpret. 
            For more information about the transforms specific to Amazon Personalize, see <a href="https://docs.aws.amazon.com/personalize/latest/dg/preparing-importing-with-data-wrangler.html#dw-transform-data">Importing data using Amazon SageMaker Data Wrangler</a>. For more information about Amazon Personalize see <a href="https://docs.aws.amazon.com/personalize/latest/dg/what-is-personalize.html">What is Amazon Personalize?</a></p>      

    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./data-wrangler-autopilot.html">Automatically Train Models on Your Data
            Flow</div><div id="next" class="next-link" accesskey="n" href="./data-wrangler-analyses.html">Analyze and Visualize</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-transform.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-transform.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>