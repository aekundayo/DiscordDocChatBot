<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Run Real-time Predictions with an Inference Pipeline - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="inference-pipeline-real-time" /><meta name="default_state" content="inference-pipeline-real-time" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="inference-pipeline-real-time.html" /><meta name="description" content="Use an Amazon SageMaker endpoint for real-time inference with an inference pipeline." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="inference-pipeline-real-time.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="de" /><link rel="alternative" href="inference-pipeline-real-time.html" hreflang="en-us" /><link rel="alternative" href="inference-pipeline-real-time.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/inference-pipeline-real-time.html" hreflang="zh-tw" /><link rel="alternative" href="inference-pipeline-real-time.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Run Real-time Predictions with an Inference Pipeline" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Run Real-time Predictions with an Inference Pipeline - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#inference-pipeline-real-time" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/inference-pipeline-real-time.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/inference-pipeline-real-time.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/inference-pipeline-real-time.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance,inference,deploy model,endpoint,prediction,ML application,serverless machine learning,multi model deployment,inference pipelines,ML model" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Deploy models for inference",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Real-time inference",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Hosting options",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-options.html"
      },
      {
        "@type" : "ListItem",
        "position" : 7,
        "name" : "Host models along with pre-processing logic as serial inference pipeline behind one endpoint",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html"
      },
      {
        "@type" : "ListItem",
        "position" : 8,
        "name" : "Run Real-time Predictions with an Inference Pipeline",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#inference-pipeline-real-time" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="inference-pipeline-real-time.html#inference-pipeline-real-time-sdk">Real-time Inference Pipeline
                    Endpoint</a><a href="inference-pipeline-real-time.html#inference-pipeline-endpoint-request">Call an Inference Endpoint</a><a href="inference-pipeline-real-time.html#inference-pipeline-example">Realtime inference pipeline
                    example</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="inference-pipeline-real-time">Run
                Real-time
                Predictions with an Inference Pipeline</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>You
            can use trained models in an inference pipeline to make real-time predictions directly
            without performing external preprocessing. When you configure the pipeline, you can
            choose to use the
            built-in
            feature transformers already available in Amazon SageMaker. Or, you can
            implement your own transformation logic using just a few lines of scikit-learn or Spark
            code. </p><p><a href="https://combust.github.io/mleap-docs/" rel="noopener noreferrer" target="_blank"><span>MLeap</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>, a serialization format and
            execution engine for machine learning pipelines, supports Spark, scikit-learn, and
            TensorFlow for training pipelines and exporting them to a serialized pipeline called an
            MLeap Bundle. You can deserialize Bundles back into Spark for batch-mode scoring or into
            the MLeap runtime to power real-time API services.</p><p>The containers in a pipeline listen on the port specified in the
                <code class="code">SAGEMAKER_BIND_TO_PORT</code> environment variable (instead of 8080).
            When
            running in an inference pipeline, SageMaker automatically provides this
            environment variable to containers. If this environment variable isn't present,
            containers default to using port 8080. To indicate that your container complies with
            this requirement, use the following command to add a label to your Dockerfile:</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true</code></pre><p>If your container needs
            to
            listen on a second port,
            choose
            a port in the range specified by the <code class="code">SAGEMAKER_SAFE_PORT_RANGE</code> environment
            variable. Specify the value as an inclusive range in the format
                <code class="userinput">"XXXX-YYYY"</code>, where <code class="code">XXXX</code> and <code class="code">YYYY</code>
            are multi-digit integers. SageMaker provides this value automatically when you run the
            container in a multicontainer pipeline.</p><div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>To use custom Docker images in a pipeline that includes <a href="sagemaker-algo-docker-registry-paths.html">SageMaker built-in algorithms</a>, you need an <a href="https://docs.aws.amazon.com/AmazonECR/latest/userguide/what-is-ecr.html">Amazon Elastic Container Registry (Amazon ECR) policy</a>. Your Amazon ECR repository must grant SageMaker
                permission to pull the image. For more information, see
                    <a href="inference-pipeline-troubleshoot.html#inference-pipeline-troubleshoot-permissions">Troubleshoot Amazon ECR
                    Permissions for Inference Pipelines</a>.</p></div></div>
            <h2 id="inference-pipeline-real-time-sdk">Create and Deploy an Inference
                    Pipeline Endpoint </h2>
            <p>The following code creates and deploys a real-time inference pipeline model with
                SparkML and XGBoost models in series using the SageMaker SDK.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">from sagemaker.model import Model
from sagemaker.pipeline_model import PipelineModel
from sagemaker.sparkml.model import SparkMLModel

sparkml_data = 's3://<span>{</span>}/<span>{</span>}/<span>{</span>}'.format(s3_model_bucket, s3_model_key_prefix, 'model.tar.gz')
sparkml_model = SparkMLModel(model_data=sparkml_data)
xgb_model = Model(model_data=xgb_model.model_data, image=training_image)

model_name = 'serial-inference-' + timestamp_prefix
endpoint_name = 'serial-inference-ep-' + timestamp_prefix
sm_model = PipelineModel(name=model_name, role=role, models=[sparkml_model, xgb_model])
sm_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge', endpoint_name=endpoint_name)</code></pre>
         
            <h2 id="inference-pipeline-endpoint-request">Request Real-Time Inference
                    from an Inference Pipeline Endpoint </h2>
            <p>The following example shows how to make real-time predictions by calling
                an
                inference endpoint and passing a request payload in JSON format:</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">import sagemaker
from sagemaker.predictor import json_serializer, json_deserializer, Predictor

payload = <span>{</span>
        "input": [
            <span>{</span>
                "name": "Pclass",
                "type": "float",
                "val": "1.0"
            },
            <span>{</span>
                "name": "Embarked",
                "type": "string",
                "val": "Q"
            },
            <span>{</span>
                "name": "Age",
                "type": "double",
                "val": "48.0"
            },
            <span>{</span>
                "name": "Fare",
                "type": "double",
                "val": "100.67"
            },
            <span>{</span>
                "name": "SibSp",
                "type": "double",
                "val": "1.0"
            },
            <span>{</span>
                "name": "Sex",
                "type": "string",
                "val": "male"
            }
        ],
        "output": <span>{</span>
            "name": "features",
            "type": "double",
            "struct": "vector"
        }
    }

predictor = Predictor(endpoint=endpoint_name, sagemaker_session=sagemaker.Session(), serializer=json_serializer,
                                content_type='text/csv', accept='application/json'

print(predictor.predict(payload))</code></pre>
            <p>The response you get from <code class="code">predictor.predict(payload)</code> is the model's
                inference result.</p>
         
            <h2 id="inference-pipeline-example">Realtime inference pipeline
                    example</h2>
            <p>You can run this <a href="https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_randomforest/Sklearn_on_SageMaker_end2end.ipynb" rel="noopener noreferrer" target="_blank"><span>example notebook using the SKLearn predictor</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> that shows how to deploy
                an endpoint, run an inference request, then deserialize the response. Find this
                notebook and more examples in the <a href="https://github.com/awslabs/amazon-sagemaker-examples" rel="noopener noreferrer" target="_blank"><span>Amazon SageMaker example GitHub repository</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
        <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./inference-pipeline-create-console.html">Create a Pipeline Model </div><div id="next" class="next-link" accesskey="n" href="./inference-pipeline-batch.html">Batch Transform</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/inference-pipeline-real-time.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/inference-pipeline-real-time.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>