<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>How LDA Works - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="lda-how-it-works" /><meta name="default_state" content="lda-how-it-works" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="lda-how-it-works.html" /><meta name="description" content="Amazon SageMaker LDA is an unsupervised learning algorithm that attempts to describe a set of observations as a mixture of different categories. These categories are themselves a probability distribution over the features. LDA is a generative probability model, which means it attempts to provide a model for the distribution of outputs and inputs based on latent variables. This is opposed to discriminative models, which attempt to learn how inputs map to outputs." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="lda-how-it-works.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/lda-how-it-works.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/lda-how-it-works.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/lda-how-it-works.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/lda-how-it-works.html" hreflang="de" /><link rel="alternative" href="lda-how-it-works.html" hreflang="en-us" /><link rel="alternative" href="lda-how-it-works.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/lda-how-it-works.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/lda-how-it-works.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/lda-how-it-works.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/lda-how-it-works.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/lda-how-it-works.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/lda-how-it-works.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/lda-how-it-works.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/lda-how-it-works.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/lda-how-it-works.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/lda-how-it-works.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/lda-how-it-works.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/lda-how-it-works.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/lda-how-it-works.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/lda-how-it-works.html" hreflang="zh-tw" /><link rel="alternative" href="lda-how-it-works.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="How LDA Works" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>How LDA Works - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#lda-how-it-works" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/lda-how-it-works.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/lda-how-it-works.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/lda-how-it-works.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Train machine learning models",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/train-model.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Choose an Algorithm",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/algorithms-choose.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Use Amazon SageMaker Built-in Algorithms or Pre-trained Models",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html"
      },
      {
        "@type" : "ListItem",
        "position" : 7,
        "name" : "Built-in SageMaker Algorithms for Text Data",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/algorithms-text.html"
      },
      {
        "@type" : "ListItem",
        "position" : 8,
        "name" : "Latent Dirichlet Allocation (LDA) Algorithm",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/lda.html"
      },
      {
        "@type" : "ListItem",
        "position" : 9,
        "name" : "How LDA Works",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/lda.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#lda-how-it-works" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="lda-how-it-works">How LDA Works</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Amazon SageMaker LDA is an unsupervised learning algorithm that attempts to describe a set of
            observations as a mixture of different categories. These categories are themselves a
            probability distribution over the features. LDA is a generative probability model, which
            means it attempts to provide a model for the distribution of outputs and inputs based on
            latent variables. This is opposed to discriminative models, which attempt to learn how
            inputs map to outputs.</p><p>You can use LDA for a variety of tasks, from clustering customers based on product
            purchases to automatic harmonic analysis in music. However, it is most commonly
            associated with topic modeling in text corpuses. Observations are referred to as
            documents. The feature set is referred to as vocabulary. A feature is referred to as a
            word. And the resulting categories are referred to as topics.</p><div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>Lemmatization significantly increases algorithm performance and accuracy. Consider
                pre-processing any input text data. For more information, see <a href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener noreferrer" target="_blank"><span>Stemming and lemmatization</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p></div></div><p>An LDA model is defined by two parameters:</p><div class="itemizedlist">
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>α—A prior estimate on topic probability (in other words, the average
                    frequency that each topic within a given document occurs). </p>
            </li><li class="listitem">
                <p>β—a collection of k topics where each topic is given a probability
                    distribution over the vocabulary used in a document corpus, also called a
                    "topic-word distribution."</p>
            </li></ul></div><p>LDA is a "bag-of-words" model, which means that the order of words does not matter.
            LDA is a generative model where each document is generated word-by-word by choosing a
            topic mixture θ ∼ Dirichlet(α). </p><p> For each word in the document: </p><div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p> Choose a topic z ∼ Multinomial(θ) </p>
            </li><li class="listitem">
                <p> Choose the corresponding topic-word distribution β_z. </p>
            </li><li class="listitem">
                <p> Draw a word w ∼ Multinomial(β_z). </p>
            </li></ul></div><p>When training the model, the goal is to find parameters α and β, which
            maximize the probability that the text corpus is generated by the model.</p><p>The most popular methods for estimating the LDA model use Gibbs sampling or
            Expectation Maximization (EM) techniques. The Amazon SageMaker LDA uses tensor spectral
            decomposition. This provides several advantages:</p><div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>
                    <b>Theoretical guarantees on results</b>. The standard
                    EM-method is guaranteed to converge only to local optima, which are often of
                    poor quality. </p>
            </li><li class="listitem">
                <p>
                    <b>Embarrassingly parallelizable</b>. The work can be
                    trivially divided over input documents in both training and inference. The
                    EM-method and Gibbs Sampling approaches can be parallelized, but not as easily.
                </p>
            </li><li class="listitem">
                <p>
                    <b>Fast</b>. Although the EM-method has low iteration
                    cost it is prone to slow convergence rates. Gibbs Sampling is also subject to
                    slow convergence rates and also requires a large number of samples. </p>
            </li></ul></div><p>At a high-level, the tensor decomposition algorithm follows this process:</p><div class="orderedlist">
             
             
             
             
        <ol><li>
                <p> The goal is to calculate the spectral decomposition of a <b>V</b> x <b>V</b> x <b>V</b> tensor, which summarizes the moments of the
                    documents in our corpus. <b>V</b> is vocabulary size
                    (in other words, the number of distinct words in all of the documents). The
                    spectral components of this tensor are the LDA parameters α and β,
                    which maximize the overall likelihood of the document corpus. However, because
                    vocabulary size tends to be large, this <b>V</b> x
                        <b>V</b> x <b>V</b>
                    tensor is prohibitively large to store in memory. </p>
            </li><li>
                <p> Instead, it uses a <b>V</b> x <b>V</b> moment matrix, which is the two-dimensional analog of the
                    tensor from step 1, to find a whitening matrix of dimension <b>V</b> x <b>k</b>. This matrix
                    can be used to convert the <b>V</b> x <b>V</b> moment matrix into a <b>k</b> x <b>k</b> identity matrix.
                        <b>k</b> is the number of topics in the model.
                </p>
            </li><li>
                <p> This same whitening matrix can then be used to find a smaller <b>k</b> x <b>k</b> x <b>k</b> tensor. When spectrally decomposed, this tensor has
                    components that have a simple relationship with the components of the <b>V</b> x <b>V</b> x <b>V</b> tensor. </p>
            </li><li>
                <p>
                    <em>Alternating Least Squares</em> is used to decompose the smaller
                        <b>k</b> x <em>k</em> x <b>k</b> tensor. This provides a substantial improvement in
                    memory consumption and speed. The parameters α and β can be found by
                    “unwhitening” these outputs in the spectral decomposition. </p>
            </li></ol></div><p>After the LDA model’s parameters have been found, you can find the topic mixtures for
            each document. You use stochastic gradient descent to maximize the likelihood function
            of observing a given topic mixture corresponding to these data.</p><p>Topic quality can be improved by increasing the number of topics to look for in
            training and then filtering out poor quality ones. This is in fact done automatically in
            SageMaker LDA: 25% more topics are computed and only the ones with largest associated
            Dirichlet priors are returned. To perform further topic filtering and analysis, you can
            increase the topic count and modify the resulting LDA model as follows:</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">&gt; import mxnet as mx
&gt; alpha, beta = mx.ndarray.load(‘model.tar.gz’)
&gt; # modify alpha and beta
&gt; mx.nd.save(‘new_model.tar.gz’, [new_alpha, new_beta])
&gt; # upload to S3 and create new SageMaker model using the console</code></pre><p>For more information about algorithms for LDA and the SageMaker implementation, see the
            following:</p><div class="itemizedlist">
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Animashree Anandkumar, Rong Ge, Daniel Hsu, Sham M Kakade, and Matus
                    Telgarsky. <em>Tensor Decompositions for Learning Latent Variable
                        Models</em>, Journal of Machine Learning Research, 15:2773–2832,
                    2014.</p>
            </li><li class="listitem">
                <p> David M Blei, Andrew Y Ng, and Michael I Jordan. <em>Latent Dirichlet
                        Allocation</em>. Journal of Machine Learning Research,
                    3(Jan):993–1022, 2003.</p>
            </li><li class="listitem">
                <p> Thomas L Griffiths and Mark Steyvers. <em>Finding Scientific
                        Topics</em>. Proceedings of the National Academy of Sciences,
                    101(suppl 1):5228–5235, 2004. </p>
            </li><li class="listitem">
                <p> Tamara G Kolda and Brett W Bader. <em>Tensor Decompositions and
                        Applications</em>. SIAM Review, 51(3):455–500, 2009. </p>
            </li></ul></div><awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./lda.html">Latent Dirichlet Allocation (LDA)</div><div id="next" class="next-link" accesskey="n" href="./lda_hyperparameters.html">Hyperparameters</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/lda-how-it-works.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/lda-how-it-works.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>