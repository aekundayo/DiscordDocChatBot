<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>View an Autopilot Model Performance Report - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="autopilot-model-insights" /><meta name="default_state" content="autopilot-model-insights" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="autopilot-model-insights.html" /><meta name="description" content="Learn how to view an Autopilot performance report graphically through a PDF, or view metrics as raw data in a JSON file." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="autopilot-model-insights.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="de" /><link rel="alternative" href="autopilot-model-insights.html" hreflang="en-us" /><link rel="alternative" href="autopilot-model-insights.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/autopilot-model-insights.html" hreflang="zh-tw" /><link rel="alternative" href="autopilot-model-insights.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="View an Autopilot Model Performance Report" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>View an Autopilot Model Performance Report - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#autopilot-model-insights" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/autopilot-model-insights.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/autopilot-model-insights.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/autopilot-model-insights.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance,Autopilot,automatic machine learning,Auto ML,Autopilot experiment for tabular data,candidate models,model results,prediction,model insights,model performance,metrics,confusion matrix" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Use automated ML, no-code, or low-code",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/use-auto-ml.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "SageMaker Autopilot",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Create an Amazon SageMaker Autopilot experiment for tabular data",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development-create-experiment.html"
      },
      {
        "@type" : "ListItem",
        "position" : 7,
        "name" : "Models generated by Amazon SageMaker Autopilot",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-models.html"
      },
      {
        "@type" : "ListItem",
        "position" : 8,
        "name" : "View an Autopilot Model Performance Report",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-models.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#autopilot-model-insights" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="autopilot-model-insights.html#autopilot-model-insights-details-and-metrics-table">Autopilot Job
                    details</a><a href="autopilot-model-insights.html#autopilot-model-quality-report">Model quality report</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="autopilot-model-insights">View an Autopilot Model Performance
                Report</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>An Amazon SageMaker model quality report (also referred to as performance report) provides
            insights and quality information for the best model candidate generated by an AutoML job.
            This includes information about the job details, model problem type, objective function,
            and other information related to the problem type. This guide shows how to view Amazon SageMaker
            Autopilot performance metrics graphically, or view metrics as raw data in a JSON
            file.</p><p>For example, in classification problems, the model quality report includes the
            following:</p><div class="itemizedlist">
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Confusion matrix</p>
            </li><li class="listitem">
                <p>Area under the receiver operating characteristic curve (AUC)</p>
            </li><li class="listitem">
                <p>Information to understand false positives and false negatives</p>
            </li><li class="listitem">
                <p>Tradeoffs between true positives and false positives</p>
            </li><li class="listitem">
                <p>Tradeoffs between precision and recall</p>
            </li></ul></div><p>Autopilot also provides performance metrics for all of your candidate models. These
            metrics are calculated using all of the training data and are used to estimate model
            performance. The main working area includes these metrics by default. The type of metric
            is determined by the type of problem being addressed.</p><p>The following performance metrics are associated with the corresponding problem
            type:</p><div class="itemizedlist">
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>Regression: <code class="code">MAE</code>, <code class="code">MSE</code>, <code class="code">R2</code>,
                        <code class="code">RMSE</code></p>
            </li><li class="listitem">
                <p>Binary classification: <code class="code">Accuracy</code>, <code class="code">AUC2</code>,
                        <code class="code">BalancedAccuracy</code>, <code class="code">F1</code>, <code class="code">LogLoss</code>,
                        <code class="code">Precision</code>, <code class="code">Recall</code></p>
            </li><li class="listitem">
                <p>Multiclass classification: <code class="code">Accuracy</code>,
                        <code class="code">BalancedAccuracy</code>, <code class="code">F1macro</code>, <code class="code">LogLoss</code>,
                        <code class="code">PrecisionMacro</code>, <code class="code">RecallMacro</code></p>
            </li></ul></div><p>You can sort your model candidates with the relevant metric to help you select and
            deploy the model that addresses your business needs. For definitions of these metrics,
            see the <a href="autopilot-metrics-validation.html#autopilot-metrics">Autopilot
                candidate metrics</a> topic.</p><p>To view a performance report from an Autopilot job, follow these steps:</p><div class="procedure"><ol><li>
                <p>Choose the <b>Home</b> icon <span class="inlinemediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/studio/icons/house.png" class="aws-docs-img-whiteBg aws-docs-img-xs-padding" style="max-width:3%" />
                         
                    </span> from the left navigation pane to view the top-level
                        <b>Amazon SageMaker Studio</b> navigation menu.</p>
            </li><li>
                <p>Select the <b>AutoML</b> card from the main working area. This
                    opens a new <b>Autopilot</b> tab.</p>
            </li><li>
                <p>In the <b>Name</b> section, select the Autopilot job that has the
                    details that you want to examine. This opens a new <b>Autopilot
                        job</b> tab.</p>
            </li><li>
                <p>The <b>Autopilot job</b> panel lists the metric values including
                    the <b>Objective</b> metric for each model under <b>Model
                        name</b>. The <b>Best model</b> is listed at the top of
                    the list under <b>Model name</b> and it is highlighted in the
                        <b>Models</b> tab.</p>
                <ol><li>
                        <p>To review model details, select the model that you are interested in
                            and select <b>View in model details</b>. This opens a new
                                <b>Model Details</b> tab.</p>
                    </li></ol>
            </li><li>
                <p>Choose the <b>Performance</b> tab between the
                        <b>Explainability</b> and <b>Artifacts</b>
                    tab.</p>
                <ol><li>
                        <p>On the top right section of the tab, select the down arrow on the
                                <b>Download Performance Reports</b> button. </p>
                    </li><li>
                        <p>The down arrow provides two options to view Autopilot performance
                            metrics:</p>
                        <ol><li>
                                <p>You can download a PDF of the performance report to view the
                                    metrics graphically.</p>
                            </li><li>
                                <p>You can view metrics as raw data and download it as a JSON
                                    file.</p>
                            </li></ol>
                    </li></ol>
            </li></ol></div><p>For instructions on how to create and run an AutoML job in SageMaker Studio, see <a href="autopilot-automate-model-development-create-experiment.html">Create an Amazon SageMaker Autopilot
      experiment for tabular data</a>. </p><p>The performance report contains two sections. The first contains details about the
            Autopilot job that produced the model. The second section contains a model quality
            report.</p>
            <h2 id="autopilot-model-insights-details-and-metrics-table">Autopilot Job
                    details</h2>

            <p>This first section of the report gives some general information about the Autopilot
                job that produced the model. These job details include the following
                information:</p>
            <div class="itemizedlist">
                 
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Autopilot candidate name</p>
                </li><li class="listitem">
                    <p>Autopilot job name</p>
                </li><li class="listitem">
                    <p>Problem type</p>
                </li><li class="listitem">
                    <p>Objective metric</p>
                </li><li class="listitem">
                    <p>Optimization direction</p>
                </li></ul></div>
         
            <h2 id="autopilot-model-quality-report">Model quality report</h2>
            <p>Model quality information is generated by Autopilot model insights. The report's
                content that is generated depends on the problem type it addressed: regression,
                binary classification, or multiclass classification. The report specifies the number
                of rows that were included in the evaluation dataset and the time at which the
                evaluation occurred.</p>
             
                <h3 id="autopilot-model-quality-report-metrics">Metrics tables</h3>
                <p>The first part of the model quality report contains metrics tables. These are
                    appropriate for the type of problem that the model addressed.</p>
                <p>The following image is an example of a metrics table that Autopilot generates for
                    a regression problem. It shows the metric name, value, and standard
                    deviation.</p>
                <div class="mediaobject">
                     
                        <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-regression-metrics.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                        Amazon SageMaker Autopilot model insights regression metrics report example.&#xA;                    " style="max-width:75%" />
                     
                     
                </div>
                <p>The following image is an example of a metrics table generated by Autopilot for a
                    multiclass classification problem. It shows the metric name, value, and standard
                    deviation.</p>
                <div class="mediaobject">
                     
                        <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-multiclass-metrics-report.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                        Amazon SageMaker Autopilot model insights multiclass classification metrics report&#xA;                            example.&#xA;                    " style="max-width:75%" />
                     
                     
                </div>
             
             
                <h3 id="autopilot-model-quality-report-graphs">Graphical model
                        performance information</h3>
                <p> The second part of the model quality report contains graphical information to
                    help you evaluate model performance. The contents of this section depend on the
                    problem type used in modeling.</p>
                 
                    <h4 id="autopilot-model-insights-auc-roc">The area under the
                            receiver operating characteristic curve</h4>
                    <p>The area under the receiver operating characteristic curve represents the
                        trade-off between true positive and false positive rates. It is an
                        industry-standard accuracy metric used for binary classification models. AUC
                        (area under the curve) measures the ability the model to predict a higher
                        score for positive examples, as compared to negative examples. The AUC
                        metric provides an aggregated measure of the model performance across all
                        possible classification thresholds.</p>
                    <p>The AUC metric returns a decimal value from 0 to 1. AUC values near 1
                        indicate that the machine learning model is highly accurate. Values near 0.5
                        indicate that the model is performing no better than guessing at random. AUC
                        values close to 0 indicate that the model has learned the correct patterns,
                        but is making predictions that are as inaccurate as possible. Values near
                        zero can indicate a problem with the data. For more information about the
                        AUC metric, see the <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener noreferrer" target="_blank"><span>Receiver operating characteristic</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> article on Wikipedia.</p>
                    <p>The following is an example of an area under the receiver operating
                        characteristic curve graph to evaluate predictions made by a binary
                        classification model. The dashed thin line represents the area under the
                        receiver operating characteristic curve that a model which classifies
                        no-better-than-random guessing would score, with an AUC score of 0.5. The
                        curves of more accurate classification models lie above this random
                        baseline, where the rate of true positives exceeds the rate of false
                        positives. The area under the receiver operating characteristic curve
                        representing the performance of the binary classification model is the
                        thicker solid line. </p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-receiver-operating-characteristic-curve.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Amazon SageMaker Autopilot area under the receiver operating characteristic curve&#xA;                                example.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>
                    <p>A summary of the graph's components of <b>false
                            positive rate </b>(FPR) and <b>true positive
                            rate </b>(TPR) are defined as follows.</p>
                    <div class="itemizedlist">
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>Correct predictions</p>
                            <div class="itemizedlist">
                                 
                                 
                            <ul class="itemizedlist"><li class="listitem">
                                    <p><b>True positive</b> (TP): The
                                        predicted the value is 1, and the true value is 1.</p>
                                </li><li class="listitem">
                                    <p><b>True negative</b> (TN): The
                                        predicted the value is 0, and the true value is 0.</p>
                                </li></ul></div>
                        </li><li class="listitem">
                            <p>Erroneous predictions</p>
                            <div class="itemizedlist">
                                 
                                 
                            <ul class="itemizedlist"><li class="listitem">
                                    <p><b>False positive</b> (FP): The
                                        predicted the value is 1, but the true value is 0.</p>
                                </li><li class="listitem">
                                    <p><b>False negative</b> (FN): The
                                        predicted the value is 0, but the true value is 1.</p>
                                </li></ul></div>
                        </li></ul></div>
                    <p>The <b>false positive rate </b>(FPR) measures
                        the fraction of true negatives (TN) that were falsely predicted as positives
                        (FP), over the sum of FP and TN. The range is 0 to 1. A smaller value
                        indicates better predictive accuracy. </p>
                    <div class="itemizedlist">
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>FPR = FP/(FP+TN)</p>
                        </li></ul></div>
                    <p>The <b>true positive rate </b>(TPR) measures the
                        fraction true positives that were correctly predicted as positives (TP) over
                        the sum of TP and false negatives (FN). The range is 0 to 1. A larger value
                        indicates better predictive accuracy.</p>
                    <div class="itemizedlist">
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>TPR = TP/(TP+FN)</p>
                        </li></ul></div>
                 

                 
                    <h4 id="autopilot-model-insights-confusion-matrix">Confusion
                            matrix</h4>

                    <p>A confusion matrix provides a way to visualize the accuracy of the
                        predictions made by a model for binary and multiclass classification for
                        different problems. The confusion matrix in the model quality report
                        contains the following.</p>
                    <div class="itemizedlist">
                         
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>The number and percentage of correct and incorrect predictions for
                                the actual labels</p>
                        </li><li class="listitem">
                            <p>The number and percentage of accurate predictions on the diagonal
                                from the upper-left to the lower-right corner</p>
                        </li><li class="listitem">
                            <p>The number and percentage of inaccurate predictions on the
                                diagonal from the upper-right to the lower-left corner</p>
                        </li></ul></div>
                    <p>The incorrect predictions on a confusion matrix are the confusion
                        values.</p>

                    <p>The following diagram is an example of a confusion matrix for a binary
                        classification problem. It contains the following information:</p>
                    <div class="itemizedlist">
                         
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>The vertical axis is divided into two rows containing true and
                                false actual labels.</p>
                        </li><li class="listitem">
                            <p>The horizontal axis is divided into two columns containing true
                                and false labels that were predicted by the model.</p>
                        </li><li class="listitem">
                            <p>The color bar assigns a darker tone to a larger number of samples
                                to visually indicate the number of values that were classified in
                                each category.</p>
                        </li></ul></div>
                    <p>In this example, the model predicted actual 2817 false values correctly,
                        and 353 actual true values correctly. The model incorrectly predicted 130
                        actual true values to be false and 33 actual false values to be true. The
                        difference in tone indicates that the dataset is not balanced. The imbalance
                        is because there are many more actual false labels than actual true
                        labels.</p>

                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-confusion-matrix-binary.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Amazon SageMaker Autopilot binary confusion matrix example.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>
                    <p>The following diagram is an example of a confusion matrix for a
                        multi-class classification problem. The confusion matrix in the model
                        quality report contains the following.</p>
                    <div class="itemizedlist">
                         
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>The vertical axis is divided into three rows containing three
                                different actual labels.</p>
                        </li><li class="listitem">
                            <p>The horizontal axis is divided into three columns containing
                                labels that were predicted by the model.</p>
                        </li><li class="listitem">
                            <p>The color bar assigns a darker tone to a larger number of samples
                                to visually indicate the number of values that were classified in
                                each category.</p>
                        </li></ul></div>
                    <p>In the example below, the model correctly predicted actual 354 values for
                        label <b>f</b>, 1094 values for label <b>i</b>
                        and 852 values for label <b>m</b>. The difference in tone
                        indicates that the dataset is not balanced because there are many more
                        labels for the value <b>i</b> than for <b>f</b>
                        or <b>m</b>. </p>

                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-confusion-matrix-multiclass.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Amazon SageMaker Autopilot multiclass confusion matrix example.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>

                    <p>The confusion matrix in the model quality report provided can accommodate
                        a maximum of 15 labels for multiclass classification problem types. If a row
                        corresponding to a label shows a <code class="code">Nan</code> value, it means that the
                        validation dataset used to check model predictions does not contain data
                        with that label.</p>
                 
                 
                    <h4 id="autopilot-model-insights-precision-gain-curve">Gain
                            curve</h4>
                    <p>In binary classification, a gain curve predicts the cumulative benefit of
                        using a percentage of the dataset to find a positive label. The gain value
                        is calculated during training by dividing the cumulative number of positive
                        observations by the total number of positive observations in the data, at
                        each decile. If the classification model created during training is
                        representative of the unseen data, you can use the gain curve to predict the
                        percentage of data that you must target to obtain a percentage of positive
                        labels. The greater the percentage of the dataset used, the higher the
                        percentage of positive labels found.</p>
                    <p>In the following example graph, the gain curve is the line with changing
                        slope. The straight line is the percentage of positive labels found by
                        selecting a percentage of data from the dataset at random. Upon targeting
                        20% of the dataset, you would expect to find larger than 40% of the positive
                        labels. As an example, you might consider using a gain curve to determine
                        your efforts in a marketing campaign. Using our gain curve example, for 83%
                        of people in a neighborhood to purchase cookies, you'd send an advertisement
                        to about 60% of the neighborhood.</p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-gain-curve.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Amazon SageMaker Autopilot gain curve example with percentage and gain&#xA;                                value.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>
                 
                 
                    <h4 id="autopilot-model-insights-lift-curve">Lift curve</h4>
                    <p>In binary classification, the lift curve illustrates the uplift of using a
                        trained model to predict the likelihood of finding a positive label compared
                        to a random guess. The lift value is calculated during training using the
                        ratio of percentage gain to the ratio of positive labels at each decile. If
                        the model created during training is representative of the unseen data, use
                        the lift curve to predict the benefit of using the model over randomly
                        guessing.</p>
                    <p>In the following example graph, the lift curve is the line with changing
                        slope. The straight line is the lift curve associated with selecting the
                        corresponding percentage randomly from the dataset. Upon targeting 40% of
                        the dataset with your model's classification labels, you would expect to
                        find about 1.7 times the number of the positive labels that you would have
                        found by randomly selecting 40% of the unseen data.</p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-lift-curve.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Amazon SageMaker Autopilot lift curve example with percentage and lift&#xA;                                value.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>
                 
                 
                    <h4 id="autopilot-model-insights-precision-recall-curve">Precision-recall curve</h4>

                    <p>The precision-recall curve represents the tradeoff between precision and
                        recall for binary classification problems. </p>
                    <p><b>Precision</b> measures the fraction of actual
                        positives that are predicted as positive (TP) out of all positive
                        predictions (TP and false positive). The range is 0 to 1. A larger value
                        indicates better accuracy in the predicted values. </p>
                    <div class="itemizedlist">
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>Precision = TP/(TP+FP)</p>
                        </li></ul></div>
                    <p><b>Recall</b> measures the fraction of actual
                        positives (TP) that are predicted as positive out of all positive
                        predictions (TP and false negative). This is also known as the sensitivity
                        and as the true positive rate. The range is 0 to 1. A larger value indicates
                        better detection of positive values from the sample.</p>
                    <div class="itemizedlist">
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>Recall = TP/(TP+FN)</p>
                        </li></ul></div>
                    <p>The objective of a classification problem is to correctly label as many
                        elements as possible. A system with high recall but low precision returns a
                        high percentage of false positives. </p>
                    <p>The following graphic depicts a spam filter that marks every email as
                        spam. It has high recall, but low precision, because recall doesn't measure
                        false positives. </p>
                    <p>Give more weight to recall over precision if your problem has a low
                        penalty for false positive values, but a high penalty for missing a true
                        positive result. For example, detecting an impending collision in a
                        self-driving vehicle.</p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-high-recall-low-precision.PNG" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Autopilot example of high recall and low precision system,&#xA;                                modelling all samples as positives.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>
                    <p>By contrast, a system with high precision, but low recall, returns a high
                        percentage of false negatives. A spam filter that marks every email as
                        desirable (not spam) has high precision but low recall because precision
                        doesn't measure false negatives. </p>
                    <p>If your problem has a low penalty for false negative values, but a high
                        penalty for missing a true negative results, give more weight to precision
                        over recall. For example, flagging a suspicious filter for a tax
                        audit.</p>
                    <p>The following graphic depicts a spam filter that has high precision but
                        low recall, because precision doesn't measure false negatives. </p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-high-precision-low-recall.PNG" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Autopilot example of high-precision and low-recall system, modeling&#xA;                                all samples as negatives.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>
                    <p>A model that makes predictions with both high precision and high recall
                        produces a high number of correctly labeled results. For more information,
                        see <a href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener noreferrer" target="_blank"><span>Precision and recall</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> article in Wikipedia.</p>
                 
                 
                    <h4 id="autopilot-model-insights-area-under-precision-recall-curve">Area under precision-recall curve (AUPRC)</h4>
                    <p>For binary classification problems, Amazon SageMaker Autopilot includes a graph of the area
                        under the precision-recall curve (AUPRC). The AUPRC metric provides an
                        aggregated measure of the model performance across all possible
                        classification thresholds and uses both precision and recall. AUPRC does not
                        take the number of true negatives into account. Therefore, it can be useful
                        to evaluate model performance in cases where there's a large number of true
                        negatives in the data. For example, to model a gene containing a rare
                        mutation.</p>
                    <p>The following graphic is an example of an AUPRC graph. Precision at its
                        highest value is 1, and recall is at 0. In the lower right corner of the
                        graph, recall is its highest value (1) and precision is 0. In between these
                        two points , the AUPRC curve illustrates the tradeoff between precision and
                        recall at different thresholds.</p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-binary-precision-recall.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Precision-recall curve depicts tradeoff between precision and&#xA;                                recall at different thresholds.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>
                 
                 
                    <h4 id="autopilot-model-insights-actual-vs-predicted-plot">Actual
                            against predicted plot</h4>
                    <p>The actual against predicted plot shows the difference between actual and
                        predicted model values. In the following example graph, the solid line is a
                        linear line of best fit. If the model were 100% accurate, each predicted
                        point would equal its corresponding actual point and lie on this line of
                        best fit. The distance away from the line of best fit is a visual indication
                        of model error. The larger the distance away from the line of best fit, the
                        higher the model error.</p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-actual-vs-predicted-plot.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Example with linear line of best fit, differing actual and&#xA;                                predicted plot, and model error.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>
                 
                 
                    <h4 id="autopilot-model-insights-standardized-residual">Standardized residual plot</h4>
                    <p>A standardized residual plot incorporates the following statistical
                        terms:</p>
                    <div class="variablelist">
                         
                         
                         
                    <dl>
                            <dt><b><span class="term"><code class="code">residual</code></span></b></dt>
                            <dd>
                                <p>A (raw) residual shows the difference between actual and
                                    values predicted by your model. The larger the difference, the
                                    larger the residual value.</p>
                            </dd>
                        
                            <dt><b><span class="term"><code class="code">standard deviation</code></span></b></dt>
                            <dd>
                                <p>The standard deviation is a measure of how values vary from an
                                    average value. A high standard deviation indicates that many
                                    values are very different from their average value. A low
                                    standard deviation indicates that many values are close to their
                                    average value.</p>
                            </dd>
                        
                            <dt><b><span class="term"><code class="code">standardized residual</code></span></b></dt>
                            <dd>
                                <p>A standardized residual divides the raw residuals by their
                                    standard deviation. Standardized residuals have units of
                                    standard deviation and are useful in identifying outliers in
                                    data regardless of the difference in scale of the raw residuals.
                                    If a standardized residual is much smaller or larger than the
                                    other standardized residuals, it indicates that the model is not
                                    fitting these observations well.</p>
                            </dd>
                        </dl></div>
                    <p>The standardized residual plot measures the strength of the difference
                        between observed and expected values. The actual predicted value is
                        displayed on the x axis. A point with a value larger than an absolute value
                        of 3 is commonly regarded as an outlier.</p>
                    <p>The following example graph shows that a large number of standardized
                        residuals are clustered around 0 on the horizontal axis. The values close to
                        zero indicate that the model is fitting these points well. The points
                        towards the top and bottom of the plot are not predicted well by the
                        model.</p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-standardized-residual.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Amazon SageMaker Autopilot standardized residual plot example.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>
                 
                 
                    <h4 id="autopilot-model-insights-residual-histogram">Residual
                            histogram</h4>
                    <p>A residual histogram incorporates the following statistical terms:</p>
                    <div class="variablelist">
                         
                         
                         
                         
                    <dl>
                            <dt><b><span class="term"><code class="code">residual</code></span></b></dt>
                            <dd>
                                <p>A (raw) residual shows the difference between actual and
                                    values predicted by your model. The larger the difference, the
                                    larger the residual value.</p>
                            </dd>
                        
                            <dt><b><span class="term"><code class="code">standard deviation</code></span></b></dt>
                            <dd>
                                <p>The standard deviation is a measure of how much values vary
                                    from an average value. A high standard deviation indicates that
                                    many values are very different from their average value. A low
                                    standard deviation indicates that many values are close to their
                                    average value.</p>
                            </dd>
                        
                            <dt><b><span class="term"><code class="code">standardized residual</code></span></b></dt>
                            <dd>
                                <p>A standardized residual divides the raw residuals by their
                                    standard deviation. Standardized residuals have units of
                                    standard deviation. These are useful in identifying outliers in
                                    data regardless of the difference in scale of the raw residuals.
                                    If a standardized residual is much smaller or larger than the
                                    other standardized residuals, it would indicate that the model
                                    is not fitting these observations well.</p>
                            </dd>
                        
                            <dt><b><span class="term"><code class="code">histogram</code></span></b></dt>
                            <dd>
                                <p>A histogram is a graph that shows how often a value
                                    occurred.</p>
                            </dd>
                        </dl></div>
                    <p>The residual histogram shows the distribution of standardized residual
                        values. A histogram distributed in a bell shape and centered at zero
                        indicates that the model does not systematically overpredict or underpredict
                        any particular range of target values.</p>
                    <p>In the following graphic, the standardized residual values indicate that
                        the model is fitting the data well. If the graph showed values far away from
                        the center value, it would indicate that those values don't fit the model
                        well.</p>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/autopilot/autopilot-model-insights-residual-histogram.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                            Standardized residual value close to zero, indicating that the&#xA;                                model fits the data well.&#xA;                        " style="max-width:75%" />
                         
                         
                    </div>
                 
             
        <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./autopilot-models-details.html">View model details</div><div id="next" class="next-link" accesskey="n" href="./autopilot-automate-model-development-notebook-output.html">Notebooks generated</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/autopilot-model-insights.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/autopilot-model-insights.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>