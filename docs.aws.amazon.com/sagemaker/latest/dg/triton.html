<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Use Triton Inference Server with Amazon SageMaker - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="triton" /><meta name="default_state" content="triton" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="triton.html" /><meta name="description" content="SageMaker enables customers to deploy a model using custom code with NVIDIA Triton Inference Server. This functionality is available through the development of Triton Inference Server Containers . These containers include NVIDIA Triton Inference Server, support for common ML frameworks, and useful environment variables that let you optimize performance on SageMaker. For a list of all available Deep Learning Containers images, see" /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="triton.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/triton.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/triton.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/triton.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/triton.html" hreflang="de" /><link rel="alternative" href="triton.html" hreflang="en-us" /><link rel="alternative" href="triton.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/triton.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/triton.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/triton.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/triton.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/triton.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/triton.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/triton.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/triton.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/triton.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/triton.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/triton.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/triton.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/triton.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/triton.html" hreflang="zh-tw" /><link rel="alternative" href="triton.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Use Triton Inference Server with Amazon SageMaker" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Use Triton Inference Server with Amazon SageMaker - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#triton" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/triton.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/triton.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/triton.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Amazon SageMaker Reference",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/reference.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Machine Learning Frameworks and Languages",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/frameworks.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Use Triton Inference Server with Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/frameworks.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#triton" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="triton.html#triton-inference">Inference</a><a href="triton.html#triton-do">What do you want to do?</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="triton">Use Triton Inference Server with Amazon SageMaker</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>SageMaker enables customers to deploy a model using custom code with NVIDIA Triton Inference Server. 
        This functionality is available through the development of 
        <a href="https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/what-is-dlc.html">Triton Inference Server Containers</a>.
        These containers include NVIDIA Triton Inference Server, support for common ML frameworks, and 
        useful environment variables that let you optimize performance on SageMaker. For a list of all 
        available Deep Learning Containers images, see 
        <a href="https://github.com/aws/deep-learning-containers/blob/master/available_images.md" rel="noopener noreferrer" target="_blank"><span>Available Deep Learning Containers Images</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>. 
        Deep Learning Containers images are maintained and regularly updated with security patches. </p><p>You can use the Triton Inference Server Container with SageMaker Python SDK as you would 
        any other container in your SageMaker models. However, using the SageMaker Python SDK is optional. 
        You can use Triton Inference Server Containers with the AWS CLI and AWS SDK for Python (Boto3). </p><p>For more information on NVIDIA Triton Inference Server see the 
        <a href="https://docs.nvidia.com/deeplearning/triton-inference-server/#" rel="noopener noreferrer" target="_blank"><span>Triton documentation</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
        <h2 id="triton-inference">Inference</h2>
	<div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>The Triton Python backend uses shared memory (SHMEM) to connect your code to Triton. SageMaker Inference provides up to half 
	        of the instance memory as SHMEM so you can use an instance with more memory for larger SHMEM size.</p></div></div>
        <p>For inference, you can use your trained ML models with Triton Inference Server to deploy an inference job with SageMaker.</p>
        <p>Some of the key features of Triton Inference Server Container are:</p>
        <div class="itemizedlist">
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem"><p><b>Support for multiple frameworks</b>: Triton can 
                be used to deploy models from all major ML frameworks. Triton supports TensorFlow 
                GraphDef and SavedModel, ONNX, PyTorch TorchScript, TensorRT, and custom Python/C++ 
                model formats.</p></li><li class="listitem"><p><b>Model pipelines</b>: Triton model ensemble 
                represents a pipeline of one model with pre/post processing logic and the connection 
                of input and output tensors between them. A single inference request to an ensemble 
                triggers the execution of the entire pipeline.</p></li><li class="listitem"><p><b>Concurrent model execution</b>: Multiple instances 
                of the same model can run simultaneously on the same GPU or on multiple GPUs.</p></li><li class="listitem"><p><b>Dynamic batching</b>: For models that 
                support batching, Triton has multiple built-in scheduling and batching algorithms 
                that combine individual inference requests together to improve inference throughput. 
                These scheduling and batching decisions are transparent to the client requesting inference.</p></li><li class="listitem"><p><b>Diverse CPU and GPU support</b>: The models 
                can be executed on CPUs or GPUs for maximum flexibility and to support heterogeneous 
                computing requirements.</p></li></ul></div>
     
        <h2 id="triton-do">What do you want to do?</h2>
        <div class="variablelist">
             
             
        <dl>
                <dt><span class="term">I want to deploy my trained PyTorch model in SageMaker.</span></dt>
                <dd>
                    <p>For a sample Jupyter Notebook, see 
                        the <a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-triton/resnet50/triton_resnet50.ipynb" rel="noopener noreferrer" target="_blank"><span>Deploy your PyTorch Resnet50 model with Triton Inference Server example</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                </dd>
             
                <dt><span class="term">I want to deploy my trained Hugging Face model in SageMaker.</span></dt>
                <dd>
                    <p>For a sample Jupyter Notebook, see 
                        the <a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-triton/nlp_bert/triton_nlp_bert.ipynb" rel="noopener noreferrer" target="_blank"><span>Deploy your PyTorch BERT model with Triton Inference Server example</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                </dd>
            </dl></div>
    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./tf.html">TensorFlow</div><div id="next" class="next-link" accesskey="n" href="./api-and-sdk-reference.html">API Reference</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/triton.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/triton.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>