<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>What Is Fairness and Model Explainability for Machine Learning Predictions? - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="clarify-fairness-and-explainability" /><meta name="default_state" content="clarify-fairness-and-explainability" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="clarify-fairness-and-explainability.html" /><meta name="description" content="Amazon SageMaker Clarify helps improve your machine learning (ML) models by detecting potential bias and helping explain the predictions that models make. It helps you identify various types of bias in pretraining data and in posttraining that can emerge during model training or when the model is in production. SageMaker Clarify helps explain how these models make predictions using a feature attribution approach. It also monitors inferences models make in production for bias or feature attribution drift. The fairness and explainability functionality provided by SageMaker Clarify provides components that help AWS customers build less biased and more understandable machine learning models. It also provides tools to help you generate model governance reports that you can use to inform risk and compliance teams, and external regulators." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="clarify-fairness-and-explainability.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="de" /><link rel="alternative" href="clarify-fairness-and-explainability.html" hreflang="en-us" /><link rel="alternative" href="clarify-fairness-and-explainability.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/clarify-fairness-and-explainability.html" hreflang="zh-tw" /><link rel="alternative" href="clarify-fairness-and-explainability.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="What Is Fairness and Model Explainability for Machine Learning Predictions?" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>What Is Fairness and Model Explainability for Machine Learning Predictions? - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#clarify-fairness-and-explainability" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-fairness-and-explainability.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-fairness-and-explainability.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-fairness-and-explainability.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Detect bias and understand explanations",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/model-explainability.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "What Is Fairness and Model Explainability for Machine Learning Predictions?",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/model-explainability.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#clarify-fairness-and-explainability" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="clarify-fairness-and-explainability.html#clarify-fairness-and-explainability-best-practices">Best Practices for
                Evaluating Fairness and Explainability in the ML Lifecycle</a><a href="clarify-fairness-and-explainability.html#clarify-fairness-and-explainability-sample-notebooks">Sample
                Notebooks</a><a href="clarify-fairness-and-explainability.html#clarify-fairness-and-explainability-toc">Guide to the SageMaker Clarify
                Documentation</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="clarify-fairness-and-explainability">What Is Fairness and Model
            Explainability for Machine Learning Predictions?</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Amazon SageMaker Clarify helps improve your machine learning (ML) models by detecting potential bias and
        helping explain the predictions that models make. It helps you identify various types of
        bias in pretraining data and in posttraining that can emerge during model training or when
        the model is in production. SageMaker Clarify helps explain how these models make predictions using a
        feature attribution approach. It also monitors inferences models make in production for bias
        or feature attribution drift. The fairness and explainability functionality provided by
        SageMaker Clarify provides components that help AWS customers build less biased and more
        understandable machine learning models. It also provides tools to help you generate model
        governance reports that you can use to inform risk and compliance teams, and external
        regulators.</p><p>Machine learning models and data-driven systems are being increasingly used to help make
        decisions across domains such as financial services, healthcare, education, and human
        resources. Machine learning applications provide benefits such as improved accuracy,
        increased productivity, and cost savings to help meet regulatory requirements, improve
        business decisions, and provide better insights into data science procedures.</p><div class="itemizedlist">
         
         
         
    <ul class="itemizedlist"><li class="listitem">
            <p><b>Regulatory</b> – In many situations, it is
                important to understand why an ML model made a specific prediction and also whether
                the prediction it made was impacted by any bias, either during training or at
                inference. Recently, policymakers, regulators, and advocates have raised awareness
                about the ethical and policy challenges posed by ML and data-driven systems. In
                particular, they have expressed concerns about the potentially discriminatory impact
                of such systems (for example, inadvertently encoding of bias into automated
                decisions).
                </p>

        </li><li class="listitem">
            <p><b>Business</b> – The adoption of AI systems in
                regulated domains requires trust, which can be built by providing reliable
                explanations of the behavior of trained models and how the deployed models make
                predictions. Model explainability may be particularly important to certain
                industries with reliability, safety, and compliance requirements, such as financial
                services, human resources, healthcare, and automated transportation. To take a
                common financial example, lending applications that incorporate the use of ML models
                might need to provide explanations about how those models made certain predictions
                to internal teams of loan officers, customer service representatives, and
                forecasters, in addition to end users/customers.</p>

        </li><li class="listitem">
            <p><b>Data Science</b> – Data scientists and ML
                engineers need tools to generate the insights required to debug and improve ML
                models through better feature engineering, to determine whether a model is making
                inferences based on noisy or irrelevant features, and to understand the limitations
                of their models and failure modes their models may encounter.</p>

        </li></ul></div><p>For a blog that shows how to architect and build a complete machine learning use case
        involving fraudulent automobile claims that integrates SageMaker Clarify into a SageMaker pipeline, see the
            <a href="https://aws.amazon.com/blogs/machine-learning/architect-and-build-the-full-machine-learning-lifecycle-with-amazon-sagemaker/" rel="noopener noreferrer" target="_blank"><span>Architect and build the full machine learning lifecycle with AWS: An end-to-end
            Amazon SageMaker</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> demo. This blog discusses how to assess pre and post training bias, how
        to mitigate the bias, and how the data features impact the prediction. There are links to
        the relevent code for each task in the ML lifecycle, including the creation of an automated
        workflow that integrates the fairness and explainablity functionality of SageMaker Clarify into a SageMaker
        Pipeline.</p>
        <h2 id="clarify-fairness-and-explainability-best-practices">Best Practices for
                Evaluating Fairness and Explainability in the ML Lifecycle</h2>
        <p><b>Fairness as a Process</b> – The notions of bias
            and fairness are highly dependent on the application. Further, the choice of the
            attributes for which bias is to be measured, as well as the choice of the bias metrics,
            may need to be guided by social, legal, and other non-technical considerations. Building
            consensus and achieving collaboration across key stakeholders (such as product, policy,
            legal, engineering, and AI/ML teams, as well as end users and communities) is a
            prerequisite for the successful adoption of fairness-aware ML approaches in
            practice.</p>
        <p><b>Fairness and Explainability by Design in the ML
                Lifecycle</b> – You should consider fairness and explainability during
            each stage of the ML lifecycle: problem formation, dataset construction, algorithm
            selection, model training process, testing process, deployment, and monitoring/feedback.
            It is important to have the right tools to do this analysis. To encourage engaging with
            these considerations, here are a few example questions we recommend you ask during each
            of these stages.</p>
        <div class="mediaobject">
             
                <img src="../../../images/sagemaker/latest/dg/images/clarify-best-practices-image.png" class="aws-docs-img-whiteBg aws-docs-img-padding" alt="&#xA;                Best practices for the process of evaluating fairness and model&#xA;                    explainability.&#xA;            " style="max-width:90%" />
             
             
        </div>
     
        <h2 id="clarify-fairness-and-explainability-sample-notebooks">Sample
                Notebooks</h2>

        <p>Amazon SageMaker Clarify provides the following sample notebooks:</p>
        <div class="itemizedlist">
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><a href="https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-clarify/fairness_and_explainability/fairness_and_explainability.html" rel="noopener noreferrer" target="_blank"><span>Explainability and bias detection with Amazon SageMaker Clarify</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> – Use SageMaker Clarify
                    to create a processing job for the detecting bias and explaining model
                    predictions with feature attributions.</p>
            </li><li class="listitem">
                <p><a href="https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_model_monitor/fairness_and_explainability/SageMaker-Model-Monitor-Fairness-and-Explainability.html" rel="noopener noreferrer" target="_blank"><span>Monitoring bias drift and feature attribution drift Amazon SageMaker Clarify</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>
                    – Use Amazon SageMaker Model Monitor to monitor bias drift and feature attribution drift over
                    time.</p>
            </li><li class="listitem">
                <p><a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-clarify/fairness_and_explainability/fairness_and_explainability_byoc.ipynb" rel="noopener noreferrer" target="_blank"><span>Fairness and Explainability with SageMaker Clarify (Bring Your Own Container)</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>
                    – This sample notebook introduces key terms and concepts needed to
                    understand SageMaker Clarify, and it walks you through an end-to-end data science workflow
                    demonstrating how to build your own model and container that can work seamlessly
                    with your Clarify jobs, use the model and SageMaker Clarify to measure bias, explain the
                    importance of the various input features on the model's decision and then access
                    the reports through SageMaker Studio if you have an instance set up.</p>
            </li><li class="listitem">
                <p><a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-clarify/fairness_and_explainability/fairness_and_explainability_byoc.ipynb" rel="noopener noreferrer" target="_blank"><span>Fairness and Explainability with SageMaker Clarify - Spark Distributed
                        Processing</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> – This sample notebook walks you through key terms
                    and concepts needed to understand SageMaker Clarify, measures the pre-training bias of a
                    dataset and post-training bias of a model, explains the importance of the
                    various input features on the model's decision, and accesses the reports through
                    SageMaker Studio if you have an instance set up.</p>
            </li><li class="listitem">
                <p><a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/end_to_end/fraud_detection/3-mitigate-bias-train-model2-registry-e2e.ipynb" rel="noopener noreferrer" target="_blank"><span>Mitigate Bias, Train another unbiased Model and Put in the Model
                        Registry</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> – This notebook describes how to detect bias using
                    SageMaker Clarify, mitigate it with <a href="https://arxiv.org/pdf/1106.1813.pdf" rel="noopener noreferrer" target="_blank"><span>Synthetic Minority Over-sampling Technique (SMOTE)</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>, train another
                    model, then put it in the Model Registry along with all the lineage of the
                    artifacts created along the way: data, code and model metadata. This notebook
                    forms part of a series that shows how to integrate SageMaker Clarify into a SageMaker Pipeline
                    that is described in the <a href="https://aws.amazon.com/blogs/machine-learning/architect-and-build-the-full-machine-learning-lifecycle-with-amazon-sagemaker/" rel="noopener noreferrer" target="_blank"><span>Architect and build the full machine learning lifecycle with AWS</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>
                    blog.</p>
            </li></ul></div>
        <p>These notebooks have been verified to run in Amazon SageMaker Studio only. If you need
            instructions on how to open a notebook in Amazon SageMaker Studio, see <a href="notebooks-create-open.html">Create or Open an Amazon SageMaker Studio Notebook</a>. If you're
            prompted to choose a kernel, choose <b>Python 3 (Data Science)</b>.</p>
     
        <h2 id="clarify-fairness-and-explainability-toc">Guide to the SageMaker Clarify
                Documentation</h2>
        <p>Bias can occur and be measured in the data at each stage of the machine learning
            lifecycle: before training a model and after model training. SageMaker Clarify can provide feature
            attribution explanations of model predictions for trained models and for models deployed
            to production, where models can be monitored for any drift from their baseline
            explanatory attributions. Clarify calculates baselines when needed. The documentation
            for SageMaker Clarify is embedded throughout the larger SageMaker documentation set at the relevant ML
            stages as follows:</p>

        <div class="itemizedlist">
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p>For further information on detecting bias in preprocessing data before it's
                    used to train a model, see <a href="clarify-detect-data-bias.html">Detect Pre-training Data Bias</a>.</p>
            </li><li class="listitem">
                <p>For further information on detecting posttraining data and model bias, see
                        <a href="clarify-detect-post-training-bias.html">Detect Post-training Data and Model
                Bias with Amazon SageMaker Clarify</a>.</p>
            </li><li class="listitem">
                <p>For further information on the model-agnostic feature attribution approach to
                    explain model predictions after training, see <a href="clarify-model-explainability.html">Amazon SageMaker Clarify Model Explainability</a>.</p>
            </li><li class="listitem">
                <p>For further information on monitoring for bias in production model inferences
                    due to the drift of data away from the baseline used to train the model, see
                        <a href="clarify-model-monitor-bias-drift.html">Monitor Bias Drift for Models in
            Production</a>.</p>
            </li><li class="listitem">
                <p>For further information on monitoring for the drift of features' contributions
                    away from the baseline that was established during model training, see <a href="clarify-model-monitor-feature-attribution-drift.html">Monitor Feature
            Attribution Drift for Models in Production</a>.</p>
            </li></ul></div>

    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./model-explainability.html">Detect bias and understand explanations</div><div id="next" class="next-link" accesskey="n" href="./clarify-configure-processing-jobs.html">Use SageMaker Clarify Bias Detection and Model Explainability</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-fairness-and-explainability.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-fairness-and-explainability.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>