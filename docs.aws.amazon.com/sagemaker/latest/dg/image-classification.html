<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Image Classification - MXNet - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="image-classification" /><meta name="default_state" content="image-classification" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="image-classification.html" /><meta name="description" content="The Amazon SageMaker image classification algorithm is a supervised learning algorithm that supports multi-label classification. It takes an image as input and outputs one or more labels assigned to that image. It uses a convolutional neural network that can be trained from scratch or trained using transfer learning when a large number of training images are not available" /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="image-classification.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/image-classification.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/image-classification.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/image-classification.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/image-classification.html" hreflang="de" /><link rel="alternative" href="image-classification.html" hreflang="en-us" /><link rel="alternative" href="image-classification.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/image-classification.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/image-classification.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/image-classification.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/image-classification.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/image-classification.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/image-classification.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/image-classification.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/image-classification.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/image-classification.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/image-classification.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/image-classification.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/image-classification.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/image-classification.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/image-classification.html" hreflang="zh-tw" /><link rel="alternative" href="image-classification.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Image Classification - MXNet" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Image Classification - MXNet - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#image-classification" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/image-classification.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/image-classification.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/image-classification.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Train machine learning models",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/train-model.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Choose an Algorithm",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/algorithms-choose.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Use Amazon SageMaker Built-in Algorithms or Pre-trained Models",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html"
      },
      {
        "@type" : "ListItem",
        "position" : 7,
        "name" : "Built-in SageMaker Algorithms for Computer Vision",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/algorithms-vision.html"
      },
      {
        "@type" : "ListItem",
        "position" : 8,
        "name" : "Image Classification - MXNet",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/algorithms-vision.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#image-classification" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="image-classification.html#IC-inputoutput">Input/Output Interface for the Image Classification
                Algorithm</a><a href="image-classification.html#IC-instances">EC2 Instance Recommendation for the Image Classification
                Algorithm</a><a href="image-classification.html#IC-sample-notebooks">Sample Notebooks</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="image-classification">Image Classification - MXNet</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>The Amazon SageMaker image classification algorithm is a supervised learning algorithm that
        supports multi-label classification. It takes an image as input and outputs one or more
        labels assigned to that image. It uses a convolutional neural network that can be
        trained from scratch or trained using transfer learning when a large number of training
        images are not available </p><p>The recommended input format for the Amazon SageMaker image classification algorithms is Apache
        MXNet <a href="https://mxnet.apache.org/api/faq/recordio" rel="noopener noreferrer" target="_blank"><span>RecordIO</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>. However, you
        can also use raw images in .jpg or .png format. Refer to <a href="https://mxnet.apache.org/api/architecture/note_data_loading" rel="noopener noreferrer" target="_blank"><span>this
            discussion</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> for a broad overview of efficient data preparation and loading for
        machine learning systems. </p><div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>To maintain better interoperability with existing deep learning frameworks, this
            differs from the protobuf data formats commonly used by other Amazon SageMaker
            algorithms.</p></div></div><p>For more information on convolutional networks, see: </p><div class="itemizedlist">
         
         
         
    <ul class="itemizedlist"><li class="listitem">
            <p><a href="https://arxiv.org/abs/1512.03385" rel="noopener noreferrer" target="_blank"><span>Deep residual learning for image
                    recognition</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> Kaiming He, et al., 2016 IEEE Conference on Computer Vision
                and Pattern Recognition</p>
        </li><li class="listitem">
            <p><a href="http://www.image-net.org/" rel="noopener noreferrer" target="_blank"><span>ImageNet image database</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a></p>
        </li><li class="listitem">
            <p><a href="https://gluon-cv.mxnet.io/build/examples_classification/index.html" rel="noopener noreferrer" target="_blank"><span>Image classification with Gluon-CV and MXNet</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a></p>
        </li></ul></div><div class="highlights"><h6>Topics</h6><ul><li><a href="image-classification.html#IC-inputoutput">Input/Output Interface for the Image Classification
                Algorithm</a></li><li><a href="image-classification.html#IC-instances">EC2 Instance Recommendation for the Image Classification
                Algorithm</a></li><li><a href="image-classification.html#IC-sample-notebooks">Image Classification Sample Notebooks</a></li><li><a href="IC-HowItWorks.html">How Image Classification Works</a></li><li><a href="IC-Hyperparameter.html">Image Classification Hyperparameters</a></li><li><a href="IC-tuning.html">Tune an Image Classification Model</a></li></ul></div>
        <h2 id="IC-inputoutput">Input/Output Interface for the Image Classification
                Algorithm</h2>
        <p>The SageMaker Image Classification algorithm supports both RecordIO
                (<code class="code">application/x-recordio</code>) and image (<code class="code">image/png</code>,
                <code class="code">image/jpeg</code>, and <code class="code">application/x-image</code>) content types for
            training in file mode, and supports the RecordIO (<code class="code">application/x-recordio</code>)
            content type for training in pipe mode. However, you can also train in pipe mode using
            the image files (<code class="code">image/png</code>, <code class="code">image/jpeg</code>, and
                <code class="code">application/x-image</code>), without creating RecordIO files, by using the
            augmented manifest format.</p>
        <p>Distributed training is supported for file mode and pipe mode. When using the RecordIO
            content type in pipe mode, you must set the <code class="code">S3DataDistributionType</code> of the
                <code class="code">S3DataSource</code> to <code class="code">FullyReplicated</code>. The algorithm supports a fully replicated model where your data is 
        copied onto each machine.</p>
        <p>The algorithm supports <code class="code">image/png</code>, <code class="code">image/jpeg</code>, and
                <code class="code">application/x-image</code> for inference.</p>
        
         
            <h3 id="IC-recordio-training">Train with RecordIO Format</h3>
            <p>If you use the RecordIO format for training, specify both <code class="code">train</code> and
                    <code class="code">validation</code> channels as values for the <code class="code">InputDataConfig</code>
                parameter of the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html"><code class="code">CreateTrainingJob</code></a> request. Specify one RecordIO
                    (<code class="code">.rec</code>) file in the <code class="code">train</code> channel and one RecordIO file
                in the <code class="code">validation</code> channel. Set the content type for both channels to
                    <code class="code">application/x-recordio</code>. </p>
         
         
            <h3 id="IC-image-training">Train with Image Format</h3>
            <p>If you use the Image format for training, specify <code class="code">train</code>,
                    <code class="code">validation</code>, <code class="code">train_lst</code>, and <code class="code">validation_lst</code>
                channels as values for the <code class="code">InputDataConfig</code> parameter of the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html"><code class="code">CreateTrainingJob</code></a> request. Specify the individual image
                data (<code class="code">.jpg</code> or <code class="code">.png</code> files) for the <code class="code">train</code> and
                    <code class="code">validation</code> channels. Specify one <code class="code">.lst</code> file in each of
                the <code class="code">train_lst</code> and <code class="code">validation_lst</code> channels. Set the content
                type for all four channels to <code class="code">application/x-image</code>. </p>
            <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>SageMaker reads the training and validation data separately from different
                    channels, so you must store the training and validation data in different
                    folders.</p></div></div>
            <p>A <code class="code">.lst</code> file is a tab-separated file with three columns that contains
                a list of image files. The first column specifies the image index, the second column
                specifies the class label index for the image, and the third column specifies the
                relative path of the image file. The image index in the first column must be unique
                across all of the images. The set of class label indices are numbered successively
                and the numbering should start with 0. For example, 0 for the cat class, 1 for the
                dog class, and so on for additional classes. </p>
            <p> The following is an example of a <code class="code">.lst</code> file: </p>
            <pre class="programlisting"><div class="code-btn-container"></div><code class="">5      1   your_image_directory/train_img_dog1.jpg
1000   0   your_image_directory/train_img_cat1.jpg
22     1   your_image_directory/train_img_dog2.jpg</code></pre>
            <p>For example, if your training images are stored in
                    <code class="code">s3://&lt;your_bucket&gt;/train/class_dog</code>,
                    <code class="code">s3://&lt;your_bucket&gt;/train/class_cat</code>, and so on, specify the
                path for your <code class="code">train</code> channel as
                    <code class="code">s3://&lt;your_bucket&gt;/train</code>, which is the top-level directory
                for your data. In the <code class="code">.lst</code> file, specify the relative path for an
                individual file named <code class="code">train_image_dog1.jpg</code> in the
                    <code class="code">class_dog</code> class directory as
                    <code class="code">class_dog/train_image_dog1.jpg</code>. You can also store all your image
                files under one subdirectory inside the <code class="code">train</code> directory. In that case,
                use that subdirectory for the relative path. For example,
                    <code class="code">s3://&lt;your_bucket&gt;/train/your_image_directory</code>. </p>
         

         
            <h3 id="IC-augmented-manifest-training">Train with Augmented Manifest Image
                    Format</h3>
            <p>The augmented manifest format enables you to do training in Pipe mode using image
                files without needing to create RecordIO files. You need to specify both train and
                validation channels as values for the <code class="code">InputDataConfig</code> parameter of the
                    <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html"><code class="code">CreateTrainingJob</code></a> request. While using the format, an S3
                manifest file needs to be generated that contains the list of images and their
                corresponding annotations. The manifest file format should be in <a href="http://jsonlines.org/" rel="noopener noreferrer" target="_blank"><span>JSON Lines</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> format in which each line
                represents one sample. The images are specified using the <code class="code">'source-ref'</code>
                tag that points to the S3 location of the image. The annotations are provided under
                the <code class="code">"AttributeNames"</code> parameter value as specified in the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html"><code class="code">CreateTrainingJob</code></a> request. It can also contain additional
                metadata under the <code class="code">metadata</code> tag, but these are ignored by the
                algorithm. In the following example, the <code class="code">"AttributeNames"</code> are contained
                in the list of image and annotation references <code class="code">["source-ref", "class"]</code>.
                The corresponding label value is <code class="code">"0"</code> for the first image and
                    <code class="code">“1”</code> for the second image:</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>"source-ref":"s3://image/filename1.jpg", "class":"0"}
<span>{</span>"source-ref":"s3://image/filename2.jpg", "class":"1", "class-metadata": <span>{</span>"class-name": "cat", "type" : "groundtruth/image-classification"}}</code></pre>

            <p>The order of <code class="code">"AttributeNames"</code> in the input files matters when
                training the ImageClassification algorithm. It accepts piped data in a specific
                order, with <code class="code">image</code> first, followed by <code class="code">label</code>. So the
                "AttributeNames" in this example are provided with <code class="code">"source-ref"</code> first,
                followed by <code class="code">"class"</code>. When using the ImageClassification algorithm with
                Augmented Manifest, the value of the <code class="code">RecordWrapperType</code> parameter must
                be <code class="code">"RecordIO"</code>.</p>
            <p>Multi-label training is also supported by specifying a JSON array of values. The
                    <code class="code">num_classes</code> hyperparameter must be set to match the total number of
                classes. There are two valid label formats: multi-hot and class-id. </p>
            <p>In the multi-hot format, each label is a multi-hot encoded vector of all classes,
                where each class takes the value of 0 or 1. In the following example, there are
                three classes. The first image is labeled with classes 0 and 2, while the second
                image is labeled with class 2 only: </p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>"image-ref": "s3://mybucket/sample01/image1.jpg", "class": "[1, 0, 1]"}
<span>{</span>"image-ref": "s3://mybucket/sample02/image2.jpg", "class": "[0, 0, 1]"}</code></pre>

            <p>In the class-id format, each label is a list of the class ids, from [0,
                    <code class="code">num_classes</code>), which apply to the data point. The previous example
                would instead look like this:</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>"image-ref": "s3://mybucket/sample01/image1.jpg", "class": "[0, 2]"}
<span>{</span>"image-ref": "s3://mybucket/sample02/image2.jpg", "class": "[2]"}</code></pre>

            <p>The multi-hot format is the default, but can be explicitly set in the content type
                with the <code class="code">label-format</code> parameter: <code class="code">"application/x-recordio;
                    label-format=multi-hot".</code> The class-id format, which is the format
                outputted by GroundTruth, must be set explicitly: <code class="code">"application/x-recordio;
                    label-format=class-id".</code></p>
            <p>For more information on augmented manifest files, see <a href="augmented-manifest.html">Provide Dataset Metadata to Training Jobs with an
            Augmented Manifest File</a>.</p>
         

         
            <h3 id="IC-incremental-training">Incremental Training</h3>

            <p>You can also seed the training of a new model with the artifacts from a model that
                you trained previously with SageMaker. Incremental training saves training time when you
                want to train a new model with the same or similar data. SageMaker image classification
                models can be seeded only with another built-in image classification model trained
                in SageMaker.</p>

            <p>To use a pretrained model, in the <a href="https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html"><code class="code">CreateTrainingJob</code></a> request, specify the
                    <code class="code">ChannelName</code> as "model" in the <code class="code">InputDataConfig</code>
                parameter. Set the <code class="code">ContentType</code> for the model channel to
                    <code class="code">application/x-sagemaker-model</code>. The input hyperparameters of both
                the new model and the pretrained model that you upload to the model channel must
                have the same settings for the <code class="code">num_layers</code>, <code class="code">image_shape</code> and
                    <code class="code">num_classes</code> input parameters. These parameters define the network
                architecture. For the pretrained model file, use the compressed model artifacts (in
                .tar.gz format) output by SageMaker. You can use either RecordIO or image formats for
                input data.</p>
         

         
            <h3 id="IC-inference">Inference with the Image Classification
                    Algorithm</h3>
            <p>The generated models can be hosted for inference and support encoded
                    <code class="code">.jpg</code> and <code class="code">.png</code> image formats as <code class="code">image/png,
                    image/jpeg</code>, and <code class="code">application/x-image</code> content-type. The input
                image is resized automatically. The output is the probability values for all classes
                encoded in JSON format, or in <a href="http://jsonlines.org/" rel="noopener noreferrer" target="_blank"><span>JSON Lines text
                    format</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> for batch transform. The image classification model processes a
                single image per request and so outputs only one line in the JSON or JSON Lines
                format. The following is an example of a response in JSON Lines format:</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="json ">accept: application/jsonlines

 <span>{</span>"prediction": [prob_0, prob_1, prob_2, prob_3, ...]}</code></pre>
            <p>For more details on training and inference, see the image classification sample
                notebook instances referenced in the introduction.</p>
         
     
        <h2 id="IC-instances">EC2 Instance Recommendation for the Image Classification
                Algorithm</h2>

        <p>For image classification, we support P2, P3, G4dn, and G5 instances. We recommend using
            GPU instances with more memory for training with large batch sizes. You can also run the
            algorithm on multi-GPU and multi-machine settings for distributed training. Both CPU
            (such as C4) and GPU (P2, P3, G4dn, or G5) instances can be used for inference.</p>
     
        <h2 id="IC-sample-notebooks">Image Classification Sample Notebooks</h2>

        <p>For a sample notebook that uses the SageMaker image classification algorithm, see <a href="https://github.com/aws-samples/amazon-sagemaker-pipelines-mxnet-image-classification/blob/main/image-classification-sagemaker-pipelines.ipynb" rel="noopener noreferrer" target="_blank"><span>Build and Register an MXNet Image Classification Model via SageMaker Pipelines</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.
            For instructions how to create and access Jupyter notebook instances that you can use to
            run the example in SageMaker, see <a href="nbi.html">Amazon SageMaker Notebook Instances</a>. Once you have
            created a notebook instance and opened it, select the <b>SageMaker
                Examples</b> tab to see a list of all the SageMaker samples. The example image
            classification notebooks are located in the <b>Introduction to Amazon
                algorithms</b> section. To open a notebook, click on its <b>Use</b> tab and select <b>Create
                copy</b>.</p>
    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./algorithms-vision.html">Vision</div><div id="next" class="next-link" accesskey="n" href="./IC-HowItWorks.html"> How It Works </div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/image-classification.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/image-classification.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>