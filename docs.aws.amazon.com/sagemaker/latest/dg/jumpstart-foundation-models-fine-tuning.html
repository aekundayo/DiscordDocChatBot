<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Fine-tune a foundation model - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="jumpstart-foundation-models-fine-tuning" /><meta name="default_state" content="jumpstart-foundation-models-fine-tuning" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="jumpstart-foundation-models-fine-tuning.html" /><meta name="description" content="Customize a foundation model with fine-tuning." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="jumpstart-foundation-models-fine-tuning.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="de" /><link rel="alternative" href="jumpstart-foundation-models-fine-tuning.html" hreflang="en-us" /><link rel="alternative" href="jumpstart-foundation-models-fine-tuning.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" hreflang="zh-tw" /><link rel="alternative" href="jumpstart-foundation-models-fine-tuning.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Fine-tune a foundation model" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Fine-tune a foundation model - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#jumpstart-foundation-models-fine-tuning" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Use automated ML, no-code, or low-code",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/use-auto-ml.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "SageMaker JumpStart",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "JumpStart Foundation Models",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models.html"
      },
      {
        "@type" : "ListItem",
        "position" : 7,
        "name" : "Customize a foundation model",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize.html"
      },
      {
        "@type" : "ListItem",
        "position" : 8,
        "name" : "Fine-tune a foundation model",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#jumpstart-foundation-models-fine-tuning" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="jumpstart-foundation-models-fine-tuning.html#jumpstart-foundation-models-fine-tuning-domain-adaptation">Domain adaptation fine-tuning</a><a href="jumpstart-foundation-models-fine-tuning.html#jumpstart-foundation-models-fine-tuning-instruction-based">Instruction-based fine-tuning</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="jumpstart-foundation-models-fine-tuning">Fine-tune a foundation
                    model</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Foundation models are computationally expensive and trained on a large, unlabeled
                corpus. Fine-tuning a pre-trained foundation model is an affordable way to take
                advantage of their broad capabilities while customizing a model on your own small,
                corpus. Fine-tuning is a customization method that involved further training and
                does change the weights of your model. </p><p>Fine-tuning might be useful to you if you need: </p><div class="itemizedlist">
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                    <p>to customize your model to specific business needs</p></li><li class="listitem">
                    <p>your model to successfully work with domain-specific language, such as
                        industry jargon, technical terms, or other specialized vocabulary</p>
                </li><li class="listitem">
                    <p>enhanced performance for specific tasks</p></li><li class="listitem">
                    <p>accurate, relative, and context-aware responses in applications</p>
                </li><li class="listitem">
                    <p>responses that are more factual, less toxic, and better-aligned to
                        specific requirements</p></li></ul></div><p>There are two main approaches that you can take for fine-tuning depending on your
                use case and chosen foundation model. If you're interested in fine-tuning your model
                on domain-specific data, see <a href="jumpstart-foundation-models-fine-tuning.html#jumpstart-foundation-models-fine-tuning-domain-adaptation">Domain adaptation fine-tuning</a>. If you're interested in instruction-based fine-tuning using prompt and response examples, see <a href="jumpstart-foundation-models-fine-tuning.html#jumpstart-foundation-models-fine-tuning-instruction-based">Instruction-based fine-tuning</a>.</p>
                <h2 id="jumpstart-foundation-models-fine-tuning-domain-adaptation">Domain adaptation fine-tuning</h2>
                <p>Domain adaptation fine-tuning allows you to leverage pre-trained foundation
                    models and adapt them to specific tasks using limited domain-specific data. If
                    prompt engineering efforts do not provide enough customization, you can use
                    domain adaption fine-tuning to get your model working with domain-specific
                    language, such as industry jargon, technical terms, or other specialized data.
                    This fine-tuning process modifies the weights of the model. </p>
                <p>For more information, see the <a href="https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/jumpstart-foundation-models/domain-adaption-finetuning-gpt-j-6b.html" rel="noopener noreferrer" target="_blank"><span>SageMaker JumpStart Foundation Models - Fine-tuning text generation GPT-J 6B model on
                        domain specific dataset</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> example notebook. You can also follow the
                    domain adaptation dataset format steps in the <a href="https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/jumpstart-foundation-models/llama-2-finetuning.html" rel="noopener noreferrer" target="_blank"><span>Fine-tune LLaMA 2 models on SageMaker JumpStart</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> example notebook.</p>
                <p>Domain adaptation fine-tuning is available with the following foundation models:</p>
                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>Some JumpStart foundation models, such as LLaMa-2-7B, require acceptance of an end-user license
                        agreement before fine-tuning and performing inference. For more information,
                        see <a href="jumpstart-foundation-models-choose.html#jumpstart-foundation-models-choose-eula">End-user license agreements</a>.</p></div></div>
                <div class="itemizedlist">
                     
                     
                     
                     
                     
                <ul class="itemizedlist"><li class="listitem"><p>BloomZ 7b1</p></li><li class="listitem"><p>GPT-J 6B</p></li><li class="listitem"><p>GPT Neo 2.7B</p></li><li class="listitem"><p>LLaMa-2-7b</p></li><li class="listitem"><p>LLaMa-2-13b</p></li></ul></div>
             
                <h2 id="jumpstart-foundation-models-fine-tuning-instruction-based">Instruction-based fine-tuning</h2>
                <p>Instruction-based fine-tuning uses labeled examples to improve the performance
                    of a pre-trained foundation model on a specific task. The labeled examples are
                    formatted as prompt, response pairs and phrased as instructions. This
                    fine-tuning process modifies the weights of the model. For more information on
                    instruction-based fine-tuning, see the papers <a href="https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html" rel="noopener noreferrer" target="_blank"><span>Introducing FLAN: More generalizable Language Models with Instruction
                        Fine-Tuning</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> and <a href="https://arxiv.org/abs/2210.11416" rel="noopener noreferrer" target="_blank"><span>Scaling Instruction-Finetuned Language Models</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                <p>Fine-tuned LAnguage Net (FLAN) models use instruction tuning to make models
                    more amenable to solving general downstream NLP tasks. Amazon SageMaker JumpStart provides a
                    number of foundation models in the FLAN model family. For example, FLAN-T5
                    models are instruction fine-tuned on a wide range of tasks to increase zero-shot
                    performance for a variety of common use cases. With additional data and
                    fine-tuning, instruction-based models can be further adapted to more specific
                    tasks that weren’t considered during pre-training. </p>
                <p>For more information, see the <a href="https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/jumpstart-foundation-models/instruction-fine-tuning-flan-t5.html" rel="noopener noreferrer" target="_blank"><span>SageMaker JumpStart Foundation Models - HuggingFace Text2Text Instruction
                        Fine-Tuning</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> example notebook. You can also follow the instruction
                    fine-tuning dataset format steps in the <a href="https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/jumpstart-foundation-models/llama-2-finetuning.html" rel="noopener noreferrer" target="_blank"><span>Fine-tune LLaMA 2 models on SageMaker JumpStart</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> example notebook.</p>
                <p>Instruction-based fine-tuning is available with the following foundation
                    models: </p>
                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>Some JumpStart foundation models, such as LLaMa-2-7B, require acceptance of an end-user license
                        agreement before fine-tuning and performing inference. For more information,
                        see <a href="jumpstart-foundation-models-choose.html#jumpstart-foundation-models-choose-eula">End-user license agreements</a>.</p></div></div>
                <div class="itemizedlist">
                     
                     
                     
                     
                     
                     
                <ul class="itemizedlist"><li class="listitem"><p>FLAN-T5 XL</p></li><li class="listitem"><p>FLAN-T5 Large</p></li><li class="listitem"><p>FLAN-T5 Small</p></li><li class="listitem"><p>FLAN-T5 Base</p></li><li class="listitem"><p>LLaMa-2-7b</p></li><li class="listitem"><p>LLaMa-2-13b</p></li></ul></div>
            <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./jumpstart-foundation-models-customize-prompt-engineering.html">Prompt engineering</div><div id="next" class="next-link" accesskey="n" href="./jumpstart-foundation-models-customize-rag.html">Retrieval Augmented Generation (RAG)</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/jumpstart-foundation-models-fine-tuning.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>