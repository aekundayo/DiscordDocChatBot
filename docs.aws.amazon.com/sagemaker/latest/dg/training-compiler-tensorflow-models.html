<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>TensorFlow - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="training-compiler-tensorflow-models" /><meta name="default_state" content="training-compiler-tensorflow-models" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="training-compiler-tensorflow-models.html" /><meta name="description" content="Use Amazon SageMaker Training Compiler to compile TensorFlow models." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="training-compiler-tensorflow-models.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="de" /><link rel="alternative" href="training-compiler-tensorflow-models.html" hreflang="en-us" /><link rel="alternative" href="training-compiler-tensorflow-models.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/training-compiler-tensorflow-models.html" hreflang="zh-tw" /><link rel="alternative" href="training-compiler-tensorflow-models.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="TensorFlow" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>TensorFlow - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#training-compiler-tensorflow-models" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/training-compiler-tensorflow-models.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/training-compiler-tensorflow-models.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/training-compiler-tensorflow-models.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance,amazon sagemaker training compiler, sagemaker training compiler, sm training compiler,compile deep learning model, compile transformer model, compile tensorflow model, compile pytorch model, compile nlp model,amazon sagemaker training compiler, sagemaker training compiler, sm training compiler,compile deep learning model, compile transformer model, compile tensorflow model, compile pytorch model, compile nlp model,transformers, transformer, model,tensorflow, pytorch, hugging face,tf.keras.model,modify training script, modify script,distributed training, data parallelism, distributed data parallel,use sagemaker training compiler for tensorflow, sagemaker training compiler for tensorflow, training compiler for tensorflow, compile tensorflow model" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Train machine learning models",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/train-model.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Amazon SageMaker Training Compiler",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/training-compiler.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Bring Your Own Deep Learning Model",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/training-compiler-modify-scripts.html"
      },
      {
        "@type" : "ListItem",
        "position" : 7,
        "name" : "TensorFlow",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/training-compiler-modify-scripts.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#training-compiler-tensorflow-models" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="training-compiler-tensorflow-models.html#training-compiler-tensorflow-models">TensorFlow Models</a><a href="training-compiler-tensorflow-models.html#training-compiler-tensorflow-models-transformers">TensorFlow Models with
                Hugging Face Transformers</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="training-compiler-tensorflow-models">TensorFlow</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Bring your own TensorFlow model to SageMaker, and run the training job with SageMaker Training Compiler.</p>
        <h2 id="training-compiler-tensorflow-models">TensorFlow Models</h2>
        <p>SageMaker Training Compiler automatically optimizes model training workloads that are
            built on top of the native TensorFlow API or the high-level Keras API.</p>
        <div class="awsdocs-note awsdocs-tip"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Tip</h6></div><div class="awsdocs-note-text"><p>For preprocessing your input dataset, ensure that you use a static input shape.
                Dynamic input shape can initiate recompilation of the model and might increase total
                training time. </p></div></div>
         
            <h3 id="training-compiler-tensorflow-models-keras">Using Keras (Recommended)</h3>
            <p>For the best compiler acceleration, we recommend using models that are subclasses
                of TensorFlow Keras (<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="noopener noreferrer" target="_blank"><span>tf.keras.Model</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>).</p>
             
                <h4 id="training-compiler-tensorflow-models-keras-single-gpu">For single GPU training</h4>
                <p>There's no additional change you need to make in the training script.</p>
             
         
         
            <h3 id="training-compiler-tensorflow-models-no-keras">Without Keras</h3>
            <p>SageMaker Training Compiler does not support eager execution in TensorFlow. Accordingly, you should
                wrap your model and training loops with the TensorFlow function decorator
                    (<code class="code">@tf.function</code>) to leverage compiler acceleration.</p>
            <p>SageMaker Training Compiler performs a graph-level optimization, and uses the
                decorator to make sure your TensorFlow functions are set to run in <a href="https://www.tensorflow.org/guide/intro_to_graphs" rel="noopener noreferrer" target="_blank"><span>graph
                mode</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
             
                <h4 id="training-compiler-tensorflow-models-no-keras-single-gpu">For single GPU training</h4>
                <p>TensorFlow 2.0 or later has the eager execution on by default, so you should
                    add the <code class="code">@tf.function</code> decorator in front of every function that you
                    use for constructing a TensorFlow model.</p>
             
         
     
        <h2 id="training-compiler-tensorflow-models-transformers">TensorFlow Models with
                Hugging Face Transformers</h2>
        <p>TensorFlow models with <a href="https://huggingface.co/docs/transformers/index" rel="noopener noreferrer" target="_blank"><span>Hugging
                Face Transformers</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> are based on TensorFlow's <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="noopener noreferrer" target="_blank"><span>tf.keras.Model</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> API. Hugging Face Transformers also provides pretrained
            model classes for TensorFlow to help reduce the effort for configuring natural language
            processing (NLP) models. After creating your own training script using the Transformers
            library, you can run the training script using the SageMaker <code class="code">HuggingFace</code>
            estimator with the SageMaker Training Compiler configuration class as shown in the previous topic at <a href="training-compiler-enable-tensorflow.html">Run TensorFlow Training Jobs with SageMaker Training Compiler</a>.</p>
        <p>SageMaker Training Compiler automatically optimizes model training workloads that are built on top of the
            native TensorFlow API or the high-level Keras API, such as the TensorFlow transformer
            models.</p>
        <div class="awsdocs-note awsdocs-tip"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Tip</h6></div><div class="awsdocs-note-text"><p>When you create a tokenizer for an NLP model using Transformers in your training
                script, make sure that you use a static input tensor shape by specifying
                    <code class="code">padding='max_length'</code>. Do not use <code class="code">padding='longest'</code>
                because padding to the longest sequence in the batch can change the tensor shape for
                each training batch. The dynamic input shape can initiate recompilation of the model
                and might increase total training time. For more information about padding options
                of the Transformers tokenizers, see <a href="https://huggingface.co/docs/transformers/pad_truncation" rel="noopener noreferrer" target="_blank"><span>Padding and
                    truncation</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> in the <em>Hugging Face Transformers
                    documentation</em>.</p></div></div>
        <div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="training-compiler-tensorflow-models.html#training-compiler-tensorflow-models-transformers-keras">Using
                    Keras</a></li><li><a href="training-compiler-tensorflow-models.html#training-compiler-tensorflow-models-transformers-no-keras">Without
                    Keras</a></li></ul></div>
         
            <h3 id="training-compiler-tensorflow-models-transformers-keras">Using
                    Keras</h3>
            <p>For the best compiler acceleration, we recommend using models that are subclasses
                of TensorFlow Keras (<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="noopener noreferrer" target="_blank"><span>tf.keras.Model</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>). As noted in the <a href="https://huggingface.co/docs/transformers/quicktour" rel="noopener noreferrer" target="_blank"><span>Quick tour</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> page
                in the <em>Hugging Face Transformers documentation</em>,
                you can use the models as regular TensorFlow Keras models.</p>
             
                <h4 id="training-compiler-tensorflow-models-transformers-keras-single-gpu">For single GPU training</h4>
                <p>There's no additional change you need to make in the training script.</p>
             
             
                <h4 id="training-compiler-tensorflow-models-transformers-keras-distributed">For distributed training</h4>
                <p>SageMaker Training Compiler acceleration works transparently for multi-GPU workloads when the
                    model is constructed and trained using Keras APIs within the scope of <a href="https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy" rel="noopener noreferrer" target="_blank"><span><code class="code">tf.distribute.Strategy.scope()</code></span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> call.</p>
                <div class="orderedlist">
                     
                     
                <ol><li>
                        <p>Choose the right distributed training strategy.</p>
                        <div class="orderedlist">
                             
                             
                        <ol><li>
                                <p>For single-node multi-GPU, use
                                        <code class="code">tf.distribute.MirroredStrategy</code> to set the
                                    strategy.</p>
                                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">strategy = tf.distribute.MirroredStrategy()</code></pre>
                            </li><li>
                                <p>For multi-node multi-GPU, add the following code to properly
                                    set the TensorFlow distributed training configuration before
                                    creating the strategy.</p>
                                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">def set_sm_dist_config():
    DEFAULT_PORT = '8890'
    DEFAULT_CONFIG_FILE = '/opt/ml/input/config/resourceconfig.json'
    with open(DEFAULT_CONFIG_FILE) as f:
        config = json.loads(f.read())
        current_host = config['current_host']
    tf_config = <span>{</span>
        'cluster': <span>{</span>
            'worker': []
        },
        'task': <span>{</span>'type': 'worker', 'index': -1}
    }
    for i, host in enumerate(config['hosts']):
        tf_config['cluster']['worker'].append("%s:%s" % (host, DEFAULT_PORT))
        if current_host == host:
            tf_config['task']['index'] = i
    os.environ['TF_CONFIG'] = json.dumps(tf_config)

set_sm_dist_config()</code></pre>
                                <p> Use <code class="code">tf.distribute.MultiWorkerMirroredStrategy</code> to
                                    set the strategy.</p>
                                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">strategy = tf.distribute.MultiWorkerMirroredStrategy()</code></pre>
                            </li></ol></div>
                    </li><li>
                        <p>Using the strategy of your choice, wrap the model.</p>
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">with strategy.scope():
    # create a model and do fit</code></pre>
                    </li></ol></div>
             
         
         
            <h3 id="training-compiler-tensorflow-models-transformers-no-keras">Without
                    Keras</h3>
            <p>If you want to bring custom models with custom training loops using TensorFlow without
                Keras, you should wrap the model and the training loop with the TensorFlow function
                decorator (<code class="code">@tf.function</code>) to leverage compiler acceleration.</p>
            <p>SageMaker Training Compiler performs a graph-level optimization, and uses the decorator to make sure
                your TensorFlow functions are set to run in graph mode. </p>
             
                <h4 id="training-compiler-tensorflow-models-transformers-no-keras-single-gpu">For single GPU training</h4>
                <p>TensorFlow 2.0 or later has the eager execution on by default, so you should add
                    the <code class="code">@tf.function</code> decorator in front of every function that you use
                    for constructing a TensorFlow model.</p>
             
             
                <h4 id="training-compiler-tensorflow-models-transformers-no-keras-distributed">For distributed training</h4>
                <p>In addition to the changes needed for <a href="training-compiler-tensorflow-models.html#training-compiler-tensorflow-models-transformers-keras">Using Keras for distributed training</a>, you need to ensure that
                    functions to be run on each GPU are annotated with <code class="code">@tf.function</code>,
                    while cross-GPU communication functions are not annotated. An example training
                    code should look like the following:</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="py ">@tf.function()
def compiled_step(inputs, outputs):
    with tf.GradientTape() as tape:
        pred=model(inputs, training=True)
        total_loss=loss_object(outputs, pred)/args.batch_size
    gradients=tape.gradient(total_loss, model.trainable_variables)
    return total_loss, pred, gradients

def train_step(inputs, outputs):
    total_loss, pred, gradients=compiled_step(inputs, outputs)
    if args.weight_decay &gt; 0.:
        gradients=[g+v*args.weight_decay for g,v in zip(gradients, model.trainable_variables)]

    optimizer.apply_gradients(zip(gradients, model.trainable_variables))

    train_loss.update_state(total_loss)
    train_accuracy.update_state(outputs, pred)

@tf.function()
def train_step_dist(inputs, outputs):
    strategy.run(train_step, args= (inputs, outputs))</code></pre>
                <p>Note that this instruction can be used for both single-node multi-GPU and
                    multi-node multi-GPU.</p>
             
         
    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./training-compiler-pytorch-models.html">PyTorch</div><div id="next" class="next-link" accesskey="n" href="./training-compiler-enable.html">Enable Training Compiler</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/training-compiler-tensorflow-models.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/training-compiler-tensorflow-models.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>