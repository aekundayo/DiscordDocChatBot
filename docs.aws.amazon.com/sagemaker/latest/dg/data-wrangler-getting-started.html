<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Get Started with Data Wrangler - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="data-wrangler-getting-started" /><meta name="default_state" content="data-wrangler-getting-started" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="data-wrangler-getting-started.html" /><meta name="description" content="Get started with Data Wrangler and follow a walkthrough to apply your knowledge." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="data-wrangler-getting-started.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="de" /><link rel="alternative" href="data-wrangler-getting-started.html" hreflang="en-us" /><link rel="alternative" href="data-wrangler-getting-started.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/data-wrangler-getting-started.html" hreflang="zh-tw" /><link rel="alternative" href="data-wrangler-getting-started.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Get Started with Data Wrangler" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Get Started with Data Wrangler - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#data-wrangler-getting-started" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-getting-started.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-getting-started.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-getting-started.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Prepare data",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/data-prep.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Prepare ML Data with Amazon SageMaker Data Wrangler",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/data-wrangler.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Get Started with Data Wrangler",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/data-wrangler.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#data-wrangler-getting-started" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="data-wrangler-getting-started.html#data-wrangler-getting-started-prerequisite">Prerequisites</a><a href="data-wrangler-getting-started.html#data-wrangler-getting-started-access">Access Data Wrangler</a><a href="data-wrangler-getting-started.html#data-wrangler-update-studio-app">Update Data Wrangler</a><a href="data-wrangler-getting-started.html#data-wrangler-getting-started-demo">Demo: Data Wrangler Titanic Dataset
                Walkthrough</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="data-wrangler-getting-started">Get Started with Data Wrangler</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>Amazon SageMaker Data Wrangler is a feature in Amazon SageMaker Studio. Use this section to learn how to access and get
        started using Data Wrangler. Do the following:</p><div class="procedure"><ol><li>
            <p>Complete each step in <a href="data-wrangler-getting-started.html#data-wrangler-getting-started-prerequisite">Prerequisites</a>.</p>
        </li><li>
            <p>Follow the procedure in <a href="data-wrangler-getting-started.html#data-wrangler-getting-started-access">Access Data Wrangler</a> to start using
                Data Wrangler.</p>
        </li></ol></div>
        <h2 id="data-wrangler-getting-started-prerequisite">Prerequisites</h2>
        <p>To use Data Wrangler, you must complete the following prerequisites. </p>
        <div class="procedure"><ol><li>
                <p>To use Data Wrangler, you need access to an Amazon Elastic Compute Cloud (Amazon EC2) instance. For more

                    information about the Amazon EC2 instances that you can use, see <a href="data-wrangler-data-flow.html#data-wrangler-data-flow-instances">Instances</a>. To learn how to view
                    your quotas and, if necessary, request a quota increase, see <a href="https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html">AWS
                        service quotas</a>.</p>
            </li><li>
                <p>Configure the required permissions described in <a href="data-wrangler-security.html">Security and Permissions</a>.
                </p>
            </li><li>
                <p>If your organization is using a firewall that blocks internet traffic, you must have access to the following URLs:</p>
                <div class="itemizedlist">
                     
                     
                     
                     
                    
                <ul class="itemizedlist"><li class="listitem">
                        <p><code class="code">https://ui.prod-1.data-wrangler.sagemaker.aws/</code></p>
                    </li><li class="listitem">
                        <p><code class="code">https://ui.prod-2.data-wrangler.sagemaker.aws/</code></p>
                    </li><li class="listitem">
                        <p><code class="code">https://ui.prod-3.data-wrangler.sagemaker.aws/</code></p>
                    </li><li class="listitem">
                        <p><code class="code">https://ui.prod-4.data-wrangler.sagemaker.aws/</code></p>
                    </li></ul></div>
            </li></ol></div>

        <p>To use Data Wrangler, you need an active Studio instance. To learn how to launch a new
            instance, see <a href="gs-studio-onboard.html">Onboard to Amazon SageMaker Domain</a>.
            When your Studio instance is <b>Ready</b>, use the instructions in
                <a href="data-wrangler-getting-started.html#data-wrangler-getting-started-access">Access Data Wrangler</a>.</p>
     
        <h2 id="data-wrangler-getting-started-access">Access Data Wrangler</h2>
        <p>The following procedure assumes you have completed the <a href="data-wrangler-getting-started.html#data-wrangler-getting-started-prerequisite">Prerequisites</a>.</p>
        
        
        <div class="procedure"><p>To access Data Wrangler in Studio, do the following.</p><ol><li>
                <p>Sign in to Studio. For more information, see <a href="gs-studio-onboard.html">Onboard to Amazon SageMaker Domain</a>.</p>
            </li><li>
                <p>Choose <b>Studio</b>.</p>
            </li><li>
                <p>Choose <b>Launch app</b>.</p>
            </li><li>
                <p>From the dropdown list, select <b>Studio</b>.</p>
            </li><li>
                <p>Choose the Home icon.</p>
            </li><li>
                <p>Choose <b>Data</b>.</p>
            </li><li>
                <p>Choose <b>Data Wrangler</b>.</p>
            </li><li>
                <p>You can also create a Data Wrangler flow by doing the following.</p>
                <ol><li>
                        <p>In the top navigation bar, select <b>File</b>.</p>
                    </li><li>
                        <p>Select <b>New</b>.</p>
                    </li><li>
                        <p>Select <b>Data Wrangler Flow</b>.</p>
                    </li></ol>
                <div class="mediaobject">
                     
                        <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/new-flow-file-menu.png" class="aws-docs-img-whiteBg aws-docs-img-padding" style="max-width:80%" />
                     
                </div>
                
                
                
            </li><li>
                <p>(Optional) Rename the new directory and the .flow file.</p>
            </li><li>
                <p>When you create a new .flow file in Studio, you might see a carousel that introduces you to Data Wrangler.</p>
                
                <p><b>This may take a few minutes.</b></p>
               
                <p>This messaging persists as long as the <b>KernelGateway</b> app on
                    your <b>User Details</b> page is <b>Pending</b>. To
                    see the status of this app, in the SageMaker console on the
                    <b>Amazon SageMaker Studio</b> page, select the name of the user you
                    are using to access Studio. On the <b>User Details</b> page,
                    you see a <b>KernelGateway</b> app under
                    <b>Apps</b>. Wait until this app status is
                    <b>Ready</b> to start using Data Wrangler. This can take around 5
                    minutes the first time you launch Data Wrangler.</p>
                <div class="mediaobject">
                     
                        <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/gatewayKernel-ready.png" class="aws-docs-img-whiteBg aws-docs-img-padding" style="max-width:80%" />
                     
                </div>
            </li><li>
                <p>To get started, choose a data source and use it to import a dataset. See <a href="data-wrangler-import.html">Import</a> to
                    learn more. </p>
                <p>When you import a dataset, it appears in your data flow. To learn more, see
                    <a href="data-wrangler-data-flow.html">Create and Use a Data Wrangler Flow</a>.</p>
            </li><li>
                <p>After you import a dataset, Data Wrangler automatically infers the type of data in each
                    column. Choose <b>+</b> next to the <b>Data
                        types</b> step and select <b>Edit data types</b>. </p>
                <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>After you add transforms to the <b>Data types</b> step, you
                        cannot bulk-update column types using <b>Update types</b>.
                    </p></div></div>
            </li><li>
                <p>Use the data flow to add transforms and analyses. To learn more see <a href="data-wrangler-transform.html">Transform Data</a>
                    and <a href="data-wrangler-analyses.html">Analyze and Visualize</a>.</p>
            </li><li>
                <p>To export a complete data flow, choose <b>Export</b> and choose
                    an export option. To learn more, see <a href="data-wrangler-data-export.html">Export</a>. </p>
            </li><li>
                <p>Finally, choose the <b>Components and registries</b> icon, and
                    select <b>Data Wrangler</b> from the dropdown list to see all the .flow
                    files that you've created. You can use this menu to find and move between data
                    flows.</p>
            </li></ol></div>
        <p>After you have launched Data Wrangler, you can use the following section to walk through how
            you might use Data Wrangler to create an ML data prep flow. </p>
     
        <h2 id="data-wrangler-update-studio-app">Update Data Wrangler</h2>
        <p>We recommend that you periodically update the Data Wrangler Studio app to access the latest
            features and updates. The Data Wrangler app name starts with
                <b>sagemaker-data-wrang</b>. To learn how to update a Studio app,
            see <a href="studio-tasks-update-apps.html">Shut down and Update Studio Apps</a>.</p>
     
        <h2 id="data-wrangler-getting-started-demo">Demo: Data Wrangler Titanic Dataset
                Walkthrough</h2>
        <p>The following sections provide a walkthrough to help you get started using Data Wrangler. This
            walkthrough assumes that you have already followed the steps in <a href="data-wrangler-getting-started.html#data-wrangler-getting-started-access">Access Data Wrangler</a> and have a new data flow file
            open that you intend to use for the demo. You may want to rename this .flow file to
            something similar to <code>titanic-demo.flow</code>.</p>

        <p>This walkthrough uses the <a href="https://s3.us-west-2.amazonaws.com/amazon-sagemaker-data-wrangler-documentation-artifacts/walkthrough_titanic.csv" rel="noopener noreferrer" target="_blank"><span>Titanic dataset</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>. It's a modified version of the <a href="https://www.openml.org/d/40945" rel="noopener noreferrer" target="_blank"><span>Titanic
                dataset</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> that you can import into your Data Wrangler flow more easily. This data set contains the survival status, age, gender, and class
            (which serves as a proxy for economic status) of passengers aboard the maiden voyage of
            the <em>RMS Titanic</em> in 1912.</p>
        <p>In this tutorial, you perform the following steps.</p>
        <div class="orderedlist">
             
             
             
             
             
        <ol><li>
                <p>Do one of the following:</p>
                <div class="itemizedlist">
                     
                     
                <ul class="itemizedlist"><li class="listitem">
                        <p>Open your Data Wrangler flow and choose <b>Use Sample Dataset</b>.</p>
                    </li><li class="listitem">
                        <p>Upload the <a href="https://s3.us-west-2.amazonaws.com/amazon-sagemaker-data-wrangler-documentation-artifacts/walkthrough_titanic.csv" rel="noopener noreferrer" target="_blank"><span>Titanic dataset</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>
                            to Amazon Simple Storage Service (Amazon S3), and then import this dataset into Data Wrangler.</p>
                    </li></ul></div>
               
            </li><li>
                <p>Analyze this dataset using Data Wrangler analyses. </p>
            </li><li>
                <p>Define a data flow using Data Wrangler data transforms.</p>
            </li><li>
                <p>Export your flow to a Jupyter Notebook that you can use to create a Data Wrangler job.
                </p>
            </li><li>
                <p>Process your data, and kick off a SageMaker training job to train a XGBoost Binary
                    Classifier. </p>
            </li></ol></div>
         
            <h3 id="data-wrangler-getting-started-demo-import">Upload Dataset to S3 and
                    Import</h3>
            <p>To get started, you can use one of the following methods to import the Titanic dataset into Data Wrangler:</p>
            <div class="itemizedlist">
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Importing the dataset directly from the Data Wrangler flow</p>
                </li><li class="listitem">
                    <p>Uploading the dataset to Amazon S3 and then importing it into Data Wrangler</p>
                </li></ul></div>
            
           
            <p>To import the dataset directly into Data Wrangler, open the flow and choose <b>Use Sample Dataset</b>.</p>
            
            <p>Uploading the dataset to Amazon S3 and importing it into Data Wrangler is closer to the experience you have importing your own data. The following information tells you how to upload your dataset and import it.</p>

            
                    <p>Before you start importing the data into Data Wrangler, download the <a href="https://s3.us-west-2.amazonaws.com/amazon-sagemaker-data-wrangler-documentation-artifacts/walkthrough_titanic.csv" rel="noopener noreferrer" target="_blank"><span>Titanic dataset</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>
                and upload it to an Amazon S3 (Amazon S3) bucket in the AWS
                Region in which you want to complete this demo.</p>
            <p>If you are a new user of Amazon S3, you can do this using drag and drop in the Amazon S3
                console. To learn how, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/user-guide/upload-objects.html#upload-objects-by-drag-and-drop">Uploading Files and Folders by Using Drag and Drop</a> in the
                Amazon Simple Storage Service User Guide.</p>
            <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>Upload your dataset to an S3 bucket in the same AWS Region you want to use
                    to complete this demo. </p></div></div>
            <p>When your dataset has been successfully uploaded to Amazon S3, you can import it
                into Data Wrangler.</p>
            <div class="procedure"><h6>Import the Titanic dataset to Data Wrangler</h6><ol><li>
                    <p>Choose the <b>Import data</b> button in your <b>Data flow</b> tab or choose the <b>Import</b> tab.</p>
                </li><li>
                    <p>Select <b>Amazon S3</b>.</p>
                </li><li>
                    <p>Use the <b>Import a dataset from S3</b> table to find the
                        bucket to which you added the Titanic dataset. Choose the Titanic dataset
                        CSV file to open the <b>Details</b> pane.</p>
                </li><li>
                    <p>Under <b>Details</b>, the <b>File type</b>
                        should be CSV. Check <b>First row is header</b> to specify
                        that the first row of the dataset is a header. You can also name the dataset
                        something more friendly, such as
                        <code class="userinput">Titanic-train</code>.</p>
                </li><li>
                    <p>Choose the <b>Import </b> button.</p>
                </li></ol></div>
            <p>When your dataset is imported into Data Wrangler, it appears in your <b>Data
                    Flow</b> tab. You can double click on a node to enter the node detail
                view, which allows you to add transformations or analysis. You can use the plus icon
                for a quick access to the navigation. In the next section, you use this data flow to
                add analysis and transform steps.</p>
         

         
            <h3 id="data-wrangler-getting-started-demo-data-flow">Data Flow</h3>
            <p>In the data flow section, the only steps in the data flow are your recently
                imported dataset and a <b>Data type</b> step. After applying
                transformations, you can come back to this tab and see what the data flow looks like.
                Now, add some basic transformations under the <b>Prepare</b> and
                    <b>Analyze</b> tabs. </p>

             
                <h4 id="data-wrangler-getting-started-demo-prep-visualize">Prepare and
                        Visualize</h4>
                <p>Data Wrangler has built-in transformations and visualizations that you can use to
                    analyze, clean, and transform your data. </p>
                <p>The <b>Data</b> tab of the node detail view lists all built-in
                    transformations in the right panel, which also contains an area in which you can
                    add custom transformations. The following use case showcases how to use these
                    transformations.</p>
                <p>To get information that might help you with data exploration and feature engineering, create a data quality and insights report.
                The information from the report can help you clean and process your data. It gives you information such as the number of missing values and the number of outliers.
                If you have issues with your data, such as target leakage or imbalance, the insights report can bring those issues to your attention. 
                For more information about creating a report, see <a href="data-wrangler-data-insights.html">Get Insights On Data and Data Quality</a>.</p>
                 
                    <h5 id="data-wrangler-getting-started-demo-explore">Data
                            Exploration</h5>
                    <p>First, create a table summary of the data using an analysis. Do the
                        following:</p>
                    <div class="procedure"><ol><li>
                            <p>Choose the <b>+</b> next to the <b>Data
                                    type</b> step in your data flow and select <b>Add
                                    analysis</b>.</p>
                        </li><li>
                            <p>In the <b>Analysis</b> area, select <b>Table
                                    summary</b> from the dropdown list.</p>
                        </li><li>
                            <p>Give the table summary a <b>Name</b>.</p>
                        </li><li>
                            <p>Select <b>Preview</b> to preview the table that will
                                be created.</p>
                        </li><li>
                            <p>Choose <b>Save</b> to save it to your data flow. It
                                appears under <b>All Analyses</b>.</p>
                        </li></ol></div>
                    <p>Using the statistics you see, you can make observations similar to the
                        following about this dataset: </p>
                    <div class="itemizedlist">
                         
                         
                         
                    <ul class="itemizedlist"><li class="listitem">
                            <p>Fare average (mean) is around $33, while the max is over $500.
                                This column likely has outliers. </p>
                        </li><li class="listitem">
                            <p>This dataset uses <em>?</em> to indicate
                                missing values. A number of columns have missing values: <em>cabin</em>, <em>embarked</em>, and <em>home.dest</em></p>
                        </li><li class="listitem">
                            <p>The age category is missing over 250 values.</p>
                        </li></ul></div>
                    <p>Next, clean your data using the insights gained from these stats. </p>
                 
                 
                    <h5 id="data-wrangler-getting-started-demo-drop-unused">Drop Unused
                            Columns</h5>
                    <p>Using the analysis from the previous section, clean up the dataset to
                        prepare it for training. To add a new transform to your data flow, choose
                            <b>+</b> next to the <b>Data type</b> step
                        in your data flow and choose <b>Add transform</b>.</p>
                    <p>First, drop columns that you don't want to use for training. You can use
                            <a href="https://pandas.pydata.org/" rel="noopener noreferrer" target="_blank"><span>pandas</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> data analysis
                        library to do this, or you can use one of the built-in transforms.</p>
                    <p>Use the following procedure to drop the unused columns.</p>
                    <div class="procedure"><p>To drop the unused columns.</p><ol><li>
                            <p>Open the Data Wrangler flow.</p>
                        </li><li>
                            <p>There are two nodes in your Data Wrangler flow. Choose the <b>+</b> to the right of the <b>Data types</b> node.</p>
                        </li><li>
                            <p>Choose <b>Add transform</b>.</p>
                        </li><li>
                            <p>In the <b>All steps</b> column, choose <b>Add step</b>.</p>
                        </li><li>
                            <p>In the <b>Standard</b> transform list, choose <b>Manage Columns</b>. 
                                The standard transformations are ready-made, built-in transformations.
                                Make sure that <b>Drop column</b> is selected.</p>
                        </li><li>
                            <p>Under <b>Columns to drop</b>, check the following column names:</p>
                            <div class="itemizedlist">
                                 
                                 
                                 
                                 
                                 
                                 
                                 
                                 
                            <ul class="itemizedlist"><li class="listitem">
                                    <p>cabin</p>
                                </li><li class="listitem">
                                    <p>ticket</p>
                                </li><li class="listitem">
                                    <p>name</p>
                                </li><li class="listitem">
                                    <p>sibsp</p>
                                </li><li class="listitem">
                                    <p>parch</p>
                                </li><li class="listitem">
                                    <p>home.dest</p>
                                </li><li class="listitem">
                                    <p>boat</p>
                                </li><li class="listitem">
                                    <p>body</p>
                                </li></ul></div>
                        </li><li>
                            <p>Choose <b>Preview</b>.</p>
                        </li><li>
                            <p>Verify that the columns have been
                                    dropped, then choose <b>Add</b>.</p>
                        </li></ol></div>
                    <p>To do this using pandas, follow these steps.</p>
                    <div class="procedure"><ol><li>
                            <p>In the <b>All steps</b> column, choose <b>Add step</b>.</p>
                        </li><li>
                            <p>In the <b>Custom</b> transform list, choose <b>Custom transform</b>.</p>
                        </li><li>
                            <p>Provide a name for your transformation, and choose <b>Python (Pandas)</b> from the dropdown list.</p>
                        </li><li>
                            <p>Enter the following Python script in the code box.</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">cols = ['name', 'ticket', 'cabin', 'sibsp', 'parch', 'home.dest','boat', 'body']
df = df.drop(cols, axis=1)</code></pre>
                        </li><li>
                            <p>Choose <b>Preview</b> to preview the change, and then
                                choose <b>Add</b> to add the transformation. </p>
                        </li></ol></div>
                 
                 
                    <h5 id="data-wrangler-getting-started-demo-missing-vals">Clean up
                            Missing Values</h5>
                    <p>Now, clean up missing values. You can do this with the <b>Handling
                            missing values</b> transform group.</p>
                    <p>A number of columns have missing values. Of the remaining columns,
                            <em>age</em> and <em>fare</em> contain missing values. Inspect this using a
                            <b>Custom Transform</b>.</p>
                    <p>Using the <b>Python (Pandas)</b> option, use the following
                        to quickly review the number of entries in each column:</p>

                    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">df.info()</code></pre>
                    <div class="mediaobject">
                         
                            <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/inspect-missing-pandas.png" class="aws-docs-img-whiteBg aws-docs-img-padding" style="max-width:80%" />
                         
                    </div>
                    <p>To drop rows with missing values in the <em>age</em> category, do the following: </p>
                    <div class="procedure"><ol><li>
                            <p>Choose <b>Handle missing</b>. </p>
                        </li><li>
                            <p>Choose <b>Drop missing</b> for the
                                    <b>Transformer</b>.</p>
                        </li><li>
                            <p>Choose <em>age</em> for the
                                    <b>Input column</b>.</p>
                        </li><li>
                            <p>Choose <b>Preview</b> to see the new data frame, and
                                then choose <b>Add</b> to add the transform to your
                                flow.</p>
                        </li><li>
                            <p>Repeat the same process for <em>fare</em>. </p>
                        </li></ol></div>
                    <p>You can use <code class="code">df.info()</code> in the <b>Custom
                            transform</b> section to confirm that all rows now have 1,045
                        values.</p>
                 
                 
                    <h5 id="data-wrangler-getting-started-demo-encode">Custom Pandas:
                            Encode</h5>
                    <p>Try flat encoding using Pandas. Encoding categorical data is the process
                        of creating a numerical representation for categories. For example, if your
                        categories are <code class="code">Dog</code> and <code class="code">Cat</code>, you may encode this
                        information into two vectors: <code class="code">[1,0]</code> to represent
                            <code class="code">Dog</code>, and <code class="code">[0,1]</code> to represent
                        <code class="code">Cat</code>.</p>
                    <div class="procedure"><ol><li>
                            <p>In the <b>Custom Transform</b> section, choose
                                    <b>Python (Pandas)</b> from the dropdown
                                list.</p>
                        </li><li>
                            <p>Enter the following in the code box.</p>
                            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="python ">import pandas as pd

dummies = []
cols = ['pclass','sex','embarked']
for col in cols:
    dummies.append(pd.get_dummies(df[col]))
    
encoded = pd.concat(dummies, axis=1)

df = pd.concat((df, encoded),axis=1)</code></pre>
                        </li><li>
                            <p>Choose <b>Preview</b> to preview the change. The
                                encoded version of each column is added to the dataset. </p>
                        </li><li>
                            <p>Choose <b>Add</b> to add the transformation. </p>
                        </li></ol></div>
                 
             
             
                <h4 id="data-wrangler-getting-started-demo-sql">Custom SQL: SELECT
                        Columns</h4>
                <p>Now, select the columns you want to keep using SQL. For this demo, select the
                    columns listed in the following <code class="code">SELECT</code> statement. Because <em>survived</em> is your target column for training, put
                    that column first.</p>
                <div class="procedure"><ol><li>
                        <p>In the <b>Custom Transform</b> section, select
                                <b>SQL (PySpark SQL)</b> from the dropdown
                            list.</p>
                    </li><li>
                        <p>Enter the following in the code box.</p>
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">SELECT survived, age, fare, 1, 2, 3, female, male, C, Q, S FROM df;</code></pre>
                    </li><li>
                        <p>Choose <b>Preview</b> to preview the change. The columns
                            listed in your <code class="code">SELECT</code> statement are the only remaining
                            columns.</p>
                    </li><li>
                        <p>Choose <b>Add</b> to add the transformation. </p>
                    </li></ol></div>
             
         




         
            <h3 id="data-wrangler-getting-started-export">Export to a Data Wrangler Notebook</h3>
            <p>When you've finished creating a data flow, you have a number of export options.
                The following section explains how to export to a Data Wrangler job notebook. A Data Wrangler job is
                used to process your data using the steps defined in your data flow. To learn more
                about all export options, see <a href="data-wrangler-data-export.html">Export</a>.</p>
             
                <h4 id="data-wrangler-getting-started-export-notebook">Export to Data Wrangler
                        Job Notebook</h4>
                <p>When you export your data flow using a <b>Data Wrangler job</b>, the
                    process automatically creates a Jupyter Notebook. This notebook automatically
                    opens in your Studio instance and is configured to run a SageMaker processing job
                    to run your Data Wrangler data flow, which is referred to as a Data Wrangler job. </p>
                <div class="procedure"><ol><li>
                        <p>Save your data flow. Select <b>File</b> and then select
                                <b>Save Data Wrangler Flow</b>.</p>
                    </li><li>
                        <p>Back to the <b>Data Flow</b> tab, select the last step
                            in your data flow (SQL), then choose the <b>+</b> to open
                            the navigation.</p>
                    </li><li>
                        <p>Choose <b>Export</b>, and <b>Amazon S3 (via Jupyter
                                Notebook)</b>. This opens a Jupyter Notebook.</p>
                        <div class="mediaobject">
                             
                                <img src="../../../images/sagemaker/latest/dg/images/studio/mohave/export-select-step.png" class="aws-docs-img-whiteBg aws-docs-img-padding" />
                             
                        </div>
                    </li><li>
                        <p>Choose any <b>Python 3 (Data Science)</b> kernel for the
                                <b>Kernel</b>. </p>
                    </li><li>
                        <p>When the kernel starts, run the cells in the notebook book until
                                <b>Kick off SageMaker Training Job (Optional)</b>.
                        </p>
                    </li><li>
                        <p>Optionally, you can run the cells in <b>Kick off SageMaker
                                Training Job (Optional)</b> if you want to create a SageMaker
                            training job to train an XGBoost classifier. You can find the cost to
                            run a SageMaker training job in <a href="http://aws.amazon.com/sagemaker/pricing/" rel="noopener noreferrer" target="_blank"><span>Amazon SageMaker Pricing</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>. </p>
                        <p>Alternatively, you can add the code blocks found in <a href="data-wrangler-getting-started.html#data-wrangler-getting-started-train-xgboost">Training XGBoost
                        Classifier</a> to the
                            notebook and run them to use the <a href="https://xgboost.readthedocs.io/en/latest/" rel="noopener noreferrer" target="_blank"><span>XGBoost</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> open
                            source library to train an XGBoost classifier. </p>
                    </li><li>
                        <p>Uncomment and run the cell under <b>Cleanup</b> and run
                            it to revert the SageMaker Python SDK to its original version.</p>
                    </li></ol></div>
                <p>You can monitor your Data Wrangler job status in the SageMaker console in the
                        <b>Processing</b> tab. Additionally, you can monitor your Data Wrangler
                    job using Amazon CloudWatch. For additional information, see <a href="processing-job.html#processing-job-cloudwatch">Monitor Amazon SageMaker Processing Jobs with CloudWatch Logs and
                        Metrics</a>. </p>
                <p>If you kicked off a training job, you can monitor its status using the SageMaker
                    console under <b>Training jobs</b> in the <b>Training
                        section</b>.</p>
               
             
                <h4 id="data-wrangler-getting-started-train-xgboost">Training XGBoost
                        Classifier</h4>
                <p>You can train an XGBoost Binary Classifier using either a Jupyter notebook or a Amazon SageMaker Autopilot. You can use Autopilot to automatically train and tune models on the data that you've transformed directly from 
                    your Data Wrangler flow. For information about Autopilot, see <a href="data-wrangler-autopilot.html">Automatically Train Models on Your Data
            Flow</a>.</p>
                <p>In the same notebook that kicked off the Data Wrangler job, you can pull the data and
                    train an XGBoost Binary Classifier using the prepared data with minimal data
                    preparation. </p>
                <div class="procedure"><ol><li>
                        <p>First, upgrade necessary modules using <code class="code">pip</code> and remove the
                            _SUCCESS file (this last file is problematic when using
                                <code class="code">awswrangler</code>).</p>
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">! pip install --upgrade awscli awswrangler boto sklearn
! aws s3 rm <span>{</span>output_path} --recursive  --exclude "*" --include "*_SUCCESS*"</code></pre>
                    </li><li>
                        <p>Read the data from Amazon S3. You can use <code class="code">awswrangler</code> to
                            recursively read all the CSV files in the S3 prefix. The data is then
                            split into features and labels. The label is the first column of the
                            dataframe.</p>
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">import awswrangler as wr

df = wr.s3.read_csv(path=output_path, dataset=True)
X, y = df.iloc[:,:-1],df.iloc[:,-1]</code></pre>
                        <ul>
                            <li>
                                <p>Finally, create DMatrices (the XGBoost primitive structure for
                                    data) and do cross-validation using the XGBoost binary
                                    classification.</p>
                                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">import xgboost as xgb

dmatrix = xgb.DMatrix(data=X, label=y)

params = <span>{</span>"objective":"binary:logistic",'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10}

xgb.cv(
    dtrain=dmatrix, 
    params=params, 
    nfold=3,
    num_boost_round=50,
    early_stopping_rounds=10,
    metrics="rmse", 
    as_pandas=True, 
    seed=123)</code></pre>
                            </li>
                        </ul>
                    </li></ol></div>
             
             
                <h4 id="data-wrangler-getting-started-shut-down">Shut down Data Wrangler</h4>
                <p>When you are finished using Data Wrangler, we recommend that you shut down the instance
                    it runs on to avoid incurring additional charges. To learn how to shut down the
                    Data Wrangler app and associated instance, see <a href="data-wrangler-shut-down.html">Shut Down Data Wrangler</a>. </p>
             
         

    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./data-wrangler.html">Prepare Data with Data Wrangler</div><div id="next" class="next-link" accesskey="n" href="./data-wrangler-import.html">Import</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-getting-started.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/data-wrangler-getting-started.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>