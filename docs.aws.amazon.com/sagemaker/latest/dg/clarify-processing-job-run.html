<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Run SageMaker Clarify Processing Jobs for Bias Analysis and Explainability - Amazon SageMaker</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="clarify-processing-job-run" /><meta name="default_state" content="clarify-processing-job-run" /><link rel="icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="../../../assets/images/favicon.ico" /><link rel="canonical" href="clarify-processing-job-run.html" /><meta name="description" content="Run SageMaker Clarify processing jobs for bias and explainability." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon SageMaker" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="Use Internet Monitor to build, train, and host machine learning models in AWS." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="clarify-processing-job-run.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="de" /><link rel="alternative" href="clarify-processing-job-run.html" hreflang="en-us" /><link rel="alternative" href="clarify-processing-job-run.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/sagemaker/latest/dg/clarify-processing-job-run.html" hreflang="zh-tw" /><link rel="alternative" href="clarify-processing-job-run.html" hreflang="x-default" /><meta name="feedback-item" content="SageMaker" /><meta name="this_doc_product" content="Amazon SageMaker" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="../../../assets/r/vendor4.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor3.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/vendor1.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-common.js@version=2021.12.02"></script><script defer="" src="../../../assets/r/awsdocs-doc-page.js@version=2021.12.02"></script><link href="../../../assets/r/vendor4.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-common.css@version=2021.12.02.css" rel="stylesheet" /><link href="../../../assets/r/awsdocs-doc-page.css@version=2021.12.02.css" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'sagemaker'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Run SageMaker Clarify Processing Jobs for Bias Analysis and Explainability" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Run SageMaker Clarify Processing Jobs for Bias Analysis and Explainability - Amazon SageMaker</title><meta name="pdf" content="/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#clarify-processing-job-run" /><meta name="rss" content="amazon-sagemaker-release-notes.rss" /><meta name="forums" content="http://forums.aws.amazon.com/forum.jspa?forumID=285" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-processing-job-run.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-processing-job-run.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=http://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-processing-job-run.html" /><meta name="keywords" content="SageMaker,Amazon SageMaker,machine learning,notebook instance,explainability,bias,run processing jobs bias explainability" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon SageMaker",
        "item" : "https://docs.aws.amazon.com/sagemaker/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Detect bias and understand explanations",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/model-explainability.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Use Amazon SageMaker Clarify Bias Detection and Model Explainability",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-configure-processing-jobs.html"
      },
      {
        "@type" : "ListItem",
        "position" : 6,
        "name" : "Run SageMaker Clarify Processing Jobs for Bias Analysis and Explainability",
        "item" : "https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-configure-processing-jobs.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="https://docs.aws.amazon.com/pdfs/sagemaker/latest/dg/sagemaker-dg.pdf#clarify-processing-job-run" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="https://docs.aws.amazon.com/index.html">Documentation</a><a href="https://docs.aws.amazon.com/sagemaker/index.html">Amazon SageMaker</a><a href="whatis.html">Developer Guide</a></div><div id="page-toc-src"><a href="clarify-processing-job-run.html#clarify-processing-job-run-spark">How to run parallel SageMaker Clarify processing
                jobs</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="clarify-processing-job-run">Run SageMaker Clarify Processing Jobs for Bias Analysis and
            Explainability</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>To analyze your data and models for bias and explainability using SageMaker Clarify, you must
        configure a SageMaker Clarify processing job. This guide shows how to configure the job inputs, outputs,
        resources, and analysis configuration using the SageMaker Python SDK API
            <code class="code">SageMakerClarifyProcessor</code>. </p><p>The API acts as a high-level wrapper of the SageMaker <code class="code">CreateProcessingJob</code> API. It
        hides many of the details that are involved in setting up a SageMaker Clarify processing job. The
        details to set up a job include retrieving the SageMaker Clarify container image URI and generating the
        analysis configuration file. The following steps show you how to configure, initialize and
        launch a SageMaker Clarify processing job. </p><div class="procedure"><h6> Configure a SageMaker Clarify processing job using the API</h6><ol><li>
            <p>Define the configuration objects for each portion of the job configuration. These
                portions can include the following:</p>
            <div class="itemizedlist">
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>The input dataset and output location: <a href="https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.clarify.DataConfig" rel="noopener noreferrer" target="_blank"><span>DataConfig</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                </li><li class="listitem">
                    <p>The model or endpoint to be analyzed: <a href="https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.clarify.ModelConfig" rel="noopener noreferrer" target="_blank"><span>ModelConfig</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                </li><li class="listitem">
                    <p>Bias analysis parameters: <a href="https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.clarify.BiasConfig" rel="noopener noreferrer" target="_blank"><span>BiasConfig</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                </li><li class="listitem">
                    <p>SHapley Additive exPlanations (SHAP) analysis parameters: <a href="https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.clarify.SHAPConfig" rel="noopener noreferrer" target="_blank"><span>SHAPConfig</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                </li></ul></div>

            <p>The configuration objects for a SageMaker Clarify processing job vary for different types of
                data formats and use cases. Configuration examples for tabular data in <a href="clarify-processing-job-run.html#clarify-processing-job-run-tabular-csv">CSV</a> and <a href="clarify-processing-job-run.html#clarify-processing-job-run-tabular-jsonlines">JSON Lines</a> format, natural
                language processing (<a href="clarify-processing-job-run.html#clarify-processing-job-run-tabular-nlp">NLP</a>), and
                    <a href="clarify-processing-job-run.html#clarify-processing-job-run-cv">computer vision</a> problems are provided in the
                following sections. </p>
        </li><li>
            <p>Create a <code class="code">SageMakerClarifyProcessor</code> object and initialize it with
                parameters that specify the job resources. These resources include parameters such
                as the number of compute instances to use.</p>
            <p>The following code example shows how to create a
                    <code class="code">SageMakerClarifyProcessor</code> object and instruct it to use one
                    <code class="code">ml.c4.xlarge</code> compute instance to do the analysis.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">from sagemaker import clarify

clarify_processor = clarify.SageMakerClarifyProcessor(
    role=role,
    instance_count=1,
    instance_type='ml.c4.xlarge',
    sagemaker_session=session,
)</code></pre>
        </li><li>
            <p>Call the specific run method of the <a href="https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.clarify.SageMakerClarifyProcessor.run" rel="noopener noreferrer" target="_blank"><span>SageMakerClarifyProcessor</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> object with the configuration objects for
                your use case to launch the job. These run methods include the following:</p>
            <div class="itemizedlist">
                 
                 
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p><code class="code">run_pre_training_bias</code></p>
                </li><li class="listitem">
                    <p><code class="code">run_post_training_bias</code></p>
                </li><li class="listitem">
                    <p><code class="code">run_bias</code></p>
                </li><li class="listitem">
                    <p><code class="code">run_explainability</code></p>
                </li><li class="listitem">
                    <p><code class="code">run_bias_and_explainability</code></p>
                </li></ul></div>
            <p>This <code class="code">SageMakerClarifyProcessor</code> handles several tasks behind the
                scenes. These tasks include retrieving the SageMaker Clarify container image universal resource
                identifier (URI), composing an analysis configuration file based on the provided
                configuration objects, uploading the file to an Amazon S3 bucket, and <a href="clarify-processing-job-configure-parameters.html">configuring the SageMaker Clarify processing job</a>.</p>
            <p>The following expandable sections show how to compute <b>pre-training</b> and <b>post-training bias
                    metrics</b>, <b>SHAP values</b>, and <b>partial dependence plots</b> (PDPs). The sections show
                feature importance for these data types:</p>
            <div class="itemizedlist">
                 
                 
                 
            <ul class="itemizedlist"><li class="listitem">
                    <p>Tabular datasets in CSV format or JSON Lines format</p>
                </li><li class="listitem">
                    <p>Natural language processing (NLP) datasets</p>
                </li><li class="listitem">
                    <p>Computer vision datasets</p>
                </li></ul></div>
        </li></ol></div><p>A guide to run parallel SageMaker Clarify processing jobs with distributed training using <b>Spark</b> follows the expandable sections.</p><div class="collapsible" data-expand-section="_collapse_all_"><awsui-expandable-section variant="container" header="Analyze tabular data in CSV&#xA;                    format" id="clarify-processing-job-run-tabular-csv" expanded="false"><p>The following examples show how to configure bias analysis and explainability
                analysis for a tabular dataset in CSV format. In these examples, the incoming
                dataset has four feature columns and one binary label column, <code class="code">Target</code>.
                The contents of the dataset are as follows. A label value of <code class="code">1</code>
                indicates a positive outcome. </p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">Target,Age,Gender,Income,Occupation
0,25,0,2850,2
1,36,0,6585,0
1,22,1,1759,1
0,48,0,3446,1
...</code></pre><p>This <code class="code">DataConfig</code> object specifies the input dataset and where to store
                the output. The <code class="code">s3_data_input_path</code> parameter can either be a URI of a
                dataset file or an Amazon S3 URI prefix. If you provide a S3 URI prefix, the SageMaker Clarify
                processing job recursively collects all Amazon S3 files located under the prefix. The
                value for <code class="code">s3_output_path</code> should be an S3 URI prefix to hold the
                analysis results. The following code example shows how to specify a data
                configuration for the previous sample input dataset.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">data_config = clarify.DataConfig(
    s3_data_input_path=dataset_s3_uri,
    dataset_type='text/csv',
    headers=[<code class="replaceable">'Target', 'Age', 'Gender', 'Income', 'Occupation'</code>],
    label='Target',
    s3_output_path=clarify_job_output_s3_uri,
)</code></pre>
                <h3 id="clarify-processing-job-run-tabular-csv-pretraining">How to
                        compute all pre-training bias metrics for a CSV dataset</h3>
                <p>The following code sample shows how to configure a <code class="code">BiasConfig</code>
                    object to measure bias of the previous sample input towards samples with a
                        <code class="code">Gender</code> value of <code class="code">0</code>.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="nohighlight">bias_config = clarify.BiasConfig(
    label_values_or_threshold=[1],
    facet_name='<code class="replaceable">Gender</code>',
    facet_values_or_threshold=[0],
)</code></pre>
                <p>The following code example shows how to use a run statement to launch a SageMaker Clarify
                    processing job that computes all <a href="clarify-measure-data-bias.html">pre-training bias
                        metrics</a> for an input dataset. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">clarify_processor.run_pre_training_bias(
     data_config=data_config,
    data_bias_config=bias_config,
    methods="all",
)</code></pre>
                <p>Alternatively, you can choose which metrics to compute by assigning a list of
                    pre-training bias metrics to the methods parameter. For example, replacing
                        <code class="code">methods="all"</code> with <code class="code">methods=["CI", "DPL"]</code> instructs
                    the SageMaker Clarify Processor to compute only <a href="clarify-bias-metric-class-imbalance.html">Class
                        Imbalance</a> and <a href="clarify-data-bias-metric-true-label-imbalance.html">Difference in Proportions of Labels</a>.</p>
             
                <h3 id="clarify-processing-job-run-tabular-csv-posttraining">How to
                        compute all post-training bias metrics for a CSV dataset</h3>
                <p>You can compute pre-training bias metrics prior to training. However, to
                    compute <a href="clarify-measure-post-training-bias.html">post-training bias metrics</a>, you must have a trained model. The
                    following example output is from a binary classification model that outputs data
                    in CSV format. In this example output, each row contains two columns. The first
                    column contains the predicted label, and the second column contains the
                    probability value for that label.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">0,0.028986845165491
1,0.825382471084594
...</code></pre>
                <p>In the following example configuration, the <code class="code">ModelConfig</code> object
                    instructs the job to deploy the SageMaker model to an ephemeral endpoint. The
                    endpoint uses one <code class="code">ml.m4.xlarge</code> inference instance. Because the
                    parameter <code class="code">content_type</code> and <code class="code">accept_type</code> are not set,
                    they automatically use the value of the parameter <code class="code">dataset_type</code>,
                    which is <code class="code">text/csv</code>.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">model_config = clarify.ModelConfig(
    model_name=your_model,
    instance_type='ml.m4.xlarge',
    instance_count=1,
)</code></pre>
                <p>The following configuration example uses a
                        <code class="code">ModelPredictedLabelConfig</code> object with a label index of
                        <code class="code">0</code>. This instructs the SageMaker Clarify processing job to locate the
                    predicted label in the first column of the model output. The Processing job uses
                    zero-based indexing in this example.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">predicted_label_config = clarify.ModelPredictedLabelConfig(
    label=0,
)</code></pre>
                <p>Combined with the previous configuration example, the following code example
                    launches a SageMaker Clarify processing job to compute all the post-training bias
                    metrics.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">clarify_processor.run_post_training_bias(
    data_config=data_config,
    data_bias_config=bias_config,
    model_config=model_config,
    model_predicted_label_config=predicted_label_config,
    methods="all",
)</code></pre>
                <p>Similarly, you can choose which metrics to compute by assigning a list of
                    post-training bias metrics to the <code class="code">methods</code> parameter. For example,
                    replace <code class="code">methods=“all”</code> with <code class="code">methods=["DPPL", "DI"]</code> to
                    compute only <a href="clarify-post-training-bias-metric-dppl.html">Difference in Positive Proportions in Predicted Labels</a> and <a href="clarify-post-training-bias-metric-di.html">Disparate Impact</a>.</p>
             
                <h3 id="clarify-processing-job-run-tabular-csv-all">How to compute all
                        bias metrics for a CSV dataset</h3>
            <p>The following configuration example shows how to run all pre-training and
                post-training bias metrics in one SageMaker Clarify processing job.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">clarify_processor.run_bias(
    data_config=data_config,
     bias_config=bias_config,
     model_config=model_config,
    model_predicted_label_config=predicted_label_config,
    pre_training_methods="all",
    post_training_methods="all",
)</code></pre><p>For an example notebook with instructions on how to run a SageMaker Clarify processing job in
                SageMaker Studio to detect bias, see <a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-clarify/fairness_and_explainability/fairness_and_explainability.ipynb" rel="noopener noreferrer" target="_blank"><span>Fairness and Explainability with SageMaker Clarify</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
                <h3 id="clarify-processing-job-run-tabular-csv-shap">How to compute
                        SHAP values for a CSV dataset</h3>
                <p>SageMaker Clarify provides feature attributions using the <a href="https://arxiv.org/abs/1705.07874" rel="noopener noreferrer" target="_blank"><span>KernelSHAP algorithm</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>. SHAP
                    analysis requires the probability value or score instead of predicted label, so
                    this <code class="code">ModelPredictedLabelConfig</code> object has probability index
                        <code class="code">1</code>. This instructs the SageMaker Clarify processing job to extract the
                    probability score from the second column of the model output (using zero-based
                    indexing).</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">probability_config = clarify.ModelPredictedLabelConfig(
    probability=1,
)</code></pre>
                <p>The <code class="code">SHAPConfig</code> object provides SHAP analysis parameters. In this
                    example, the SHAP <code class="code">baseline</code> parameter is omitted and the value of
                    the <code class="code">num_clusters</code> parameter is <code class="code">1</code>. This instructs the
                    SageMaker Clarify Processor to compute one SHAP baseline sample based on clustering the
                    input dataset. If you want to choose the baseline dataset, see <a href="clarify-feature-attribute-shap-baselines.html">SHAP
                        Baselines for Explainability</a>.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">shap_config = clarify.SHAPConfig(
    num_clusters=1,
)</code></pre>
                <p>The following code example launches a SageMaker Clarify processing job to compute SHAP
                    values.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">clarify_processor.run_explainability(
    data_config=data_config,
    model_config=model_config,
    model_scores=probability_config,
    explainability_config=shap_config,
)</code></pre>
                <p>For an example notebook with instructions on how to run a SageMaker Clarify processing job
                    in SageMaker Studio to compute SHAP values, see <a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-clarify/fairness_and_explainability/fairness_and_explainability.ipynb" rel="noopener noreferrer" target="_blank"><span>Fairness and Explainability with SageMaker Clarify</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
             
                <h3 id="clarify-processing-job-run-tabular-csv-pdp">How to compute
                        partial dependence plots (PDPs) for a CSV dataset</h3>
                <p>PDPs show the dependence of the predicted target response on one or more input
                    features of interest while holding all other features constant. An upward
                    sloping line, or curve in the PDP, indicates that the relationship between the
                    target and input feature(s) is positive, and the steepness indicates the
                    strength of the relationship. A downward sloping line or curve indicates that if
                    an input feature decreases, the target variable increases. Intuitively, you can
                    interpret the partial dependence as the response of the target variable to each
                    input feature of interest.</p>
                <p>The following configuration example is for using a <code class="code">PDPConfig</code>
                    object to instruct the SageMaker Clarify processing job to compute the importance of the
                        <code class="code">Income</code> feature.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">pdp_config = clarify.PDPConfig(
    features=["Income"],
    grid_resolution=10,
)</code></pre>
                <p>In the previous example, the <code class="code">grid_resolution</code> parameter divides
                    the range of the <code class="code">Income</code> feature values into <code class="code">10</code>
                    buckets. The SageMaker Clarify processing job will generate PDPs for <code class="code">Income</code>
                    split into <code class="code">10</code> segments on the x-axis. The y-axis will show the
                    marginal impact of <code class="code">Income</code> on the target variable.</p>
                <p>The following code example launches a SageMaker Clarify processing job to compute
                    PDPs.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">clarify_processor.run_explainability(
    data_config=data_config,
    model_config=model_config,
    model_scores=probability_config,
    explainability_config=pdp_config,
)</code></pre>
                <p>For an example notebook with instructions on how to run a SageMaker Clarify processing job
                    in SageMaker Studio to compute PDPs, see <a href="https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-clarify/fairness_and_explainability/explainability_with_pdp.ipynb" rel="noopener noreferrer" target="_blank"><span>Explainability with SageMaker Clarify - Partial Dependence Plots (PDP)</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
             
                <h3 id="clarify-processing-job-run-tabular-csv-shap-pdp">How to compute
                        both SHAP values and PDPs for a CSV dataset</h3>
                <p>You can compute both SHAP values and PDPs in a single SageMaker Clarify processing job. In
                    the following configuration example, the <code class="code">top_k_features</code> parameter
                    of a new <code class="code">PDPConfig</code> object is set to <code class="code">2</code>. This instructs
                    the SageMaker Clarify processing job to compute PDPs for the <code class="code">2</code> features that
                    have the largest global SHAP values. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">shap_pdp_config = clarify.PDPConfig(
    top_k_features=2,
    grid_resolution=10,
)</code></pre>
                <p>The following code example launches a SageMaker Clarify processing job to compute both
                    SHAP values and PDPs.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">clarify_processor.run_explainability(
    data_config=data_config,
    model_config=model_config,
    model_scores=probability_config,
    explainability_config=[shap_config, shap_pdp_config],
)</code></pre>
            </awsui-expandable-section><awsui-expandable-section variant="container" header="Analyze tabular data&#xA;                    in JSON Lines format" id="clarify-processing-job-run-tabular-jsonlines" expanded="false"><p>The following examples show how to configure bias analysis and explainability
                analysis for a tabular dataset in &gt;SageMaker JSON Lines dense format. See <a href="cdf-inference.html#cm-jsonlines">JSONLINES Request Format</a> for more information. In
                these examples, the incoming dataset has the same data as the previous section, but
                they're in the JSON Lines format. Each line is a valid JSON object. The key
                    <code class="code">Features</code> points to an array of feature values, and the key
                    <code class="code">Label</code> points to the ground truth label.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>"Features":[25,0,2850,2],"Label":0}
<span>{</span>"Features":[36,0,6585,0],"Label":1}
<span>{</span>"Features":[22,1,1759,1],"Label":1}
<span>{</span>"Features":[48,0,3446,1],"Label":0}
...</code></pre><p>In the following configuration example, the <code class="code">DataConfig</code> object
                specifies the input dataset and where to store the output. The features parameter is
                set to the <a href="https://jmespath.org/" rel="noopener noreferrer" target="_blank"><span>JMESPath</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> expression
                    <code class="code">Features</code> so that the SageMaker Clarify processing job can extract the array of
                features from each record. The <code class="code">label</code> parameter is set to JMESPath
                expression <code class="code">Label</code> so that the SageMaker Clarify processing job can extract the
                ground truth label from each record.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">data_config = clarify.DataConfig(
    s3_data_input_path=jsonl_dataset_s3_uri,
    dataset_type='application/jsonlines',
    headers=['Age', 'Gender', 'Income', 'Occupation', 'Target'],
    label='Label',
    features='Features',
    s3_output_path=clarify_job_output_s3_uri,
)</code></pre><p>You must have a trained model to compute post-training bias metrics or feature
                importance. The following example is from a binary classification model that outputs
                JSON Lines data in the example's format. Each row of the model output is a valid
                JSON object. The key <code class="code">predicted_label</code> points to the predicted label, and
                the key <code class="code">probability</code> points to the probability value.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class=""><span>{</span>"predicted_label":0,"probability":0.028986845165491}
<span>{</span>"predicted_label":1,"probability":0.825382471084594}
...</code></pre><p>In the following configuration example, a <code class="code">ModelConfig</code> object
                instructs the SageMaker Clarify processing job to deploy the SageMaker model to an ephemeral
                endpoint. The endpoint uses one <code class="code">ml.m4.xlarge</code> inference instance.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">model_config = clarify.ModelConfig(
    model_name=your_model,
    instance_type='ml.m4.xlarge',
    instance_count=1,
    content_template='<span>{</span>"Features":$features}',
)</code></pre><p>In previous configuration example, the parameter <code class="code">content_type</code> and
                    <code class="code">accept_type</code> are not set. Therefore, they automatically use the
                value of the <code class="code">dataset_type</code> parameter of the <code class="code">DataConfig</code>
                object, which is <code class="code">application/jsonlines</code>. The SageMaker Clarify processing job uses
                the <code class="code">content_template</code> parameter to compose the model input by replacing
                the <code class="code">$features</code> placeholder by an array of features.</p><p>The following example configuration shows how to set the label parameter of the
                    <code class="code">ModelPredictedLabelConfig</code> object to the JMESPath expression
                    <code class="code">predicted_label</code>. This will extract the predicted label from the
                model output.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">predicted_label_config = clarify.ModelPredictedLabelConfig(
    label='predicted_label',
)</code></pre><p>The following example configuration shows how to set the <code class="code">probability</code>
                parameter of the <code class="code">ModelPredictedLabelConfig</code> object to the JMESPath
                expression <code class="code">probability</code>. This will extract the score from the model
                output.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">probability_config = clarify.ModelPredictedLabelConfig(
    probability='probability',
)</code></pre><p> To compute bias metrics and feature importance for datasets in JSON Lines format,
                use the same run statements and configuration objects as the previous section for
                CSV datasets. You can run a SageMaker Clarify processing job in SageMaker Studio to detect bias
                and compute feature importance. For instructions and an example notebook, see <a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-clarify/fairness_and_explainability/fairness_and_explainability_jsonlines_format.ipynb" rel="noopener noreferrer" target="_blank"><span>Fairness and Explainability with SageMaker Clarify (JSON Lines Format)</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p></awsui-expandable-section><awsui-expandable-section variant="container" header="Analyze tabular data for&#xA;                    NLP explainability" id="clarify-processing-job-run-tabular-nlp" expanded="false"><p>SageMaker Clarify supports explanations for natural language processing (NLP) models. These
                explanations help you understand which sections of text are the most important for
                your model predictions. You can explain either the model prediction for a single
                instance of the input dataset, or model predictions from the baseline dataset.To
                understand and visualize a model’s behavior, you can specify multiple levels of
                granularity. To do this, define the length of the text segment, such as its tokens,
                sentences, paragraphs.</p><p>SageMaker Clarify NLP explainability is compatible with both classification and regression
                models. You can also use SageMaker Clarify to explain your model's behavior on multi-modal
                datasets that contain text, categorical, or numerical features. NLP explainability
                for multi-modal datasets can help you understand how important each feature is to
                the model's output. SageMaker Clarify supports 62 languages and can handle text which includes
                multiple languages.</p><p>The following example shows an analysis configuration file for computing feature
                importance for NLP. In this example, the incoming dataset is a tabular dataset in
                CSV format, with one binary label column and two feature columns.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">0,2,"Flavor needs work"
1,3,"They taste good"
1,5,"The best"
0,1,"Taste is awful"
...</code></pre><p>The following configuration example shows how to specify an input dataset in CSV
                format and output data path using the <code class="code">DataConfig</code> object.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">nlp_data_config = clarify.DataConfig(
    s3_data_input_path=nlp_dataset_s3_uri,
    dataset_type='text/csv',
    headers=['Target', 'Rating', 'Comments'],
    label='Target',
    s3_output_path=clarify_job_output_s3_uri,
)</code></pre><p>The following example output was created from a binary classification model
                trained on the previous input dataset. The classification model accepts CSV data,
                and it outputs a single score in between <code class="code">0</code> and <code class="code">1</code>.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">0.491656005382537
0.569582343101501
...</code></pre><p>The following example shows how to configure the <code class="code">ModelConfig</code> object
                to deploy a SageMaker model. In this example, an ephemeral endpoint deploys the model.
                This endpoint uses one <code class="code">ml.g4dn.xlarge</code> inference instance equipped with
                a GPU, for accelerated inferencing.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">nlp_model_config = clarify.ModelConfig(
    model_name=your_nlp_model_name,
    instance_type='ml.g4dn.xlarge',
    instance_count=1,
)</code></pre><p>The following example shows how to configure the
                    <code class="code">ModelPredictedLabelConfig</code> object to locate the probability (score)
                in the first column with an index of <code class="code">0</code>.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">probability_config = clarify.ModelPredictedLabelConfig(
    probability=0,
)</code></pre><p>The following example SHAP configuration shows how to run a token-wise
                explainability analysis using a model and an input dataset in the English
                language.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">text_config = clarify.TextConfig(
    language='english',
    granularity='token',
)
nlp_shap_config = clarify.SHAPConfig(
    baseline=[[4, '[MASK]']],
    num_samples=100,
    text_config=text_config,
)</code></pre><p>In the previous example, the <code class="code">TextConfig</code> object activates the NLP
                explainability analysis. The <code class="code">granularity</code> parameter indicates that the
                analysis should parse tokens. In English, each token is a word. For other languages,
                see the <a href="https://spacy.io/usage/linguistic-features#tokenization" rel="noopener noreferrer" target="_blank"><span>spaCy
                    documentation for tokenization</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>, which SageMaker Clarify uses for NLP processing. The
                previous example also shows how to use an average <code class="code">Rating</code> of
                    <code class="code">4</code> to set an in-place SHAP baseline instance. A special mask token
                    <code class="code">[MASK]</code> is used to replace a token (word) in
                <code class="code">Comments</code>.</p><p>In the previous example, if the instance is <code class="code">2,"Flavor needs work"</code>,
                set the baseline to an average <code class="code">Rating</code> of <code class="code">4</code> with the
                following baseline.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">4, '[MASK]'</code></pre><p>In the previous example, the SageMaker Clarify explainer iterates through each token and
                replaces it with the mask, as follows.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">2,"[MASK] needs work"

4,"Flavor [MASK] work"

4,"Flavor needs [MASK]"</code></pre><p>Then, the SageMaker Clarify explainer will send each line to your model for predictions. This
                is so that the explainer learns the predictions with and without the masked words.
                The SageMaker Clarify explainer then uses this information to compute the contribution of each
                token.</p><p>The following code example launches a SageMaker Clarify processing job to compute SHAP
                values.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">clarify_processor.run_explainability(
    data_config=nlp_data_config,
    model_config=nlp_model_config,
    model_scores=probability_config,
    explainability_config=nlp_shap_config,
)</code></pre><p>For an example notebook with instructions on how to run a SageMaker Clarify processing job in
                SageMaker Studio for NLP explainability analysis, see <a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-clarify/text_explainability/text_explainability.ipynb" rel="noopener noreferrer" target="_blank"><span>Explaining Text Sentiment Analysis Using SageMaker Clarify</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p></awsui-expandable-section><awsui-expandable-section variant="container" header="Analyze image data for computer&#xA;                    vision explainability" id="clarify-processing-job-run-cv" expanded="false"><p>SageMaker Clarify generates heat maps that provide insights into how your computer vision
                models classify and detect objects in your images.</p><p>In the following configuration example, the input dataset consists of JPEG
                images.</p><pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">cv_data_config = clarify.DataConfig(
    s3_data_input_path=cv_dataset_s3_uri,
    dataset_type="application/x-image",
    s3_output_path=clarify_job_output_s3_uri,
)</code></pre><p> In the previous configuration example, the <code class="code">DataConfig</code> object
                contains an <code class="code">s3_data_input_path</code> set to an S3 URI prefix. The SageMaker Clarify
                processing job recursively collects all image files located under the prefix.</p>
                <h3 id="clarify-processing-job-run-tabular-cv-image-classification">How
                        to explain an image classification model</h3>
                <p>The SageMaker Clarify processing job explains images using the KernelSHAP algorithm, which
                    treats the image as a collection of super pixels. Given a dataset consisting of
                    images, the processing job outputs a dataset of images where each image shows
                    the heat map of the relevant super pixels.</p>
                <p>The following configuration example shows how to configure an explainability
                    analysis using a SageMaker image classification model. See <a href="image-classification.html">Image Classification - MXNet</a> for more
                    information.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">ic_model_config = clarify.ModelConfig(
    model_name=your_cv_ic_model,
    instance_type="ml.p2.xlarge",
    instance_count=1,
    content_type="image/jpeg",
    accept_type="application/json",
)</code></pre>
                <p>In the previous configuration example, a model named
                        <code class="code">your_cv_ic_model</code>, has been trained to classify the animals on
                    input JPEG images. The <code class="code">ModelConfig</code> object in the previous example
                    instructs the SageMaker Clarify processing job to deploy the SageMaker model to an ephemeral
                    endpoint. For accelerated inferencing, the endpoint uses one
                        <code class="code">ml.p2.xlarge</code> inference instance equipped with a GPU.</p>
                <p>After a JPEG image is sent to an endpoint, the endpoint classifies it and
                    returns a list of scores. Each score is for a category. The
                        <code class="code">ModelPredictedLabelConfig</code> object provides the name of each
                    category, as follows.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">ic_prediction_config = clarify.ModelPredictedLabelConfig(
    label_headers=['bird', 'cat', 'dog'],
)</code></pre>
                <p>An example output for the previous input of ['bird','cat','dog'] could be
                    0.3,0.6,0.1, where 0.3 represents the confidence score for classifying an image
                    as a bird.</p>
                <p>The following example SHAP configuration shows how to generate explanations
                    for an image classification problem. It uses an <code class="code">ImageConfig</code> object
                    to activate the analysis.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">ic_image_config = clarify.ImageConfig(
    model_type="IMAGE_CLASSIFICATION",
    num_segments=20,
    segment_compactness=5,
)

ic_shap_config = clarify.SHAPConfig(
    num_samples=100,
    image_config=ic_image_config,
)</code></pre>
                <p>SageMaker Clarify extracts features using the <a href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic" rel="noopener noreferrer" target="_blank"><span>Simple Linear Iterative Clustering (SLIC)</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> method from scikit-learn
                    library for image segmentation. The previous configuration example, the
                        <code class="code">model_type</code> parameter, indicates the type of image
                    classification problem. The parameter <code class="code">num_segments</code> estimates how
                    many approximate number of segments will be labeled in the input image. The
                    number of segments is then passed to the slic <code class="code">n_segments</code> parameter. </p>
                <p>Each segment of the image is considered a super-pixel, and local SHAP values
                    are computed for each segment. The parameter <code class="code">segment_compactness</code>
                    determines the shape and size of the image segments that are generated by the
                    scikit-image slic method. The sizes and shapes of the image segments are then
                    passed to the slic <code class="code">compactness</code> parameter.</p>
                <p>The following code example launches a SageMaker Clarify processing job to generate heat
                    maps for your images. Positive heat map values show that the feature increased
                    the confidence score of detecting the object. Negative values indicate that the
                    feature decreased the confidence score.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">clarify_processor.run_explainability(
    data_config=cv_data_config,
    model_config=ic_model_config,
    model_scores=ic_prediction_config,
    explainability_config=ic_shap_config,
)</code></pre>
                <p>For a sample notebook that uses SageMaker Clarify to classify images and explain its
                    classification, see <a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-clarify/computer_vision/image_classification/explainability_image_classification.ipynb" rel="noopener noreferrer" target="_blank"><span>Explaining Image Classification with SageMaker Clarify</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
             
                <h3 id="clarify-processing-job-run-tabular-cv-object-detection">How to
                        explain an object detection model</h3>
                <p>A SageMaker Clarify processing job can detect and classify objects in an image and then
                    provide an explanation for the detected object. The process for explanation is
                    as follows.</p>
                <div class="orderedlist">
                     
                     
                     
                <ol><li>
                        <p>Image objects are first categorized into one of the classes in a
                            specified collection. For example, if an object detection model can
                            recognize cat, dog and fish, then these three classes are in a
                            collection. This collection is specified by the
                                <code class="code">label_headers</code> parameter as follows.</p>
                        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">clarify.ModelPredictedLabelConfig(

label_headers=object_categories,

)</code></pre>
                    </li><li>
                        <p>The SageMaker Clarify processing job produces a confidence score for each object.
                            A high confidence score indicates that it belongs to one of the classes
                            in a specified collection. The SageMaker Clarify processing job also produces the
                            coordinates of a bounding box that delimits the object. For more
                            information about confidence scores and bounding boxes, see <a href="object-detection-in-formats.html#object-detection-recordio">Response Formats</a>.</p>
                    </li><li>
                        <p>SageMaker Clarify then provides an explanation for the detection of an object in
                            the image scene. It uses the methods described in the <b>How to explain an image classification model</b>
                            section.</p>
                    </li></ol></div>
                <p>In the following configuration example, a SageMaker object detection model
                        <code class="code">your_cv_od_model</code> is trained on JPEG images to identify the
                    animals on them. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">od_model_config = clarify.ModelConfig(
    model_name=your_cv_ic_model,
    instance_type="ml.p2.xlarge",
    instance_count=1,
    content_type="image/jpeg",
    accept_type="application/json",
)</code></pre>
                <p>The <code class="code">ModelConfig</code> object in the previous configuration example
                    instructs the SageMaker Clarify processing job to deploy the SageMaker model to an ephemeral
                    endpoint. For accelerated imaging, this endpoint uses one
                        <code class="code">ml.p2.xlarge</code> inference instance equipped with a GPU.</p>
                <p>In the following example configuration, the
                        <code class="code">ModelPredictedLabelConfig</code> object provides the name of each
                    category for classification.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">ic_prediction_config = clarify.ModelPredictedLabelConfig(
    label_headers=['bird', 'cat', 'dog'],
)</code></pre>
                <p>The following example SHAP configuration shows how to generate explanations
                    for an object detection.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">od_image_config = clarify.ImageConfig(
    model_type="OBJECT_DETECTION",
    num_segments=20,
    segment_compactness=5,
    max_objects=5,
    iou_threshold=0.5,
    context=1.0,
)
od_shap_config = clarify.SHAPConfig(
    num_samples=100,
    image_config=image_config,
)</code></pre>
                <p>In the previous example configuration, the <code class="code">ImageConfig</code> object
                    activates the analysis. The <code class="code">model_type</code> parameter indicates that the
                    type of problem is object detection. For a detailed description of the other
                    parameters, see <a href="clarify-processing-job-configure-analysis.html">Configure the Analysis</a>.</p>
                <p>The following code example launches a SageMaker Clarify processing job to generate heat
                    maps for your images. Positive heat map values show that the feature increased
                    the confidence score of detecting the object. Negative values indicate that the
                    feature decreased the confidence score.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">clarify_processor.run_explainability(
    data_config=cv_data_config,
    model_config=od_model_config,
    model_scores=od_prediction_config,
    explainability_config=od_shap_config,
)</code></pre>
                <p>For a sample notebook that uses SageMaker Clarify to detect objects in an image and
                    explain its predictions, see <a href="https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-clarify/computer_vision/object_detection/object_detection_clarify.ipynb" rel="noopener noreferrer" target="_blank"><span>Explaining object detection models with Amazon SageMaker Clarify</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            </awsui-expandable-section></div>
        <h2 id="clarify-processing-job-run-spark">How to run parallel SageMaker Clarify processing
                jobs</h2>
        <p>When working with large datasets, you can use <a href="https://spark.apache.org/" rel="noopener noreferrer" target="_blank"><span>Apache Spark</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> to increase the speed of your SageMaker Clarify processing jobs. Spark is
            a unified analytics engine for large-scale data processing. When you request more than
            one instance per SageMaker Clarify processor, SageMaker Clarify uses the distributed computing capabilities from
            Spark.</p>
        <p>The following configuration example shows how to use
                <code class="code">SageMakerClarifyProcessor</code> to create a SageMaker Clarify processor with
                <code class="code">5</code> compute instances. To run any jobs associated with the
                <code class="code">SageMakerClarifyProcessor</code>, SageMaker Clarify using Spark distributed
            processing.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><code class="">from sagemaker import clarify

spark_clarify_processor = clarify.SageMakerClarifyProcessor(
    role=role,
    instance_count=5,
    instance_type='ml.c5.xlarge',
)</code></pre>
        <p>If you set the <code class="code">save_local_shap_values</code> parameter of <a href="https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.clarify.SHAPConfig" rel="noopener noreferrer" target="_blank"><span>SHAPConfig</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> to <code class="code">True</code>, the SageMaker Clarify processing job saves the local
            SHAP value as multiple part files in the job output location. </p>
        <p>To associate the local SHAP values to the input dataset instances, use the
                <code class="code">joinsource</code> parameter of <code class="code">DataConfig</code>. If you add more
            compute instances, we recommend that you also increase the <code class="code">instance_count</code>
            of <a href="https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.clarify.ModelConfig" rel="noopener noreferrer" target="_blank"><span>ModelConfig</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> for the ephemeral endpoint. This prevents Spark workers'
            concurrent inference requests from overwhelming the endpoint. Specifically, we recommend
            that you use a one-to-one ratio of endpoint-to-processing instances.</p>
    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="https://docs.aws.amazon.com/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./clarify-processing-job-data-format-image.html">Image data</div><div id="next" class="next-link" accesskey="n" href="./clarify-processing-job-analysis-results.html">Get Analysis Results</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-processing-job-run.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=SageMaker&amp;topic_url=https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-processing-job-run.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>